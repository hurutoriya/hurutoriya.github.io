<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>hurutoriya</title><link>https://shunyaueta.com/</link><description>Recent content on hurutoriya</description><generator>Hugo -- gohugo.io</generator><language>ja</language><lastBuildDate>Thu, 27 Apr 2023 09:47:18 +0900</lastBuildDate><atom:link href="https://shunyaueta.com/index.xml" rel="self" type="application/rss+xml"/><item><title>Obsidian 上で画像の大きさを調整する方法</title><link>https://shunyaueta.com/posts/2023-04-27-0947/</link><pubDate>Thu, 27 Apr 2023 09:47:18 +0900</pubDate><guid>https://shunyaueta.com/posts/2023-04-27-0947/</guid><description>Obsidian で画像を貼り付けた際に、元の画像が大きいせいで極大ドデカ画像になって小さくしたいときが多々あります。
サッと大きさの調整ができないかなと探したら、公式で提供されていた1のでメモっておきます。
が&amp;hellip;この記事を書いた後に Minerva さんで詳細な記事2が書かれていることが発覚しましたが、まぁ自分への備忘録もあるのでこのまま公開します。
Obsidian はここらへんのちょっとした操作が、Markdown 内で完結するように公式で提供されているのは素晴らしいですね。
自分は ![[hoge]] でノートを埋め込んで表示できるようにしているところは本当に頭がいいなと感動して使っています。 これぞ Obsidian が構造化して、モジュラー構造でノートを書ける由縁ですね。
Take the link, add ‘|’ sign towards the end and write a number. Eg. : ![[image.jpg]] to ![[image.jpg|300]] &amp;gt; https://forum.obsidian.md/t/resize-image/6517/8
&amp;#160;&amp;#x21a9;&amp;#xfe0e; 画像サイズを指定したい - Minerva&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description></item><item><title>(恐らくみんなが求めている)懇親会に全振りした、非公開イベントを計画している</title><link>https://shunyaueta.com/posts/2023-04-26-1518/</link><pubDate>Wed, 26 Apr 2023 15:18:10 +0900</pubDate><guid>https://shunyaueta.com/posts/2023-04-26-1518/</guid><description>今まで自分は以下のようないろんな勉強会を学生の頃からずっと開催してきました。
大学生: tsukuba.rb つくばの Ruby コミュニティ 大学院生: prml-seminar PRML 本の輪講と論文紹介 社会人: Machine Learning Casual Talks - connpass 機械学習の実運用の知見を共有する会の運営に混ぜてもらって第 5 回から参加して第 13 回まで開催 ですが、オンライン雑談により、意識的に新たな繋がりを作る機会を取り戻したお話という話でも書きましたが、勉強会が COVID-19 の影響でオンラインに移行したことで懇親会に相当する文化がなくなった気がします。
オンライン雑談でも頻繁に話がでるのが、
「今までみたいに勉強会の懇親会とかで他社の内情とか(話せる範囲で)聞けたら面白んですけど、今はオフラインのイベントはなかなか開催されてないから、そもそもそういう機会もないどうしたもんでしょうね」
です。
こういう話を通じて、発表はせずに参加者同士のネットワーク作成と懇親会での談話に全ふりしたイベントがあっても面白いんじゃないかと思って、現在 5 月中旬に開催企画中です。
今回は非公開イベントとして開催しますが、理由として、試験的な企みなのと参加者のクオリティをある程度担保するためです。
異論はあると思いますが、最近考えていることとして、正直最近のイベント運営のモチベーションとして発表の場は、学会や、かなりデカイ開発者向け会議(例えば自分の分野で思い浮かぶのは、 USENIX, kubecon, PyCon、Berlin Buzzwords とか(適当すぎる列挙)) にまかせておけばエエやんけ派になりました。
運営者として、イベントを上記のレベルのブランド? クオリティまで持っていくの楽しそうだし、尊敬しますが、その土俵で戦うよりも、コミュニティ醸造に振ったほうが楽しいのではと思い企画しました。
今回は、主にオンライン雑談を通じて知り合った検索&amp;amp;推薦システムに関わっている人や、弊社の検索チーム、推薦チームの同僚たちを招待して、オフラインでワイワイする予定です。
というわけで最近、勉強会運営?というかイベント運営で考えていることをまとめてみました。
また開催後に感想記事を書こうかなと思います。
ではでは</description></item><item><title>ワイヤーロックを使えば、出先でもベビーカーを安心して手放せるので、みんなに知ってほしい</title><link>https://shunyaueta.com/posts/2023-04-25-1153/</link><pubDate>Tue, 25 Apr 2023 11:53:15 +0900</pubDate><guid>https://shunyaueta.com/posts/2023-04-25-1153/</guid><description>表題のとおりです。
子供を連れてベビーカーで買い物に行った際に、自分ひとりだけの場合、スーパーのカートとベビーカーを両方押すのは相当めんどくさいというかきつい。
よくあるパターンとして、カゴだけ持ってベビーカーに載せたり、ベビーカーを押しつつ持ったりしている人がいるけど、それもまぁしんどい。
で、活躍するのがワイヤーロック。
サンワサプライ セキュリティワイヤー一体型ダイヤル錠
(百均とかで購入できますが、イメージしやすいように Amazon のリンクを張っておきます。)
自分の場合、駐輪場にベビーカーを置いて、ワイヤーロックをかけて、そこにベビーカーを置かせてもらう。(自分はできるだけ迷惑がかからない場所を選んでベビーカーを置いてます) これで、ベビーカーを手放せるので、快適に子連れで買い物ができる。 最高。
時折、ワイヤーロックなしとかでもベビーカーを置いている人がいて、日本の治安的に盗まれることは無いだろうけど、施錠しておいたほうが気兼ねなく置いておけるので、自分はワイヤーロックをかけている。</description></item><item><title>子供が道中で無限に遊びたがるのに対応するために、持ち運べる椅子を買ったら大勝利</title><link>https://shunyaueta.com/posts/2023-04-25-1044/</link><pubDate>Tue, 25 Apr 2023 10:44:08 +0900</pubDate><guid>https://shunyaueta.com/posts/2023-04-25-1044/</guid><description>子供が道中に無限に遊びたがる1んですが、毎回座る場所がなくてきついので、どこでも座れる軽い椅子があったら良いなと思っていた。
で気軽に持ち運べる椅子無いかなと探してていいの見つけたのでかってみたんですが、これがめっちゃ良かった。 最初は一脚で良いかなと思っていたけど、良すぎたので妻の分も合わせて追加で更に一脚買った。
DEERFAMY アウトドア チェア コンパクト
この商品の良いところは、よくあるコンパクトな折りたたみ椅子と違って、高さがあるので座ってても疲れない。なので 30-40 分くらい余裕で道草を食べれるようになり、子供が満足するまで遊べるように付き合えるようになった。
文明の利器、最高!
道端に落ちている石とか、草とか、看板見たりとかありとあらゆる方法で遊び尽くしている。&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description></item><item><title>LLM(大規模言語モデル) 妄想雑記</title><link>https://shunyaueta.com/posts/2023-04-17-2323/</link><pubDate>Mon, 17 Apr 2023 23:23:57 +0900</pubDate><guid>https://shunyaueta.com/posts/2023-04-17-2323/</guid><description>ここ最近友人といろんな妄想を議論して楽しかったのでここで吐き出しておく
OS に組み込まれ、端末内部に LLM が内蔵されたら世界が変わる。これを実現した OS はゲームチェンジャーになれそう。Windows, Android, iOS のどれかが候補だが、完成度は iOS に期待したい。 現状の GPT の難点は経済的な持続性がないこと。1 推論 10 円とかの記事も出ていたが、Microsoft の 365 への GPT の機能の統合は損して得取れ戦略で、競合他社から顧客基盤を奪うためにやっていそう?例えば、一年後に GPT による機能は追加で 1000 円追加で支払ってくださいと言われても、便利すぎて全員払うのでは? それをサーバーを介さずに端末内部で全て完結して処理がもし行うことができるようになれば、それこそ爆発的に普及する兆し Apple の apple/ml-stable-diffusion: Stable Diffusion with Core ML on Apple Silicon のように、例えば Apple の開発者が誰でも GPT のモデルをライブラリで利用できれば、それだけでプラットフォームとしての魅力は格段に増す。今は 3rd party で色々出てきているが、それを公式に OS 内部に組み込まれている状態で提供されたら凄すぎん? Siri が GPT に置き換わる？ Apple が何もやっていないはずはない GPT Plugin のように例えば、端末内部のアプリに Siri(GPT)がアプリのワークフローを実行できたら驚異 LLM が外の世界とインタラクションを行いたい時にどうやって認証認可をすべきだろう? 例えばアプリは、各種スマホの機能などを使えるけど、LLM でも例えばライトを付けてというと点灯できたり、直接そういう権限をもっていても色々と遊べそう</description></item><item><title>Twitter の検索システムを学ぶ - 概要編</title><link>https://shunyaueta.com/posts/2023-04-17-2252/</link><pubDate>Mon, 17 Apr 2023 22:52:30 +0900</pubDate><guid>https://shunyaueta.com/posts/2023-04-17-2252/</guid><description>Twitter&amp;rsquo;s Recommendation Algorithm Elon Mask が以前から計画していた、Twitter の検索&amp;amp;推薦関連のシステムが GitHub で公開された。 良い機会なので、いままでの Twitter 検索の記事をまとめつつ、コードも読んでみます。
この記事はシリーズになっており、以下の構成で進めていく。
概要編 論文解説 コードを読んでみた Twitter&amp;rsquo;s New Search Architecture 2010-10-06 公開 この時期に新しいアーキテクチャに移行 MySQL による検索から Lucene による検索へ移行 要件 1000 tweets/sec 12000 queries/sec 1 billion queries / day 新しいアーキテクチャで、一桁大きい規模のトラフィックに耐えられることを期待している Tweet はリアルタイムなので、もちろん検索システムもリアルタイム性が非常に重要 indexing latency も非常に重要 tweet された 10 秒後には検索可能になってほしい indexer 自体のレイテンシは 1 秒以下である必要がある(indexer 自体はデータパイプランの一部でしかないため) Lucene を改造 Lucene は素晴らしいが、リアルタイム検索を行うにはまだ足りない点がある メモリ内のデータ構造を書き直す。 ポスティングリストを特に書き直す。 ガーベージコレクションの改善 lock free のデータ構造とアルゴリズム 逆順に走査可能なポスティングリスト 効率的なアーリークエリリターン 移行後 システム全体の 5%しか利用していないが、50 倍近いツイートをインデックスできている。 移行したことでユーザーに利点は果たしてあるのか? 検索対象が非常に増えた(bigger index と書かれているが恐らく検索できる範囲が増えたのでは?</description></item><item><title>RSSリーダーってのを使ってまして、え、知らない? そういう便利なツールがあるんですよ</title><link>https://shunyaueta.com/posts/2023-04-07-0207/</link><pubDate>Fri, 07 Apr 2023 02:07:54 +0900</pubDate><guid>https://shunyaueta.com/posts/2023-04-07-0207/</guid><description>2018 年の中頃だろうか、今の会社に入って同じチームにいる学生インターンとして働いている同僚と昼飯を食べにいった時に話題になったのが情報収集どうやっていますかネタで、
学生さん「どういう方法で情報あつめているんですか? 普段からいろんなネタ知っているじゃないですか?」
自分「良い記事を見かけたら、RSS リーダーに登録して更新を見逃さないようにしてますね~」
学生さん「RSS ってなんですか?」
自分「RSS リーダーってのを使ってまして、え&amp;hellip;&amp;hellip;.知らない? そういう便利なツールがあるんですよ」
キュレーション、SNS の台頭の影響で、RSS の存在さえも知らない世代が存在している。なるほど、もうそんな時代になってしまったのか?と当時はかなり衝撃的な回答でした。
Blog なのに RSS 配信しないサービスなんなの?と今でも息巻いている自分ですが、先日 Twitter で RSS リーダーに関するアンケート1をとってみたところ、
自分の Blog の投稿を Twitter に連携させているんですが、実際には RSS 登録しているので無くても大丈夫 → 0 票/15 票 RSS 登録していないので Twitter 経由 →15 票/15 票 と衝撃な結果でした。
自分のフォロワーなので、ある程度エンジニアの方もいる(その仮定自体、おかしいですが)のを踏まえた上で、自分の Blog って Twitter 経由じゃないと読まれないのか、オープンな規格である RSS も公開しているのにな~と衝撃を受けました。
って話を今日、同僚の alpicola さん、frsw さんとワイワイしてました。 もちろん二人は RSS を知っているので、当時のインターネッツ談義をすることができてよかった
https://twitter.com/hurutoriya/status/1641229912836292608&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description></item><item><title>現在 Lucene の KNN ベクトルの最大次元数は1024次元 だが、それを2048次元に変更できないかという議論</title><link>https://shunyaueta.com/posts/2023-03-26-2208/</link><pubDate>Sun, 26 Mar 2023 22:08:18 +0900</pubDate><guid>https://shunyaueta.com/posts/2023-03-26-2208/</guid><description>初心者だけど Apache Lucene に貢献したい場合におすすめのチケットラベルのチケットを眺めていたときに面白いチケットがあった。
取り上げるのは、
Increase the number of dims for KNN vectors to 2048 [LUCENE-10471] · Issue #11507 · apache/lucene
というチケットだが、表題の通りで、現在 KNN ベクトルとして扱える最大次元数は 1024 次元だが、それを 2048 次元に変更できないかの議論がされている。
該当 PR はこちら
https://github.com/apache/lucene/pull/874/files
- public static final int MAX_DIMENSIONS = 1024; + public static final int MAX_DIMENSIONS = 2048; と一行の変更だが、大きな議論が巻き起こっている。
例えば、
MobileNet v2 は 1280 次元 OpenAPI/ GPT-3 のベクトルは 2048 次元 なので、2048 次元にすればそれらのベクトルを扱うことができるのではという課題提起。 概ねみんな反対ではないが懸念点として
ある程度は既存の値から上げてもいいが、制限は設けるべきで次元削減などで特定の次元数以下にユーザーが処理しておくべき ref Java API が Vector API を提供するようになれば、今の実装はすべて変わるので、難しいね ref CNN ベースのモデルを使っている人は、Lucene の近傍探索が使えないという状況は改善すべき。(もちろんどこまで許容すべきかは議論すべきですが) ref この決断は一方通行(制限を再び少なくしようという流れは永久に来ない)なので、急がずに慎重にベンチマークや正当性の議論などが必要 ref プラグラマブルに自由に設定することはできますか？ それは可能ですが、フォークして自分の Lucene をメンテナンスすることになるので推奨できない ref また、この決定にはデータと評価結果が無いと決定できません。争点は、1048 次元にあわせるために、ユーザー側がなぜ次元削減ができないのかという点もあると思います。 ref 歴史的にユーザーは Luene の制限と常に戦ってきているものなので、今回の制限について文句を言われても正直気にしていません。最も心配なのは、KNN Vector の機能は初期段階であり、制限をゆるくすると柔軟性が低下してしまうことです ref 2023-01-03: この issue が作成されてから、多くの変化が起きました。現在では OpenAI の ChatGPT が世の中を席巻しています。最低でも OpenAI が提供するベクトルの次元数である、1536 次元に変更することはできませんか?</description></item><item><title>同僚との雑談で情熱プログラマーはやはり良いぞと盛り上がる</title><link>https://shunyaueta.com/posts/2023-03-24-2318/</link><pubDate>Fri, 24 Mar 2023 23:18:51 +0900</pubDate><guid>https://shunyaueta.com/posts/2023-03-24-2318/</guid><description>Slack の huddle で同僚の @yaginuuun さん、 @frsw さんが雑談をしており、自分が乱入したときに
「強くなりたいっすよねぇ~」という話をしており(途中から乱入したので適当いっているかも)、
そこで、自分が強い弱いだと、情熱プログラマーの
一番の下手くそでいよう - Be the Worst -
って弱いポジションをあえて狙いにいって、強くなろうぜって考えめっちゃ良いですよねという話で @frsw さんと盛り上がり、この本は僕らめっちゃ好きでという布教活動をしていると、 @yaginuuun さんが書籍の購入を終えて読み始めており、その行動の速度感に感動。
ソフトウェアエンジニアの寓話系の書籍は僕は好きでちょこちょこ読むんですが、情熱プログラマーは一番好きだと言える書籍
また、最終出社日 - kmuto’s blogで、情熱プログラマーの編集者である kmuto さんの記事で知ったんですが、情熱プログラマーは初期は「My Job Went To India オフショア時代のソフトウェア開発者サバイバルガイド」というタイトルで、その後、情熱プログラマーに変わったというネタを共有して盛り上がった。
好きなことを雑に語れる場ってのは楽しいですねぇ</description></item><item><title>Web 検索とデータマイニングのトップカンファレンス WSDM2023 で気になった研究</title><link>https://shunyaueta.com/posts/2023-03-18-2357/</link><pubDate>Sat, 18 Mar 2023 23:57:07 +0900</pubDate><guid>https://shunyaueta.com/posts/2023-03-18-2357/</guid><description>去年1に引き続き WSDM2023 の論文が公開されたので、ざっと眺めて気になったものを書き留めておく。
Home | WSDM'23 - The 16th ACM International WSDM Conference
Keynote Maarten de Rijke University of Amsterdam, Date: Wednesday, March 1, 2023 Title: Beyond-Accuracy Goals, Again
Tutorials Trustworthy Algorithmic Ranking Systems https://github.com/socialcomplab/Trustworthy-ARS-Tutorial-WSDM22 Workshops WSDM 2023 Crowd Science Workshop クラウドソーシングをテーマにしたワークショップ Accepted Papers Active Ensemble Learning for Knowledge Graph Error Detection Junnan Dong (The Hong Kong Polytechnic University); Qinggang Zhang (The Hong Kong Polytechnic University); Xiao Huang (The Hong Kong Polytechnic University)*; Qiaoyu Tan (Texas A&amp;amp;M University); Daochen Zha (Rice University); ZHAO ZIHAO (Hong Kong Polytechnic University) Revisiting Code Search in a Two-Stage Paradigm Fan Hu (Renmin University of China)*; Yanlin Wang (Sun Yat-sen University); Lun Du (Microsoft Research); Xirong Li (Renmin University of China); Hongyu Zhang (University of Newcastle); Shi Han (Microsoft Research); Dongmei Zhang (Microsoft Research Asia) Visual Matching Is Enough for Scene Text Retrieval Lilong Wen (zhejiang university)*; Yingrong Wang (Zhejiang University); Dongxiang Zhang (Zhejiang University); Gang Chen (Zhejiang University) Beyond Hard Negatives in Product Search: Semantic Matching using One-Class Classification (SMOCC) Arindam Bhattacharya (Amazon)*; Ankit Gandhi (Amazon); Vijay Huddar (Amazon); Ankith M S (Amazon); Aayush Moroney (Amazon); Atul Saroop (Amazon); Rahul Bhagat () Industry Day Simulating Humans at Scale to Evaluate Voice Interfaces for TVs: the Round-Trip System at Comcast Learning to Infer Product Attribute Values From Descriptive Texts and Images, Pablo Montalvo and Aghiles Salah (Rakuten Group, Inc.</description></item><item><title>究極手抜きのフワフワだし巻きたまご</title><link>https://shunyaueta.com/posts/2023-03-16-1203/</link><pubDate>Thu, 16 Mar 2023 12:03:37 +0900</pubDate><guid>https://shunyaueta.com/posts/2023-03-16-1203/</guid><description>材料 卵 4 個(L サイズ) 水 200ml だしの素大さじ 1 調理工程 材料をすべて混ぜる。だしの量や水の多さなどは適宜調整してください 油を引いて熱した卵焼き器(必ずテフロン加工、鉄製だと絶対に焦げ付きます)に、1 の材料を投入する 投入した卵が半熟程度に固まるまで、スクランブルエッグのようにひたすら混ぜる(混ぜることでフワフワになります) 全体が半熟程度に固まってきたら混ぜるのをやめる、卷くことが可能になるまで加熱する。(熱を入れれば入れるほど出汁成分が飛ぶので、フワフワが好きな人は火を通しすぎないのがコツです) 全体が固まったら、三つ折りにしてお皿に設置。(卵焼きのように何重にもクルクル巻かなくて大丈夫) もし、半熟より完全に火が通った卵焼きが好きな人は、そのままお皿を 600W で 2 分ほどチンすると完全に火が通ります。 完成図 昨日、気に入っている料理の話で盛り上がり、自分のお気に入りのこのレシピを共有したいので Obsidian にまとめているレシピを Blog で公開した。</description></item><item><title>オンライン雑談により、新たな繋がりを作る機会を意識的に取り戻したお話</title><link>https://shunyaueta.com/posts/2023-03-14-1320/</link><pubDate>Tue, 14 Mar 2023 13:20:29 +0900</pubDate><guid>https://shunyaueta.com/posts/2023-03-14-1320/</guid><description>2021 年の頭から、オンライン雑談1を積極的に行っている。
背景 子供が産まれ、フルリモートでなければ育児に打ち込むことができなかったので、フルリモート体制には本当に感謝している。
だが、副作用として、フルリモート体制になってから、社外・社内ともに関係性が希薄になりがちだったのでなんとかしたいなと思っていた。 以前は勉強会や学会などで新しい人と知り合うことができていたが、フルリモートになってからは無意識に獲得できていた新しい繋がりが発生する機会が消失した。
そのため、COVID-19 の影響でオフラインでの勉強会開催は出来ない時期だったが、フルリモートでも新しい交流の場を作れないかと試行錯誤していた。 Human-in-the-Loop を題材にした機械学習の勉強会を開催したでも触れたが、オンラインでのバーチャル懇親会は、リアルの懇親会の場を代替できるものではなかった。(それはそう) 自分は 1:1 の話を求めているのがこの体験で言語化出来た。(多くても 4 人くらいまでならオンラインでも許容範囲内だが、実現は難しい)
で、意識的に新しい繋がりに遭遇するために始めたのがオンライン雑談だ。
オンライン雑談爆誕 オンライン雑談なら、子供の寝かしつけが終わった後にベッドを抜け出して喋れる。なによりも家でなにかあっても対応できるのは非常に大きな利点だ。 基本的に夜に外に出かけるということは、妻に負担を押し付けると同義なので可能な限りは避けたい。
募集方法は基本的に Twitter で行っている。初期は、いいねしてくれていた、前から気になってはいたが直接話したことのない相互フォローの方に DM で調整していた。 最近は募集ツイートしても反応がそもそも皆無なので、自分から話してみたい方に Twitter の DM や連絡先のメールアドレスに突然話を持ちかけて、オンライン雑談をしている。
オンライン雑談の予定調整には Calendly を利用していて、ログを見てみると、この 2 年 3 ヶ月で 60 回分のログが残っていた。
単純に計算すると毎月 2-3 回程度オンライン雑談をやっていることになる。 最近は募集しても相手が釣れなくなっているので、毎月 1-2 回程度になっているが、それでも楽しい。 このオンライン雑談のおかげで両手では数え切れないくらいの人数と新しく知り合えたし、旧友とも話すことができたので、本当によかった。
このリモートワークが認知され始めた時代だからこそ、ビデオチャットのお誘いも気軽にできるなと思っている。 個人的に COVID-19 以前だと、自分は今の気軽さでビデオチャットしませんかと誘いにくかった気がする。 どちらかというとビデオチャットするなら飯食いに行きますか?になりがち問題。(でも気軽に調整できる場所にも住んでいない場合は難しいねと終わっちゃうんだよな)
オンライン雑談は、そもそも SNS の相互フォローやブログの読者などで相手のことが気になっているけど、今までリアルで話す機会がなかったり、結局予定調整が難しい場合の落とし所としてはかなり良いなと思っていて、これからも続けていきたい。
意識の変化 この「無意識ではなく、意識的に関係性を作りに自主的に動く」考えは、オンライン雑談を通じて言語化できた考えなんだけど、既存の友人とも意識的に交流をすることにつながって、結果的にすごく良かった。
隔週でオフィスに出社することがあるんですが、そのときに意識的に同僚との雑談の場を必ず設けたり、妻に育児を任せられる日を選んで出社しているので、夜ご飯を友人と食事したりと出社の機会を最大限に活用していて楽しい。
ここでオンライン雑談の意味を補足しておくと、ビデオチャットでの雑談を意味します。技術的トピックから、趣味、近況報告など幅広い話題で雑談ワイワイします。&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description></item><item><title>初心者だけど Apache Lucene に貢献したい場合におすすめのチケットラベル</title><link>https://shunyaueta.com/posts/2023-03-11-1727/</link><pubDate>Sat, 11 Mar 2023 17:27:09 +0900</pubDate><guid>https://shunyaueta.com/posts/2023-03-11-1727/</guid><description>2023 年の目標で、Apache Lucene へのコントリビューションを掲げましたが、既存の GitHub チケットを探しても初心者向けのチケットタグ good first issue にはチケットが紐付けられていなかったので、メーリングリストに質問したら、Lucene PMC の Michael Sokolov さんがこのタグが初心者にはおすすめだよと返信をいただけたので、ここに残しておきます。
メーリングリストに以下の質問をしたら、
Hello Lucene users.
Last time I checked good first issue in GitHub issues to start a contribution of Lucene. https://github.com/apache/lucene/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22
But currently no issues with this label. I don&amp;rsquo;t know the current operation of this label, but in the future, Is this label will utilized? Because good first issues label issues are a very nice starting point for beginner contributors.</description></item><item><title>Slack bot の Eeny がスクラムイベントのファシリテーターを選出するのにめっちゃ便利</title><link>https://shunyaueta.com/posts/2023-03-02-1132/</link><pubDate>Thu, 02 Mar 2023 11:32:47 +0900</pubDate><guid>https://shunyaueta.com/posts/2023-03-02-1132/</guid><description>経緯 スクラムイベントのファシリテーターは特定の人がやるのではなく、誰でもできるようにしたい 特定メンバーを選出するスクリプト自体はすぐかけるが、それを Slack で連携するに zapier を使って運用していたが、色々とめんどくさい(原因不明のエラーが出たり、zapier のワークフローがやりたいことは単純なのに、複雑になりがち) もっとお手軽にファシリテーターを選出できないかなと探していたら、他のチームが Eeny という Slackbot で実現していてその Bot がめっちゃ便利 Eeny | A Slack bot for picking people at random
運用方法 今やっている運用法としては、
Slack アカウントを特定のリストに追加・削除 Slack reminder でそのリストを定期的に呼び出せば、そのリストのスラックのアカウントの中から自動的に選出される ラウンドロビン方式ではないので、２回連続で選出されることもあるが、その時はpick again というボタンが表示されておりクリックすれば Eeney によって再び選出されるので、その取り回しも簡単。 @Eeny stats HOGE でリストHOGEで過去に選出されたアカウントの統計量も見れるから、特定のメンバーが偏ってファシリテーターしている状態も簡単に確認できる。
設計が秀逸だなと思ったのは、Eeny 自体は定期実行機能を持っていなくて、メンションされたときにリアクティブに結果を返すだけにしているのが、運用に柔軟性があって素晴らしいなと思った点です。
このおかげで、自律的なファシリテーター運営が簡単にできるようになって最高</description></item><item><title>2023年の目標</title><link>https://shunyaueta.com/posts/2023-02-17-0126/</link><pubDate>Fri, 17 Feb 2023 01:26:13 +0900</pubDate><guid>https://shunyaueta.com/posts/2023-02-17-0126/</guid><description>書籍の翻訳プロジェクトを完遂させて、2023 年中には出版されるように努める
見返すと 2021-05-10 からこの企画が始まっている。現時点で一番の山場は終わっており、今は粛々と第 3 者レビュアーからの結果を取り込んで、体裁を整えている。 Apache Lucene のコントリビューターを目指して日々活動する
OSS 活動自体に興味はあったが、ドキュメント集成くらいしか出来ていなかったので、コントリビューターを目指しつつ Lucene がどう動いているのかの理解を深めていく PR を作成したり、マージされたなどの定量指標は予想しづらいので、Lucene の深堀り記事を何本かけたかで振り返ってみたい。今年を振り返った後に Lucene の理解が深まっていれば大勝利 今年も SNS に振り回されないように時間を浪費しないために使わない。連絡ツール、告知ツールとしてのみ今年も利用
SNS のタイムラインを眺める時間をやめた浮いた時間で以下のことを行なう。 最低でも月に 1 冊本を読んで、Obsidian にまとめる 英語学習を習慣化
普段の仕事はほぼ英語なのだが、隔月に一度あるチームビルディングでランチを食べている際に以下のような事が 3-4 回ほどありモチベーションが湧いている。
恥ずかしいほど多人数でガヤガヤしている場合の英語が聞き取れない 日常会話での単語がわからない また、毎週開催されるオンラインのチームビルディングランチがあるのだが、そこでも込み入った話題を話せない体験がとても歯がゆかいのも良いモチベーションになっている
同僚が非常に意欲的に英語学習を行っていてそれも良いモチベーションに。
2021 年 強さへの旅 - 運河 の英語学習の習慣化記事が非常に刺さったのでこれを踏襲したい
定量的行動
Anki で単語強化: 1 日 15m
English Vocabulary Test: How Many Words Do You Know? で 3748 words ELSA Speak : 1 日 15m
Obsidian の日報テンプレに今日学んだ英語欄を追加して日々追記
今思うとこれを Anki に連携すると良さそう 健康面</description></item><item><title>ニュースレター近況</title><link>https://shunyaueta.com/posts/2023-02-17-0005/</link><pubDate>Fri, 17 Feb 2023 00:05:59 +0900</pubDate><guid>https://shunyaueta.com/posts/2023-02-17-0005/</guid><description>記事ストックの改善 以前は、Pocket→Obisdian→ 執筆という流れだったが、 ストックされている昔の記事を Pocket からサルベージする際に、UI, UX が非常にストレスフルかつ時間を吸い取られるのでやめた。
Pocket は以下の点で辛かった。
リスト形式は無く、グリッドしか用意されていない 20 件?ごとに疑似ページネーションが走ってめんどくさい page が 10 件以上超えると Pocket がフリーズする 最初は、Pocket 追加時にタグnl (NewsLetter の nl)を付与してみることにしたが、Pocket でニュースレターに関係無い記事を保存する際に毎回タグを付与するかいなかという考えがめんどくさくなったので(1 日で諦めた)、Obsidian の特定ファイルに毎回手動でコピペするようにした。
記事一件あたりの追加時間が 5 秒ほど増えるが、回り回って記事を Obisidian にまとめる時間が一番めんどくさい作業なので、これにしたおかげでストレス無く完全に Obsidian で完結してニュースレター作業に取り組めるようになった。
購読者 100 人突破 また、 17 回目のニュースレターを一般公開して、Twitter でリンクを告知するとメール購読者が 100 人を突破した。
最新号をメール購読者のみの先行配信するのは、賛否両論あると思うが、購読者が増える要素になっているのではなかろうか?
本来は Blog で公開していたときと同じく、すべての記事を全公開で良いのだが、Twitter がダメになった時自体に備えてメール購読者の数も増えてほしいので購読者数が増えるようなインセンティブ設計にしてみた。
これから 忙しいとニュースレター書くのをおろそかになってしまったりするが、書き始めると意外と楽しいし気分転換にもなっていることが多い。
そのため一回の配信の量にはあまりこだわらず 2 週間に 1 号程度の配信頻度を保っていきたい。 なぜなら最低でも 2 週間に 1 時間程度も記事を読む時間が確保できないのは、それはそれで心の余暇が完全に喪失しており問題だからだ。
時間計測アプリを toggl から session へと乗り換えてみたのも個人的にはすごく効果的で、集中して短時間で書き切れるようになったと思う。</description></item><item><title>時間計測アプリを toggl から Session へと乗り換えてみた</title><link>https://shunyaueta.com/posts/2023-02-12-0133/</link><pubDate>Sun, 12 Feb 2023 01:33:29 +0900</pubDate><guid>https://shunyaueta.com/posts/2023-02-12-0133/</guid><description>自分はかなり前から、タスクの時間計測のために toggl の無料枠を使わせてもらっていたが、作業計測をそもそも忘れたりしてしまい、振り返っても計測自体ができていないことが多かった。 あとはどこまで詳しく取るべきかの切り分けが出来ず、結局最近は個人プロジェクトの書籍翻訳の時間計測のためにしか利用できていなかった。
最近集中力が散漫になっていることを課題に感じていたので、良い機会なのでこの機会にツールを乗り換えてみて、日々の生産性を向上できないか試してみる。
色々と比較したが、 Session - Pomodoro focus timer with analytics が一番自分の求めているものに近かった。
OSS が可能なら良かったが、単純なポモドーロタイマーならあるが、自分が求めている以下のような機能が無い。
非 Web アプリ 統計機能 web サイトとアプリのブロック 音楽を流す ポモドーロごとへの感想 なので、 Best Pomodoro Time Alternatives - 2023 | Product Hunt　で良さげなポモドーロタイマーアプリを探してみた。
Flow – Pomodoro timer for Mac, iPhone, and iPadもミニマルなデザインかつ、月 1$ で、買い切り 30$と値段は非常に魅力的なのだが、session と比べると、細かい機能差があり、手に馴染みそうだったのが、session だと思ったので、こちらを使い始めてみる。
特に session の統計画面は見返していて楽しそうである。
Apple のプラットフォームでしか使えないのは一つの懸念点だが、自分はなんだかんだ当面の間 Apple 製品を使うことになると思うので、その時が来たらまた別のツールを考えれば良い。
今までは可能なら購読形式のツールは使いたくなかったが、このツールで自分の集中力を向上できるなら年課金したとしても安い買い物かなと思って開き直ってきた。 お金で、生産性を買う姿勢&amp;hellip;
とりあえず、一ヶ月くらい使ってみます。
以下のページで機能更新やカスタム方法などを公開してくれているが、こういうアップデート系統の記事って見るの楽しいですよね。過去の軌跡を追いかけることができますし。
Session - Changelog
一つの欠点は、非常に気に入っていた toggl と Obsidian の連携プラグインである
mcndt/obsidian-toggl-integration: A Toggl integration plugin for the popular knowledge base application Obsidian.</description></item><item><title>redis-cli の結果を標準出力として受け取って jq でわかりやすく表示したい</title><link>https://shunyaueta.com/posts/2023-02-10-1740/</link><pubDate>Fri, 10 Feb 2023 17:40:23 +0900</pubDate><guid>https://shunyaueta.com/posts/2023-02-10-1740/</guid><description>動機 Redis を扱っているのだが、その際にデバッグ用途で、内部で保存されているデータを redis-cli で対象の redis に対してコマンドを実行して確認する。
だがこのままだとコマンドの結果が JSON として返されるが見にくいので見やすく整形したいのが動機。
詳細 自分が知っている方法だと
redis-cli で、対象の redis に対してコマンドを実行できるインタラクティブモードに入る。 そして以下のコマンドを実行すると、VALUE の結果が確認できる。
get KEY この結果は JSON として出力されるが、ターミナル上では整形されず非常に見づらかった。
解決方法 よく見ると公式ドキュメントに書かれていた1。
以下のように redis-cli と同じ行で、redis に対して実行したいコマンドを追記して実行すれば、標準出力として表示される。
redis-cli get KEY この結果が JSON として出力され、可読性を向上させるために jq2 で整形したい場合は、以下のようなコマンドを実行すればよい
redis-cli get KEY | jq . To run a Redis command and return a standard output at the terminal, include the command to execute as separate arguments of redis-cli. https://redis.io/docs/ui/cli/
&amp;#160;&amp;#x21a9;&amp;#xfe0e; jq - jq is a lightweight and flexible command-line JSON processor.</description></item><item><title>2022年分の確定申告</title><link>https://shunyaueta.com/posts/2023-02-06-2305/</link><pubDate>Mon, 06 Feb 2023 23:05:42 +0900</pubDate><guid>https://shunyaueta.com/posts/2023-02-06-2305/</guid><description>今年は、副業を行っていなかったので、寄附金控除のみ。 時間を計測していたが、今年は 30 分で確定申告できた。
2020 年は紙の寄附金の証明書を集めておいて、手作業で入力後、寄附金控除アップロードした覚えがある。寄附金の証明書管理が面倒くさかった。 2021 年は寄附金控除は xml で吐き出せるようになったので、freee で xml を読み込んで提出1 。医療費控除や青色申告もあったのでまとめると 24 時間ほどを要した。 納税先とマイナポータルが連携しており、事前に設定しておけば、数クリックですべてのデータが連携されるのは非常に快適な体験だった。
e-tax 連携のおかげで、寄附金の証明書を管理しなくて良くなったのは、良いことですね。 特にこれだけの規模の書類は全体で見ると決して小さくない数だと思うので、意味のあるペーパーレス化ですね。
e-tax は毎年どんどん快適になるので、素晴らしいサービスだなと思っています。 マイナンバーと保険証連携による、医療費控除も数年後には実現しているのかなと思うと、更に確定申告が楽になりそうですね。 開発に携わっている方に感謝です。
2021 年分の確定申告&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description></item><item><title>「私たちは子どもに何ができるのか」を読んだ</title><link>https://shunyaueta.com/posts/2023-01-18-1001/</link><pubDate>Wed, 18 Jan 2023 10:01:56 +0900</pubDate><guid>https://shunyaueta.com/posts/2023-01-18-1001/</guid><description>私たちは子どもに何ができるのか――非認知能力を育み、格差に挑むを読んだ。
3 行感想 非認知能力というのは、環境によって育まれるものであり、明示的にそのスキルを伸ばそうとして伸ばせるものではない 子供の感情の揺れ動きをサポートするために、予期しないことが発生しない平穏な環境を提供するのが親の役目。予期しないことが起こったとしても、親は決して直情的な反応をせず淡々と、共感して、愛情を持って接する 愛情を持って接する介入効果で、子供の身体的成長にも好影響を及ぼした結果とかあって人類面白すぎる 短く端的にどんなことが影響があるのか、何を親は徹底すべきなのかが明示的に書かれている。(総ページ数も 120p ほどでサクッと読めます)
特に、自分が持っていた疑問である
「で、結局非認知能力がもてはやされいるけど、どうやって伸ばすの結局何なの?」
のしっくりした答えがここに書かれいて、この点だけでもよかった。</description></item><item><title>2022年に買って愛用しているもの</title><link>https://shunyaueta.com/posts/2023-01-03-2213/</link><pubDate>Tue, 03 Jan 2023 22:13:51 +0900</pubDate><guid>https://shunyaueta.com/posts/2023-01-03-2213/</guid><description>恒例の買って愛用しているものの振り返り記事です。
過去の記事
2021 年に買って愛用しているもの #blog
恒例の振り返りです。
南部鉄器製の鉄器 手持ちのテフロン加工の調理器具が剥げてきて寿命を迎えつつあったので、以前から興味があった南部鉄器製の鉄器に挑戦してみた。最初は以下の二つをセットで買った。 岩鋳 揚鍋 16cm 岩鋳フライパン 24cm 結果的に大正解で、このおかげで料理をするのが更に楽しくなった。特に揚げ鍋、揚げ物の仕上がりが顕著に変わり家族から大好評。フライパンも最高に美味しいチャーハンが作れる。その後、鉄製の調理器具が気に入って、卵焼き器も鉄製に買い替えた。 及源 玉子焼き 角玉子焼 この卵焼き器はまだ修行を終えていないので必ず焦げ付いてしまうのが、焦げ付きがなくなってきているのを見るのもまた楽しみ。利用後のメンテナンスがめんどくさいと言われているが、自分は幸運にも面倒くさく感じない性質で良かった。自分が死ぬまで短めに見ても 40 年はあるが、死ぬまでこの器具を使えるというのはいいものですね。3-4 年スパンでフライパンを使い切っては買い換えるというのも嫌だったので丁度いい。 あたりまえのぜひたくという料理エッセイが自分は非常に好きなんですが、そこの茶碗蒸しの回がめっちゃ好きで、中華鍋とせいろで茶碗蒸しを作るんですが、自分でもやりたいな~と惹かれている。だが、中華鍋とせいろが置く場所が我が家には無いので、広い家に引っ越したら挑戦したい&amp;hellip; 料理は日常の中で試行回数を重ねられるし、美味しいものが食べれるしでいいことだらけの趣味ですね~。一軒家とかに住んだら七輪とかも導入してろばた焼きもやりたい。 スマートエンジェル イージスジュニア G 生まれたての子供を乗せるためにチャイルドシートを買っていたのだが、車での外出時にどうにも起きに召していないので、買い替えてみたところ大正解だった。(妻の提案に感謝)。このおかげで車に乗った際に子供が鬼のように泣くのをやめて、寝るようになり車で遠出・旅行ができるようになった。 スマートエンジェルは西松屋のプライベートブランドなのですが、どれも品質が高くてかつお値段がマザーテレサ並みに優しく愛用しています。 スマホの車載ホルダー 以前持っていた Anker の車載ホルダーは、子供が分解するのにハマっており、どこかに消え去ったので購入し直した。Anker の車載ホルダーを利用してわかったことは、自分にはワイヤレス充電機能は必要ないし、ホルダー形式も万力タイプで挟むのではなくフックタイプが良いということ。万力タイプで挟む形式は、密着率をあげるためのゲルが剥がれてきてしまい耐用回数が少ないことがわかった。なので、その不満点を解消するために、フック式スマホ車載ホルダー を購入した。完全に蛇足ですが、この系統の商品って Amazon だと有象無象のクローン商品があって、ガワは違うけど、OEM で全部中身同じではという商品しか見当たらないので、良い商品を探し当てるの大変ですね。 Amazon ベーシック デスクマウント シングル モニターアーム ブラック リモートワークが始まった当初は、ダンボール箱の上にディスプレイを置いて、高さを底上げしてたんですが、最近、微妙に高さが足りていないのが気になってきた。日々使うものだからもっと投資しても、良いなと思いブラックフライデーで安くなっていたので買った。首を少し傾けないと行けない状態がなくなり、デスク周りもスッキリして快適。この系統の商品も 10 年以上は余裕で耐えると思うので、もっと早めに買っておけばよかった。 OOFOS(ウーフォス) 腰痛をいかに抑えるかが長期的に快適に働くための大事な要素だと思っている。そのためスタンディング状態で気軽に移れるようにしたかったので、購入。商品の存在を知ったキッカケは同僚が買っていたことで、近くのスポーツショップで試着をしてウーフォスに決めた。リカバリーサンダルは様々なブランドが商品を出してきており、有名なメーカーだとテリックやホカオネオネなどがあるが、自分は足型・触感ともにウーフォスが一番好みだった。去年、スタンディングデスクマットを買ったが、それと併用して使っています。 Software Habitify 習慣化アプリ。買いきりライセンスで、プレミアム版を買った。自分は、サブスクはできるだけ増やしたくない派なのでありがたい。定常的に飲んでおきたい薬(自分の場合は花粉症の舌下治療)や、習慣づけたい習慣行動などを登録している。 1Password 年間プラン 今まで 7 年ほど買い切りプランで生き残ってきたが、買いきりで購入したライセンスが古すぎて、そのライセンスだと 1Password が使えなくなったので思い切って購読形式に移管した。買い切り型は DropBox での同期形式だったが、購読形式は 1Password アカウントによる同期で、DropBox に縛られない同期ができて楽。支払いは、1Password のギフトカードを購入してそこから支払うことで割安に契約した 前述したとおり極力購読型の支出はしたくなかったのだが、1Password にはとても長い間お世話になっているので、応援の意味を込めて契約した。 MargineNote3 技術書のメモを Obsidian で取っていたのだが、取っている最中に自分が行う行動は、以下の二つに大きく分けられる。 コピペ → 構造化 → 頭の中に理解して反芻する コードを書いたり、ノートを取ったりする １つ目の作業で、ざっと読み込んでいくのだが、PDF リーダーや epub リーダーからコピペをしているときにあれ、めっちゃめんどくさい。こんなにめんどくさいなら、だれか良いアプリとか開発しているのでは思っていた。 その後、Obsidian で PDF マーカーや注釈可能な拡張機能が無いかなとフォーラムを探してたら、MarginNote3 を愛用しているぜという投稿をキッカケに出会った。結果的になんで今まで使わなかったんだろうかというレベルで情報を構造化して読み取るのが楽になった。購読型ではなく買い切り形式だったのも非常にありがたかった。(大事なことなので、何回でも言わせてください) 今の状況を疑って、もっと便利にするにはどうしたらいいんだろうかと考える癖は本当に大事ですね。今までのコピペして、構造化してという時間がもったいなすぎる。</description></item><item><title>Elasticsearch の Go client で有名な olivere/elastic がES8 以降はサポートしないので、利用者は公式クライアントに移行しよう</title><link>https://shunyaueta.com/posts/2022-12-13-2218/</link><pubDate>Tue, 13 Dec 2022 22:18:45 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-12-13-2218/</guid><description>Elasticsearch を Go lang から利用できるクライアントライブラリで、非公式なパッケージではolivere/elasticがあります。 このパッケージはかなりの人気を誇っており、なんと 2012 年から開発され現状 Elasticsearch v1.0 からすべてのバージョンをサポートしています。 素晴らしい OSS ですね。
ES8 をサポートせずにメンテナンスモードに入る経緯 ES8 以降のサポートをどうするか決めあぐねている現状の経緯はこちらの issue に olivere さんから直接説明してくれています。 直接 olivere さんの意見を読んだほうが良いので、引用のみしておきます。
Announcement: Future directions (updated on 2022-07-22) · Issue #1533 · olivere/elastic
Finally a word about this repository. I&amp;rsquo;m sorry about all the people still waiting for an Elastic v8 version, waiting for their PRs to be merged and issues to be answered. I had a hard time personally over the last two years, and when I had to decide whether working on Elastic or focusing on my health is the top priority, I always decide for the latter.</description></item><item><title>Search Engineering Newsletter を substack へ移行します</title><link>https://shunyaueta.com/posts/2022-12-04-0003/</link><pubDate>Sun, 04 Dec 2022 00:03:06 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-12-04-0003/</guid><description>Search Engineering Newsletter vol.04 では、Revue から自分の Blog での配信に移りました。 その時の経緯としては
だが、自分のサイトは公開しているので、誰でも見れる。 そのためリーチする層に差が出るわけでもなかったかなと今更ながら気づいた。
でしたが、
実際問題、自前の Blog でもニュースレターでも誰でも見れる事自体は変わらないが、誰に届くかは Blog ではなくニュースレターの方が幅広い読者に見てもらえるのでは? ニュースレター専用のメディアにすることで、ニュースレター自体がどれくらい需要があるかを切り分けて追跡しやすい 1 最近は更新を告知するチャンネルの Twitter が将来的にどうなるかわからない状態2。そしてその流入量は決して少なくない。 また、自分が書いた記事を届ける手段をプラットフォームに依存しない形式で保持して、読者とつながっておくのは改めて重要性を感じた そのため、substack でニュースレターを再開してみることにしました。
substack で期待していることは、読者とのコミュニケーションが取りやすくなるのでニュースレターを通じて、ピックアップした記事の議論や感想などを交えるようになると面白そうだなと思っています。
配信方法を都度変えて、読者の方にはお手間をおかけしますが、配信しているニュースレターを面白いと感じていただけた方は substack での購読を以下からよろしくおねがいします。 ニュースレターの配信もこれ以降は substack のみで行う予定です。
https://searchengineeringnewsletter.substack.com/
過去記事もこの記事以外は Blog からは削除して、substack に移行してみます。&amp;#160;&amp;#x21a9;&amp;#xfe0e;
既存の購読者の方がいた revue に戻ろうかと思ったのですが、Briefing: Twitter Will Shut Down Newsletter Product Revue By Year End — The Information という記事をみてやめた。実際に購読しているニュースレターが revue をやめまくっている(今回の Twiter 買収で Revue が停止するという情報がでまわっているため。) いまのイーロン・マスクの動きを見ていると選択と集中の時期で、revue を維持するという未来が予想できない。&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description></item><item><title> Beam summit 2022 雑感</title><link>https://shunyaueta.com/posts/2022-11-06-2252/</link><pubDate>Sun, 06 Nov 2022 22:52:09 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-11-06-2252/</guid><description>毎年開催される Apache Beam の会議、Beam Summit 2022 で講演資料が公開されていたので、気になる資料を読んだ。
以下に面白かった記事の備忘録を放流しておく
Google&amp;rsquo;s investment on Beam, and internal use of Beam at Google Google 内部で現在フルタイム Beam 開発者は 25 人! (多いな) Go SDK 提供開始がめでたい 現在は Java, Python, Go の３つの言語をサポート 機械学習の推論を Beam の特性を生かしてスケーラブルに実行可能な RunInference も提供できた! TypeScript SDK も提供予定! contribution している方も募集中 https://github.com/apache/beam/tree/master/sdks/typescript Beam Playground を使えば、Beam がより効果的に学べるよ https://play.beam.apache.org/ チケット管理では Jira をやめて GitHub Issues に移行したよ(最近の Apache Project の潮流な気がする。Lucene も移行していた) Beam @TwitterEvaluation, Adoption, Migration and future. 毎日実行される data pipeline の総数 5 万 200PB 超えのボリュームをデータ処理 7 兆のイベント数 Beam の魅力 batch, streaming の両者を扱うことができる、かつモダンな実行フレームワーク ランナーの柔軟性 複数のクラウド環境で実行可能 複数のプログラミング言語で動く 優れた OSS コミュニティ RunInference: Machine Learning Inferences in Beam Apache Beam 2.</description></item><item><title>情報検索・検索技術 Advent Calendar 2022 を開催します</title><link>https://shunyaueta.com/posts/2022-11-05-1147/</link><pubDate>Sat, 05 Nov 2022 11:47:43 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-11-05-1147/</guid><description>2021 年に引き続き、2022 年も情報検索・検索技術 Advent Calendar を作ってみました。
情報検索・検索技術 Advent Calendar 2022 - Adventar
kivantium さんの 創作+機械学習 Advent Calendar 2022 を開催します - kivantium 活動日記 の記事がいいなと思ったので、僕も自分の Blog で告知しておきます。
2021 年にアドベントカレンダーを作成したきっかけとしては、そもそもブログ記事の執筆が自分は好き他人が書いた記事を読むのは楽しい。 アドベントカレンダーの文化はそういう自分の嗜好にぴったりなので、自分の好きな検索技術領域がまだ作られていない! 作らねば! というのがモチベーションでした。
実際のところ、検索技術に携わってはいるが、Blog 記事をあまり書かない人もアドベントカレンダー起因で記事を書くきっかけになっているじゃないかなと思っています。
現時点で 登録数 12/25人となっています。ご登録頂いた方々ありがとうございます! みんなでワイワイ投稿して盛り上げていきましょう。</description></item><item><title>env Studio No such file or directory というVisual Studio Code 起因のエラーへの対処方法</title><link>https://shunyaueta.com/posts/2022-11-04-1727/</link><pubDate>Fri, 04 Nov 2022 17:27:50 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-11-04-1727/</guid><description>VSCode をcodeコマンドから実行可能にするとPATHに Visual Studio Code の空白スペースが含まれてしまうことが原因でこのエラーが発生する。
具体的には VSCcode の PATH が以下のように登録されてしまっている。
PATH = ...PATH:/Applications/Applications/Visual Studio Code.app/Contents/Resources/app/bin 自分が遭遇したエラーは、環境変数を参照する make コマンドで
make test env: Studio: No such file or directory というエラーが出てくるようになり、make task が実行できなくなってしまった。
原因として自分の場合は、brew で VSCode をインストールしなおしたら、このエラーが出てくるようになった。
対処方法 公式ページに書いてあるとおりの方式1でパスを通せば解決する。 具体的に解説すると
VS Code を起動 コマンドパレット(Cmd+Shift+P)を開いて、shell commandと打ち込み、Shell Command: Install 'code' command in PATH を選択して実行 でこのエラーが出てこなくなる。
もしくは、ダブルクォーテーションでPATHを登録すればこの問題は回避可能
export PATH=&amp;#34;\$PATH:/Applications/Visual Studio Code.app/Contents/Resources/app/bin&amp;#34; Visual Studio Code on macOS You can also run VS Code from the terminal by typing &amp;lsquo;code&amp;rsquo; after adding it to the path:</description></item><item><title>Elasticsearch 8.4 から利用可能な従来の検索機能と近似近傍探索を組み合わせたハイブリッド検索を試す</title><link>https://shunyaueta.com/posts/2022-10-29-2337/</link><pubDate>Sat, 29 Oct 2022 23:37:35 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-10-29-2337/</guid><description>表題の通り、Elasticsearch 8.4 から待望の近似近傍探索と従来の検索を組み合わたハイブリッド検索が可能になったらしいので、試してみました。
Elascticsearch 8 で導入された近似近傍探索について Elasticsearch 公式の記事1がわかりやすく近似近傍探索について語られています。 また、日本語では@pakio さんの紹介記事2も非常にわかりやすいので、そちらも御覧ください。
嬉しいけど物足りない点 公式の資料3や@pakio さんの資料でも触れられていますが、
You can’t currently use the Query DSL to filter documents for an approximate kNN search. If you need to filter the documents, consider using exact kNN instead. Elasticsearch の Query DSL との併用不可というのが物足りない点でした。
端的に説明すると Elasticsearch 8 で利用可能になった近似近傍探索は、あくまでベクトル間のみの近似近傍探索のみできるのであって、従来の Elasticsearch の検索機能(term や filter)と近似近傍探索を組み合わせて検索できないということです。
Vespa の開発者の Jo さんも同様の点4について触れていました。
The most surprising part of the announcement is that they won&amp;rsquo;t allow combining the nearest neighbor search with standard query terms and filters.</description></item><item><title>Elasticsearchの近似近傍探索を使って、ドラえもんのひみつ道具検索エンジンを作ってみた</title><link>https://shunyaueta.com/posts/2022-10-23-2344/</link><pubDate>Sun, 23 Oct 2022 23:44:13 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-10-23-2344/</guid><description>Elasticsearch 8 系から使用可能になった近似近傍探索1を使って、ドラえもんのひみつ道具の自然言語検索ができる検索エンジンを作ってみた。
デモ動画のように、検索したいひみつ道具を説明する文章することで近しいひみつ道具が検索されます。
コードは GitHub に公開してあるので、興味のある方は手元で、動かして遊ぶことが出来ます。 poetry と Docker さえあれば動くようになっています。
hurutoriya/doraemon-himitsu-dogu-search: Doraemon Himitsu Dogu Japanese semantic search based on Elascticsearch ANN
システムの概要図はこんな感じ
所感 ドラえもんのひみつ道具のデータセットを今回１から作ったが、パースと前処理がめんどくさくてここが一番手間がかかった。が、工夫しないと出来なかったので、一番楽しいところでもあった。 文章の特徴抽出は、sonoisa/sentence-bert-base-ja-mean-tokens-v2 · Hugging Faceを使わせていただき、驚くほど簡単に実現できた。 実際はもっと精度を高めるには、fine tune などがいいのだろうが、システム側を作ることに注力したかったので今回は割愛 デモアプリの構築は streamlit を使って 20m くらいで作れたので、相変わらず便利すぎて愛用している。今回の検索エンジンは CLI から実行もできるが、こうやってデモアプリがあったほうがそれっぽくて気持ちいい。 インデキシング時にトーカナイザーのことなど全く考えずに特徴ベクトルだけインデキシングして、それで検索が成り立つというのは新鮮。閾値設定しなければゼロヒット問題にも直面しないので、できることの幅は広がりそう。 Elasticsearch の近似近傍探索は、今回ベクトル同士の近似近傍探索しかやっていないが、それもインデキシング、クエリ部分は公式ドキュメントを見れば事足りたので変にハマることはなかった。 クエリ部分はこれだけで書けた。
query = { &amp;#34;knn&amp;#34;: { &amp;#34;field&amp;#34;: &amp;#34;vector&amp;#34;, &amp;#34;query_vector&amp;#34;: sentence_embeddings[0], &amp;#34;k&amp;#34;: 10, &amp;#34;num_candidates&amp;#34;: 100, }, &amp;#34;fields&amp;#34;: [&amp;#34;name&amp;#34;, &amp;#34;description&amp;#34;], } result = es.search(index=INDEX_NAME, body=query) ぶっちゃけて言えば、この規模で近似近傍探索のみやるなら検索エンジンを使わずとも Python 内でインメモリ探索して完結して動くと思うので Elasticsearch を使う意義を考えざるをえないが、自分が触ってみたかったのでやってみた。 そのおかげで色々学べたことが多いので、手を動かしてよかった。</description></item><item><title>CloudComposer の Variables (環境変数)を gcloud cli で取得する</title><link>https://shunyaueta.com/posts/2022-10-17-1630/</link><pubDate>Mon, 17 Oct 2022 16:30:58 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-10-17-1630/</guid><description>Airflow 1 系で設定されている環境変数を JSON ファイルとして GUI を使って書き出す方法の続報です。
前回、Airflow CLI からでも環境変数を JSON ファイルとして出力できる1が、手元から実行しても GCP 上のインスタンスにしか保存されなかったので諦めたと書きました。 ですが、その問題を解決できたので、解決方法を公開しておきます。
Cloud Storage に格納されるデータ | Cloud Composer | Google Cloudによると、Cloud Composer インスタンス内部のディレクトリは GCS にマッピングされているらしい。
マッピング関係は以下( GCP のドキュメントをそのまま引用)
フォルダ Storage パス マッピングされたディレクトリ 説明 DAG gs://bucket-name/dags /home/airflow/gcs/dags 環境の DAG を保存します。このフォルダ内の DAG のみが環境にスケジュールされます。 プラグイン gs://bucket-name/plugins /home/airflow/gcs/plugins カスタム プラグインを保存します。カスタムのインハウス Airflow 演算子、フック、センサー、インターフェースなどです。 データ gs://bucket-name/data /home/airflow/gcs/data タスクが生成して使用するデータを保存します。このフォルダは、すべてのワーカーノードにマウントされます。 ログ gs://bucket-name/logs タスクの Airflow ログを保存します。ログは Airflow ウェブ インターフェースでも利用できます。 それを使えば、/home/airflow/gcs/data にファイルを保存すれば、CloudComposer が保有している GCS の gs://bucket-name/data にアクセスすれば、そのファイルが参照可能になる。</description></item><item><title>Python で zip関数を使う際に、２つの配列が同じ大きさを想定する場合は 3.10 から導入された strict=True を使おう</title><link>https://shunyaueta.com/posts/2022-10-17-1156/</link><pubDate>Mon, 17 Oct 2022 11:56:22 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-10-17-1156/</guid><description>Python で２つの配列を for 文で扱いたい場合によく使うのが zip() です。
zip()を使った for 文では暗黙的に同じ大きさが要求されると思っていたが、実際には以下のように２つの配列の大きさが異なっていてもエラーが出ないことに気が付かず、困ったことがあった。
In [1]: a = [1,2,3,4] In [2]: b = [1,2,3] In [3]: for i,j in zip(a,b): ...: print(i,j) ...: 1 1 2 2 3 3 てっきり、大きい配列の要素を参照時にエラーが発生するかと思ったら、そんなことはなかった。
assert とかで事前にコケるようにしておくとか必要そう。 もしくは、両者の配列のサイズが同じことを明示的に確認するのが吉。
また蛇足だが、Stackoverflow では意図的に異なる大きさの配列を上手く循環させつつ回したい場合の対処法も書いてあり勉強になった。1
2022-10-27: 追記
@ftnext さんから以下の情報2を教えてもらいました。
小さい方を読み切ったら for を抜けるの予想と違いますよね。 3.10 から zip に strict 引数が追加されており、True を指定すれば長さが異なると ValueError を送出するようになったんです！ https://docs.python.org/ja/3/library/functions.html#zip… また長い方に合わせたいときは zip_longest が標準ライブラリの itertools にありますー
なるほど。
Without the strict=True argument, any bug that results in iterables of different lengths will be silenced, possibly manifesting as a hard-to-find bug in another part of the program.</description></item><item><title>Airflow 1系で設定されている環境変数を JSON ファイルとしてGUIを使って書き出す方法</title><link>https://shunyaueta.com/posts/2022-10-04-1549/</link><pubDate>Tue, 04 Oct 2022 15:49:30 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-10-04-1549/</guid><description>CloudComposer(GCP の Airflow のマネージドサービス)で運用している Airflow 1 系上で設定されている環境変数を JSON ファイルとして書き出したかったが、つまずいたのでメモを公開しておく。
Airflow の運用の理想としては、リポジトリをベースに CI 経由で CloudComposer を構築していくのがベスト。 だが、Airflow では GUI でお手軽に環境変数(Airflow では Variables という概念1)が設定でき、便利な半面、デメリットとしてリポジトリをベースにした Single Source of Truth の状態が保てなくなってしまう。
Airflow の環境変数を JSON ファイルとして書き出す方法 上部の Admin メニューから、Variablesをクリックしてページに移動 With selectedボタンをクリックすると Exportボタンがドロップダウンリスト内にでてくるので、これをクリックすれば Airflow に保存されている環境変数を JSON ファイルとして書き出せる Export できるとは初見でわからなかったのでこの UI を考えた人は罪深い。@naoさんに教えていただけて感謝! Airflow CLI からでも環境変数を JSON ファイルとして出力できるらしい2が、手元から
gcloud composer environments run COMPOSER_NAME --location asia-northeast1 variables -- --export env.json を実行してもローカルには保存されなかったので、実行結果は CloudComposer 内部のインスタンスに保存されている模様。
Bash と GCS のオペレーターを組み合わせれば JSON ファイルを GCS に保存はできそうだが、それもめんどくさそうではある。 直接 SSH で CloudComposer のインスタンスにつなげたほうがまだ楽そうですよね</description></item><item><title>Meta が公開したデータ処理の効率化・高速化を狙うエンジン Velox が面白そう</title><link>https://shunyaueta.com/posts/2022-09-01-2139/</link><pubDate>Thu, 01 Sep 2022 21:39:30 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-09-01-2139/</guid><description>日課の RSS フィードを眺めていると、クエリエンジンやデータ処理の最適化のための高速化ライブラリが Meta が OSS として公開した1 のを知った。
Velox のリポジトリはこちら
facebookincubator/velox: A C++ vectorized database acceleration library aimed to optimizing query engines and data processing systems.
実際にリポジトリを観てみると C++で書かれており、たしかにパフォーマンスが高いのが納得。
ドキュメントやチュートリアルなどはこちらのサイトで用意されています。
Hello from Velox | Velox
Meta 社内では、Presto や Spark に適用して処理の高速化、PyTorch に活用して前処理や特徴量エンジニアリングの高速化が進められているらしいです。
技術ブログ記事 1が何をやっているか明瞭なので、かいつまんでメモを残しておきます。
SQL の分析、ストリーミング処理や機械学習のためのデータ処理など実際の処理内容は似通っているが、様々なフレームワークが使われ、独立して進化している。 この断片化によって、保守と拡張が困難になっていたが、それらを統合する形で実行可能にするのが Verox Presto, Spark などのデータ処理エンジンは、一見異なるように見えるが、レイヤー構造で考えると非常に似通っている。 Verox は一般的に実行エンジンレイヤーの代わりとなり、式評価、集約、ソート、結合などの処理を提供する。(一般的に data plane と呼ばれる) 実例と結果 Presto は Java で実行されるが、それを C++の Velox で置き換えた。Prestissimo というプロジェクト名で進んだ。(カッコいいね) Java での実行と比べると、大体 6 倍ほど高速化された Spark 上では、Gluten とよばれるプロジェクトで Velox と同じように C++での実行を試みるプロジェクトが公開されている。 PyTorch の TorchArrowを Velox 上で実行可能 最終的には、Velox で従来のデータマネジメントの部分と機械学習インフラストラクチャの部分の垣根を統一することを狙っている。</description></item><item><title>Java の memory map を理解する</title><link>https://shunyaueta.com/posts/2022-08-22-1300/</link><pubDate>Mon, 22 Aug 2022 13:00:43 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-08-22-1300/</guid><description>Apache Lucene のインデックスの取り扱いについて勉強していたら、 Java の memory map について言及されていたが、Jave の memory map1 について日本語で分かりやすく解説されている記事がなかったので、勉強がてらまとめた。 メモリマップ自体の説明はこちらのサイトが非常にわかりやすかった2
mmap はファイルとメモリーアドレスのマッピングを行う
つまり、ファイルをメモリ上にマップ(射影)してメモリ上でファイルを扱えるようにするということですね。 Apache Lucene の使用例だと、Lucene の検索用のインデックスファイルを MMap でメモリ上にマップして扱えるようにしていそう。
参考にしたのは上記２つの記事がわかりやすい記事だった。
Java プログラムに関連するメモリは 4 部分から構成される3
Stack: メソッドが呼ばれた際に、Stack はメソッドを完了させるためのメモリ空間を提供する。この空間はパラメータやローカル変数、現在のオブジェクトへの参照などが格納されている。Frame はメモリ空間を参照し、メソッドの呼び出しをサポートする。Stack は LIFO(Last in First out)方式で動作し、呼び出し基のメソッドの Stack frame を削除するために最後の Stack frame(現在実行中のメソッド) を削除する必要がある。 Heap: Java で作成されるオブジェクトは全て Heap で作成される。 Static Area: プログラムの実行中に存在する値を格納するメモリを参照する。静的な変数を宣言した際に、この領域に存在する。 Code: 実行されるコードが格納される場所。 中でも Java の Memory mapped file は、メモリから直接ファイルにアクセスするのに役立つ Java の特殊ファイル4。 Java は、java.nio パッケージで Memory mapped file をサポートしている。 Memory mapped I/O は、ファイル システムを使用して、ユーザーから直接ファイルシステムページへの仮想メモリマッピング(virtual memory mapping)を確立する。Memory mapped file は単純に大きな配列として扱うことができ、Memory mapped file に使用されるメモリーは、Java の Heap 空間外部が利用される。</description></item><item><title>Apache Beam 2.40 で導入された scikit-lean, Pytorch の効率的な推論が可能になる RunInference API を試してみる</title><link>https://shunyaueta.com/posts/2022-08-18-1938/</link><pubDate>Thu, 18 Aug 2022 19:38:29 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-08-18-1938/</guid><description>2022-07-21 に Google Cloud が Cloud DataFlow の新機能として、DataFlow ML という新機能を発表した。1
Dataflow ML - Speaking of ML transforms, Dataflow now has added out of the box support for running PyTorch and scikit-learn models directly within the pipeline. The new RunInference transform enables simplicity by allowing models to be used in production pipelines with very little code. These features are in addition to Dataflow&amp;rsquo;s existing ML capabilities such as GPU support and the pre and post processing system for ML training, either directly or via frameworks such as Tensorflow Extended (TFX).</description></item><item><title>KDD2022 で気になった研究</title><link>https://shunyaueta.com/posts/2022-08-15-2335/</link><pubDate>Mon, 15 Aug 2022 23:35:35 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-08-15-2335/</guid><description>2022/08/14 - 2022/08/18 に開催される Knowledge Discovery and Data Mining (KDD) 2022 の情報が出揃ってきたので、気になった情報をメモしておく。
自分が気になるトピックは、変わらず機械学習の実応用とその周辺領域なのでそれに偏ったリストになっている。
ADS invited speaker KDD 2022 ADS Invited Speakers
An overview of AWS AI/ML’s recent contributions to open source ML tools: Accelerating discovery and innovation
招待講演は確か毎回論文化されて ACM で公開されるので論文公開されたらぜひ読みたい。
Tutorias KDD 2022 Tutorials Schedule に Tutorial の情報がまとまっているが、タイトルだけでウェブサイトへのリンクが一切なく、読み手に不親切なので来年は、改善してほしい。去年はそんなことなかったので、なんとか来年はもとに戻って欲しい。
Graph-based Representation Learning for Web-scale Recommender Systems. Authors: Ahmed El-Kishky (Twitter)*; Michael Bronstein (Twitter); Ying Xiao (Twitter); Aria Haghighi (Twitter) Twitter が開催する Tutorial で、すごく面白そうなのだが全く情報が見つからなかった。Twitter Cortex にも情報が更新されていないので、しばらくしたら公開されていることを祈る。 New Frontiers of Scientific Text Mining: Tasks, Data, and Tools.</description></item><item><title>poetry show でパッケージ名に (!) が付与されている意味</title><link>https://shunyaueta.com/posts/2022-08-10-1717/</link><pubDate>Wed, 10 Aug 2022 17:17:29 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-08-10-1717/</guid><description>poetry show は、poetry の設定ファイルの pyproject.tomlに記載された利用可能なパッケージ名を表示してくれる。
例えば、ターミナルで poetry install を行う前に、poetry showを行うと以下のような結果がでる。
そして、grep で上記の結果を表示させてみると
&amp;gt; poetry show | grep aiohttp aiohttp (!) 3.8.1 Async http client/server framework (asyncio) と パッケージ名に (!)が付与されている。
この(!)ってそもそもどんな意味なのか気になったので調べてみました。
Poetry のコードを直接読んでみると、 test_show_basic_with_not_installed_packages_non_decoratedのテストケースが今回の事例にマッチしており、わかりやすかった。 意味としては、「インストールされたパッケージに対する show コマンドを非装飾モードで結果を出力」へのテストだ。 状況としては、cachyとpendulumを poetry add して、 cachyのみを poetry install している。
poetry.package.add_dependency(Factory.create_dependency(&amp;#34;cachy&amp;#34;, &amp;#34;^0.1.0&amp;#34;)) poetry.package.add_dependency(Factory.create_dependency(&amp;#34;pendulum&amp;#34;, &amp;#34;^2.0.0&amp;#34;)) cachy_010 = get_package(&amp;#34;cachy&amp;#34;, &amp;#34;0.1.0&amp;#34;) cachy_010.description = &amp;#34;Cachy package&amp;#34; pendulum_200 = get_package(&amp;#34;pendulum&amp;#34;, &amp;#34;2.0.0&amp;#34;) pendulum_200.description = &amp;#34;Pendulum package&amp;#34; installed.add_package(cachy_010) その後に、poetry show を実行した際に以下のように(!)が期待される出力となっている。
cachy 0.1.0 Cachy package pendulum (!</description></item><item><title>「リーダーの作法」マネジメントに限らず、エンジニアとして仕事の作法について書かれた良書</title><link>https://shunyaueta.com/posts/2022-08-08-1145/</link><pubDate>Mon, 08 Aug 2022 11:45:24 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-08-08-1145/</guid><description>リーダーの作法 ささいなことをていねいにを読み終えた。 著者は Netscape でマネージャー、Apple でディレクター、Slack でエグゼクティブを経験した Michael Lopp さんで、過去にBeing Geek や Managing Humans を書かれている。 翻訳の質も非常に高く、楽しく読めた。1
そんなにマネジメント関係を読んでいるわけではないが、HITH OUTPUT MANAGEMENT や、エンジニアのためのマネジメントキャリアパス ―テックリードから CTO までマネジメントスキル向上ガイド 同じくらい良い書籍で、学びや共感を多く感じた。
自分はマネジメントのポジションについたことはないが、仕事をしていくなかでマネジメント関係のソフトスキルや複数人でどうやってうまくリーダシップを発揮して、大きい問題を解決するかに興味があるので、良い書籍が目につくと積極的に読んで解像度をあげている。
心に響いた文章と所感 マネジメントとは、まずチームが直面している障害やメンバー間の軋轢といった情報を明らかにすることであり、さらにそうして得た情報を分析して、進むべき正しい道を見出すことである、ということでした。
マネジメントの定義として、チームの課題は他の書籍でも述べられているがメンバー間の関係性について言及しているのは確かにねという腹落ちだった。
ポジションに関わらず全ての業務で一貫して言えるのは、なにが最も ROI が高い課題かを突き止めて地道に解決していくことだな~と思える。
6 章 プロフェッショナルとしての成長を図る質問表
6 章の成長を計測するための質問表は、あらためて自分が何をやりたいのかの解像度をあげる良い質問集だったので半年や一年ごとにこの質問を更新して、定期的に見つめ直していきたい。
新しい仕事では、一刻一刻で多くを学びます。その環境に関する情報をたくさん集めているのです。チームや自分の役割、そして会社についての自分の理解を日々新たにしているのです。
新メンバーがあげるチームの違和感は、フィードバックをもらった後に一ヶ月後見直して見ると重要度が下がることがあるよねと。これは、自分も経験あるが、チームで働くうちに内部の事情を理解して、重要だけど緊急じゃないよね、実際やりたいけどコスト的に割に合わないなど課題に対しての解像度があがることで、優先順位が変わることがありました。
そういう人たちが長年にわたって私に教えてくれた重要な教訓の一つは、壁に書かれた文字より、語られるストーリーの方が重要だということです。
ここで腹落ちしたのは、あらためて人を動かすのは物語(ストーリーテリング)だということ。「なぜ」 そうなったのかってものすごく重要だなと。DesignDocs もそうですが、なぜそうなったかがわかると人間ってものすごく腹落ちして理解できるな~と 自分もドキュメントを書くときは、「なぜ」そうなったのかをきちんと書いて人を動かせる文章を書けるようになっていきたい
手厳しいフィードバックの場合は、何も見落とさないようにするためにあと 2 段階のプロセスがあります。ステップ 1：どんなに批判的なフィードバックであっても、耳を傾け、ほんの少しでも理解の糸口を探す。ほんのわずかでも？よくぞ聞いてくれました。
時には、フィードバックがあまりにも衝撃的で、理解できないこともあります。そこで、第二のステップです。ステップ 2：聞いたことを繰り返しましょう。
ここのストーリーは面白くて、図星な本質的なフィードバックを感情的に反応しそうになってしまうのをどうやって傾聴して、フィードバックを受け入れて自己を改善するかが語られていて面白かった。
リアルタイムにフィードバックし、他のプレイヤーに親切かつ教育的な方法でアドバイスを送ります。災難に直面しても冷静さを失いません。わかりやすいコミュニケーション、実証された専門知識、わかりやすく行動につながるフィードバック、そして落ち着いた性格。堅実なリーダーの性質について説明しましたが、まだ大切なことがあります。いいでしょうか、こうしたふるまいは、多くの人がやっているのをこれまで見てきました。DJ が特別なのは、常にこのようなリーダーであることです。
ゲームを通して、リーダー像がどのように振る舞うべきなのかを説明しており、非常にわかりやすかった。
リーダーシップとは、他人に見せるために選ぶ服であり、私は揺るぎない優しさを選びます。
そして、書籍の最後の文章が、まさに「リーダーの作法」という心構えであり定期的に見返したい。
全体を通して、エッセイとして語られて教訓を学べるので楽しく読めた。2 他の書籍と比較すると、リーダーとして情緒的にどう振る舞うべきかも触れている点が、個人的に読み応えがあった。 自分があらためてマネジメントのポジションにつくことがあれば読み返したくなる書籍だった。
総じて、自分が体験したトピックは強く共感を抱けて学びが多かったというのが興味深い。 ビスマルクの名言で「愚者は経験に学び、賢者は歴史に学ぶ」があるが、自分も本を読むことで歴史から学んでいけるようになりたい。 そのために最近習慣化したいので、読んだ後に読書ノートを作ってちゃんと振り返ることで定着できないか試行錯誤中。 Obsidian にノートをまとめるようになってからは、読書ノートを作るのも楽しくなったので、良いツールは習慣化形成にも役立ちますね。
プライベートで書籍の翻訳プロジェクトを勧めているのだが、このような本が母国語で読める環境はあらためて素晴らしい文化だなと強く思うようになった。&amp;#160;&amp;#x21a9;&amp;#xfe0e;
蛇足) 13 章のストーリーが個人的に一番笑える皮肉が書いてあって、一読の価値あり。 当たり前のことをきちんとやるって、難しいけどその作法は大事。&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description></item><item><title>Makefile でコマンドの前に @ を付けると、コマンド自身は表示されず結果のみ表示される</title><link>https://shunyaueta.com/posts/2022-06-22-0001/</link><pubDate>Wed, 22 Jun 2022 00:01:36 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-06-22-0001/</guid><description>Makefile を眺めているとコマンドの前に@をつけているターゲットがあり、その効果を調べてみた1。日本語での記事が無かったので記事を書いた。
以下のように、コマンドの前に @をつけたコマンドとつけていないコマンド両方を実行してみる。
echoing-silencing: @echo &amp;#34;表示されない&amp;#34; echo &amp;#34;表示される&amp;#34; &amp;gt; make echoing-silencing 表示されない echo &amp;#34;表示される&amp;#34; 表示される なので、例えばお役立ち事例として、Makefile でターゲットの実行時に、何を行うか説明をしたい場合に @を付けるとスッキリした文をターミナルに表示することができる。
https://makefiletutorial.com/
Command Echoing/Silencing Add an @ before a command to stop it from being printed
You can also run make with -s to add an @ before each line
&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description></item><item><title>愛用しているツールを更新: Joplin→Obsidian &amp; TickTick → Todoist</title><link>https://shunyaueta.com/posts/2022-06-03-2133/</link><pubDate>Fri, 03 Jun 2022 21:33:01 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-06-03-2133/</guid><description>ノートアプリを Joplin から Obsidian へ 2021-03-13 に notion から joplin に乗り換えた。 理由としては
notion を マークダウンのメモ帳としか使わない DB 機能やテンプレート機能は必要としていない
なのでロックインされずに自分で管理できる OSS の joplin のほうが良いなと思って乗り換えました。 必要な機能は全て満たしてるので満足 と Joplin に乗り換えて大きな不満は無く使い続けていたのですが、Obsidian に乗り換えました。
きっかけは ryuzeee さんの記事1 なんですが、以前から存在は知っていたObsidian をとりあえず食わず嫌いせずに触って見ようかと思い立ち、Joplinの記事を Obsidian のフォーマットにすべて変換2して使い始めてみたところ、とても心地よい使い心地で感動して乗り換えを決定した。
元の Joplin がそもそも Obsidian と同じローカルのプレーンテキストを扱うという思想なので移行がとても簡単でした。
乗り換えを決めた点として、
daily note プラグインと Calendar プラグインで日誌がめちゃくちゃ快適に書けるようになった。自分は日誌という形でログを残しつつ作業をしているのだが、このプラグインで毎日の日誌の記入がとても快適になった。 ぷーおんさんが書いてくれている記事3が、このプラグインの魅力をわかりやすく紹介されています。
またバックリンクの機能がやはり強力で、プラグインも PKM(Personal Knowledge Management) を目的に作成されたツールが多いので、それも気に入った。(ランダムノートを開いて、ノートを整備する機能はなるほど!となる便利さ)
Joplin でもバックリンクのプラグインはあり使っていたが、Obsidian のバックリンク機能は比較してとても完成度が高い。バックリンクを使った繋がりの提案や、つながりが無いノートも見つける機能があったりと書いていて楽しい。
また、自分は料理を良くするのだが、普段参照するレシピも PKM で管理することで有機的な管理ができるようになりとても楽しい。これぞ PKM という事例だなとしみじみ。
logseqというアプリも気になったのだが、アウトライナーアプリで、自分は文章として作成したいので今回は Obsidian を選んだ。
一つ困った点としては、Joplin では Dropbox 経由で Mac と Android 間でノートを同期できていたのだが、Obsidian では Dropbox を使った同期ができなくなった。 だが、スマホでメモを見たくなる用途は主にレシピを見たいときだけだった。どうしても我慢できなくなったら頑張ってデバイス間同期をしてみる。</description></item><item><title>Label Studio を k8s にデプロイする</title><link>https://shunyaueta.com/posts/2022-06-03-2044/</link><pubDate>Fri, 03 Jun 2022 20:44:01 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-06-03-2044/</guid><description>前回 Label Studio の紹介記事1を書きましたが、自分以外にもチーム全体で Label Studio を使いたいという要望があったので Web アプリとして labelstudio をホストしました。 意外と簡単に k8s 上でホストできたので、その方法を公開しておく。
Label Studio の運用方法は、 Docker イメージが提供されているので、それを使用するのが最も簡単です。
CloudRun を使ってサーバーレスで動かす方法2もありますが、今回は k8s 上に Label Studio の Docker イメージをデプロイして、運用することになりました。
k8s のマニフェストファイルは、公式リポジトリ3を参考に作成しました。
apiVersion: v1 kind: Service metadata: name: labelstudio namespace: development spec: ports: - name: http port: 8080 protocol: TCP selector: app: labelstudio --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: labelstudio-data-pvc namespace: development spec: accessModes: - ReadWriteOnce resources: requests: storage: 50Gi --- apiVersion: apps/v1 kind: Deployment metadata: labels: app: labelstudio name: labelstudio namespace: development spec: replicas: 1 selector: matchLabels: app: labelstudio template: metadata: labels: app: labelstudio spec: containers: - image: heartexlabs/label-studio:v1.</description></item><item><title>Re:プログラム雑談 188回：ゲスト回：MessagePassingの話とか</title><link>https://shunyaueta.com/posts/2022-05-12-2337/</link><pubDate>Thu, 12 May 2022 23:37:15 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-05-12-2337/</guid><description>自分が大好きだった、Message Passing はなしをふったりふられたの後日談を @karino2 さんが、Podcast で語ってくれていたので、アンサーソング。
読者としては、Message Passing という共著ブログは RSS に登録して毎回とても楽しみにしていた。 著者陣はなぜかやってよかった、大成功だね! という感想を出している方が少なく @morrita さんが
特に皆が書いてくれたものを読むのはすごく楽しかったので、うまくいった気もしています。 https://messagepassing.github.io/023-s1/04-morrita/
というポジティブな感想を残してくれており、読者としても著者陣が良い体験として経験されているとすごく嬉しい。 続編を期待しております。
以下、Podcast 内でのご意見に関するお話。記憶の中から書き出しているので正確性に欠けるかもしれません
書く習慣を身に着けていないと、書けないし、普段から書く習慣を実践したい @morrita さん
同意。自分も今年から脱 Twitter をして、Blog で記事を執筆するようにしているが、以前よりもほんの少しだけど読みやすい文章に変わった気がする。
Blog 記事の感想は欲しい。。。が今だと一方通行。Twitter での言及はいまがポピュラーだが、それはなんか違う。 どちらかというち意見を書くというよりも、意見を求めているときがある。
これも非常にわかる。自分も双方的な意見交換を Blog 上で行いたくてコメント機能を導入1したが、今の所導入してから 1 件のリアクションしかされていない&amp;hellip;2
このコメント機能の Giscus の良いところは、
記事に絵文字リアクションを行える GitHub アカウントが必要なのでスパムをかなり弾けそう なのだが、全然使われない&amp;hellip;
はてぶで 969 件とかなりブックマーク3された記事で、自分の Blog でもおそらく歴代最大の閲覧数を持つ記事でさえもコメントはされなかった。
いや、はてぶやってるヒトははてぶでコメントすると思うので、単純にはいえないですが&amp;hellip;一つの指標として
はてなスターや、Medium の clap のような弱いシグナルが欲しくて導入したのだが、なかなか思い通りにいかない。
海外の有名所の Blog 記事だとコメントが殺到しているので、これも日本独特の問題なのか? それとも到達する数の規模が違うからそのぶんコメントが多くなる傾向などがあるのだろうか?
increments などの雑誌に比べて Message Passsing は、他の著者が書いた記事に返信していくような形式なので、重複した内容が少ないのが良い点 @morrita さん
自分もそう思うな~。MEssage Passing の面白さは著者陣がリレー記事のように言及しあって相互作用が発生しているのが面白い点だと思う。
意見表明だけだと偉そう</description></item><item><title>社内でデータ分析結果を可視化・共有する際に Google Colab が便利</title><link>https://shunyaueta.com/posts/2022-05-10-2200/</link><pubDate>Tue, 10 May 2022 22:00:23 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-05-10-2200/</guid><description>社内でデータ分析のレポートを書く際は Google Colab がとても便利な事に気がついた。
Google Bigquery でデータを抽出、Google Sheets で可視化 従来だと、自分がやっていた方法として、
Google BQ などで分析対象結果のデータを抽出 その結果を Google Spread Sheet として保存して、Google Sheets の機能で可視化。元の SQL のコードは、別シートを作ってそこに貼り付けておく。 利点としては、一度データを抽出した後は、Google Sheets で二次加工が簡単にできる点がとても便利。 また、 Google Sheet を共有後に Produc Manager が出したい数値を、Product Manager 自身が Google Sheets を元にさっと計算することもできる。
だが、二次加工が便利なのはいいが、大抵の可視化ってパターンが決まっているかつ二次加工の状況が必ず発生するわけではないので、SQL 取得とその可視化を一気通貫でできないかなと考えていた。
なにか良い方法無いかなと思っている矢先に、別のチームの同僚が、Google Colab を使って、BQ を dataframe として保存後 matplotlib で可視化しているのを見かけて、
求めていたのは&amp;hellip;こ、これだ&amp;hellip;.
となり、速攻取り入れました。
良いと思ったところは積極的に真似する
Google Colab なら、データの取得・加工・可視化までを完結可能 Google Colab の利点を列挙しておく
SQL のコード、データ抽出や可視化のロジックなどが Python で記述可能かつ、Google Colab で完結 matplotlib で可視化できるので、見やすく美しい図を作れる そしてそのコードは他のデータ分析でも再利用可能 pandas dataframe で Google BQ からデータを取得するので、Standard SQL だけでは難しい計算も pandas、 numpy や scipy などを使ってデータ加工が簡単にできるのも、便利 Google Sheets 同様、簡単に社内で共有できる Markdown も Google Colab 内で書けるので、凝った文章などもいれてレポートも書ける マジックコマンドで、Google BQ の結果を dataframe として保存1したり、</description></item><item><title>2022年、はじめてのまともな確定申告</title><link>https://shunyaueta.com/posts/2022-05-04-2243/</link><pubDate>Wed, 04 May 2022 22:43:11 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-05-04-2243/</guid><description>2022 年、初めてまともな確定申告をやったので、所感をメモ。
実際には 2021 年に初めて確定申告を行ったのだが、ふるさと納税と医療費控除のみだったので、まとも?な確定申告は 2022 年がはじめてといってもいいだろう。
会計ソフトはマネーフォワードと迷ったが、クラウド会計ソフト freee 会計を採用した。 前評判では会計知識がある人からすると抽象化されすぎており、むず痒くなるという記事を見たのだが会計知識がない自分からすると全く問題なく使えた。 会計周りもすべてクレカ経由でしか支出していないのでひたすら振り分けて終わり。 これらは実質作業時間 15 時間程度。 振替項目が何が適切なのかの調査に一番時間が取られた。 書類提出も Andorid のアプリと連携することで free で完結して、ネット上で提出できて良い体験だった。 来年もしやることがあればものすごく早く終わりそう。 マネーフォワードの確定申告は、最初の画面で心が折れて回れ右をした。
freee が「寄附金控除に関する証明書」の xml を読み込める機能に対応しており、ポチポチで終わった。 事前の証明書を発行するための手続きが若干煩雑だったが、今までに比べると圧倒的に楽だった。 証明書の管理もしなくて良くなったのは革命では? 実作業時間は 30 分程度。 紙がもったいないので、個人的には自治体から書類は送らないで欲しい。
医療費控除は、国税庁が公開してくれているエクセルにデータを打ち込んで終わり。 実作業時間は 2 時間程度。 そのフォーマットに free が対応してくれているので読み込んで終わり。
最終的な e-Tax の提出は、スマホでカードリーダーを読み込んで連携1させれば終わりだったので非常に快適だった。 2021 年は張り切って、IC カードリーダーを買ったが結局手持ちの Mac と Safari の相性が悪くかなり粘ったが結局紙に印刷して送付したという思い出がある。
アイ・オー・データ IC カードリーダー ぴタッチ 確定申告 e-Tax
国税庁が用意した Safari の拡張機能周りが魔窟で、当時のサイトを忘れたがマニュアルにかかれていない設定をしないとマイナンバー読み込みプログラムがそもそも起動しなかった。 リベンジできてなにより。 完全に無用になった IC カードリーダーは即売却した。
総評 年々システムが改善されて自動化されていて、素晴らしい。
賛否両論あると思うが、医療費もマイナンバーの保険証化2によりデータが収集されるらしいのでぜひ浸透してほしい。 最近のニュースでは別途診察代金が請求される方式らしく3、ここに税金使わないで何に使うんだろうかと思ったが、予算が取れなかったのかなと色々と考えをめぐらした。 せっかく良い活用が期待できるのに、使う動機を無くすのはもったいない。
e-Tax、スマホがあれば IC カードリーダーは不要に - ケータイ Watch&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description></item><item><title>gRPCurl で `Failed to process proto source files.: could not parse given files:` エラーが出たときの対処方法</title><link>https://shunyaueta.com/posts/2022-04-28-2114/</link><pubDate>Thu, 28 Apr 2022 21:14:16 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-04-28-2114/</guid><description>gRPCurl 1 を使ってリクエストを送る際に、 reflection を機能を使わずに protobufs のファイルを読み込もうとすると
Failed to process proto source files.: could not parse given files: ~ no such file or directory とエラーがでてコマンドが実行できなかった。
対処方法としては grpcurl コマンドを実行する際に、-proto フラグを利用するだけではなく、-import-path フラグを指定する必要がある2。
-import-pathフラグの指定により、参照する protobufs の依存関係のパスを grpcurl に伝えることで上記のエラーが解消される。
例えば、protobufs の内部で
import &amp;#34;~/---.proto&amp;#34; のように他の protobufs を import していると上記のエラーの発生原因となる。
つまり、-import-pathを指定しないと、import 文実行時に grpcurl 内部で、参照する protobufs の root path が不明なので、パスがうまく処理されずに import 文の実行処理がコケてしまうと理解。
fullstorydev/grpcurl: Like cURL, but for gRPC: Command-line tool for interacting with gRPC servers&amp;#160;&amp;#x21a9;&amp;#xfe0e;
Proto Source Files&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description></item><item><title>子供の就寝時に使っているホワイトノイズマシンをGoogle Home から Dreamegg に変更</title><link>https://shunyaueta.com/posts/2022-04-26-2320/</link><pubDate>Tue, 26 Apr 2022 23:20:44 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-04-26-2320/</guid><description>過去に 1 歳児の時点で育児の際に役立ったものに関する記事1を書いた。 今回は、その中で重宝していたホワイトノイズマシンを Google Home mini からDreamegg ホワイトノイズマシンに置き換えたので備忘録がてらメモ。
ホワイトノイズマシンとしての Google Home mini の欠点 当初は既に持っている Google Home mini がホワイトノイズマシンとして使えることが分かり、とてもありがたがったが使っていくうちに課題点が見えてきた。
まず一つ目が、ウェイクワードによる起動が手間がかかる。 子供が寝ているときや寝る前にホワイトノイズマシンを起動するのだが、その際に
自分「OK Google, ホワイトノイズを流して」
というわけだが、この音声入力が非常に煩わしい。子供が寝とんやぞ!と。 しかも一回で成功したならまだしも、子供が起きないように囁くように言うので、
Google Home「すみません、聞き取れませんでした!」
と返してくるのが、非常にイラッとする。子供が起きちゃうでしょうが!!となる。
2 つ目が安定性の問題で、ホワイトノイズは 12 時間再生されるのだが、Google Home をホワイトノイズマシンとして使い始めて 4 ヶ月程度経過してくると、3-4 時間経過するとなぜか再生が切れていたりすることが多くなったり、エラーメッセージと共にそもそも再生できないことが多くなった。 使い方としては、子供が寝ている間の 7-12 時間再生を 4 ヶ月毎日行うという、耐久試験のような使い方をしているので不具合が出るのも仕方ない気がしている。
また、後述する Dreamegg に乗り換えたあとに知ったのだが、Google Home のホワイトノイズの再生機能のスペックが変更されたとのことで、なおさら乗り換えてよかったなと感じた。
No longer 12 hours with small 2 second break every hour 2
Dreamegg ホワイトノイズマシンの良さ そんなこんなで、Google Home の限界を感じていたときにホワイトノイズマシンを調べていたら、Dreamegg というメーカーのホワイトノイズマシンを知り、勢いで買ってみたがこれが大正解だった。 Dreamegg が提供するホワイトノイズマシンも安眠グッズシリーズで複数台あるので、自分の用途に合ったものを買うとよい。 自分は、一番安価なものと当時は 1500 円しか変わらなかったので、興味本位で一番ハイエンドのDreamegg ホワイトノイズマシン D3 Pro を購入してみた。</description></item><item><title>slug の作成パターンを変えて、同日に複数の記事を執筆できるようにした</title><link>https://shunyaueta.com/posts/2022-04-24-0026/</link><pubDate>Sun, 24 Apr 2022 00:26:07 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-04-24-0026/</guid><description>slug とは、URL 末尾の識別子のこと1で、hugo では自分だと記事を書く際に Makefile で以下のコマンドで作成していた。
new: ## Make new post with date as slug hugo new posts/$(shell date &amp;#39;+%Y-%m-%d&amp;#39;)/index.md いろんな考えがあるが、自分は slug の作成時に頭を全く使いたくないので、以前からdate コマンドを使ってYYYY-MM-DDの形式で slug を作成している。 SEO などのために、slug にタイトルを入れるパターンもあるが、記事の作成の流れとして自分は、
ドラフトを hugo new で作成。この時点でタイトルはまだ確定していない 書き上げていくうちにタイトルを最終決定 なので、タイトルは slug に含めない派。
だが、従来の date '+%Y-%m-%d' の欠点として同日に複数の記事を作成すると衝突してしまうと問題があった。 今まではそれを避けるために、メモ帳に下書きを書いてあとからコマンドを打って記事を作成して対処していた。
が、それもめんどくさいと感じたので、
date '+%Y-%m-%d' → date '+%Y-%m-%d-%H%M'
にして、 date コマンドに時間と分数を末尾に追加するように slug 作成コマンドを変更した。
これで、同じ日に複数の記事を書けるようになった。
Why ‘slug’ and not ‘permalink’&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description></item><item><title>Google Colab で Spacy による NER の結果を表示するには、jupyter 引数を True にする必要がある</title><link>https://shunyaueta.com/posts/2022-04-08/</link><pubDate>Fri, 08 Apr 2022 21:04:13 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-04-08/</guid><description>自然言語処理のフレームワークの Spacy を使って、Google Colab 上で NER の可視化を行う際に
import spacy spacy.displacy.render(doc, style=&amp;#39;ent&amp;#39;) と実行しても
&amp;lt;div class=&amp;#34;entities&amp;#34; style=&amp;#34;line-height: 2.5; direction: ltr&amp;#34;&amp;gt;&amp;lt;/br&amp;gt;\n&amp;lt;mark class=&amp;#34;entity&amp;#34; style=&amp;#34;background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;&amp;#34;&amp;gt;\n 2022年\n &amp;lt;span style=&amp;#34;font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem&amp;#34;&amp;gt;Date&amp;lt;/span&amp;gt;\n&amp;lt;/mark&amp;gt;\n、\n&amp;lt;mark class=&amp;#34;entity&amp;#34; style=&amp;#34;background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;&amp;#34;&amp;gt;\n 日本人\n &amp;lt;span style=&amp;#34;font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.</description></item><item><title>自然言語処理トップ国際会議の System Demonstrations について</title><link>https://shunyaueta.com/posts/2022-04-04/</link><pubDate>Mon, 04 Apr 2022 23:48:58 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-04-04/</guid><description>仕事でご縁ができた方と、自然言語処理(NLP)領域での国際会議で Industry track に相当する文化って何かありますかねとお聞きした話が面白かったので文章にしておく。
この領域を知ったきっかけとしては、CyberAgent さんの記事1を読んだ際に知ったのだが、自然言語処理領域のトップカンファレンスの ACL2, NAACL3, EMNLP4などでは Industry Track ではなく、 System Demonstration という部門が用意されているらしい。
例えば、Industry Track で有名所だと KDD の Applied Data Science Track5 や RecSys の Industry Talk6 があります。 それらと比較して異なる点としては、
What problem does the proposed system address?
Why is the system important and what is its impact?
What is the novelty in the approach/technology on which this system is based?
Who is the target audience?
How does the system work?</description></item><item><title>Human-in-the-Loop 🧐 🤝 🤖 を題材にした機械学習の勉強会を開催した</title><link>https://shunyaueta.com/posts/2022-03-31/</link><pubDate>Thu, 31 Mar 2022 00:30:50 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-03-31/</guid><description>先日の記事で告知した1のですが、昨夜、「Human In The Loop」を題材にした勉強会を開催してきました。
実際に Human In The Loop を扱った MLOps の論文2 を過去に書いているくらい興味のある分野なので、この領域を盛り上げていくために開催できてよかった。
オンライン勉強会でしたので、配信動画を Youtube で公開しております。 Human In The Loop に興味のある方はぜひご覧ください。
Machine Learning Casual Talks #13 (Online) 各発表について 各発表の説明は割愛して、一言感想を述べさせていただきます。
Editors-in-the-loop なニュース記事要約システムの提案 by @upura 業務成果を国際会議のワークショップに通されたの素晴らしいですね 👏 (自分も論文を出したことがありますが)、論文を書くことが目的ではない職種で論文を出すのはそもそも体力が必要なので、提出してなおかつ採択されたのは素晴らしいの一言!
Active Learning for Auto Annotation by @tkc79 自分たちのプロダクトで実際に能動学習の効果を検証して学びを得るというのは得難い経験ですね。尊い! 実際にやってみた上での実践的な経験を語ってくれたのが面白かったです。
NeurIPS Data-Centric AI Workshop by @K_Ryuichirou Data Centric AI Workshop の要約を話して頂きました。 The Godfather of MLOps である D.Sculley さん 3が 「Technical Debt in ML: A Data-Centric View」の話をされていたらしいのですが、これは見なければ&amp;hellip;!</description></item><item><title>機械学習モデルの改善手法の一つ、 Human-in-the-Loop について</title><link>https://shunyaueta.com/posts/2022-03-22/</link><pubDate>Tue, 22 Mar 2022 00:16:51 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-03-22/</guid><description>Human In The Loop は、機械学習のモデルのライフサイクルに人が介在することにより、機械学習モデルの改善を目指す手法。
Human In The Loop の定義 YANS2021 で公開された馬場先生の Human-in-the-Loop 機械学習 / Human-in-the-Loop Machine Learning の資料は、現状の HITL の取り組みをわかりやすく説明してくれています。
ここでの Human In The Loop の定義が一番明瞭かなと個人的には思っており、
Q. より良いモデルを効率的に学習するために人間をどう活用するか?
と書かれています。
Human In The Loop はちょっと意味が広めになりがちな言葉でもあるなと個人的には思っており、機械学習モデルの出力を使ってアノテーションを行う能動学習(Active Learning)の事を主に意味していることが多いが、もう少し広めの機械学習モデルのライフサイクルの中に、人間によるデータのレビューを設置すること 1 でも使われたりする。 が、根本的には馬場先生の定義したリサーチクエスチョンに帰結しますね。
日本語の書籍だと、
鹿島先生、小山先生、馬場先生らの ヒューマンコンピュテーションとクラウドソーシング 喜連川先生、森嶋先生らのクラウドソーシングが不可能を可能にする: 小さな力を集めて大きな力に変える科学と方法 などがデータをどうやって効率的に多数の人間の手によって取得していくかの領域を扱っている書籍。
英語の書籍だと Human-in-the-Loop Machine Learning: Active learning and annotation for human-centered AI がドンピシャの内容ですね。 中身は、能動学習とアノテーションの実践的知識について書かれています。
チョット前に見かけたこの資料は
人間参加型の AI 活用 (Human-in-the-loop)
Human In The Loop について浅く広くまとめられていているので、Human In The Loop の概観を知りたい人には良いかも知れない。</description></item><item><title>Googleによる機械学習の実応用をテーマにしたCoursera の講義は、機械学習プロジェクトに携わるなら一度は見ておいても損はない</title><link>https://shunyaueta.com/posts/2022-03-17/</link><pubDate>Thu, 17 Mar 2022 22:44:05 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-03-17/</guid><description>過去に執筆した記事1を見返していたら
そういえば講師陣がめちゃくちゃ良いこと言ってるんだけど記事内に掲載してなかったなと思い、動画を見返すと今でも学びが多かったので、講義のスクリーンショットを見返しつつ筆をとってみた。
今見たら、日本語版の講義 How Google does Machine Learning 日本語版も公開されているので、興味の湧いた方はぜひ受講しましょう。Certificate を発行しないなら無料で受講できると思います。 講義内容の説明は、過去記事1で行っているので気になる方は御覧ください。
機械学習プロジェクトの努力の割当: 期待と現実 ML Surprise https://www.coursera.org/learn/google-machine-learning/lecture/aUjhG/ml-surprise
Hidden Technical Debt in Machine Learning Systemsと同じ話ですね。上記の論文でよく参照される図よりも、
Hidden Technical Debt in Machine Learning Systems から引用
機械学習プロジェクトを
KPI の定義 データ収集 インフラ構築 モデルの最適化 システムインテグレーション 上の 5 項目で分けて、棒グラフの各項目が割合と順序を示しているので更にわかりやすいですね。
機械学習のシステム面かプロジェクト面のどちらに注力しているかという話ですが、プロジェクト面まで包括して説明しているのは良いですね。
機械学習で避けるべき上位 10 個の落とし穴 The secret sauce https://www.coursera.org/learn/google-machine-learning/lecture/BdsV6/the-secret-sauce
講師陣が Google 内部でのインタビューを行い、機械学習プロジェクトのアンチパターンのランキング Top10 を公開してくれています。
アンチパターンの列挙ですが、肯定文と否定文が混じっているので、否定文で統一しています。
機械学習の知識と同じくらい、ソフトウェア開発とインフラストラクチャの知識・経験を要求される
まだデータを収集していなかった
データが既に使える状態だと仮定していた
NOTE: 例えばデータは収集されているが使える状態ではないとかですね。CSV ではなく、PDF でデータが保存されていたり、目当てのデータを取得するのに前処理をしないとそもそも取得できないなど&amp;hellip; 過去に主催した勉強会でも同じような事が言及されてます。 @yuzutas0 さん、あらためて登壇ありがとうございました!
データマネジメントなき ML は、破綻する。 #MLCT
Human In The Loop を維持していなかった</description></item><item><title>タスク管理ツールを Todoist から TickTick へ試しに乗り換えてみた</title><link>https://shunyaueta.com/posts/2022-03-13/</link><pubDate>Sun, 13 Mar 2022 00:13:08 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-03-13/</guid><description>2022 年、タスク管理を TickTick で行うで、TickTick の存在をしり興味が湧いたので、Todoist のサブスクリプションの更新期限も近かったので実験的に乗り換えてみた。
タスクのインポート自体は、TickTick 自体がよくできていて、Todoist で TickTick のアプリの認証をするだけですべて完了するのは楽だった。Todoist 自体には何の不満も感じずプレミアム登録を 4 年ほど継続していた。
自分のタスク管理ツール遍歴 OmniFocus 2013.05-2016.09
買い切り型の Mac, iPhone アプリが提供されているとても手触りの良いタスク管理アプリ。使い心地に全く不満はなかったが、Android, Linux, Web の提供がなかったので、Todoist に乗り換えた。高専 4 年から修士 1 年くらいまで使っていた記憶。今でも良い思い出があるくらいには使い心地とデザインが良かった。特に Todoist でも似たような最近追加されたが、予定されているタスクと左側の Mini calendar でどれくらいの量があるか把握できる Focus 機能がとても良かった。 この時の体験のおかげで Mac の有料アプリは質が高いなぁという印象がついた。あと買い切り型のアプリだったので今思えばそれもありがたかった。
Mac App: 4000 円 iOS App: 2000 円
と少しお高めの値段だが、買い切りでこのクォリティだったので非常に大満足。
今だと、Mac, iOS 以外に Web 版も提供していると聞いて、Web に手を出していることに驚いた。 そのまま Android アプリも作ってくれないだろうか
Todoist 2016.10-2022.02
Apple 製品でしか使えない製品は嫌だと思って乗り換えたので Todoist。仕様当初は予定されるタスクの一覧機能がなかった覚えがあるが、2020 年位?から近日中のタスクという機能が提供され始めて嬉しかった。 機能改善のアップデートが頻繁にあり、マークダウンでコメントをかけるようになったり、カンバン表示、サブタスクにも対応したりしていて好印象。乗り換えた TickTick と比べると全体的に使い心地が良かった。そこらへんは後述します。
購読型で年額 4056 円
TickTick 2022.</description></item><item><title>Google が公開している、より良いデータ分析のためのガイドブック「Good Data Analysis」で、データ分析の要所が簡潔にまとめられていて感動した</title><link>https://shunyaueta.com/posts/2022-03-08/</link><pubDate>Tue, 08 Mar 2022 20:42:56 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-03-08/</guid><description>Google の非公式ブログで、The Unofficial Google Data Science Blog というデータサイエンスをテーマにしたブログがある。
その中で、
Practical advice for analysis of large, complex data sets
の記事を元にして作られた Google Developers Guides: Machine Learning Guides &amp;gt; Good Data Analysis を昨日見かけて読んでいたら素晴らしいドキュメントだったので、ここでその感動を共有したかったので筆をとったしだい。
Good Data Analysis の概要 Technical: どのような技術を使ってデータを見るべきか Process: データへの取り組み方。どのような観点でデータを見るべきか Mindset: どのような考えでデータ分析をすすめていくべきか の三段構成でガイドブックが書かれている。
特にガイドブックで自分が好きな言葉は Mindset 章の
Data analysis starts with questions, not data or a technique
データ分析は質問とともにのみ始まる、データや技術からデータ分析は始まらない
と
Be both skeptic and champion
懐疑的であれ、そしてそのデータに一番詳しい存在(チャンピオン)であれ
でした。
最近課題の理解が本当に大事だなと痛感する出来事に直面した後にこのドキュメントを読んだので非常に刺さりました。
Google は、同様のガイドブックシリーズで
Rules of Machine Learning: 機械学習実践の聖書 People+AI Guidebook: 機械学習を用いた体験をどう作り込むかの知識とベストプラクティスがまとめられている を公開してくれていて、彼らが経験して本質的な知見を文章化して公開してくれるのは非常にありがたい。</description></item><item><title>デスクトップのGoogle 検索の検索フォームUIがかなり変化していた</title><link>https://shunyaueta.com/posts/2022-03-04/</link><pubDate>Fri, 04 Mar 2022 00:03:08 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-03-04/</guid><description>現在 AB テスト中なのかもしれないが、かなり変化している。
以前は QAC(Query Auto Completition) のみ、検索フォームにフォーカスがあたった時に表示していた記憶がある。 だが、現在は一度キーワードを検索して検索結果画面に遷移した後に、検索フォームにフォーカスすると
の画面のように、Query Suggest や Knowledge graph の結果をキーワードフォームに表示するようになった。
確かに、キーワードを再度検索する際に上記のコンポーネントを入れるのは試してみるのは良いのかもしれない。
特にデスクトップの検索ならハコもかなり余っているのでまだ有効活用できる余地はありそう。
でも、検索のユーザーインターフェースを紹介する書籍ではアンチパターンなのでどうなんだろうか。
情報検索のためのユーザインタフェース
1.1: KEEPING THE INTERFACE SIMPLE https://searchuserinterfaces.com/book/sui_ch1_design.html
Figure 1.1: Search results listings from Infoseek in 1997 (left) and Google in 2007 (right), courtesy Jan Pedersen. 画像は上記から引用
と思いつつも、今の Google 検索のインターフェイスも
書籍の Google 検索と見比べてもかなりリッチになっているので、書籍が執筆された 2011 年からすると時代は変わっている感も否めない。
スクリーンショットが取られた 2007 年から 15 年以上も経過してますしね
@joho_hideo さんから面白いコメントがあったので追記しました。
@joho_hideo 特別事例ですが「COVID-19」の検索結果はよく設計されていると思います。 https://twitter.com/joho_hideo/status/1499549278012055552
確かに、これぞまさに情報検索の真髄ですね。 ダッシュボード的な情報を表示している
情報検索のためのユーザインタフェース も現状の状況も踏まえた改訂版が出たら面白そう？</description></item><item><title>Amazon の製品検索で使われるロバストなキャッシュ手法の論文「ROSE: Robust Caches for Amazon Product Search」</title><link>https://shunyaueta.com/posts/2022-03-03/</link><pubDate>Thu, 03 Mar 2022 09:35:29 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-03-03/</guid><description>Web 検索とデータマイニングのトップカンファレンス WSDM2022 のワークショップで The First International Workshop on INTERACTIVE AND SCALABLE INFORMATION RETRIEVAL METHODS FOR ECOMMERCE (ISIR-ecom) が先日開催された。
テーマは e コマース上での検索において
検索システムのスケーラビリティ どうやって適合性(Relevancy)をシステムで改善したか システムの改善 についてをテーマにした検索エンジニアなら垂涎もののワークショップとなっている。
同様の検索システムや実応用に注目したワークショップでは、以下のようなワークショップがある。
SIGIR Workshop On eCommerce 2017 年から毎年開催。累計 5 回開催 International Workshop on Industrial Recommendation Systems 2020 年から開催。累計二回 歴史としては、 SIGIR ecom が長く、これだけの期間継続開催してくれているのはありがたい限り。
機械学習系の国際会議でも手法ではなく、どう現実世界に適用したかに注目したワークショップが益々誕生しており非常に良い流れ。
ACCEPTED PAPERS は 5 本あり、
Amazon: 2 eBay: 1 The Home depot: 2 と企業関係者による論文が 100%となっている。
https://github.com/ISIR-eCom/ISIR-eCom.github.io/tree/main/papers 最後の PDF 番号が 9 なので、最低でも 9 本の投稿はあった模様。</description></item><item><title>Web 検索とデータマイニングのトップカンファレンス WSDM2022 で気になった研究</title><link>https://shunyaueta.com/posts/2022-03-01/</link><pubDate>Tue, 01 Mar 2022 20:47:53 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-03-01/</guid><description>WSDM は web 検索とデータマイニングのトップカンファレンスの一つです。検索好きなら見てて楽しい論文がたくさん公開されており、毎年採択された研究を楽しみに見ています。
今回 WSDM2022 が 2022/02/21 - 2022/02/25 に開催されたので気になった発表をメモ。
今までこういう気になったトピックなどは Joplin にメモして公開していなかったが、公開しても差し支えはないなと思ったので Blog 記事として公開していってみる。
自分の興味関心トピックは今は基本的に検索関連と機械学習の実践事例なので、それに沿った選出になっています。
Industry Day https://www.wsdm-conference.org/2022/industry-day-schedule/
Challenges in Data Production for AI with Human-in-the-Loop, Dmitry Ustalov (Toloka) Scalable Attribute Extraction at Instacart, Shih-Ting Lin (Instacart) Graph Neural Networks for the Global Economy with Microsoft DeepGraph, Jaewon Yang, Alex Samylkin, Baoxu Shi (LinkedIn, Microsoft) Near real time AI personalization for notifications at LinkedIn, Ajith Muralidharan (LinkedIn) Invited Talk: Rethink e-Commerce Search Workshops https://www.</description></item><item><title>3人以上のスケジュール調整をする際には、ベータ版だけど Calendly の Meeting polls がとても便利</title><link>https://shunyaueta.com/posts/2022-02-25/</link><pubDate>Fri, 25 Feb 2022 16:36:48 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-02-25/</guid><description>予定調整サービスのCalendly 皆さん使われていますか?
僕は COVID-19 の影響でオンライン雑談を始めたのですが、カレンダーと連動したスケジュール調整とビデオチャットの準備が同時にされる点が便利すぎて感動して、ずっと愛用してます。
チャットで Calendly の自分の予約ページへのリンクを共有するだけで、スケジュール調整がすべて終わるのでまぁ便利。
社内だと相手のスケジュールが見えるので問題ないのですが、社外の方だとスケジュールが把握できないので、オンライン雑談は社外の人が主なので、重宝しています。
チャットで従来は
「&amp;ndash;日の&amp;ndash;の時間帯はいかがでしょうか?」 「一応カレンダーを抑えておきたいので、メールアドレスを教えてもらってもよろしいでしょうか? カレンダーを招待させていただいております」 のコミュニケーションが必要だったんですが完全になくなりました。最高
今までの Calendly 使用履歴を見ると 20 件以上使っていました。そんなにオンライン雑談をしていたのか&amp;hellip;!
ですが、スケジュール調整って自分と相手の２人だけ参加するパターン以外に自分を入れて 3 人以上参加する場合もあります。その場合は Calendly の仕様にあっていなかったので、泣く泣く従来の方法で確認をとっていました。
ですが、2021 年の年末にMeeting Polls という自分以外に複数人の参加者がいる場合の調整機能がリリースされました。
機能説明などは、以下の公式 Blog 記事がわかりやすいです。
日本語で簡単に説明すると
Calendly Meeting Polls の流れ 主催者: スケジュール候補の時間帯を複数選択 ここが Calendly らしい顧客のことを考えた機能なんですが、候補として選ばれた時間帯は Calendly がスケジュールを作成して自分のカレンダー上で時間を抑えておいてくれます。そのおかげで、スケジュールが確定する前に「あれ、自分で候補にあげたスケジュールを抑えていなくて、別のスケジュールで埋まってしまった&amp;hellip;」という悲しい事態を防げます。最高 主催者: 参加予定のメンバーにリンクを送信 参加者: メンバーは複数の候補の参加可能かどうか投票を行う。その際にスケジュールの招待をするための、名前とメールアドレスを入力。 主催者: 全員が参加できるスケジュールを選択する 主催者: 候補日のスケジュールはすべて削除され、参加者が招待されたスケジュールのみカレンダー上に残る 参加者: カレンダー上でスケジュール招待される この機能ですが、無料枠で使えるようにしてくれているので、非常に太っ腹。 誰でも使えます。
自分の場合は、勉強会の運営時に登壇者の方々のスケジュール調整や、オンライン雑談が自分含めて 3 人以上の際に便利に使わせてもらっています。
Calendly のプロダクト開発の姿勢は非常に大好きで、僕が Meeting Polls を使った履歴から対象にしていると思うんですが、メールで、Meeting Polls でみんなが待望していた機能を実装したよお知らせが来ていて、「これが本来のもらって嬉しい情報だよなぁ、気持ちの良いメール配信だ」と毎回感動しています。 顧客のことを考え抜いたプロダクト開発は、所作に現れますね~。
というわけで、
3 人以上のスケジュール調整をする際には、ベータ版だけど Calendly の Meeting poll がとても便利だからみんな使おうというお話でした。</description></item><item><title>オンライン開催前提だからこそ可能な省エネ勉強会運営 ~勉強会運営再開してみた~</title><link>https://shunyaueta.com/posts/2022-02-22/</link><pubDate>Tue, 22 Feb 2022 22:21:47 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-02-22/</guid><description>自分はMachine Learing Casual Talksという勉強会の運営を @chezou さん、 @tetsuroito さん、 @komiya_atsushi さんの運営陣に合流する形で 2018/7 に再開しました。
もともと自分は根底として勉強会運営が好きで、つくばにいた頃から、tsukuba.rb や PRML勉強会などの勉強会運営をしていたというのもある。
詳しい経緯は過去に記事に書いていた。 見返すとなかなかにエモい文章ですね。
Machine Learning Casual Talks #5 を開催しました
その後子供が産まれる直前の 2020/05 に12 回目を開催して以降、育児で時間的・精神的余裕がなくなって開催が途絶えてしまっていた。
2021/06 に社内チャットで、
育児で運営が途絶えてしまったんですが、皆さんどう克服しましたか?
という質問したら、要約すると
@lestrrat さん 燃え尽きてもいいじゃないか by @lestrrat @sinmetal さん 志低く、無くならないようにしようぐらいの気持ちです。 と多種多様な考えを聞けて自分の中でも色々と考えが深まりました。
当時の僕の反応を拾ってみるとこんな感じ
志が低いというのはとても良いですね。存続させるの大事だなぁと痛感してます:relaxed: 僕も学生でつくばにいた頃東京の勉強会は参加できないけど、資料公開してくれるのありがてぇ、そしてこの分野(機械学習エンジニア) に興味あるけどそもそも鶏卵問題で経験がないと参入できないから知見を公開してくれるの助かるなぁという思い出があったなと今思い出しました w 今は実務でバリバリ触れているからこそ初心を忘れてしまったのかもしれないので、情報発信の大事さを今一度噛み締めました
で、 2022/02 の現在ふとリアル開催?の時に比べるとオンライン開催ってめちゃくちゃ省エネで開催できるなと気が付きました&amp;hellip;!
開催の手間 やるべきことを簡単に洗い出してみます。
共通部分 開催前 登壇者探す connpass 作成 Twitter 告知 当日 Twitter 実況 司会 リアル開催 数ヶ月前 会場確保(自分の場合メルカリの会場を毎回スポンサーとしてお借りしていた)。なぜならメルカリが勉強会会場として高頻度で使われるのでハコを抑えるのが毎回激戦区だった。 スポンサーしてもらうために申請 当日(会社にて) 開催ビルで準備。入場用の道具(入場用、案内用の看板設営、ポスター印刷して看板に挿入) 開始時間 1 時間前から動き出す 懇親会のデリバリー受け取り、配備 会場の音響設備、接続確認 100 個以上の椅子や机を勉強会スタイルに並び替える(これがマンパワーが必要で地味にきつい、これを運営のみんなでやっていた) 登壇者全員の接続確認 懇親会終了後撤収 ゴミなどがちゃんとゴミ箱に捨てられているかの確認と清掃 机・椅子などもきれいに全部拭いて、元の形に戻す。基本的に準備したものをすべてもとに戻していく 9 回目以降は、撤収ボランティア枠を設けて手伝ってもらっていた。確か 8 回目の時に @keisuke_umezawa さんや @nasuka さんが手伝いますよと自発的に行ってもらえてめちゃくちゃ感激した覚えがある(実際は 4-5 人に手伝ってもらいましたが全員は覚えてないです、すみません)。この場面は本当~に良い記憶として残っている。なんか運営していてよかったと思った一番の記憶かもしれない。その後毎回無償で手伝ってもらうのは申し訳ないので、抽選枠ではなく、ボランティア枠と撤収作業を手伝ってもらえると、確実に勉強会に参加できますよという仕組みを作った覚えがある。 21:30 に撤収開始で、終わるのは 22:30 くらい。帰宅は日付が変わるか変わらないかという感じ オンライン開催 前日 配信が問題なくできているかのリハーサル 当日(自宅にて) 開催 30m 前に登壇者にビデオチャットに参加していただき、接続確認 懇親会終了後、そこはすでに自宅。例えば 23 時に終わったとしても、23 時には家にいるこれって凄い。 とオンライン開催のコストは比類できないほど低いことがわかりますね。</description></item><item><title>技術的負債は必要にかられて解消するからこそ大きな価値を生み出すのでは? というお話</title><link>https://shunyaueta.com/posts/2022-02-01/</link><pubDate>Tue, 01 Feb 2022 21:19:15 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-02-01/</guid><description>最近、技術的負債の優先順位付けとどうやって消化すべきかを考えていた時に、同僚のスーパーエンジニアの方から本質的なアドバイスを聞けたのでメモ。 自分は技術的負債タスクの消化をどうやって仕組み化して、定常的に消化していくべきかを試行錯誤していた。
なぜなら、機能開発と比較すると優先度が低くなりがちな技術的負債タスクを定常的に消化できているチームこそ、短期と中長期の視線を兼ね揃えたバランスが取れた戦略が取れているのではと考えていたからだ。 なので消化できないのは仕組み化がうまくできていないから、どうにか解決できないかなと思っていた。
だが、同僚がくれた言葉で目から鱗が落ちた
その技術的負債解消が本当に必要ならやりますよね。 必要でないならやらない、他にもっと重要なタスクがあるなら、そっちを優先するのでいいんじゃないかなと。 本当に必要なタスクならやると優先順位付けするので、直近必要でないと思っている無理して消化する必要はないですよ。
なるほど、これに尽きる。 今までは優先度が低かったとしても技術的負債タスクを消化できていることが良い文化なのではと勘違いしていた。
そのタスクを解決したら何が嬉しいか、どんな価値を提供できるかを常に考えて、優先順位付けを行って抱えている技術的負債タスクの中でも選定して解くべき課題に集中して解くべきだと学べた。
それこそが価値を生み出すエンジニアだなぁ。学び
注)もちろん場合によりけりなので、自分がいる環境での学びです。</description></item><item><title>Slack チャンネルに GitHub の特定リポジトリのrelease を通知する</title><link>https://shunyaueta.com/posts/2022-01-27/</link><pubDate>Thu, 27 Jan 2022 11:44:11 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-01-27/</guid><description>Slack 公式のヘルプページには反映されていないが、GitHub の Slack integration で特定リポジトリの release を購読してチャンネルに通知することができる。
利用用途としては、更新を追いかけておきたいリポジトリやリリースチャンネルに対して、リリースが作成されました、このリリースが次のデプロイ予定だよと通知させたい場合に便利。
Slack コマンド
# リリースを購読 /github subscribe elastic/elasticsearch releases # デフォルトで、issues, pulls, commits, release, deployment すべてが購読されてしまうので、 releases 以外購読を解除 /github unsubscribe elastic/elasticsearch issues,pulls,commits,deployments Slack の日本語公式ドキュメントにはフィードバックを送ったので、近いうちに反映されるかもしれない
References GitHub と Slack を連携させる integrations/slack</description></item><item><title>OSS の Google BigQuery UDF `bqutil.fn` を使えば UDF の独自実装を置き換えられるかもしれない</title><link>https://shunyaueta.com/posts/2022-01-20/</link><pubDate>Thu, 20 Jan 2022 00:03:07 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-01-20/</guid><description>TL;DR; UDF を独自実装する前に、bqutil.fnを眺めておくと車輪の再発明が回避できるかも
背景 SQL は、特定の処理を行う際にデータの型が同一でないとエラーが発生しますが、もとのスキーマを紹介するよりももっとお手軽にカラムの型を確認したいときがありませんか?
例えば、出力結果を見ただけでは、12345 が STRING なのか INT64 なのか判別不可能ですよね。(もし判別可能な方法知っている人いたら教えて下さい&amp;hellip;)
GCP による OSS UDF の bqutil.fn なのでお手軽に BigQuery の結果の型を確認したい時になにか良い方法がないかなと調べていたら、OSS でbqutil.fnという UDF が GCP から提供されていた。
例えば型の確認の場合、以下の ユーザー定義関数（UDF) はどの GCP プロジェクトから実行しても実行可能
bqutil.fn.typeof() このbqutil.fn はbigquery-utils/udfs/community/のディレクトリに格納されている UDF がbqutil という GCP プロジェクトのfn データセットに同期されているので、どの GCP プロジェクトの Google BigQuery から実行しても bqutil.fn.typeof()を実行可能にしているらしい。 頭良い
This directory contains community contributed user-defined functions to extend BigQuery for more specialized usage patterns. Each UDF within this directory will be automatically synchronized to the bqutil project within the fn dataset for reference in queries.</description></item><item><title>GitHub discussion を使ったコメントシステム giscus を導入</title><link>https://shunyaueta.com/posts/2022-01-19/</link><pubDate>Wed, 19 Jan 2022 00:21:05 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-01-19/</guid><description>Blog にコメントシステムを採用したいなと思って giscus を入れてみた。
経緯 Blog を読んだ際にコメントするまでではないけど、書いた人に対するシグナルとして、絵文字リアクションという仕組みがとても好き。 Medium だと clap 👏 だったり、はてなだとはてなスター ⭐️ ですね。また Slack や GitHub の emoji reaction も同じ発明だと思う
また、はてぶや Twitter 以外でも感想が書ける場所があると良いのではと思いコメントシステムを Blog に導入してみた。
選定基準 コメントシステムの採用候補は２つ
utterances GitHub issues をベースにしたコメントシステム giscus は GitHub Discussions をベースにしたコメントシステム 両者とも OSS で、コメントのデータを GitHub 上で保持できるのが魅力的。 DISQUSも同じ機能を提供してくれているが、自分のデータは自分で持ちたいかつデザインが激しめな印象があるので、uttrances, giscus が候補に残った。
両者ともデザインシンプルで良い。
だが、giscus は コメントを取り扱うなら issues ではなく Discussions のほうが適しているという動機から作られた。
giscus は記事に対してリアクションができたり、コメントに関する voting もあるので、迷わず giscus を採用する流れとなった。
確かに issues よりも GitHub Discussions のほうがコメントという概念に適していると思う。
というわけで GitHub でサインインすれば記事末尾にて、giscus を通じてコメントやリアクションができるようになったので、リアクションお待ちしております&amp;hellip;! 👇</description></item><item><title>Search Engineering Newsletter vol.00</title><link>https://shunyaueta.com/posts/2022-01-16/</link><pubDate>Sun, 16 Jan 2022 00:00:37 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-01-16/</guid><description>検索技術とその関連領域を取り扱うニュースレターを不定期配信してみることにします。
2022 年から心機一転として、情報発信を今まで Twitter メインでやっていましたが、ニュースレターで行っていこうと思っています。 以下の Revue のリンクから登録が可能です。
Search Engineering Newsletter By hurutoriya
扱うトピックとしては、検索エンジンと情報検索の周辺領域です。 経緯としては、自分の職域である情報は積極的に収集しており、どうせなら発信したいなと考えて Twiter や、機械学習エンジニア時代には Revue を使って MLOps 領域に特化してニュースレター配信を試しにやってみた(覚えているかたもいるかも?)ことがありましたが、結局 Twitter で配信すれば同じではと考えてしまい、なんだかんだ継続できませんでした。
ですが、最近は Twitter での情報取得から抜け出して、一息ついた状態で情報収集を行うようになりたいなと思うなかで、改めて Twitter の発信だけではなく、ニュースレターのように頻度は不定期だが高品質な情報が一箇所にまとまって届けることができたら面白いなと考えました。(またニュースレター形式だと Twitter では届かない層にも届くんじゃないのかなと)
現在は自分は検索エンジニアとして働いており、検索技術と情報検索の情報を積極的に収集しています。そのなかで自分が当該領域で注目したニュースレターを不定期に配信できればなと思ってニュースレターを再開してみました。 検索領域に関連する気になった記事や自分の Blog 記事の執筆などをここで紹介していきます。
不定期配信ですが、興味を持っていただけたらぜひ購読をお願いします。</description></item><item><title>OSSのアノテーションツール Label Studio を使って、快適にアノテーションする</title><link>https://shunyaueta.com/posts/2022-01-09/</link><pubDate>Sun, 09 Jan 2022 23:05:16 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-01-09/</guid><description>Google Spread Sheet による即席アノテーションの限界 データ分析で、ラベルがないデータに対して、自分でアノテーション(ラベルを付与)してデータの傾向を素早く掴みたい時がある。 例えば、文章に対してネガティブ・ポジティブなクラスを割り振ったり、画像に対して人が写り込んでいるか否かなどの簡単な分類タスクでは、お手軽に Google Spread Sheet などを使って、500 件のアノテーションはそこまで問題がなく気合でやれる。
実際の流れとしては、GCP を採用している場合、Google BigQuery から SQL でデータを抽出してそのまま Google Sprad Sheet に出力、=image()関数で CDN から画像の URL を参照できたりなどなどかなり便利。 Spread Sheet を共有して複数人でも作業ができるのも魅力的。
だが、文章の特定の部分を選択してタグを付けたかったり、クラス数が二桁など少し複雑なアノテーションタスクを行いたい場合 Google Spread Sheet では、アノテーションの生産性が劇的に落ちる、もしくは不可能になる。あくまで Google Spread Sheet はお手軽にラベリングを行うだけで、ラベリング専用ツールではないので当然の帰着ではある&amp;hellip;
Label Studio とは 今回紹介するLabel Studioは OSS データのラベリング(アノテーション)ツールは、
画像 画像分類 物体認識 セマンティックセグメンテーション 音声 音声分類 話者分類 感情認識 文字起こし 文章 文書分類 固有表現抽出(NER) 質疑応答 感情分析 時系列データ 時系列分類 時系列分割 イベント認識 マルチモーダル 対話処理 文字認識(OCR) ビデオ・音声の時系列分類 など多種多様なドメインに対してラベリングを行うことができるソフトウェアだ。
また、アカウント認証や、キーボードショートカットなどアノテーションの生産性を向上させる基本的な機能が標準で搭載されており、アノテーション効率の向上と管理が期待できる。
同様に OSS の自然言語タスクに特化したアノテーションツールのdoccano も検討したが、Label Studio は自然言語以外にも画像やランキングなど多種多様なラベリングタスクに対応しているので、後々にアノテーションしたいデータの種類が増えたとしても Label Studio を活用できて便利そうなので、今回は Label Studio を選択した。</description></item><item><title>2021年に買って愛用しているもの</title><link>https://shunyaueta.com/posts/2022-01-07/</link><pubDate>Fri, 07 Jan 2022 21:14:25 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-01-07/</guid><description>2021 年に購入して、今も愛用しているものを記しておく。 買ったものだと、その後愛用しているか定かではないかつ良い品なのかわからないので、愛用しているもの限定です。
CORONA(コロナ) 衣類乾燥除湿機 除湿量 18L (木造 20 畳 / 鉄筋 40 畳まで) 日本製 Amazon
買ったきっかけは、2020 年に築浅の物件に引っ越したが新築の傾向なのか湿気が溜まりやすく、油断して、パントリーの床においていた旅行用のボストンバッグがカビてしまっていたことがあった。水取りぞうさんなどで対応していたことがあったが、知らぬ間に満水になり気づくのが遅れることが多かった。
そのため思い切って一番除湿力が高そうなこの機種を買ったところ大満足。梅雨の時期には一晩起動しておくと朝には 4.5L のタンクが必ず満タンになり、部屋の中に漂う嫌なモワモワ感が完全に消え去って住心地が圧倒的に向上した。また副次的に良かったのは衣類乾燥機能がすごく良かった。雨で部屋干しをせざるを得ないときもこの機能を使えば全く臭わずに乾燥させることができて、一粒で二度美味しい家電だった。またフィルターも 10 年は交換しなくても良いのが良い。1 年経った今でも全く臭わない。タンク自体も特有の臭さが全くないので最高。
AfterShokz Aeropex 骨伝導イヤホン Amazon
リモートワークの開始に伴い、最初は 2019 年頃にオフィスでの騒音対策として購入したWH-1000XM3を使っていたのだが、長時間つけると耳が痛くなることが多かった。またイヤーインタイプのイヤホンも自分は耳の形が合わなくてフィット感がいまいちだったりモゾモゾして 1 時間のミーティングでも嫌なことが多かった。AirPods も検討したが、自分は iPhone ではなく Pixel を使っているし、気づかずに落として紛失しそうで怖かったのでなにか良いイヤホンがないか探していた。Shokz はその悩みを完全に解決してくれた。耳は防がないし、1-2h つけても全く痛くならないし、何より軽い。Shokz はいろんなシリーズがあるが、
ミドルレンジのものを買ってなんか違うなと思うのは嫌だったので思い切ってハイエンドモデルを買ったがとても満足している。もしかしたらOpenMove でも良いかもしれないが、試したことがないのでわからん。ブランド名も After・Shokz から Shokz に変わって、(OpenRun Pro)が出たのでちょっと気になっている。バッテリーが更に長持ちなのと小型化、低音が効くようになったらしい。
Shokz いいですよね！自分も使ってます。新しく出る OpenRun 系統は 29g と、Aeropex と比べると 3g 重いようです。小型化の方がより適切かと感じました。 by @tatsuokundayo
2022/01/08: @tatsuokundayo さんにご指摘いただいた点を修正
WH-1000XM3はノイズキャンセリング機能は感動するレベルだったが、オフィスに行くことがなくなった今、用済みなのでメルカリで売った。速攻で売れたので気持ちよかった。
Xiaomi Mi ハンディクリーナー ミニ Mi Vacuum Cleaner Mini コードレス ミニ掃除機 ハンディ掃除機 Amazon</description></item><item><title>Python で DeepL API Free を利用してテキストファイルを翻訳する</title><link>https://shunyaueta.com/posts/2022-01-05/</link><pubDate>Wed, 05 Jan 2022 23:02:06 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-01-05/</guid><description>機械翻訳サービスの DeepL はアプリだけでなく API 提供も行っている。 今回は DeepL が公開している free API を利用して、テキストファイルを英日翻訳して、翻訳結果をテキストファイルとして保存する方法について説明する。
無料 API は1か月あたり500,000文字の上限ありの制限があるが、Pro version と変わらない品質の翻訳を行うことができる。 個人利用する分にはこの文字数制限は特に大きな問題にはならないと思われる。
https://www.deepl.com/ja/pro#developer
まずアカウントを作成して、DeepL API Free のAPI_KEYを入手する。 その後、以下のスクリプトを実行すれば、翻訳元のファイル名にJA_という接頭辞がついたファイルが保存される。
import requests # NOTE: put API KEY API_KEY:str = &amp;#39;&amp;#39; # NOTE: put target file path target_file:str = &amp;#34;&amp;#34; with open(target_file) as f: txt = f.read() params = { &amp;#34;auth_key&amp;#34;: API_KEY, &amp;#34;text&amp;#34;: txt, &amp;#34;source_lang&amp;#34;: &amp;#39;EN&amp;#39;, &amp;#34;target_lang&amp;#34;: &amp;#39;JA&amp;#39; } request = requests.post(&amp;#34;https://api-free.deepl.com/v2/translate&amp;#34;, data=params) result = request.json() with open(&amp;#34;JA_&amp;#34;+target_file, &amp;#34;w&amp;#34;) as text_file: text_file.</description></item><item><title>2022 年の目標</title><link>https://shunyaueta.com/posts/2022-01-01/</link><pubDate>Sat, 01 Jan 2022 21:34:30 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-01-01/</guid><description>Objective 1 検索エンジニアの領域でシニアレベルのスキルを身につける
KR 1 2022 年に国際会議・インダストリー会議のどちらでも良いので、対外発表できる成果を出す 成果を提出するのは 2023 年で OK
KR 2 Python, Go の両方を自信を持って書けるように。 TODO: 定量的に測定して数値化する
Write Code Every Day とか良いのかもしれない? wakatime とかでどれくらい書いたかを算出しても面白いかもしれない。 もしくは Atcoder とか?
Objective 2 有限な自分の時間の管理を生産的に行って、手を動かしまくる習慣を身につける
KR 1 Toggl を積極的に使って、1 年間どれだけ生産的な時間を創出できてか可視化する KR 2 継続して、SNS は断つ(ダラダラと見ない) 2021 年も設定していたが、2022 年も引き続き。連絡手段と周知を行うことのみに特化して使うようにする。 SNS での情報取得は辞めて、RSS や News letter などで情報を取得するようにしはじめた。今の所凄く良い。 自分も News letter を過去にやって続かなかったりしたけど、なんかやってみたいなと思うようになりつつも Blog でいいのではと思ったり&amp;hellip;
KR 3 2021 年の 5 月から開始している翻訳プロジェクトを一段落させて出版可能な状態まで持っていく 詳細はまで伏せますが、自分が発起人の翻訳プロジェクトがあるんですが、今年の年末までには出版可能な状態まで仕上げていきたい。 友人 2 名を誘って始めたプロジェクトだが、初めての経験ということもあり学びが多い。
KR 4 (Advance) 自前で検索エンジンを運用した個人開発のサービスを作る。 同僚の@yomo さんが、個人で検索サービスを運営しているのですが、この取組が素晴らしいなと思ったので自分も真似したい。</description></item><item><title>2021 年振り返り</title><link>https://shunyaueta.com/posts/2021-12-29/</link><pubDate>Wed, 29 Dec 2021 22:42:08 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-12-29/</guid><description>うなすけさんの wakatime を利用した振り返り方が面白かったので、来年は真似したいと思い導入してみた。
サーバーサイドエンジニアとして 2021 年に使った技術と来年の目標
なので先週くらいから wakatime を使って、VSCode での利用統計をとってみることにした。
https://wakatime.com/
Markdown が圧倒的に多いのは現在 Markdown で執筆活動をしてるからですね。
仕事をほぼ納めてから導入して執筆しかまともにしてないからこうなってるな。。。 詳細は今はお話できないのですが、再来年くらいには形になっていることを祈る。
利用した技術一覧 Language New: Go Backend 開発ではメインで使っている。今までは Python がほぼメインだったが、検索チームに異動したことで Go が必要不可欠になったので頑張って習得中。久々に新しい言語に触れるけど新鮮な気持ち。明確に型があると、エディタがガンガンサジェストしてくれて楽しい。間違ってるとすぐ知らせてくれる。Go も Python までのレベルまで引き上げて書けるようにしておきたい所存。 New: Java (code reading) 主に Apache Lucene と Apache Beam の code reading をしていたのがメイン。同僚からは VSCode ではなく、IntelliJ IDEA 入れたほうがめちゃくちゃ捗るよと言われつつもまだ使いこなせていない&amp;hellip;。Lucene, Solr, Elasticsearch のどれかに来年は contribute してみたい。 Python Google BigQuery と組み合わせたデータ分析や可視化、Airflow で利用。あとは機械学習サービスの改修でも書いていた。なんだかんだ手に馴染んでいるのがやはり Python で、2022 年は一段階上のコードを書けるようになりたい。1/4 ほど読んで積ん読になってしまっている Fluent Python を読みきらないと&amp;hellip; StandardSQL Google BigQuery でお世話になっている。まだまだ「え、こんな便利関数あったんだ」となる。ちょっとした前処理は BQ に投げたほうが遥かに効率が良いので、BQ→Python で何をどこまでやるかはバランス感覚がやはり大事。 Software New: Apache Beam Java は code reading, Python は自分で入門がてら形態素解析する Beam model を書いていた。Apache Beam Go SDK が GA になったので、なにか作りたい。原著論文も勉強会で今度話したいな。ストリーミングで処理を行いたい際には、選択肢の第一候補に入るソフトウェアかつ動いている仕組みがめちゃくちゃおもしろいので、もっと深堀りして書いていきたい。 New: Apache Airflow (CloudComposer) GCP の各サービスを組み合わせてゴニョゴニョしたいときにものすごく楽。なれるまではデバッグが辛かった。そんなにこなれたことやっていなかったとしても、ピタゴラスイッチ的なデバッグが必要になることが多いので、最初は辛かったけど、慣れたらめっちゃ便利。 New: Apache Lucene 社内の code readning 勉強会で、近似近傍探索のロジックを眺めていた。 Amazon が e コマース検索を Lucene により、どうスケールさせているか at Berlin Buzzwords 2019 の記事でも Lucene 自体の特性を表層的に理解できてスゲーッ!</description></item><item><title>Jupyter Notebook で画像をダウンロードすることなく、URLから参照してPandas DataFrame内部に表示させる</title><link>https://shunyaueta.com/posts/2021-12-28/</link><pubDate>Tue, 28 Dec 2021 23:04:19 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-12-28/</guid><description>データ分析などをしていると、画像はダウンロードせずに特定の CDN (GCP なら GCS, AWS なら S3 など)で提供されている画像を参照して、 Jupyter Notebook 上で良い感じに表示させたいときがありませんか?
例えば、画像と説明文がペアになっているデータを画像自体はダウンロードせずに Jupyter 上で画像と説明文を DataFrame として表示させたいときが多々ある。 元の画像自体は CDN に格納されていて、画像をダウンロードする必要はなく参照するだけのときにはすごく便利。 毎度画像を CDN からダウンロードするのも無駄なので、画像を加工せずに Jupyter 上で表示するだけなら、この方法がベストですね。
url からとってきた画像を jupyter に表示する でも同じような課題に取り組んでいるが、今回紹介する方法なら余計なパッケージを入れずに最小構成で Jupyter 上で表示できるのが利点。
import pandas as pd from IPython.display import HTML # NOTE: https://www.irasutoya.com/2021/01/onepiece.html から画像を参照 onepiece = { &amp;#34;モンキー・D・ルフィ&amp;#34; : &amp;#34;https://1.bp.blogspot.com/-uxIsaN0S5lQ/X-FcrvAAInI/AAAAAAABdD4/6uw_qNUh9dQrG0aUzIExybt84yTEmXOPwCNcBGAsYHQ/s200/onepiece01_luffy.png&amp;#34;, &amp;#34;ロロノア・ゾロ&amp;#34; : &amp;#34;https://1.bp.blogspot.com/-rzRcgoXDqEg/YAOTCKoCpPI/AAAAAAABdOI/5Bl3_zhOxm07TUGzW8_83cXMOT9yy1VJwCNcBGAsYHQ/s200/onepiece02_zoro_bandana.png&amp;#34;, &amp;#34;ナミ&amp;#34; : &amp;#34;https://1.bp.blogspot.com/-2ut_UQv3iss/X-Fcs_0oAII/AAAAAAABdD8/jrCZTd_xK-Y6CP1KwOtT_LpEpjp-1nvxgCNcBGAsYHQ/s200/onepiece03_nami.png&amp;#34;, &amp;#34;そげキング（ウソップ）&amp;#34; : &amp;#34;https://1.bp.blogspot.com/-mZpzgXC1Sxk/YAOTCAKwWTI/AAAAAAABdOM/5B4hXli0KLU5N-BySHgjVbhZscKLSE-bQCNcBGAsYHQ/s200/onepiece04_usopp_sogeking.png&amp;#34;, } df = pd.DataFrame({&amp;#34;Name&amp;#34;: onepiece.keys(), &amp;#34;Image&amp;#34;: onepiece.values()}) def path_to_image_html(path): return f&amp;#39;&amp;lt;img src=&amp;#34;{path}&amp;#34;/&amp;gt;&amp;#39; pd.</description></item><item><title>Amazon検索ランキングの奥深さ at MLconf SF 2016</title><link>https://shunyaueta.com/posts/2021-12-26/</link><pubDate>Sun, 26 Dec 2021 22:52:06 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-12-26/</guid><description>1 日遅れてしまいましたが、情報検索・検索技術 Advent Calendar 2021 25 日目の記事です。
ついにアドベントカレンダー最終日を迎えました! 今年はまだ検索領域のアドベントカレンダーが作られていないからということで、勢いで情報検索・検索技術 Advent Calendar 2021を作りましたが、多くの方に投稿に協力していただきありがとうございました。
社内勉強会の発表でネタを探しており、2016 年と少し昔の情報ですが、Amazon の製品検索において、どのようにランキングを行っているかの公演動画が非常に面白かったので、勉強がてら残したメモを記事として公開します。
今回の口頭発表は MLconf という開発者会議(非学会・非アカデミック)で発表されています。 自分が知る限り、MLconf は機械学習黎明期から高品質な発表が継続されて発信されており、非常に素晴らしいカンファレンスの一つ。 国際会議には投稿されていないが、実応用の観点からしてとても学びの多い発表がとても多いです。 機械学習の応用を考えている場合、世界の最先端事例を知ることができるので非常におすすめです。
Referemces Sorokina, D., &amp;amp; Cantu-Paz, E. (2016, July). Amazon search: The joy of ranking products. In Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval (pp. 459-460).
Amazon Search: The joy of ranking products in amazon science Youtube メモ 自分の私的な意見は NOTE: で書いておきます。</description></item><item><title>Offers Magazine というメディアに、エンジニアによる業務実績の論文化について寄稿した</title><link>https://shunyaueta.com/posts/2021-12-07/</link><pubDate>Tue, 07 Dec 2021 22:58:10 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-12-07/</guid><description>少し前のことだが、Offers Magazine さんに、「エンジニアによる業務実績の論文化」をテーマとして寄稿した。
機械学習エンジニアの学会での論文発表のススメ。応募から査読通過までの流れ
メディアに寄稿するのは初めてなので良い経験になった。
会社によっては業務成果を論文提出まで持っていくまでに難しい会社もあるかと思いますが、それに見合った対外的な成果を得れたので本当にやってよかったと思える。 USENIX は、MLOps に限らずシステムやセキュリティ、SRE 領域など、ソフトウェアエンジニア領域で幅広く投稿できるので、自分の成果を引用可能な形式で残したい人にはぜひ投稿してみたほしい。 素晴らしい仕組みを USENIX は提供していると思う。
何より自分にとって、この分野のエキスパートのレビュアーからこの成果を対外発表するのは非常にリスペクトするとコメントをいただけたりして、良い刺激になった。
論文公開して一年と少しが経過して、先日 Google Scholar を確認すると引用数が 1 になっていて非常に嬉しい!!
Auto Content Moderation in C2C e-Commerce citation
2021 年には、機械学習エンジニアから検索エンジニアになったが、この分野も論文化できそうなネタが無限にあるので時間はかかるだろうが 2023 年には論文提出ができる段階になりたい(否、なる)。</description></item><item><title>投げ銭サービスのBuy me a cofee をBlog に導入してみた</title><link>https://shunyaueta.com/posts/2021-12-04/</link><pubDate>Sat, 04 Dec 2021 22:24:38 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-12-04/</guid><description>@potato4d さんや @takuti さんがBlog に Buy me a cofeeを導入していて、自分も導入したいと思いたち、導入してみた。
やったこととして、Blog記事の末尾に、サポート機能として自分のbuy me a cofeeページへのリンクが表示されるようにした。
導入経緯 以下のポストに強く共感と興味を持った。特に良い文章は抜粋しておく
情報に対して価値を感じてくれた人に還元してもらえるのは素直に嬉しい
ブログに Buy Me a Coffee の投げ銭導線を設置した @shu223 さんの とにかく、「技術の発信」でも収入が得られる時代が到来しつつある
技術書でご飯は食べられるのか？ #技術書典 技術で稼げるようになった今、内発的動機（興味）があっても外発的動機（お金）が伴わないと優先度が上がりにくいということは起きていて、だからこそ勉強自体でも稼げるようよう仕組み化したいと思っていて、それが去年から試行錯誤してる「技術情報発信のマネタイズ」です。 tweet
の方針に凄く興味と共感が持てた。
拝金主義というわけではなく、投げ銭文化自体が凄く良い文化なので自分もその波に乗ってみたさがあり、導入してみた。
zenn やnote でも良い記事だなと思った際には、投げ銭をしたりするが、個人Blog でも簡単にその機能が作れるのは良い時代になった。
もし自分が価値ある情報を提供することで、誰かの助けになり、その人達が還元してくれたなら凄くよいなと思った。業界全体がその流れになると面白いと思う。
早速、この前書いた記事 を友人に送ったら、メンテナンスお疲れ様の意をこめて Coffee ☕️ を奢ってくれた。
へんたい運用お疲れ様でした link
手探りで作った記憶が蘇る。開発、メンテとありがとう link</description></item><item><title>2013年4月に友人とリリースした高専からの大学編入体験談投稿サービスが8年の時を経て成仏した</title><link>https://shunyaueta.com/posts/2021-12-03/</link><pubDate>Fri, 03 Dec 2021 23:28:52 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-12-03/</guid><description>高専 5 年生の卒業前の春休みに友人 3 人と集まって、2013 年 4 月にリリースした個人開発の Web サービスが完全に終わりを迎えた。
2021 年の現在から換算すると 8 年以上前の出来事であり、時の流れは凄まじい。
先程アプリをデプロイしていた Heroku 上からも完全に削除をしたのだが、色々と昔のことを思い出したので筆を執ってみる。
開発当時 当時仲の良かった同じクラスの友人 3 人で、春休みに友達の家に泊まりつつ 2 泊３日で、Rails 3 でロジック部分を作り上げた。 Twitter ログインや DB 定義なども本を読んだり、ネットの記事を参考にひいこら言いつつ実装していった。
Heroku を使って、 http://kosen.herokuapp.com/ という URL でサービスを提供しており、Twitter ログインで編入体験談投稿、ログイン無しで掲示板で編入情報について交換できるような機能を提供していた。(注: サイト名のネーミングセンスが若気の至りすぎるので言及しません)
最終的に Bootstrap で見た目を整えて、編入後の授業が本格的に始まる前の 2013/04/10 にはリリースしていた模様。
共同開発した友人の 2013/04/28 に書かれた当時のブログ記事が残っていた。 8 年経過しても、その時の状況がブログ記事として残っているの凄い。 自分はブログのホスティングサービスをひたすら変遷して、現在の GitHub pages に落ち着いたので尊敬する。
ついに動き出しました!! 編入体験談のまとめサービス 「HenTai ~編入体験談~」 http://kosen.herokuapp.com 午前 0:15 · 2013 年 4 月 10 日 tweet
当時全く Web サービスの運用方法も全く知らない自分が、インターネット上に Rails アプリを公開できたので間違いなく Heroku のおかげだと思う。GitHub repository と連携して Push すれば Rails アプリがデプロイされる体験はとても簡単だった。</description></item><item><title>kubernetes デプロイ時に `MatchExpressions:[]v1.LabelSelectorRequirement(nil)}: field is immutable` エラーが出た際に対処方法</title><link>https://shunyaueta.com/posts/2021-12-02/</link><pubDate>Thu, 02 Dec 2021 16:48:54 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-12-02/</guid><description>k8s で manifest file を編集して実行したら以下のようなエラーが出て実行できなかった。
Exception ( Monitor Deploy ) Deploy failed: The Deployment “&amp;mdash;” is invalid: spec.selector: Invalid value: v1.LabelSelector{MatchLabels:map[string]string{“app”:“&amp;mdash;”}, MatchExpressions:[]v1.LabelSelectorRequirement(nil)}: field is immutable
調べてみたところ、
once deployed the label selectors of kubernetes service can not be updated until you decide to delete the existing deployment
ref: MatchExpressions:[]v1.LabelSelectorRequirement(nil)}: field is immutabl #508
らしく、一度デプロイされたk8s service の label selector は、既存のdeployment を削除しないとアップデートは不可能らしい。
なので、field is immutableというエラー文は正しいわけですね。
そのdeployment を削除しても良い状態なら、以下のコマンドを実行後再度デプロイすれば、k8s service のlabel selector は実行されます。
kubectl delete deploy &amp;lt;deployment-name&amp;gt; もしくは、k8s service のlabel selectorの変更を諦めて既存のまま運用するのがもう一つの正解でしょうか。</description></item><item><title>Amazonがeコマース検索を Lucene により、どうスケールさせているか at Berlin Buzzwords 2019</title><link>https://shunyaueta.com/posts/2021-11-26/</link><pubDate>Fri, 26 Nov 2021 20:59:21 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-11-26/</guid><description>情報検索・検索技術 Advent Calendar 2021 1 日目の記事です。 早めに書き終えたので、カレンダー登録日の 2021/12/01 よりもはやめですが、記事を公開してしまいます。
Berlin Buzzwords はドイツで毎年開催されている OSS を利用した検索、データ処理、データベースに焦点をあてたカンファレンスです。
検索関係のシステムに携わっている場合、毎年面白い内容が目白押しなのでぜひとも見てほしい。
今回は Berlin Buzzwords 2019 で発表された「Amazon では Lucene をどう活用して e コマース検索をスケールさせているか」の講演動画を社内勉強会で紹介するために視聴したので、そのメモを公開する。
E-Commerce search at scale on Apache Lucene YouTube Web page PDF 自分の所感などを切り分けるため、自分の意見は IMO ではじめた文にして、メモっています。
Overview クエリの p999 latency に対して非常に厳しい制限を行っている IMO このクエリの p999 latency 定義は、Lucene+(おそらく内製で今も開発している、response を返すための Lucene server?)が返す検索のレスポンスを指していると思われる p99.9 latency を SLA として、監視しているのはたしかにとてもシビアな基準だと感じる。 Amazon の query rate はめちゃくちゃピーキー (daily, weekly, yearly) Why Lucene? Lucene は成熟しており、豊富な検索エンジンの機能が揃っている 情熱を持ったコミュニティが存在している Uber, Airbnb, Linkedin 全部 Lucene を使っている maxscore scoring , Weak AND, Lucene 8.</description></item><item><title>Standard SQLのCOALESCEで、時間経過によってカラム名が変化したデータを柔軟に抽出する</title><link>https://shunyaueta.com/posts/2021-11-06/</link><pubDate>Sat, 06 Nov 2021 22:40:02 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-11-06/</guid><description>データの蓄積帰還が長くなってくると、例えば JSON 形式でログを取っているが、同じデータでもマイグレーションやロギングロジックの更新などでkey の名前が変化したりする場合がある。
その場合取り扱いに困るのが、古い key と新しい key をどのように併合するかだ。 例えば特定の日次できれいにデータが入れ替わっているのなら、色々やりようがあるが、クライアントなどのログの場合データの変化も均一ではないので、徐々に変化していることが大半なので、日次で別々の抽出をして結合するというアプローチも難しい。
その際に役立つのが Standard SQL 条件付き構文の COALESCE だ。
COALECSCE は、引数の最初の非 NULL の値を返す関数で、
COALESCE(NULL, &amp;#39;B&amp;#39;, &amp;#39;C&amp;#39;) だと Bが返される。この関数を使うことで、複数カラムを一つに併合することができる。
具体例を交えつつ実践してみる 例えば、以下のように昔のカラム名が title で、全く同じデータが新しいカラムの title_v2 に入ってきているとする。
NOTE: json を例題に key の抽出にしたほうが実際の状況に沿いますが、カラムのみで表現したほうが説明が簡単なので今回はそちらを採用。
用意したデータ WITH menues AS (SELECT &amp;#34;うどん&amp;#34; as title, NULL as title_v2, &amp;#34;2021/10/06&amp;#34; as created UNION ALL SELECT &amp;#34;ラーメン&amp;#34;, NULL, &amp;#34;2021/10/07&amp;#34; UNION ALL SELECT NULL, &amp;#34;そば&amp;#34;, &amp;#34;2021/10/08&amp;#34; UNION ALL SELECT &amp;#34;カツ丼&amp;#34;, NULL, &amp;#34;2021/10/09&amp;#34; UNION ALL SELECT &amp;#34;カツ丼&amp;#34;, &amp;#34;カツ丼&amp;#34;, &amp;#34;2021/10/10&amp;#34; UNION ALL SELECT NULL, &amp;#34;カレー&amp;#34;, &amp;#34;2021/10/11&amp;#34;) SELECT * FROM menues title title_v2 created うどん 2021/10/06 ラーメン 2021/10/07 そば 2021/10/08 カツ丼 2021/10/09 カツ丼 カツ丼 2021/10/10 カレー 2021/10/11 2021/10/10 のデータなどは旧カラムと新カラムにダブルライトされています。</description></item><item><title>Google Cloud Pub/Sub に公開された結果はDataflow template を使えばめちゃくちゃ簡単に確認できる</title><link>https://shunyaueta.com/posts/2021-11-05/</link><pubDate>Fri, 05 Nov 2021 23:05:22 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-11-05/</guid><description>PubSub に出力された結果を確認するのって、なかなか手間がかかりませんか?
最近同僚に簡単な確認方法を教えてもらい、感動したのでそれを記事にしました。
確認方法 PubSub のメッセージを出力する Google Cloud Storage bucket を同一 GCP プロジェクトで作成する。 GCP の Pub/Sub ページに移動する 確認したい Pub/Sub topic をクリックする ページ下部にある CREATE SUBSCRIPTION ボタンを押すと選択肢で、Create subscription, Export to BigQuery, Export to Cloud Storageがあり、 Export to Cloud Storageを選択する。 BigQuery、 Google Cloud Storage への吐き出しを行い際に、自動的に subscription が生成される。 Export to Cloud Storage を選択すると、Text 形式か Abro 形式での出力にするかを選択できる。基本的には簡単に確認できる Text 形式を選ぶと良さげ。 選択後、下記のような設定画面が出てくるので情報を埋めていく。基本的には、どこの Google Cloud Storage に出力するかを埋めれば完了。 10m ほどすると Streaming job の Dataflow の起動が完了して、一定期間ごとに Pub/Sub の topic に公開されたデータがテキスト形式で出力され始めます。 出力された GCS の結果を眺めるには、 gsutil コマンドなどを使うのが簡単です。自分はgsutil cat の結果をコピーして VS Code で確認しています。 Cloud Dataflow のテンプレート機能については、端的に説明すると、GUI でパラメータを設定するだけで、Dataflow によるデータ処理が簡単に実行できるようになる機能です。</description></item><item><title>Airflow でDAGを任意のタイミングで一度だけ実行する方法</title><link>https://shunyaueta.com/posts/2021-10-12/</link><pubDate>Tue, 12 Oct 2021 00:07:05 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-10-12/</guid><description>Airflow で作成したDAGを自動で定期実行せずに、あえて手動実行で一度だけ実行したい場合もある。
DAGのオプションを以下のように設定する。
schedule_interval を &amp;ldquo;@once&amp;rdquo; に設定することで、一度だけDAGが実行される is_paused_upon_creation を True に設定することで、DAGが作成時に自動的に実行されず、DAGが停止状態で作成される。 デフォルトではFalseとなっており、自動実行される。 from airflow import DAG with DAG( dag_id=&amp;#34;sellerscore_initial_batch&amp;#34;, # NOTE: dosen&amp;#39;t need to repeat schedule_interval=&amp;#34;@once&amp;#34;, # NOTE: we have to manually start the this DAG is_paused_upon_creation=True, ) as dag: Reference Airflow: schedule_interval = &amp;lsquo;@once&amp;rsquo; Docs - airflow.models.dag</description></item><item><title>クエリ分類(Query Classification) について社内の勉強会で話してきた</title><link>https://shunyaueta.com/posts/2021-10-09/</link><pubDate>Sat, 09 Oct 2021 00:42:40 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-10-09/</guid><description>今年の 10 月から、新しく入社した同僚とともに、検索領域の論文や技術ブログを定期的に紹介する社内勉強会をはじめてみた。 定常的に開催されることが一番大事だよねという方針になったので、以下のような仕組みで、可能な限り低コストで継続できるような仕組みにした。
参加者は何も準備をしなくても大丈夫で、勉強会中に紹介された論文をみたり話を聞くだけで良い 発表者は凝った資料は用意するのは必須ではなく、極論論文を画面共有で見せながらしゃべるだけでも問題なし 当面の目標としては、来年の年末まで継続されているように気長に続けていきたい。
第一回は、発起人の一人である自分がクエリ分類について発表を行った。
Query Understanding for Search Engines (The Information Retrieval Series, 46) の第二章を主にテーマとして取り上げて紹介した。
メイントピックは KDDCup2005 として開催されたクエリ分類コンペの優勝者の手法について紹介を行ったので、気になる方はスライドを公開しているので御覧ください。
このコンペの特徴として、
データセットが生データ特有の問題として汚い そしてラベルデータの規模がとても少ない という鬼畜仕様だった。 だがコンペ参加者はそんな状態を物と物せずにありとあらゆる手段で精度向上に努めていてそれらの手法と姿勢がとても参考になった。
Query Understanding の包括的な解説は 晋策さんが書かれた 検索体験を向上する Query Understanding とは がわかりやすいのでおすすめです。
検索領域は本当に奥深い&amp;hellip;</description></item><item><title>Hugo で記事の更新日をgitと連携して自動的に取得して表示させる</title><link>https://shunyaueta.com/posts/2021-10-06/</link><pubDate>Wed, 06 Oct 2021 20:38:58 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-10-06/</guid><description>最近昔書いていた技術記事の情報が古くなりすぎて不正確なこともあったので、書き直すときがあったのだが、そのときに自動的に最終更新日を記事に表記できないか探していたら、実現方法があったのでメモしておきます。
やっていることは Last Modified Date with Hugo の記事をと完全に一緒だが、日本語での情報が無かったので備忘録がてら記録を残す。
Hugo は各ページに関する情報をFront Matter Variables という仕組みで Markdown 上に定義します。 主に YAML 形式で記述されていることが多いです。
lastmod という変数が更新日を表す変数であり、この変数に対して更新日の情報を与えてやれば記事の最終更新日を表現することができる。
Front Matter に lastmod: &amp;quot;2021-03-31&amp;quot; の形式で与えておけば、以下の形式で記事作成日と最終更新日を表記できる。
{{ $date := .Date.Format &amp;#34;02.01.2006&amp;#34; }} {{ $lastmod := .Lastmod.Format &amp;#34;02.01.2006&amp;#34; }} &amp;lt;p&amp;gt;Published on: {{ $date }}&amp;lt;/p&amp;gt; &amp;lt;p&amp;gt;Edited on: {{ $lastmod }}&amp;lt;/p&amp;gt; だが、毎回記事を編集するたびに lastmod 変数を追記するのは面倒なので自動化できるなら自動化したい。
config.yaml で、以下の設定を行う。
enableGitInfo: true enableGitInfoを trueにすることで、各ページに対してGit 情報を更新日として付与してくれる。
最後にconfig.yaml で以下の設定を行えば、 Front Matter の lastmod 変数に対して、 Front Matter で定義されているlastmod、もしその情報がなければ各ページの gitの最終コミット日を返すという設定がされる。
frontmatter: lastmod: - lastmod - :git 参考になると思うので、当ブログでの実際の変更点はこちら</description></item><item><title>CloudComposer のDAGをCircleCIで更新する</title><link>https://shunyaueta.com/posts/2021-10-04/</link><pubDate>Mon, 04 Oct 2021 22:23:24 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-10-04/</guid><description>Cloud Composer(Airflow) の DAG を GitHub リポジトリで管理して、CI によりリポジトリで管理している DAG を Pull Request がマージされると Cloud Composer の DAG へ同期する方法について説明する。
DAG は、ルートディレクトリ直下の dags/ というディレクトリに格納されている状態を前提とする。
以下の２つのコマンドラインツールを利用して実現できる。
Service Account の認証のために gcloud DAG の同期のために gsutil CircleCI によるワークフローの記述例は以下のとおり
version: 2.1 jobs: rsync-dags: working_directory: ~/workspace docker: - image: gcr.io/google.com/cloudsdktool/cloud-sdk:alpine environment: GOOGLE_APPLICATION_CREDENTIALS: /gcp-service-key.json steps: - checkout - run: name: Sync DAG folder to GCS&amp;#39;s DAG folder command: | echo &amp;#34;${CLOUD_COMPOSER_CREDENTIALS_JSON}&amp;#34; &amp;gt; ${GOOGLE_APPLICATION_CREDENTIALS} gcloud auth activate-service-account --key-file ${GOOGLE_APPLICATION_CREDENTIALS} gsutil -m rsync -d -r dags \ &amp;#34;$(gcloud composer environments describe {COMPOSER_NAME} --project={GCP_PROJECT} --location={REGION} --format=&amp;#34;get(config.</description></item><item><title>CircleCI アプリ内の設定ファイルエディターを利用して、CI上の環境変数などローカルCLIでは確認できない挙動を素早く確認して修正する</title><link>https://shunyaueta.com/posts/2021-10-01/</link><pubDate>Fri, 01 Oct 2021 20:39:06 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-10-01/</guid><description>TL;DR; Pull Requestのコミット履歴を汚さずにCircleCIのConfigmap をWeb上で編集して、CIの挙動をすぐ試せる機能がすごく便利 課題点 CircleCI の上のCIの挙動のデバッグをする際、ブランチにプッシュをせずに挙動が確認できる方法としてローカルCLIを利用する方法がある。 しかし、CIのマシン上で定義されている環境変数などは、ローカルCLIを使用しても確認することができない。
そのためコミットでCIが失敗している際には、
Rerun Job with SSHを利用してSSHで接続して、環境変数を確認 再度 config.yml を修正して、コミットをプッシュ だが、上手くいかないので1→2を繰り返す を繰り返してしまい、コミット履歴が不用意に汚れてしまう。
解決方法 この問題点を解決する方法として、CircleCI アプリ内の設定ファイル エディターを利用するのがすごく便利だった。
この機能は、ジョブのページの右上からアクセスできる。 Rerun ボタンの右に... ボタンがあり、そのボタンをクリックすると
Project Settings Configuration File の選択項目があり、Configuration File をクリックすると、config.yml のウェブエディターが起動する。 エディターでYAMLファイルを編集後、右上のSave and Runボタンをクリックすれば、PRで作成されているブランチと別のリモートブランチがCircleCIによって新たに作成されるので、もとのPRのコミット履歴を汚さずにCIの問題を修正できる。
Reference CircleCI アプリ内の設定ファイル エディターの使用</description></item><item><title>GCPのCloud Composer のDAGを素早く・簡単にデバッグする</title><link>https://shunyaueta.com/posts/2021-09-29/</link><pubDate>Wed, 29 Sep 2021 22:20:23 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-09-29/</guid><description>GCPでAirflow をマネージドサービスで使えるサービスで Cloud Composer が存在する。 BigQueryやBigTable, PubSub などGCPの各サービスをDAGとして定義してジョブを定期実行できるので非常に便利だが、その代わりDAGを実行するまで結果がわからないので、CloudComposer を一度実行するしか無いのでデバッグが困難になる傾向がある。
また、GitHubのリポジトリにDAGを保存して、CIでCloud Composerを更新するようしていると PRを都度作ってマージされないと確認できないという場合もある。
ローカルでDocker で走らせれば良いのじゃないかというツッコミがあると思いますが、結局 Cloud Composer 上での動作を確かめないといけないので、今回の記事を書くことにしました。
NOTE: 自分が使用しているComposerのversionはcomposer-1.8.0-Airflow-1.10.3 です。基本的にやれることは一緒だと思います。また、dev, prodで同一のDAGが走るCloud Composer を運用しているという前提です。
アプローチは２つ
logger.info() を仕込んで、DAGのなかで何が起こっているかを理解する import logging logger = logging.getLogger(__name__) logger.info() loggerをDAGを記述した Pythonファイルに仕込んで、内部で何が起こっているかを把握する。
各DAGのlogは、
GCPのCloud ComposerのページにアクセスしてAirflow webserver 列のボタンをクリックしてAirflowのWeb applicaiton にログイン 確認したいDAGをクリック DAG内のtask をクリックして表示されるモーダル内の View Logをクリックすると、loggerの情報が確認できる gstuil rsync コマンドでのGCSへのDAGの同期 gstuil rsyncコマンドを使うことで、リポジトリのDAGファイルをGCSに格納されている開発環境上のCloudComposer のDAGファイルに直接同期してPull Request マージ後のDAGの挙動を確認できる。
Cloud Composer のDAGは、自動作成されたGoogle Cloud Storage(GCS)に格納されており、GCSをCloud Composerが定期的に監視してCloud Composerを更新している。 つまり、GCS上のDAGファイルを直接更新してやるとそれがCloud Composerに反映される。 体感として2-3分に一度は監視されているので、ほぼ待ち状態がない状態で確認できて便利です。
以下のコマンドでリポジトリのDAGファイルをGCSに反映させます。
gsutil -m rsync -d -r dags &amp;#34;$(gcloud composer environments describe {COMPOSER_NAME} --project={GCP_PROJECT} --location={REGION} --format=&amp;#34;get(config.</description></item><item><title>Pandoc を使って抽出できなかったWord内部の画像をGoogle Driveを使って抽出する</title><link>https://shunyaueta.com/posts/2021-09-27/</link><pubDate>Mon, 27 Sep 2021 00:18:26 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-09-27/</guid><description>先日の記事 では、pandoc の--extract-media オプションをオンにしても word 内部の画像を抽出することができなかった。
だが、Google Drive を使うことで Word 内部の画像を抽出することができたのでここに記しておく。
対象の Word ファイルを Google Drive にアップロードする そのファイルを Google Docs で開く File → Download → Web Page (.html, zippted) でウェブページとして zip ファイルをダウンロードする zip ファイルを解凍後、その中にあるimages フォルダに Word 内部の画像が格納されている</description></item><item><title>Pandoc で特定のディレクトリ直下にある複数のWordをMarkdown形式に一括変換する</title><link>https://shunyaueta.com/posts/2021-09-19/</link><pubDate>Sun, 19 Sep 2021 23:52:45 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-09-19/</guid><description>表題の通り、Pandoc を使って、特定ディレクトリ配下にある複数の Wordファイル(*.docx) を Markdownファイル(*.md) へ一括変換したい。
単一Wordファイルの変換コマンド 単一の変換である場合は、@tomo-makes さんのWordファイル(.docx)をMarkdownへ変換する を参考に実行すると良いと思います。
自分は特に困らなかったので、despan の処理は省いた形にしました。 また、--extract-media をオンにして指定しても Wordファイル内の画像を上手く抜き出せなかったです。 WordファイルからMarkdownファイルへの完全変換って難しい。まさに餅をもち米に戻す行為に近い&amp;hellip;
pandoc -s {input}.docx --wrap=none -t gfm -o {output}.md 複数Wordファイルの変換コマンド ワンライナーのシェルスクリプトを組んで実行する。 実行時には、変換元のWordファイルが配置されているディレクトリで実行する。
for f in *.docx; do pandoc -s &amp;#34;$f&amp;#34; --wrap=none -t gfm -o &amp;#34;${f}.md&amp;#34;; done &amp;quot;${f}.md&amp;quot; の部分を &amp;quot;../../docs/${f}.md&amp;quot; のような形で修正してやれば、所定のディレクトリへ変換されたMarkdownファイルが生成される。
Reference How can I convert a whole directory of files from Markdown to RTF?</description></item><item><title>gcloud commands で PubSub に jsonファイルをメッセージとして公開 (Pusblish) する</title><link>https://shunyaueta.com/posts/2021-09-07/</link><pubDate>Tue, 07 Sep 2021 12:22:16 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-09-07/</guid><description>gcloud commands で PubSub に json ファイルをメッセージとして公開 (Pusblish) する
jq コマンドが必要になるが、一番簡単に実現できるのは
$ gcloud pubsub topics publish {PUBSUB_TOPIC_NAME} --message &amp;#34;$(cat {FILE_NAME} | jq -c)&amp;#34; jq コマンドの -c オプションは compact-output を意味している。デフォルトだと pretty-prints になってしまう。 それを避けるために-cオプションを使用している。
ref Publishing messages to topics Read a txt file JSON data to publish the messages in Cloud Pub Sub</description></item><item><title>gRPC client evans で portforward 先のリモートサーバーにリクエストを行う</title><link>https://shunyaueta.com/posts/2021-08-19/</link><pubDate>Thu, 19 Aug 2021 16:51:05 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-08-19/</guid><description>evans
evans は対象のサーバーの gRPC のリフレクション機能が起動されていれば、proto ファイルを参照せずに便利な [REPL mode](gRPC のリフレクション機能) を使用できます。
If your server is enabling gRPC reflection, you can launch Evans with only -r (&amp;ndash;reflection) option.
gRPC のリフレクション機能については evans 作者の ktr0731 さんが解説している記事が非常にわかりやすいです。
gRPC リフレクションはなにをしているか？
ローカルの 5000 番のポートをリモートサーバの 5000 番ポートにフォワード (port-forward)しているとします。 例えば、kubectl だと以下のような実行コマンドになります。
Forward a local port to a port on the Pod
kubectl port-forward pods/hoge-asas32s 5000:5000 そして、ポートフォワードのシェルは保持した上で、別にシェルを起動します。
この際に 対象となるlocalhost:5000 に対して、--host, --port オプションで指定してやれば evans の REPL モードが起動します。
REPL &amp;gt; evans -r --host localhost --port 5000 ______ | ____| | |__ __ __ __ _ _ __ ___ | __| \ \ / / / _.</description></item><item><title>システムの応答速度は本質的な価値提供であることを示す A/B テストの実例</title><link>https://shunyaueta.com/posts/2021-08-13/</link><pubDate>Fri, 13 Aug 2021 23:41:08 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-08-13/</guid><description>内容 システム提供において、基本的に高速であればあるほど顧客は嬉しいものだが、実際のところ高速なシステムを提供して、どの程度の価値が発生するのかが気になったので、調べてみた。
2021/08/14 追記 A/Bテスト実践ガイド　真のデータドリブンへ至る信用できる実験とは の書籍で同様な事例が紹介されているとのこと。情報提供ありがとうございます。 実務でA/Bテストに向き合った人間であれば必ず一度は考えたことのあるトピックについて、アメリカのテックカンパニー（Airbnb, Google, LinkedInなど）勤務の著者らが国際会議で発表された研究もちゃんと引用して見解を述べており説得力がある。 従って、現時点における最高レベルの意思決定をデータ（A/Bテスト）に基づいて行いたいと思うなら、一度は目を通しておくべきであり関係者必携だと思う。 ※個人的には”Webサービスのレイテンシーと利益の関係（５章や”多くのスピード問題”の節）”がお気に入りで、サイトのレイテンシー改善がいかに収益に貢献し得るか、つまりCodeの実行速度というエンジニアのアウトプットがダイレクトに収益に貢献できるか？をデータに基づいてきちんと測っているのが印象的で興味深かった内容でした。 Amazon review
Three Challenges in Building Industrial-Scale Recommender Systems&amp;quot; - Keynote for ORSUM@RecSys'20 3rd Workshop on Online Recommender Systems and User Modeling でのkeynote session で発表された内容
講演者は Sebastian Schelter さんという方で、アカデミックもインダストリーもどちらもバリバリにこなしている人だった。日本だとこういう経歴の人ってかなり珍しい気がするので、やはり層が厚い
ふと@hagino3000 さんのツイートが印象に残っていたので、記録のためにこちらに。1年くらい前のやり取りだけど、印象に残っていて今回この記事を書いたきっかけでもある。
推薦システムのレイテンシが15msと32msで差が出るかA/B Testしたって。推薦結果は同じで片方はあえて遅らせたって事だよな、はじめて聴く実験だ。15msの方がrevenueが良かったとの事。 twitter
公開されている動画はこちら
Three Challenges in Building Industrial-Scale Recommender Systems&amp;quot; - Keynote for ORSUM@RecSys'20
19,20枚目のスライド
要約すると、
既存の研究では、検索エンジン上で人工的に応答速度を遅らせた際にネガティブな影響が発生した。
では、逆に応答速度を早めた場合どのような影響になるのだろうか? とてもおもしろい事例があるので是非紹介したい、
オンプレのシステムからGoogle Cloud に移行するイベントを利用した実験を行った。マイグレーション時にサービングシステムの最適化などを行い、マイグレーション後のシステム性能向上した。この最適化により、モデルやシステム構成は全く同じだが、p90 の応答速度がオンプレのシステムでは 32ms だったものが、GCPでは15ms に向上した。 これにより生じた差異を活用して、以下のA/B テストを行った。 32ms をcontroll, 15ms をtest 群に分けてA.</description></item><item><title>子供が1歳児を迎えるまでに、育児で役に立ったもの</title><link>https://shunyaueta.com/posts/2021-07-23/</link><pubDate>Fri, 23 Jul 2021 22:22:56 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-07-23/</guid><description>去年の秋頃に子供を授かり、色々と役に立った情報や製品、サービスなどがあったので備忘録がてら残しておく。 ベビーウォール、プレイマット、服や抱っこひもなど鉄板系で買えば良いものなどは記す必要が無いのであえて書いてない。
書籍・情報源 ★★★ 赤ちゃん寝かしつけの新常識 科学的な見地に基づいた、赤ちゃんの睡眠に関する情報を纏めた書籍。データやメタ分析、また著者の経験に基づいて、どう寝かしつけに取り組めばいいのか説明してくれている。 ★★ 小児科医のママが教える 離乳食は作らなくてもいいんです。 簡単にまとめると、離乳食をわざわざ作るのではなく販売されている商品で離乳食をカバーしたほうが栄養素、準備に係る労力もなくなってみんな幸せという書籍 ★ 厚生労働省が公開している情報 ac.jp, go.jp の資料の信憑性は高いので、優先して閲覧するようにしている。 ★ 赤ちゃんとママ・パパのための情報 by 花王 花王がお医者さんと連携して作成している F&amp;amp;Q サイト。 モノ ★★★ 食洗機 哺乳瓶を電子レンジで殺菌するものもあるが、こちらのほうが食器も合わせて洗えるのでめちゃくちゃ楽。変にやけどする心配もない。哺乳瓶を 8 本程度買っておいて、食洗機で毎日 4 本程度洗っていく運用が非常に楽だった。 ★★★ 防水敷き布団カバー 子供がよる咳がひどくて飲んだミルクを吐いてしまっている場合があるのだが、その際に布団をすべて洗う必要がなくなるので非常に助かる。自分は西松屋で買ったけど、Amazon でも打っているので紹介 ★★★ iHerb で購入する栄養満点ベビーフード Gerber のライスシリアル など、日本の離乳食と比較して味付けが素材そのままの味で、必須栄養素が添加されている Gerber を愛用して買っている。離乳食にミルクと混ぜて会えると簡単に離乳食が作れるので非常に便利。小児科医のママが教える 離乳食は作らなくてもいいんです。で Gerber の存在を知れた。 ★★★ スワドルアップ 2-5 ヶ月ごろまで愛用していた。抱っこしている状態から、ベッドに置くと一種で起きて泣き出す確率が 9 割から 1 割程度に減る神の道具。途中で起き出すこともかなり少なくなった。 ★★★ ニトリの引っ張るだけで取り込めるハンガー わざわざベビーハンガーなどを買う必要は無い。引っ張って回収できるのが便利。Amazon でも同様のものが売られている ★★★ Google Home Mini ホワイトノイズを再生するのに使っている。「OK Google ホワイトノイズを流して」で 11 時間程度連続再生してくれるので子供の就寝時間中ほぼカバーできる。 赤ちゃん寝かしつけの新常識 で紹介されていたので導入してみたが、寝ている部屋の近くで音を立ててしまったり、一緒の部屋で寝ていて自分のベッドの軋む音で泣かなくなったので非常にありがたい。Alexa とかでも同等の機能はあるんじゃないのでしょうか。昼寝のときもちょっとした音で起きなくなるのでありがたし 2022-04-26: 追記: 子供の就寝時に使っているホワイトノイズマシンを Google Home から Dreamegg に変更 ★★ Xiaomi Mi スマートバンド 子供が深夜に起きた際にスマホで時計を確認すると光が強すぎるので、適切な光量で確認できる。また、料理しているときにタイマーとしても秀逸です。アラームも振動で起床できるので他の人を起こさずに起床できる点も秀逸。何よりも安いので気軽に買えるのが良い ★★ クリップライト 赤ちゃん寝かしつけの新常識でも紹介されている、レッドライトを買うと高いので、クリップライトを買って、百均で買った赤色の透明の下敷きを当ててレッドライトを即席で作成したがなんの問題もなく使えている。実際に深夜に起きて作業をしていると赤色のライトだと眩しいという感覚が非常に和らいでいる気がする ★ オムツ替え防水シート おむつ交換時にいきなりおしっこが発射されることもあるので、防水シートを買った。購入後いざという時何度も助かったので便利 サービス・アプリ ★★★ ぴよログ 睡眠やミルク、排泄の回数などを夫婦間で共有して管理できる。細かな使い勝手が洗練されていて感動するレベル。できた 🚩 という項目があり、これをこまめに付けておくと見返すときにニヤつきながら成長を振り替えれる。 ★★★ メルカリ 元値が数千円台の子供服やおもちゃを 300 円、送料込みで買える。数十着は買ったのではなかろうか。ここでしか見つからないようなかわいい服も多くて、見てての楽しい ★★ ベビーカレンダー このアプリは仕組みが面白い。こどもの生後の日数に合わせて、生後 N 日だと~ができるようになりますとか、こういうことをこころがけましょうと日めくり的に毎日記事が見れて、書籍を一度にまとめて読むよりも今必要なことを適宜教えてくれる感じで助かった。 ★★ ジモティー 4 万円相当のベビーベッドを無料でいただけた。車で 2 時間程度の場所だったが、旅行がてら受け取りに行った。感謝。 ★ とりあえず登録しておくといいサービス 楽天ママ割 Amazon ファミリー ★ Amazon、ベビー用品クーポン おむつやおしりふきなど時々割引クーポンで、ドラッグストアより安くなるときがあり、そのときに購入している。通常時はドラッグストアのほうがやすいので使い分けている おむつカテゴリ おしりふき まとめ 可能な限り効率化できるような、仕組みづくりに投資したほうが幸せになれる。あと体力が一番大事、健康が最強!</description></item><item><title>mvn archetype:generate でJavaのプロジェクト雛形を作成する際のオプションの解説</title><link>https://shunyaueta.com/posts/2021-07-18/</link><pubDate>Sun, 18 Jul 2021 00:05:06 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-07-18/</guid><description>最近、Java を業務で触っている。 門外漢の自分からすると Maven のお作法が分からなかったので、備忘録がてら残しておく。
mvn archetype:generate コマンドのオプションの意味 mvn archetype:generate コマンドを使えば任意のテンプレートに沿ったプロジェクトを一発で作成することができる。
具体例として、Apache Beam でプロジェクト管理ツールである Maven を使って、mvn archetype:generate コマンドを用いて、プロジェクト作成を行う場合、公式サイトでは以下のように指定されている
$ mvn archetype:generate \ -DarchetypeGroupId=org.apache.beam \ -DarchetypeArtifactId=beam-sdks-java-maven-archetypes-examples \ -DarchetypeVersion=2.31.0 \ -DgroupId=org.example \ -DartifactId=word-count-beam \ -Dversion=&amp;#34;0.1&amp;#34; \ -Dpackage=org.apache.beam.examples \ -DinteractiveMode=false オプション名 意味 archetypeGroupId archetypeの groupId つまり、テンプレートを提供している作成元の識別子 archetypeArtifactId archetype のテンプレート。個々では beam-sdk に対応したプロジェクトテンプレートを作成している。 archetypeVersion テンプレートのバージョン groupId Java のパッケージ名のルールに則ったすべてのプロジェクトで唯一に識別可能な識別子。今回は org.example が使われており、実際は識別子として機能指定なさそうな名前ではある。(実際昔のプロジェクトでは重複可能な単語が使われていることが多いが、その場合は marven に登録する際に名前が衝突して登録ができないとのこと artifactId 任意の名前が使用可能であり、jar ファイルのバージョン抜きの名前を指定する。プロジェクトのパッケージ名と考えたら良さそう。これが作成されるロートディレクトリのフォルダ名 version プロジェクトのバージョン情報 package クラスやインターフェースの名前空間を指す。基本的に groupid と同一だが、groupid を接頭辞にして、独自に付け足すこともある。 interactiveMode ウィザード形式の生成をするかしないか Reference Guide to naming conventions on groupId, artifactId, and version maven プロジェクトの作成 archtypeArtifactId を指定する package 宣言 | java-code</description></item><item><title>eコマースの検索と推薦についてのサーベイ論文である 'Challenges and research opportunities in eCommerce search and recommendations' を社内勉強会で発表した</title><link>https://shunyaueta.com/posts/2021-07-10/</link><pubDate>Sat, 10 Jul 2021 23:20:58 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-07-10/</guid><description>SIGIR eCom を探索していたら発見したサーベイ論文の &amp;ldquo;Challenges and research opportunities in eCommerce search and recommendations&amp;quot;が面白かったので、社内の勉強会で発表してきた。
和訳すると、「e コマースの検索と推薦における挑戦と研究トピック」で、e コマースにおける検索と推薦の課題が明瞭に書かれていて非常に面白い論文でした。 自分もまだ検索エンジニアとして日が浅いので、手持ちのパターンを増やせるように日々勉強していますが、この論文のおかげでかなり解像度が上がった。
個人的に面白かったのは、
そもそも、顧客が商品を検索するというタスクの奥深さと面白さが知れる Query Understanding は、非構造なクエリを構造化されたクエリに変換するのが究極的な目標 Learn to Rank(LtR)の実践的な課題点として、LtR 適用時に、Native Ranker とのギャップが発生して非連続な検索結果を返してしまうことがある 実際のクエリから、購入される商品はクエリと商品が関連性が高いとは限らないのでモデルを学習させる際には要注意 Amazon での実例として クエリ「ダイヤモンドリング」に対して LtR を適用すると、実際のクエリとそれに紐づくランキングシグナルから学習すると、「ダイヤモンドリング」というクエリで、「ジルコニウムリング」が大量に購買されていたので LtR では、「ダイヤモンドリング」というクエリに対して、「ジルコニウムリング」を表示するようになってしまった これは、学習データを全く見ないで適用するとそうなりそうだけど、広範囲に影響を及ぼす LtR の QA は非常に骨が折れそう Ref: Amazon Search: The Joy of Ranking Products スライド作成元の Markdown ファイルはhurutoriya/deckはこちらです。 スライド内のリンクに簡単にアクセスできます。
e コマースでの検索に改善したいけど何したらいいかわからんという人は、とりあえずこれ見れば OK という論文だったので読めてよかった
余談 Matching &amp;amp; Ranking の章までを解説したけど、それでも 45m 喋りっぱなしで最後のほうがかなり駆け足になってしまった。 また、英語での発表になったけど、やはり熟れたわかりやすい発表レベルに達するには、まだまだだなぁ感じた。精進せねば
今回スライド作成に Marp を使いましたが、VS Code 上でスラスラとかけつつ読みやすくテンションの上がるデザインに簡単にできて感動しました。これからも愛用したいなと思います。
年末くらいに、検索エンジニアとして 9 ヶ月経過するので、役になった学習リソースなどをまとめたい</description></item><item><title>How to get the uploaded file path and processing its file in Streamlit</title><link>https://shunyaueta.com/posts/2021-07-09/</link><pubDate>Fri, 09 Jul 2021 22:40:37 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-07-09/</guid><description>Motivation Streamlit is a powerful tools to quickliy build the demo application. If we use Streamlit file upload feature via WebBrowser then we need to its file path to process the uploaded file. So I will introduce how to get uploaed file path in Streamlit.
Example We buid the PDF File upload feature in Streamlit and its PDF file convert to image. We use Belval/pdf2image which is a populer PDF converting tool.</description></item><item><title>Streamlit でアップロードしたファイルのパスを取得して、特定の処理をする</title><link>https://shunyaueta.com/posts/2021-07-08/</link><pubDate>Thu, 08 Jul 2021 22:40:37 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-07-08/</guid><description>モチベーション Streamlit は Python code のみで簡単かつ高速に Web アプリを作成できる強力なパッケージ。 Streamplit で作られた Web アプリ経由でファイルをアップロードして、そのファイルを処理したい際の具体的な実現方法がなかったので備忘録がてら残しておく。
PDF ファイルをアップロードして、画像に変換する Web アプリ 具体的に例を交えつつ説明する。 Streamlit を使って、PDF ファイルをアップロードしてアップロードされた PDF ファイルを画像化するアプリを作成する。 今回は、Belval/pdf2image という PDF パッケージを使用する。 このパッケージは処理したい PDF のファイルパスを要求するインターフェースなので今回の実例に沿っていてわかりやすい。 ローカルマシンは MacOS を想定しており、pdf2image はpoppler の事前インストールが必須。
完成形のスクリーンショット GitHub でもコードを公開しておきました。
hurutoriya/streamlist-file-uploader-example
デモ動画はこちら
Demo Movie in Youtube
Makefile Makefile は依存パッケージを事前インストールするために採用
install: brew install poppler poetry install run: poetry run streamlit run streamlit_pdf_uploader/main.py Poetry for package management 環境構築は poetry を使っています。
[tool.poetry] name = &amp;#34;streamlit-pdf-uploader&amp;#34; version = &amp;#34;0.</description></item><item><title>2021年05月時点で自分が実践しているMLOpsの情報収集方法</title><link>https://shunyaueta.com/posts/2021-05-29/</link><pubDate>Sat, 29 May 2021 22:32:58 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-05-29/</guid><description>先日、同僚に「機械学習プロジェクトに興味があるんだけど、おすすめの資料があったら教えてほしい」と言われたので、Blog 記事に現時点でのおすすめの資料としてまとめておいたら、数年後見返したら面白そうだと思ったので記事として公開しておく。
おすすめの資料 プロジェクトマネジメントや考え方、思想 How Google does Machine Learning これは機械学習を実応用する人たちにはぜひ見てほしいビデオ講義。前半が、機械学習プロジェクトの計画や、優先順位、よくあるアンチパターンについて GCP で機械学習について多く関わってきたエンジニアが解説してくれていて、非常に勉強になる。 感想記事 リーン・スタートアップ　ムダのない起業プロセスでイノベーションを生みだす 顧客が求めるものを作ろう。機械学習にこだわったらまずだめなので&amp;hellip; (詳しくは後述の Rules of ML を呼んでみよう。) 関連する良いフレームワークとして @nishio さんの機械学習キャンバス もおすすめです。 Make something people want. by Paul Graham 人によって意見が別れるところではありますが、機械学習エンジニアとして、これがなぜ機械学習で必要なのかの「なぜ」を説明できないとたいてい上手く行かない経験がある。つまるところ、必要とされるものを見つけ出して作っていこうぜということですね Netflix がカスタマーを誰よりも理解するためのデータ分析プロセス、コンシューマー・サイエンスの紹介 カスタマーオブセッションの考え方を、常に心のなかに秘めつつ世の中を良くするプロダクトを作りたい MLOps, 機械学習エンジニアリング Rules of Machine Learning 全員これを毎日読もう。聖書 仕事ではじめる機械学習 第 2 版 MLCT 創始者の @chezou さんが筆頭に書き上げた実践的な機械学習本。日本人で機械学習をやりたいならまずこれを買うべし。 AI アルゴリズムマーケティング 自動化のための機械学習/経済モデル、ベス トプラクティス、アーキテクチャ 邦訳だとべらぼうに怪しい感じになってしまっているが、内容はとんでもなく素晴らしい。マーケティングのために機械学習を適用することが多いと思うが、かなり網羅的に適用例を解説してくれている。原著の英語は無料なので、中身が気になる人はそちらをおすすめする。無料公開偉大すぎる MLOps: 機械学習における継続的デリバリーと自動化のパイプライン GCP による MLOps の解説。人によって、MLOps の定義って差異がありますが、自分はここで語られている ML システム構築のすべてのステップで自動化とモニタリングを推進できます こそが、 MLOps の骨子だなと思っています。クラウドサービスは、開発に関係する知識をパターン化して、資料を公開してくれるのでありがたいですね。 Google Cloud で機械学習を実装するためのベスト プラクティス この資料なんかは、GCP で機械学習を実践したい場合にはまず見ておけば困ることはなさそうですね 各クラウドサービスの MLOps の white paper AWS, Azure は普段使わないので深く言及しませんが、同様の資料は公開されたりしています。 Practitioner Guide to MLOps by GCP MLOps: Continuous Delivery for Machine Learning on AWS Azure Best practices for MLOps - DevOps for machine learning.</description></item><item><title>Poetry からsetup.py を自動生成する</title><link>https://shunyaueta.com/posts/2021-05-23/</link><pubDate>Sun, 23 May 2021 23:42:28 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-05-23/</guid><description>現状の Poetry では、pyproject.toml を基にした setup.py の直接的な自動生成をサポートしていない。
Support generation of poetry manged setup.py file #761
え？なんで setup.py が必要なんですか? poetry build で生成される source と wheels で事足りるんじゃないですかというツッコミがあると思います。
PyPI や Jflog などでホストせずに、GitHub のリポジトリでパッケージを管理したり、特定のサブディレクトリをパッケージとして扱う際には、未だ setup.py での依存関係の記述が必要です。
Poetry による実現方法 poetry build コマンドと Makefile を組み合わせることで、pyproject.toml に対応した setup.py の自動生成ができるのでそれを採用します。 コマンドはGitHub のissues でのコメントを参考にしました。 1
# package name PACKAGE = lib .PHONY: build-package build-package: ## Generate setup.py by poetry command for shared package poetry build # source ./dist で解凍 tar zxvf dist/$(PACKAGE).</description></item><item><title>KyTeaをPythonで扱えるMykyteaを使うために必要なこと</title><link>https://shunyaueta.com/posts/2021-05-19/</link><pubDate>Wed, 19 May 2021 22:04:41 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-05-19/</guid><description>テキスト解析機 KyTea KyTeaを業務で使う機会があり、Python wrapper である Mykytea を使ってみたのですが、poetry や pip で Mykytea をインストールするだけでは、
Library not loaded: /usr/local/lib/libkytea.0.dylib in version = &amp;quot;0.1.5&amp;quot;
上記のエラーが出力され、KyTea を使うことができませんでした。 Mykytea のリポジトリに issue 1 を立てて、@chezou さんにお聞きしてみたところ、
Good point. Mykytea wheel assumes that kytea is installed under /usr/local/lib, while your kytea exists another place. This should be Mykytea issue and there are two options we can avoid it like:
Use delocate, like Linux&amp;rsquo;s audit-wheel https://realpython.com/python-wheels/ Install from source using wheel instead.</description></item><item><title>[抄訳] 検索エンジンの達成度と検索チームの成熟度モデル</title><link>https://shunyaueta.com/posts/2021-05-12/</link><pubDate>Wed, 12 May 2021 22:33:23 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-05-12/</guid><description>@rilmayer_jp さんのツイート をきっかけに、検索チームの成熟度モデルの存在を知りました。ありがとうございます!
Eric Pugh さんが、検索エンジンに関する会議で公演した内容で、検索チームがどのように成熟していくかをモデル化しており、それが面白かったので備忘録として残しておく
更新 2021/05/13 : 原著者のEric Pugh さんから、抄訳のご快諾いただけました。ありがとうございます 翻訳元資料 Search Relevance Organizational Maturity Model slide Haystack LIVE! 2020 Search Relevance Organizational Maturity Model 検索エンジンのレベル 検索エンジンへの要求をどれだけ満たしているかをピラミッド構造でわかりやすく説明している
検索チームの成熟度モデル 7 項目の検索チームの評価項目を考え、3 段階で評価を行う
ビジネス 顧客の要求の理解 検索技術 実験駆動 UX コンテンツ強化 データ保有 発展 ステークホルダーがリアルタイム KPI を使用している データ解析から質的なデータを得ている カスタムプラグインを作成している A/B テスト、オフラインテストをサポートしている 革新的な発見性を提供している(chatbot, 等) NLP やデータサイエンティストの専任チームが取り組んでいる 多種多様な、複雑かつ大規模なデータを扱っている 実践 不定期にレポートを行っている いくつかのユーザーテスト、基礎的な分析を行っている 関連性のための複雑な設定、プラグインの使用をしている 実験は適用可能だが、A/B テストなどはできない 発見しやすくするための UI を提供している 分類学や概念体型の適用をしている データの複雑度の監視している 基礎 ビジネスインパクトが測定されていない クエリログは存在しない、またはユーザーテストを行っていない 技術スタックを適度に調整している 検索のテストは手作業で行い、デプロイは低頻度 1 ページに 10 個の検索結果がある 僅かな取り組み(シノニムなど) とても単純なデータモデル 感想 ひと目で</description></item><item><title>Pythonで、変数を挿入して柔軟にSQLクエリを構築する</title><link>https://shunyaueta.com/posts/2021-04-29/</link><pubDate>Thu, 29 Apr 2021 22:52:25 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-04-29/</guid><description>データ処理のタスクをこなしていると、Python で SQL に変数を挿入し柔軟に SQL クエリを構築したくなる。 例えば、
中間テーブルを作るために Airflow などで定期的なジョブを実行し、SQL の createdの時間を当日のものに変更する training, dev, test でデータを分割する際に、createdの条件を変更して 3 パターンのデータを取得する などが考えられる。
変数を SQL に組み込んで実行したい際には、kayak/pypikaのような SQL builder もあるが、個人的に可読性が悪くなったり、SQL クエリの作成のためだけに余計なパッケージをいれたくない。そのためパッケージを入れずにシンプルに完結する方法をここでは紹介する。
編集履歴 2021/05/12: twitter で docstring ではなく string literal ですよという指摘をいただき修正 ref 2021/05/12: twitter での意見を反映 1. 単なる文字列として SQL クエリを構築 def get_guery(num: int, category: str): sql=f&amp;#34;SELECT field1, field2, field3, field4 FROM TABLE WHERE condition1={num} AND condition2={category}&amp;#34; return sql f-string で文字列に変数を挿入して、SQL クエリを構築 だが、
SQL が長くなると PEP8 に準拠せず、E501 line too longに抵触する 視認性が低く、SQL クエリの実行内容を理解しづらい 2.</description></item><item><title>機械学習エンジニアから検索エンジニアに転生</title><link>https://shunyaueta.com/posts/2021-03-27/</link><pubDate>Sat, 27 Mar 2021 23:54:15 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-03-27/</guid><description>2018 年 2 月に株式会社メルカリに機械学習エンジニアとして入社したが、来月から同社で検索エンジニアに転向する。
機械学習エンジニアとして 入社してからは主に、機械学習により同社での Cusotmer Service 分野の業務効率化を推進してきた。 この３年間で、実応用を前提にした機械学習プロジェクトの1→100と０→１の両者を体験できたのは得難い経験だった。
主に 2 つのプロジェクトを取り組んできたが、そのうちの一つである「機械学習による商品監視プロジェクト」の成果を論文として公開 できたのは、自分としても嬉しい。
この領域はTrust and Safaty とよばれており、少し聞き慣れない言葉かもしれないが、サービスを提供するにあたって必須となるサービスの信頼と安全性を高めることを指す。 少し前に Pinterest がこの領域でのカンファレンスを開催していて、この領域での機械学習の需要がなくなることは無いだろうなと改めて確信を得た。
Trust &amp;amp; Safety Machine Learning Summit なぜ検索エンジニア? キャリアで新しいことに挑戦したい時、鶏と卵問題は必ず発生すると思っている。 例えば機械学習エンジニアが募集されているが、実務経験を重視されるので未経験だとそもそもポジションに就くことができない。
データとエンジニアリングの重なる領域でもう一段スキルと経験を深めたいなと検討した領域が検索領域だったが、一般的な募集では検索領域での経験 N 年以上を求むというものが多く、未経験での転職の壁はなかなかに厳しい。 なら内部での異動はどうだろうと去年の年末に希望を出してみたところ、まずは実験的にチーム異動してみようという話になった。 2 月の半ばから 1 ヶ月程度検証期間を経て問題なしということで、ひとまず正式に検索チームに異動できることになった。
身内贔屓というわけではないが、世界的に見ても同社の検索チームは領域的にもチームとしても凄くエキサイティングだと思っている。 まさに情熱プログラマーでも提唱されている、一番の下手くそでいようが実践できるので凄くワクワクしている。
一番の下手くそでいよう by 情熱プログラマー ソフトウェア開発者の幸せな生き方 扱う技術スタックなどは変わりますが、僕の中では根本的にデータとエンジニアリングにどっぷり浸かる点では機械学習エンジニアだろうと検索エンジニアだろうと変わりはしないので、着実に経験を積んでいきたいなと思っています。
直近の目標としては 2 年以内に、検索領域で自分の興味とマッチする査読付き国際会議
KDD CHIIR SIGIR ecom ECNLP OpML MLSys に採択されるような、Novel な(今までにない)成果を出したい</description></item><item><title>pipenv でローカルパッケージが正常にインストールされないときの対処法</title><link>https://shunyaueta.com/posts/2021-03-13/</link><pubDate>Sat, 13 Mar 2021 21:43:44 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-03-13/</guid><description>TL; DR; pip install pipenv==2018.11.26 をすれば直った!!!!! 実行環境 $pipenv --version pipenv, version 2020.11.15 直面した問題 ./app/ ├── model │ └── setup.py └── serving └── Pipfile のような構成で、modelというローカルパッケージを作成しており、serving 直下の Pipfile は、model を読み込んで setup.py に記述されている依存パッケージもインストールするようにしたい。
serving ディレクトリで、以下のコマンドを入力すればローカルパッケージが pipenv によりインストールされるはずだが
pipenv install --editable ../model 依存関係をすべて記述するはずの Pipenv.lock には、modelのパスのみが記述され、ローカルパッケージが要求する依存パッケージが記述されていない。
原因を探してみたところ、
Installing a local package with pipenv install &amp;lsquo;-e .&amp;rsquo; doesn&amp;rsquo;t save dependencies #1024
同じ GitHub issue を発見しダメ元で pipenv を以下のコマンドでダウングレードして見たところ
pip install pipenv==2018.11.26 なんと&amp;hellip;. 直った。無事にローカルパッケージの依存パッケージが Pipenv.lock に記述されており、無事にローカルパッケージが serving 直下で動くようになった。</description></item><item><title>2021年の目標</title><link>https://shunyaueta.com/posts/2021-03-05/</link><pubDate>Fri, 05 Mar 2021 20:42:15 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-03-05/</guid><description>ちょっと遅れましたが、最近これからどうするかについて色々と考えていて、その過程で 2021 年をどう過ごすかが決まったのでメモ。
3 つの目標 Senior Software Engineer として確固たる実力を身につけることに集中 英語にふれることを習慣化 SNS を断ち自分にとって後悔の無い時間を歩む Senior Software Engineer として確固たる実力を身につけることに集中 まず Senior Software Engineer と自分で胸を張って宣言できる実力を身につける。
最近は自分のキャリアを専門性を深堀りしていくとして、Software Engineer としての道を進んでいくことを決めた。
上記の理由として自分は Data Scientist になれるほど専門性は無いと思っている。Ph.D は持っていないし、再び博士課程に行くとしても研究は辛い。また Machine Learning Engineer や Data Scientist に特化していっても将来 30 年間働いていく中でそれらのレッドオーシャンで自分が生き抜いていけるとは思えない。 Software Engineer という職に飽きるまでは Product Manager のキャリアも考えなくていいと思った。その葛藤を同僚の人にも相談したが、輝かしい経歴(アメリカの有名大学で CS 専攻 →SWE→PM と天上人)の人でも、手を動かせなくなることに焦りを感じるよとおっしゃられていて非常に共感した。
何よりも今の会社に入社して 3 年間働いてきた経験で身に染みたのは、Software Engineer という職業が楽しいなと思えた。もちろんデータ分析や機械学習などにも楽しさがあるが、それらを最大限レバレッジをきかせるためには Software Enginner としてのスキルが必須であり、最終的に物事を実現するためも避けて通れないと考えている。
2020/03 からは新しいキャリアを見据えて少し方向転換をしてみることした。機械学習やデータ分析領域からは離れないが、チームが変わって扱う領域も異なるので非常に楽しみだ。弱くてニューゲームを楽しもう
英語にふれることを習慣化 最近親しい人と雑談する際に言葉に出すようにしているんですが、国外で働くことに憧れを持っています。業務でも英語を使ったコミュニケーションはムラがあるが 4-7 割ほどになっている。今の段階はコミュニケーションはできるが、細かいミスや相手にネイティブレベルのスピードで喋られると脳みそがストップして働くのをやめてしまうのでなんとかしたい。社内の語学学習強化トレーナーの人に相談したところ、やはり毎日時間を積み重ねていくしかないと言われたので、今の気合でしゃべる英会話から自分でも自信を持てる英語の力を持っていきたいなと思っている。
SNS を断ち自分にとって後悔の無い時間を歩む これは自戒なのですが、何気なくボーッとして SNS を見たりする時間が多く、学生の頃にあったひたむきに何かを学び積み重ねていくという習慣が消え去ってます。やばい。集中力も継続できないしで焦燥感だけが高まり行動ができていないという悪循環です。
人生を楽しむためにも、貴重な時間を自分自身に自信を持って過ごせるように後悔のない時間を歩んでいきたい。
これらの目標は toggl で追跡しておいて、毎月どれくらいの時間を費やせたかを振り替えれるようにする 学び続けるということを習慣化したいので、学びの内容が可視化されるように、これからは学んだことを文章化して気軽に Blog 記事としてアウトプットしていく</description></item><item><title>GKE 上にて Pythonで logger.info() を行うとCloud logging では stderr に保存され、すべてエラーになる問題への対処法</title><link>https://shunyaueta.com/posts/2021-03-03/</link><pubDate>Wed, 03 Mar 2021 00:29:03 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-03-03/</guid><description>Python のアプリケーションで、Cloud logger にログを出力したいときに
標準の Python logging モジュールを利用して、ログを出力する Python Cloud Logging package を使用する 上記の２つの方法があります。
不必要にパッケージを増やしたくはないので、1 の標準モジュールで Cloud Logger へ出力できないか試してみました。
標準の Python logging モジュールを試す 標準の logging モジュールでログを出力したいときに
import logging logger = logging.getLogger(__name__) def hoge(): logger.info(&amp;#39;logging Start 2021&amp;#39;) と、logging.info() を仕込んで、Cloud logger にログを出力してみると、logger.info() で出しているはずなのに、Cloud logger 上ではすべてエラーとして扱われてしまっています。
原因を特定するために、logger のログを見てみると logger.info() がすべて stderr標準エラーストリームへ出力されてしまっています。
{ &amp;#34;textPayload&amp;#34;: &amp;#34;2021-02-20 21:26:51,012 - root:predict:36 - INFO: logging Start\n&amp;#34;, ... }, &amp;#34;timestamp&amp;#34;: &amp;#34;2021-02-20T12:26:51.013213826Z&amp;#34;, &amp;#34;severity&amp;#34;: &amp;#34;ERROR&amp;#34;, &amp;#34;labels&amp;#34;: { ... }, &amp;#34;logName&amp;#34;: &amp;#34;projects/.../logs/stderr&amp;#34;, &amp;#34;receiveTimestamp&amp;#34;: &amp;#34;2021-02-20T12:26:55.</description></item><item><title>GKE でローリングアップデート後、ローカルからポートフォワードでリクエストを投げるとcurl: (52) Empty reply from server と返ってくるときの対処方法</title><link>https://shunyaueta.com/posts/2021-02-21/</link><pubDate>Sun, 21 Feb 2021 23:46:30 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-02-21/</guid><description>前提 ローカルからkubectlでポートフォワードして、GKEにリクエストを投げて確認を行っている
発生した問題 deployment のローリングアップデート前は問題なくポートフォワードを通してリクエストが返っていた。コードに変更を加えてGKE上でも確認をしたかったので、まずローカルで確認をして問題がなかった変更が、ローリングアップデート後ポートフォワード でGKE にリクエストを投げると curl: (52) Empty reply from server と返ってくる。
TL; DR; ポートフォワードはrolling update が終わったら貼り直そう。なぜなら、ポートフォワードの接続先はローリングアップデート前後で変化するため。 エラーメッセージ curl でリクエストした際のメッセージ
curl: (52) Empty reply from server Port foward の出力
uid : Error: No such container: xxxxx まとめ 発生していた問題は、ローリングアップデートを行うと、ポートフォワードの接続先が変更され、その際にローリングアップデート前後でkubectl でのポートフォワードは固定されたままなのでリクエストはサーバーから返ってこないという説明するのも恥ずかしい問題でした。
理由は単純だけど、気づくのに時間がかかってしまった。k8s の動きを理解していないからこういうので時間を溶かしてしまった。反省
Appendix Performing a Rolling Update</description></item><item><title>Standard SQLで 列と列の組み合わせの数を集計したい</title><link>https://shunyaueta.com/posts/2021-02-09/</link><pubDate>Tue, 09 Feb 2021 23:27:37 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-02-09/</guid><description>group by は集計作業において根幹となる処理ですが、少し手の混んだ集計をしたいときに毎回調べていることが多かったのでここに学んだことをまとめておく
今回やりたいことは
A 列が α になっている行の B 列の種類を集計したい
です。
はじめに 実際のデータを用意したほうが、理解が深まるので擬似的なテーブルを作成する。 テーブルのデータの概略として、何日に sender (送信者) が receiver (受信者) にいくら送金(price)したかを格納しているテーブルとする。
StandardSQL は WITH を使って簡単にモックテーブルを作れるのが良いところ。
#standardSQL WITH `transactions` AS ( SELECT &amp;#39;A&amp;#39; AS sender, &amp;#39;B&amp;#39; AS receiver, 600 AS price, &amp;#39;2020-01-01&amp;#39; AS day UNION ALL SELECT &amp;#39;A&amp;#39;, &amp;#39;B&amp;#39;, 1200, &amp;#39;2020-01-01&amp;#39; UNION ALL SELECT &amp;#39;A&amp;#39;, &amp;#39;B&amp;#39;, 600, &amp;#39;2020-01-01&amp;#39; UNION ALL SELECT &amp;#39;A&amp;#39;, &amp;#39;C&amp;#39;, 2000, &amp;#39;2020-01-01&amp;#39; UNION ALL SELECT &amp;#39;A&amp;#39;, &amp;#39;D&amp;#39;, 3000, &amp;#39;2020-01-01&amp;#39; UNION ALL SELECT &amp;#39;A&amp;#39;, &amp;#39;D&amp;#39;, 2000, &amp;#39;2020-01-01&amp;#39; UNION ALL SELECT &amp;#39;B&amp;#39;, &amp;#39;C&amp;#39;, 700, &amp;#39;2020-01-01&amp;#39; UNION ALL SELECT &amp;#39;B&amp;#39;, &amp;#39;C&amp;#39;, 300, &amp;#39;2020-01-01&amp;#39; UNION ALL SELECT &amp;#39;B&amp;#39;, &amp;#39;D&amp;#39;, 250, &amp;#39;2020-01-01&amp;#39; UNION ALL SELECT &amp;#39;A&amp;#39;, &amp;#39;B&amp;#39;, 400, &amp;#39;2020-01-02&amp;#39; UNION ALL SELECT &amp;#39;A&amp;#39;, &amp;#39;B&amp;#39;, 1000, &amp;#39;2020-01-02&amp;#39; UNION ALL SELECT &amp;#39;A&amp;#39;, &amp;#39;B&amp;#39;, 1200, &amp;#39;2020-01-02&amp;#39; UNION ALL SELECT &amp;#39;A&amp;#39;, &amp;#39;B&amp;#39;, 2000, &amp;#39;2020-01-02&amp;#39; UNION ALL SELECT &amp;#39;B&amp;#39;, &amp;#39;C&amp;#39;, 450, &amp;#39;2020-01-02&amp;#39; UNION ALL SELECT &amp;#39;B&amp;#39;, &amp;#39;C&amp;#39;, 500, &amp;#39;2020-01-02&amp;#39; ) SELECT * FROM transactions sender receiver price day A B 600 2020-01-01 A B 1200 2020-01-01 A B 1800 2020-01-01 A C 2000 2020-01-01 A D 3000 2020-01-01 A D 2000 2020-01-01 B C 700 2020-01-01 B C 300 2020-01-01 B D 250 2020-01-01 A B 400 2020-01-02 A B 1000 2020-01-02 A B 1200 2020-01-02 A B 2000 2020-01-02 B C 450 2020-01-02 B C 500 2020-01-02 列と列の組み合わせの数を集計する 日次ごとに送金者が何人に送ったかを集計したい、つまり(sender, receiver)のペアを考えて、sender を固定した上で何人に送金したいかを集計したとする。 上記のデータだと</description></item><item><title>pip 実行時に sys.stderr.write(f"ERROR: {exc} ") とエラーが出てpipを実行できないときの対処方法</title><link>https://shunyaueta.com/posts/2021-02-08/</link><pubDate>Mon, 08 Feb 2021 23:29:12 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-02-08/</guid><description>新しいマシンでpipをセットアップして実行しようとすると
&amp;gt;&amp;gt; pip Traceback (most recent call last): File &amp;#34;/usr/local/bin/pip&amp;#34;, line 11, in &amp;lt;module&amp;gt; load_entry_point(&amp;#39;pip==21.0&amp;#39;, &amp;#39;console_scripts&amp;#39;, &amp;#39;pip&amp;#39;)() File &amp;#34;/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/pkg_resources/__init__.py&amp;#34;, line 489, in load_entry_point return get_distribution(dist).load_entry_point(group, name) File &amp;#34;/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/pkg_resources/__init__.py&amp;#34;, line 2843, in load_entry_point return ep.load() File &amp;#34;/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/pkg_resources/__init__.py&amp;#34;, line 2434, in load return self.resolve() File &amp;#34;/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/pkg_resources/__init__.py&amp;#34;, line 2440, in resolve module = __import__(self.module_name, fromlist=[&amp;#39;__name__&amp;#39;], level=0) File &amp;#34;/Library/Python/2.7/site-packages/pip-21.0-py2.7.egg/pip/_internal/cli/main.py&amp;#34;, line 60 sys.stderr.write(f&amp;#34;ERROR: {exc}&amp;#34;) というエラーが出た。
デフォルトの Python の実行ランタイムが 2.x 系なのでそれに起因するエラーだった。 pip を Python2 系でおそらくインストールしており、pip21 に更新後は Python3.</description></item><item><title>TFXの歴史を振り返りつつ機械学習エンジニアリングを提案する論文「Towards ML Engineering: A Brief History Of TensorFlow Extended (TFX)」</title><link>https://shunyaueta.com/posts/2021-01-17/</link><pubDate>Sun, 17 Jan 2021 00:18:47 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-01-17/</guid><description>この記事はMLOps Advent Calendar 2020の 25 日目の記事です。(盛大に遅れました)
KDD2019 の招待講演で Google が TFX の歴史について発表されており、TFX 信者の自分としては発表内容が以前から気になっていたが、公開はされておらずなんとかして見れないかな~と思っていましたが、TensorFlow の Blogで該当の招待講演が論文化されたことを知ったのでメモがてら抄訳として残しておく。
注意)この翻訳記事は原著論文の著者陣からレビューはされていません Shunya Ueta, are providing a translation and abridgment, which has not been reviewed by the authors. Citation Karmarkar, A., Altay, A., Zaks, A., Polyzotis, N., Ramesh, A., Mathes, B., … &amp;amp; Li, Z. (2020). Towards ML Engineering: A Brief History Of TensorFlow Extended (TFX). arXiv preprint arXiv:2010.02013. ***
Towards ML Engineering with TensorFlow Extended (TFX) at KDD2019 Towards ML Engineering with TensorFlow Extended (TFX) ACM PDF は arxiv でも閲覧可能 https://arxiv.</description></item><item><title>PythonでApache beam 入門</title><link>https://shunyaueta.com/posts/2020-12-26/</link><pubDate>Sat, 26 Dec 2020 00:41:30 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-12-26/</guid><description>TensorFlowの勉強をしていたら、Apache beam を前処理に採用していたケースがあり、興味を持ったので深堀りしてみます。
興味が湧いたモチベーションとしては、
データ量が増加しても前処理部分を難なくスケールできそう(前処理部分をスケールさせて高速に実験を回したい、並列化などはすべて良い感じにbeamに任せれそう バッチとストリーミングの両者に対応可能なので、柔軟な機械学習の推論サービスが提供できるのでは? (GCPの参考資料 Data preprocessing for machine learning: options and recommendations) Apache beam を触りつつ分散データ処理を学びたい https://github.com/jhuangtw/xg2xg#services
を見てみるとGoogle 内部のFlume という並列データパイプライン技術がApache beam として公開されているみたいです。
Apache beam について端的に説明すると
Apache beam は3つの考えを基礎にしています。
Unified ストリーミング、バッチの両者のケースに一つのプログラミングモデルで対応可能な統一性 Portable 実行パイプラインが複数の実行環境で実行可能な可搬性 Extensible 新しいSDK、IO Connectorsや変換ライブラリなどをを書いて共有することができる拡張性 Java, Python, Go やScalaを使ってBeam Model を作成して任意のruntime で実行する流れです。
自分はPythonが一眼手軽に書けるのでこの記事ではPythonで紹介していきます。
Version 2.14.0 からPython 3がサポートされたのは非常にありがたいですね。それまではPython 2のみをサポートしており、その影響で技術選定時に採用しづらかったのでは無いのでしょうか?
Spotify が作成しているApach BeamとDataflowのScala APIであるscioが開発されており、そちらも気になっています。
https://github.com/spotify/scio https://engineering.atspotify.com/2017/10/16/big-data-processing-at-spotify-the-road-to-scio-part-1/ では、まずは実際に動かしながら学んでみようということで
https://beam.apache.org/get-started/try-apache-beam/
を参考にApache Beam をPython SDKで試してみます
COLABで実行を試せるので便利ですね
ですが、Python2で実行されるように設定されているのでPython3で実行してみました。
実行したcolab のコードを見ていきます。
環境準備 apache-beam のinstallとGCSからApache beamで処理を行うテキストファイルをダウンロードします。</description></item><item><title>機械学習・ソフトウェアエンジニアリングをテーマにしたPodcast just4fun.fm を始めてみた</title><link>https://shunyaueta.com/posts/2020-09-27/</link><pubDate>Sun, 27 Sep 2020 21:57:47 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-09-27/</guid><description>機械学習エンジニアをしている hurutoriya が機械学習、Software Engineering 周りに関する学んだことなど最近楽しいと思っていることを発信していくPodcast です
扱うトピックとしては、普段学んだ機械学習、ソフトウェアエンジニアリング、読んだ論文やデータ分析などについて扱っていきます。 もし、ご興味あれば購読お願いします。主要なPodcast Platformで購読可能です。
just4fun.fm Google Podcasts Apple Podcasts Pocket Casts ご感想などは Twitter ハッシュタグ #just4funfm でお待ちしております
なぜ Podcast なのか？ 以前からPodcastは日常的に聴いていて、自分の中でもすごく好きなメディアのうちの一つです。 前からやってみようかなと思っていたんですが、周りの人たちがPodcastを始めたのを機によし自分もやるかと始めてみました
Blogと比べてみると、
ブログ書くよりかはサラッと配信できる、音声で配信するのも新鮮で面白い その代わり、換気扇とかの音が気になり音源環境とかはめちゃくちゃ気を使う 発表レベルの構造化したトークよりも雑談レベルでワイワイするほうがPodcastは向いてる感じはする。前者だと準備やらなんやらで公開できずに死の谷に落ちそう 喋っているうちに思考が洗練されていくので、あまり気負いすぎずに喋りたい事を発信していくのが良さそう しばらく試験的に続けていきたいと思います。
Anchor 凄い AnchorでPodcastを始めると、自動的にAppole Podcast, Google Podcast, Pocket CastなどPodcastのプラットフォームに自動配信される。 Google Podcastは、配信開始と通知が来ても実際は2-3日後に視聴可能になると問い合わせたら返信がきた Support here. Sorry for the confusion with your podcast on Google. Allow me to explain this to you. We have noted that for some users the podcast link takes a week or so to become active, so it should begin working soon!</description></item><item><title>自分なりの機械学習エンジニアスキル構成論</title><link>https://shunyaueta.com/posts/2020-09-21/</link><pubDate>Mon, 21 Sep 2020 00:13:08 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-09-21/</guid><description>機械学習エンジニアとして働き始めて2年7ヶ月が経過した。
機械学習エンジニアというロールは会社によって期待される内容が異なってくるが、今の会社で働いてきた経験に基づき自分の中の機械学習エンジニアスキル構成論を整理してみる。
TL; DR 人によって考える理想のスキル論は違うので他の人の持論を聞いてみたい テクいことをやりたい気持ちはあるが、地道なやるべきことがたくさんあるのがこの世界 自分の中で機械学習エンジニアにとって大事なスキル Software Engineer 40% 機械学習サービス実装スキル Product Manager 30% 機械学習プロジェクト自体を成功に導くスキル Data Scientist 30% データに基づき、意思決定し改善していくスキル Machine Learning Engineer as Software Engineer なぜSWEの比率が一番上なのか？
どれだけ良いモデルができたとしてもそれが活用されるシステムがなければ成果を出せないからです
データを活用してインパクトの大きい課題を解決するための、サービスを実装して、運用して改善していく どの方法がベストか考えた上で、それを実現していく 例えば、R&amp;amp;Dスタイルでモデル開発と実装者を完全に分ける組織構造もあると思いますが、このスタイルはいろんな会社のお話を聞く限りは、組織構造がよほど洗練されていないとうまく稼働しないじゃないかなと思っている
Full Cycle Developers at Netflixでは、システム開発のライフサイクルである
design, development, test, deploy, operate, support
を1チームが一気通貫で責任を持つスタイルをNetflixが提唱している。
今所属している会社もMicro Serviceでの開発に注力していて、まさにFull Cycleスタイルで機械学習サービス開発を行っている。 個人的に機械学習プロジェクトとこの方式の相性の良いところは、例えば、職能ごとにモデル開発、システム開発と運用を行うメンバーを分割すると、
モデルを作ってデプロイはしたが運用は他人任せになってしまい継続的な改善が回しづらい 役割が分離されていることで、モデルの詳細を完全に把握できないので実際のトラブル発生時に対応が困難 運用を考えてモデルがデザインされていないので運用者にしわ寄せがくる などアンチパターンが数多く存在する
Micro Serviceでの開発は上記の課題を解決して、作って終わりではなく自分たちでシステムデザインからサポートまで行うことで、そのサービスの継続的な改善に責任と自由を手にして開発することできる また、プロジェクトデザインの段階からシステム開発・運用を念頭に動くことができるので、やってみてうまく動かないなどの不確実性を大きく減少させる
Machine Learning Engineer as Product Manager 機械学習プロジェクトは、POCなどで検証を行いプロジェクトが始まりますが最初の壁である
機械学習で解ける余地のある大きなインパクト(やる価値)のある問題 をまず自分たちのサービスで発見する必要があります。(正直コレが一番難しい)
CourseraでHow Google does Machine Learning の講義を修了したの講義でもGoogleでの機械学習プロジェクトのマネジメントについて言及されていますが、
そもそもデータがない Human In The Loopを導入していない(継続的なデータの自浄作用が存在しない) などそれらの要素が欠けるだけで簡単にプロジェクトは失敗します。</description></item><item><title>GitHub codeowners でGithubグループを指定しても反映されない時の対処方法</title><link>https://shunyaueta.com/posts/2020-09-19/</link><pubDate>Sat, 19 Sep 2020 11:31:36 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-09-19/</guid><description>GitHub の CODEOWNERS という機能を使えば、レポジトリに対する PR では設定された CODEOWNER が APPROVE を出さないとマージされないようにできます。
この機能を使うことで、例えばそのリポジトリのオーナーであるグループが必ず PR を確認しないとマージできないようにすることでコードのクオリティを保つ仕組みが作れます。
TL;DR GitHub codeowners で特定のグループを CODEOWNERS に設定したいときは、そのグループをレポジトリの /settings/accessで Maintain として追加しないと GitHub PR で自動的に reviwer に追加されない リポジトリで.github/CODEOWNERS のファイルを作成して、以下の形式で GitHub group を追加する * @octo-org/codeowners-team リポジトリの設定の/settings/accessにアクセスして、@octo-org/codeowners-team を Maintain として追加する。 *試していないのですが、Write や Triage 権限でも問題ないかもしれません。
この設定をしたあとに、GitHub PR を新たに作成すると、自動的に CODEOWNERS の approve がないとマージされないように設定されるはずです。
自分自身がハマった経緯 グループ全体のアカウントが追加されているa-group/allという Github Group がすでにリポジトリのアクセス権限に Write 権限として追加されており、全員が write 権限をもっているなら codeowners としての権限も問題ないだろうと思っていたらハマりました。
CODEOWNERS の仕組みを知ると理解できるのですが、a-group/all が指定したいグループの包含関係にあるからといって、そのように取り扱ってくれるわけではないということですね。</description></item><item><title>pandas を使って特定のディレクトリのCSVファイルをすべて連結して一つのCSVファイルを作成</title><link>https://shunyaueta.com/posts/2020-09-09/</link><pubDate>Wed, 09 Sep 2020 23:49:37 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-09-09/</guid><description>目的 複数の同じフォーマットの CSV ファイルが特定のディレクトリに配置されており、その CSV ファイル群を一つの CSV ファイルに連結したい
今回は、Python の Pandas と pathlib を使って上記の目的を実現します。
実行環境 In [1]: import pandas as pd In [2]: pd.__version__ Out[2]: &amp;#39;1.1.2 In [3]: import sys ...: print(sys.version) 3.8.2 (default, Jul 19 2020, 07:23:27) [Clang 11.0.3 (clang-1103.0.32.62)] 目的となる csv ファイルは tmp ディレクトリに以下のような形式で配置されているとする
tmp ├── 1.csv ├── 2.csv └── 3.csv 各ファイルはこのような形式で保存されています。
id name created 1 John 2020/09/10 2 bob 2020/09/10 3 taro 2020/09/11 以下の Python スクリプトを実行
import pathlib import pandas as pd def contcat_csv(f_path:str): # pathlibのitedir()で対象とするディレクトリのCSVファイル一覧をジェネレーターとして取得 csvs = [pd.</description></item><item><title>MLOps の国際会議 OpML'20 に、機械学習を活用した商品監視の改善に関する論文が採択されたので登壇してきた</title><link>https://shunyaueta.com/posts/2020-09-06/</link><pubDate>Sun, 06 Sep 2020 23:31:03 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-09-06/</guid><description>MLOps の査読付き国際会議 2020 USENIX Conference on Operational Machine Learning (略称 OpML'20)に論文が採択されたので、登壇してきた。
Podcast でも紹介しました。
#1 MLOps の国際会議 OpML20 について at just4fun.fm
MLOps の査読付き国際会議と OpML の立ち位置 機械学習エンジニアリング・MLOps の領域の会議でも一番有名なものとして 2018 年に発足したMLSysがあります。(ちなみに最初は SysML という名前でした) このカンファレンスの傾向としては、アカデミアの研究者主体の発足経緯からアカデミアからインダストリーへの橋渡し的立ち位置となっています。 具体的には、発表者はアカデミアの方が大半でハードウェアから、モデルの OSS 公開など幅広く機械学習エンジニアリング・MLOps の周辺領域をカバーしています。
OpML はその一年後に、USENIXが母体の会議として MLOps を軸にした会議として誕生しました。 USENIX は SRECON、OSDI などを開催している団体です。 学術的なスタイルに則り、先端的な計算機システムの成果を論文として公開されています。MLSys と対称的にこちらはインダストリーからアカデミアへの橋渡し的立ち位置となっています。発表内容は企業での発表者が多く、実際の運用で得られた各企業の MLOps のベストプラクティスなどがメインで話されています。 個人的には OpML のほうが、MLOps のど真ん中を主体に置いているので MLSys よりも盛り上がってほしいなと思っています。
OpML'19 がどのような様子だったかは、以下の記事がわかりやすいです。
OpML ‘19 参加レポート The first conference of Operational Machine Learning: OpML ‘19 自分自身、機械学習エンジニアリングや MLOps 周りのカンファレンス情報などを追いかけていますが、この分野で査読付きかつ論文として残せる形式の国際会議は主に上記の２つの認識です。</description></item><item><title>Python の内包表記とジェネレータ式のメモリ使用量比較</title><link>https://shunyaueta.com/posts/2020-08-23/</link><pubDate>Sun, 23 Aug 2020 21:28:10 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-08-23/</guid><description>リストを構築する際に Python ではリスト内包表記とジェネレータ式の２種類が存在する。 今回、リスト構築時にメモリ使用量にどれだけ差異が発生するのか調査をしてみた。 メモリ使用量の調査には、memory_profilerというパッケージを使用した。
まず、２つのリストのデカルト積のタプルを表示するプログラムでの比較
from memory_profiler import profile @profile def main(): &amp;#34;&amp;#34;&amp;#34; Comparision List comprehension VS generator memory usage &amp;#34;&amp;#34;&amp;#34; colors = &amp;#34;colors&amp;#34; * 1000 sizes = &amp;#34;S&amp;#34; * 100 for shirts in ((color, size) for color in colors for size in sizes): print(shirts) [print((color, size)) for color in colors for size in sizes] if __name__ == &amp;#34;__main__&amp;#34;: main() Filename: src/listcomp_vs_generator.py Line # Mem usage Increment Line Contents ================================================ 4 10.</description></item><item><title>AOJの「ITP I」40問をPythonで解いた</title><link>https://shunyaueta.com/posts/2020-08-04/</link><pubDate>Tue, 04 Aug 2020 03:38:58 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-08-04/</guid><description>はじめに コーディングの腕をもっと磨きたいなと思ったので、以下の記事を参考に始めてみた
https://qiita.com/e869120/items/f1c6f98364d1443148b3 全部で 44 問ありますが、最後の 4 問は競プロとはあまり関係ないので、ITP1_1-A から ITP1_10-D までの 40 問を解くことをお勧めします。
まずは最初におすすめされた、AOJ の ITP1_1-A から ITP1_10-D までの 40 問を解いてみた 無料でこのサービスが提供されてるの素晴らしい 標準入力、出力の整形が少し手間取ったけど、あとは愚直に解いていった
http://judge.u-aizu.ac.jp/onlinejudge/ 感想としては、
やってみたら、意外と楽しい。特に自分で諦めずに試行錯誤して、オンラインで一発で AC もらえるとめちゃくちゃ嬉しい テストケースに通る、すなわち正しい、それが書けたら達成感がある 何かしらのお題に沿って、コードを書くという動機ができるので、書くことに慣れたい場合も有用そう toggl で時間計測しながら、やって見直してみたら 15h46m 費やしていた。大体 1 問 25m くらい
次の目標、
AtCoder で水色を目指す!!! データ構造周りや、アルゴリズム周りはまだまだ弱いのでそこらへんを抑えていきたい 当面は、以下の２つに投資していきます
機械学習だけに縛られない、SWE としてスキル底上げ 機械学習関係の確固たる基礎知識と実装力 以下に自分が書いた回答例を放流しておきます。
Rule 15 分試行錯誤しても、緒がわからない場合は諦める わからなかったとき、もっと上手な書き方は以下を参考にしました https://qiita.com/cmtennis1042/items/5f1e7f071081176e857f ITP1_1_A: Hello World print(&amp;#39;Hello world&amp;#39;) ITP1_1_B: X Cubic x = input() print(x ** 3) ITP1_1_C: Rectangle a, b = map(int, input().</description></item><item><title>How to write the UnitTest with stdin at Pytest</title><link>https://shunyaueta.com/posts/2020-07-25/</link><pubDate>Sat, 25 Jul 2020 03:18:14 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-07-25/</guid><description>If you want to write UnitTest when using stdin in Python. Pytest provide setattr function in monkeypatch
from io import StringIO import sys def divide(): input = sys.stdin.readline return list(input()) def gather(): input = sys.stdin.readline return sum(list(map(int, input().split()))) def test_divide(monkeypatch): monkeypatch.setattr(&amp;#39;sys.stdin&amp;#39;, StringIO(&amp;#39;abc&amp;#39;)) assert divide() == [&amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;c&amp;#39;] def test_gather(monkeypatch): monkeypatch.setattr(&amp;#39;sys.stdin&amp;#39;, StringIO(&amp;#39;1 2 3&amp;#39;)) assert gather() == 6 Reference Monkeypatching/mocking modules and environments I want to use stdin in a pytest test https://gist.</description></item><item><title>Machine Learning Casual Talks # 12 を開催しました</title><link>https://shunyaueta.com/posts/2020-06-13/</link><pubDate>Sat, 13 Jun 2020 23:06:44 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-06-13/</guid><description>Machine Learning Casual Talks 第 12 回を開催しました。 前回から少し開きがあり、7 ヶ月ぶりの開催となりました。
https://mlct.connpass.com/event/172550/
今回の個人的なテーマはベストプラクティスとアンチパターンです。
@keigohtr さんには、AWS の各種サービスを使った機械学習実験基盤をアベジャの適用事例と重ね合わせて、説得力のあるベストプラクティスを語っていただきました。 @yuzutas0 さんには、機械学習の前に、データのマネジメントがいかに必要かを語っていただきました。建設的に改善していこうぜという未来が語られていて、個人的にお話を依頼した甲斐がありました 同僚の @overs_5121 さんには、メルカリ : TensorFlow Lite で、気付きにくい便利機能をユーザーに提唱 の裏話や、適用までの泥臭い事例をお話していただきました。 登壇者の皆様、改めて登壇の依頼をご快諾いただきありがとうございました。
また、コロナウイルスの影響もあり試験的ですが完全なオンライン開催となりました。 配信面は今回は完全に @chezou さんに頼らせていただきました。 プロフェッショナルな配信ありがとうございました！ 配信のベストプラクティスや様子などは、こちらを御覧ください
Google Meet と YouTube Live でオンラインミートアップの配信をした
勉強会の資料と動画 資料ページ Machine Learning Casual Talks #12 - YouTube 所感としては、以前から配信 NG の発表以外は積極的に YouTube で公開していたのだが、参加者の皆様からはオンライン開催でありがたいと声が大きく、個人的に驚きました。
自分が思うに、オンライン参加も配信動画を後から見るのも、リアルタイムで質問ができないこと以外は大きな差異が無いと思っていたのだが、参加者側からすると大きく異なるようで新鮮だった。
オンライン勉強会開催側のコツ 最低でも
配信者 司会者 配信の監視を行う監視者 の 3 役がいないとオンライン開催は難しいことがわかった
ライブ配信視聴者数は、以下のような遷移となりました。 500 人参加申込みがあり、最大視聴者数が 252 人とギリギリ 5 割を超えました。
今までのオフラインでの開催は 6-8 割くらいだったので、それと比較すると上出来かなと思います。 また、オンライン開催はオフライン開催と比べて会場の確保コストや懇親会おじさんの発生などを抑えられるので、その点もありがたかったです。 オフライン開催だと、会場撤収が効率的に終わっても 22:00、家に帰ると 23:00 なので、イベント主催者にとっても開催しやすい気がしますね。</description></item><item><title>自走プログラマーを読み終えた</title><link>https://shunyaueta.com/posts/2020-05-10/</link><pubDate>Sun, 10 May 2020 17:13:34 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-05-10/</guid><description>自走プログラマーを読み終えた。
読み始めたきっかけとして、自分は機械学習エンジニアとして現在働いているが、できることの幅を広げるために最近はソフトウェアエンジニアとしてのスキルをもっと伸ばしたいと考えている。
自走プログラマーは、Python を使ったアプリケーション開発のアンチパターンとベストプラクティスを例示して学ぶことができる書籍で、今回の自分の状況にすごくフィットしていて楽しく学習することができた。
Python 独特のはまりどころは、Kindle: The Hitchhiker’s Guide to Python, The Hitchhiker’s Guide to Python でも数多く参照されていて、こっちも後から読んでおきたいなと思いました。
次は、ちゃんとした Pythonista になれるように、Fluent Python を読みます。@ynqa さん、以前この本を教えて下さり、ありがとうございました。
長らく積ん読になっていますが、毎日読み進めていきます。
20 歳頃の寝る間を惜しんで、ウェブアプリを開発していたときのワクワク感が徐々に蘇ってきた気がしています。
ある程度書けるようになってきたら、なにかアプリとか作って公開したいなと思っています！</description></item><item><title>ソフトウェア開発における Upstream と Downstream の意味</title><link>https://shunyaueta.com/posts/2020-04-27/</link><pubDate>Mon, 27 Apr 2020 23:55:42 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-04-27/</guid><description> Upstream Upstream はそのシステムが依存しているジョブ Upstream のデザインが変わることで、システムも影響をうける Downstream Downstream はそのシステムが影響を与える影響を与える部分 例えば、Web Application などでは、データベースは Downstream となる
e.g. Web service→ Databese という流れでデータが作成される
References https://reflectoring.io/upstream-downstream/ https://softwareengineering.stackexchange.com/questions/71080/what-does-downstream-upstream-design-mean/83686 https://en.wikipedia.org/wiki/Upstream_(software_development) https://en.wikipedia.org/wiki/Downstream_(software_development)</description></item><item><title>Pythonの関数のデフォルト引数はmutable(上書きされる)</title><link>https://shunyaueta.com/posts/2020-04-26/</link><pubDate>Sun, 26 Apr 2020 12:04:13 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-04-26/</guid><description>例えば以下のように、デフォルト引数で初期化を行い、文字列を追加する関数があるとする。
def append_to(values=[]): values.append(&amp;#34;Hoge&amp;#34;) return values 期待する振る舞いとしては。
In [14]: def append_to(values=[]): ...: values.append(&amp;#34;Hoge&amp;#34;) ...: return values ...: In [17]: append_to() Out[17]: [&amp;#39;Hoge&amp;#39;] In [18]: append_to() Out[18]: [&amp;#39;Hoge&amp;#39;] と関数呼び出しごとに、values は空のリストに初期化されるので上記のように返ってきてほしい
だが、実際に表示されるのは
In [14]: def append_to(values=[]): ...: values.append(&amp;#34;Hoge&amp;#34;) ...: return values ...: In [17]: append_to() Out[17]: [&amp;#39;Hoge&amp;#39;] In [18]: append_to() Out[18]: [&amp;#39;Hoge&amp;#39;, &amp;#39;Hoge&amp;#39;] である。
実際に内部で何が起きているかというと
In [23]: def append_to(values=[]): ...: values.append(&amp;#34;Hoge&amp;#34;) ...: return values ...: In [24]: pinfo append_to Signature: append_to(values=[]) Docstring: &amp;lt;no docstring&amp;gt; File: ~/&amp;lt;ipython-input-23-4530a91351ab&amp;gt; Type: function In [25]: append_to() Out[25]: [&amp;#39;Hoge&amp;#39;] In [26]: pinfo append_to Signature: append_to(values=[&amp;#39;Hoge&amp;#39;]) Docstring: &amp;lt;no docstring&amp;gt; File: ~/&amp;lt;ipython-input-23-4530a91351ab&amp;gt; Type: function In [27]: append_to() Out[27]: [&amp;#39;Hoge&amp;#39;, &amp;#39;Hoge&amp;#39;] In [28]: pinfo append_to Signature: append_to(values=[&amp;#39;Hoge&amp;#39;, &amp;#39;Hoge&amp;#39;]) Docstring: &amp;lt;no docstring&amp;gt; File: ~/&amp;lt;ipython-input-23-4530a91351ab&amp;gt; Type: function が起きている。 pinfo は ipython 上で、オブジェクトの情報が確認できる便利コマンドです。 関数呼び出しごとに、デフォルト引数の values が上書きされていっていることがわかります。 これは、Python のデフォルト引数が、関数が定義されたときのみ評価され、毎回毎回評価されるわけではない。(Ruby は評価される) ここでわかるのは、mutable</description></item><item><title>機械学習システムの信頼性を数値化し、技術的負債を解消する論文「 The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction」</title><link>https://shunyaueta.com/posts/2020-04-25/</link><pubDate>Sat, 25 Apr 2020 01:35:20 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-04-25/</guid><description>[抄訳] What’s your ML test score? A rubric for ML production systemsで紹介した論文の続編があったので読んでみました。
注意)この翻訳記事は原著論文の著者陣からレビューはされていません Shunya Ueta, are providing a translation and abridgment, which has not been reviewed by the authors. Change log 2021/02/03 ML Test Score を簡単に計算できるGoogle Spread Sheets を公開 2020/06/24 著者の Eric Breck さんに連絡をし、抄訳の公開を快諾していただきました。ありがとうございます。 完全な citation 情報を追記しました。 この翻訳記事が著者のレビューを受けていないことを追記しました。 Citation Eric Breck, Shanqing Cai, Michael Salib, . The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction. In 2017 IEEE International Conference on Big Data (Big Data) (pp.</description></item><item><title>機械学習システムの信頼性を数値化する論文「 What’s your ML test score? A rubric for ML production systems」</title><link>https://shunyaueta.com/posts/2020-04-19/</link><pubDate>Sun, 19 Apr 2020 22:18:10 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-04-19/</guid><description>NIPS206 にて開催された Reliable Machine Learning in the Wild - NIPS 2016 Workshop (2016) という、現実世界でどうやって信頼性の高い機械学習に取り組んでいくかについてのワークショップがある。
ここで Google から発表された What’s your ML test score? A rubric for ML production systems がとても面白く、身になるものが多かったのでメモがてら抄訳を残しておく。
PDF Slide 発表動画もワークショップページにて公開されています。 change logs 2021-04-25 この原著論文の完全版になっている論文の抄訳を新たに公開しています。 [抄訳]: The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction 概略 現実世界のプロダクションシステムで機械学習を使う際に、機械学習の研究実験と異なる、小さなもしくは小さくない問題がある テストとモニタリングはプロダクションレディの機械学習システムにとって必要不可欠 しかし、どれくらいのテストとモニタリングをすれば十分と言えるのだろうか? この論文では、それらの問題を解決する ML Test Score という基準を提案する Introduciton Google 内で積み重ねたベストプラクティスをもとに、実行可能なテスト、そしてその機械学習システムがどのていどプロダクションレディなのかを示すスコアシステムを提案
このスコアは、機械学習を始めたばかるのチームからエキスパートがあつまるチームまで幅広く適用可能
注意: 一般的な Sofware Engineering のベストプラクティスは含んでいない
そのかわり、学習とサービングのための Unit Test Coverage の計算方法など機械学習に必要不可欠な点を抑えている</description></item><item><title>CourseraでHow Google does Machine Learning の講義を修了した</title><link>https://shunyaueta.com/posts/2020-04-18/</link><pubDate>Sat, 18 Apr 2020 00:59:23 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-04-18/</guid><description>Coursera でHow Google does Machine Learning の講義を修了した
Certificate はこちら
7 割が、機械学習プロジェクトの始め方、実際のハマりどころなどが Google 内の実例などに基づいて語られていて面白かった。 特に、
Secret Sourse ML Sutprise の部分が、アンチパターンや成功方法などが語られていて実際に実務で機械学習をやっている自分としてはわかる~~~~と共感がすごくできて面白かった。初めて機械学習プロジェクトを担当する PM の方にも良い教材なのではと思いました。
残りの 3 割は、qwiklab を使って、Notebook を立ち上げたり、Google BQ 叩いたり、Pandas, Google Cloud Vison API など各 ML 系の API を触るといった感じで、初心者過ぎて自分にはレベル感が少しあいませんでしたが、これも非エンジニアの方が機械学習ってこんな感じかと学ぶきっかけにはすごく良さそうです。
最初の 7 割の部分は、改めてデータ利活用を前提にしたプロジェクトを牽引していく際にここで見つめ直す形になってよかったです。
最近、Cousera での講義を始める機会があり Andrew Ng 先生の機械学習コースぶりに Coursera をやっているが、勉強のペースメーカーが決められるのと講義内容の質も高いので自分にとってはすごく相性が良い。
技術書を読むときも同じペースで、実行できないかなと画策したい</description></item><item><title>Courseraで Getting Started with Google Kubernetes Engine の講義を修了した</title><link>https://shunyaueta.com/posts/2020-04-12/</link><pubDate>Sun, 12 Apr 2020 00:59:23 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-04-12/</guid><description>表題のとおりですが、Getting Started with Google Kubernetes Engine という Coursera の講義を終了しました
業務で k8s を本格的に使い始め、ちゃんと理解したいな~と思いこのコースを取りました。
半年前に Kubernetes 完全ガイド impress top gear シリーズ をサラッと読んではいたのですが、やはり手を動かして学んでいないと実際に kubectl command など完全に忘れているし、スキルとして身についていない感半端なかったので、良い機会なので Hands-on が提供うされている Coursera を使って学んでみました。
個人的にこの講義がめちゃくちゃオススメなのが、 GKE の講義なので Google が提供する qwiklab が使えます。 一時的に GCP プロジェクトが作成され、そこでハンズオンができるのですがこれが実際に手を動かしながら学ぶという形式にすごく良いのと k8s の構築もすべてクラウドでできえるので変に環境構築でハマることなく快適に学習に集中できました。
もう、これがめちゃくちゃ快適でハンズオンとしてすごく快適に手を動かせなら、k8s の初歩的な概念や Command line などを学べました。
実際に手を動かしながら学ぶべきものだと思うので、このハンズオン形式の講義はありがたかったです!
後は学ぶにつれて、 k8s の凄さがわかってきたので理解して使いこなせるようになればスケールするシステムを個人でも作れそうなので、頑張っていきます。</description></item><item><title>遅すぎる `pandas.read_gbq` を使わずに、Google BigQueryから高速にデータを読み込む</title><link>https://shunyaueta.com/posts/2019-10-03/</link><pubDate>Thu, 03 Oct 2019 23:52:54 +0900</pubDate><guid>https://shunyaueta.com/posts/2019-10-03/</guid><description>pandas.read_gbq 便利ですよね。 クレデンシャルファイルを認証画面からコピペすれば Jupyter Notebook 上で簡単に認証され、Google BigQuery が実行されてその結果がそのままデータフレームとして扱えます。 Jupyter Notebook と Google BigQuery を連携させたいときは愛用していました(過去形)。
問題点 そこそこ大きなデータを持ってこようとすると、めちゃくちゃ遅くてストレスが凄い 解決方法として、Google BigQuery で巨大なデータをダウンロードする方法について書きます。
実は Google の公式ドキュメントでも推奨されています。
https://cloud.google.com/bigquery/docs/pandas-gbq-migration https://cloud.google.com/bigquery/docs/bigquery-storage-python-pandas 方法は以下の２つ。
google-cloud-bigquery をインストールして、マジックコマンドで Google BQ を実行 BQ 実行 →BigQuery table として保存 →GCS へ保存 → gsutil でマシンへコピー 1 番目は、Jupyter 上でマジックコマンドで Google BQ が実行できて、速度も pandas.rad_gbq よりも高速です 2 番目はそもそも実行結果が巨大な場合で、目安としては1GB以上なら 2 番目の方法を使えば楽です。
1, google-cloud-bigquery をインストールして、Jupyter Notebook のマジックコマンドで Google BQ を実行 pip install --upgrade google-cloud-bigquery[bqstorage,pandas] magic command を実行
%load_ext google.cloud.bigquery 後は Jupyter Notebook のセルで以下のコマンドを実行すれば、</description></item><item><title>Jupyter Notebook上にTensorboard を わずか2行で表示させる</title><link>https://shunyaueta.com/posts/2019-09-25/</link><pubDate>Wed, 25 Sep 2019 23:16:07 +0900</pubDate><guid>https://shunyaueta.com/posts/2019-09-25/</guid><description>Pytorch 1.2 からは公式に Tensorboard がサポートされている
Tensorboard とは、学習の状況を可視化できる TensorFlow Family の一種
Jupyte Notebook 上で学習状況を確認したい場合に Tensorboard をそのまま表示して確認できれば楽なので、試してみる
sample code: https://pytorch.org/docs/stable/tensorboard.html import torch import torchvision from torch.utils.tensorboard import SummaryWriter from torchvision import datasets, transforms # Writer will output to ./runs/ directory by default writer = SummaryWriter() transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]) trainset = datasets.MNIST(&amp;#39;mnist_train&amp;#39;, train=True, download=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) model = torchvision.models.resnet50(False) # Have ResNet model take in grayscale rather than RGB model.</description></item><item><title>How to connect the Google Compute Engine via Visual Studio Code</title><link>https://shunyaueta.com/posts/2019-09-24/</link><pubDate>Tue, 24 Sep 2019 17:35:05 +0900</pubDate><guid>https://shunyaueta.com/posts/2019-09-24/</guid><description>1. Generate SSH config file using gcloud command line gcloud compute config-ssh https://cloud.google.com/sdk/gcloud/reference/compute/config-ssh
You cant get ssh config for your Google Compute Engine project!
Notice: you need choose target GCP project before run below command.
gcloud config set project &amp;lt;your-project-id&amp;gt; 2. Install Remote SSH extention in Visual Studio Code. https://code.visualstudio.com/blogs/2019/07/25/remote-ssh
3. Press ⇧⌘P &amp;amp; Select target connection in Visual Studio Code! Finaly you can connect in Visual Studio Code. Welcome to VS code when you write the code in SSH connection.</description></item><item><title>ビジネスでインパクトが出せるデータサイエンティストになるには</title><link>https://shunyaueta.com/posts/2019-09-23/</link><pubDate>Mon, 23 Sep 2019 18:48:47 +0900</pubDate><guid>https://shunyaueta.com/posts/2019-09-23/</guid><description>@pseudo_finite さんから
「ビジネスでインパクトが出せるデータサイエンティストになるためには」
をご恵贈していただいたので、感想をここに記します。
経営システム誌に寄稿したものができました。30 部あるので欲しい方はお声がけください。私の 10 年間の経験を整理して中堅のデータサイエンティスト向けに書いたものになります。批判的なフィードバックなどいただけると嬉しいです。(@pseudo_finite) tweet January 18, 2019
批評 1. データサイエンティストが力を発揮する場 データサイエンティストとして成果を発揮するには、事業ドメイン・そしてデータの規模と質に依存する
圧倒的に同意です。自分も現職に就職する際には、データ規模・質・種類や社内のデータに関する文化などを考慮して会社を選びました。 最後の一文も完全に同意で、良いデータさえあれば基本的に問題は解きやすく簡単になると思っています。
2. 課題設定 データサイエンティストの仕事の肝は適切な課題設定
本質的な課題設定とはそもそもなんなのかと考えてみます。
ここで、本質的な課題設定を解明するための大きな障壁になるのは、
自社が事業会社か ドッグフーディングできるサービスを運営しているか どうかではないでしょうか?
日常的に自社のサービスを使っていると、顧客視点での改善点や課題点などを見つけることができる。 また、サービスをより深く知ることで深い考察や客観的な観察をすることができる。 スタートアップ界隈では浸透している リーンスタートアップの考え方は、本質的な課題の発見に非常に相性が良いと思っています。
また、データ分析では、単なる集計や相関ではなく、顧客がどんな状況で何をしたいのかを考えてユーザーリサーチをすることも非常に重要です。 ジョブ理論 イノベーションを予測可能にする消費のメカニズム で語られているトピックですが、非常に勉強になります。
3. 解決方法の設定 自然なモデリングと実現可能性のあるモデリング
自分はデータサイエンティストではなく、機械学習エンジニアとして働いているので、その立場からの視点です。 実感するのはまず何よりも実装力が大事だと思います。
実装ができるからこそ、実験ができる。その実験から知見を得て改善のサイクルが回り始める。
関連する暦本先生の tweet が面白かったので、ご参考まで
4. 検証 施策実行後の検証は必須
個人的には自分が最も重要だと思う点はここである。 確かに施策が成功したら、燃え尽きたくなる気持ちはわかるが、なぜ成功したのかを解明して再現性を担保しなければ知見としてストックされない。 そして知見の溜め込みの速さ・多さこそがビジネスとしての優位性につながるのではないのだろうか? これこそ、まさに科学的思考の本幹ですね。
5. 育成 データサイエンティストの育成は非常に難しい
育成の点は、自分も最近考えていたことですが、
例えば研究室のセミナーや論文の赤入れなどで議論をしたからこそ科学的思考方法が身についたのか? を考えていました。
僕の結論では、 強い相関はあれど研究室での議論により全員が身科学的思考方法を会得するのは難しいのではないかと思っています。 (もちろん全員が身につけることこそ、研究室の本懐だと思います)
Software Enginnering やアカデミアの世界では、レビュー文化を体験してあくまで内容に関する批判であり、 フィードバックを受け入れて改善する姿勢を身に着けていることも大事だなと最近感じています。
Team Geek ―Google のギークたちはいかにしてチームを作るのか の書籍で語られる HRT の精神ですね。</description></item><item><title>How to concat image using skimage</title><link>https://shunyaueta.com/posts/2019-06-17/</link><pubDate>Mon, 17 Jun 2019 00:07:33 +0900</pubDate><guid>https://shunyaueta.com/posts/2019-06-17/</guid><description>When you need to concat same size image to make figure.
skimage &amp;amp; numpy combination is too powerfull to concat images.
This is sample script.
from skimage import data, io import numpy as np img = skimage.data.astronaut() imgs= [img for i in range(10)] skimage.io.imsave(&amp;#34;sample_h.png&amp;#34;,np.hstack(imgs)) skimage.io.imsave(&amp;#34;sample_v.png&amp;#34;,np.vstack(imgs)) After that you can get below images.
Via Gist: https://gist.github.com/hurutoriya/fedf059ad3db5c67b16d8d5dd6d3df70</description></item><item><title>Hugo Tips</title><link>https://shunyaueta.com/posts/2019-06-16/</link><pubDate>Sun, 16 Jun 2019 23:09:18 +0900</pubDate><guid>https://shunyaueta.com/posts/2019-06-16/</guid><description> Hugo 0.32から page bundle が使用可能に この機能で画像ファイルを以下のファイル構成で構築できる - hoge/ - index.md - hoge.png これにより、markdown とアセットファイルが同一ディレクトリ内に収まるのでアセットファイルの管理が簡単になる
hugo new で特定のエディタを開くには? hugo new posts/hoge.md --editor=&amp;#34;code&amp;#34; 作成時にslug に日付を含める 今回は2020-09-09の形式で slug を作成する hugo new posts/$(date &amp;#39;+%Y-%m-%d&amp;#39;)/index.md page をビルドして結果を確認する hugo server 下書きも含めてビルドする hugo server -D</description></item><item><title>Machine Learning Casual Talks #10 を開催しました</title><link>https://shunyaueta.com/posts/2019-06-15/</link><pubDate>Sat, 15 Jun 2019 22:01:27 +0900</pubDate><guid>https://shunyaueta.com/posts/2019-06-15/</guid><description>MLCT #10 を開催しました。
Machine Learning Casual Talks とは
実サービスにおける機械学習の経験をカジュアルに語り合おう
を目的としたコミュニティです。
スポンサー 前回と同じく本イベントは株式会社メルカリにスポンサーとして会場と懇親会の提供を受け開催することができました。 スポンサー依頼を快諾いただきありがとうございました!
配信動画はこちら!
Sli.do がパネルディスカッションでめっちゃ便利な件 今回は、パネルディスカッションで sli.do をスクリーンにフルスクリーンで表示してモデレーションを行いました。
手元のスマートフォンで質問をハイライトして、回答を終えたものはアーカイブという運用でしたが、とても快適なのでみなさんぜひお試しください。 スクリーンでの表示画面が SPA で同期されているので、手元のスマートフォンで更新すればリアルタイムで同期されるのがとても便利です。</description></item><item><title>Machine Learning Casual Talks #8 を開催しました</title><link>https://shunyaueta.com/posts/2019-02-02/</link><pubDate>Sat, 02 Feb 2019 18:41:32 +0000</pubDate><guid>https://shunyaueta.com/posts/2019-02-02/</guid><description>Machine Learning Casual Talks 第 8 回の開催を無事終えました
MLCT とは
実サービスにおける機械学習の経験をカジュアルに語り合う
コミュニティです
スポンサー 今回も同じく本イベントは株式会社メルカリにスポンサーとして会場と懇親会を提供を受け開催することができました!
Machine Learning Casual Talks #8 (2019/01/28 18:30〜)
当日の配信動画はこちら
当日の発表資料はすべてこちらにあります
Machine Learning Casual Talks #8 - 資料一覧 - connpass
エムスリー 西場さん
BEDORE すみのさん
TL;DR; エムスリーの西場さん、すべてをこなす toB の機械学習サービス、システムアーキテクチャデザインかなり考えないとキツイ 懇親会での 🍣 の需給予測失敗しかけた 次回挑戦したいこと 今回会場撤収時に有志の参加者、登壇者の方が撤収作業を手伝っていただき非常に助かりました。次回は有志で会場撤収ボランティアの参加枠を作ろうかなと思いました。運営コストを下げるのは、継続で一番大事だなと思っているので、お手伝いいただいた皆様ありがとうございました。助かるという感情が出てくる前に、素直にめちゃくちゃ嬉しかったです!
参加率も 8 割を超えていて欠席率が非常に少なかったのも継続していきたい</description></item><item><title>Machine Learning Casual Talks #7 を開催しました</title><link>https://shunyaueta.com/posts/2018-12-15/</link><pubDate>Sat, 15 Dec 2018 19:29:59 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-12-15/</guid><description>Machine Learning Casual Talks 第七回を無事開催しました
Machine Learning Casual Talks #7 (2018/11/20 18:30〜)
MLCT とは
実サービスにおける機械学習の経験をカジュアルに語り合おう
というコミュニティです。
スポンサー 今回も同じく本イベントは株式会社メルカリにスポンサーとして会場と懇親会を提供を受け開催することができました。スポンサー依頼を快諾いただきありがとうございました!
遺伝異常により髪が青く変色してしまったタカヤナギ=サン
ABEJA の機械学習導入事例と辛い話を大田黒さんにお話していただきました!
今回の勉強会資料は以下にまとまっています。
Machine Learning Casual Talks #7 — 資料一覧 — connpass
今回の内容を今北産業
機械学習エンジニアとしてのキャリアのお話を タカヤナギ=サン 実世界に根付いた IOT と機械学習サービスはかなり辛い 各社の機械学習エンジニアの定義が揺らいでいるので、世界が壊れる 今回の改善点 参加枠の多様性 絶対参加するぞ枠 一般参加枠 初回参加枠 SNS 枠 Blog 枠 と今までは一つの枠で扱っていたものを、5 つの枠に分散して用意してみました。
なぜかというとドタキャンやノーショーの方の影響で本当に参加したい方や初回参加の方の機会が喪失してしまうのはいただけないので、それを解決したなと思ったのが始まりです。
初回参加枠を設けることで、新規参加者が増えて内輪感が解消されるのも狙ってみました。その影響か前回と比較して 2 割ほど参加率が増えてよかったです :)
パネルディスカッション 登壇者 2 名と僕がモデレーターを行い、パネルディスカッションを行いました。単なる発表保の質疑応答時よりも話が盛り上がってなによりでした~
次回予告 次回 MLCT 第 8 回は 2019/01/28 に参加予定です!
現実世界での機械学習の辛みを共有したい・語りたいという方はゼヒご参加ください~
Machine Learning Casual Talks #8 (2019/01/28 18:30〜)</description></item><item><title>Machine Learning Casual Talks #6 を開催しました</title><link>https://shunyaueta.com/posts/2018-10-14/</link><pubDate>Sun, 14 Oct 2018 03:01:01 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-10-14/</guid><description>機械学習の信頼性が熱いよねというお話
柚餅子 さんの発表風景
2018/09/25 の MLCT #6 を開催しました。
MLCT とは
実務における機械学習の話や経験をカジュアルに語り合おう
というコミュニティです。
スポンサー 今回も同じく本イベントは株式会社メルカリにスポンサーとして会場と懇親会を提供を受け開催することができました。スポンサー依頼を快諾いただきありがとうございました!
Machine Learning Casual Talks #6 (2018/09/25 19:00〜)
発表資料一覧 👇(スライドと配信動画) Machine Learning Casual Talks #6 - 資料一覧 - connpass
柚餅子さん リブセンスにおける機械学習システムの信頼性エンジニアリング SRE の考えを機械学習システムに取り入れるというお話ですが、筋が良さそう。特に SLO 周りはうちでも取り入れないなぁと思いました Naomichi Agata さん ユーザーフィードバックと機械学習 半教師あり学習で解くというアプローチは非常に筋が良さそうで気になった。技術書典の書籍も気になる 👀 gamella さん マーケット予測モデルの PCDA の回し方 ms 単位のデータを学習データにして株価の UP/DOWN を予測する。。。。適用するドメインの難易度が鬼ゲーすぎて、ハラハラしそうだけど解きがいがありそう @yu-ya4 さん Big Query ML を使ってみた話 さらっと BQML を試して成果が出ましたと言っていたが、良い問題を探し出す嗅覚がすごいなと思いました。実際 BQ だけで過不足なくモデリングが終わるなら理想の世界ですね~ Kosuke Kitahara さん 発表資料は後日公開されます。謎の力により Youtube 配信はされていません KPT Keep 動画配信を問題なく完了できた 魅力ある発表内容を維持できた Problem 参加率が低かった。前回は 65%程度の参加率でしたが、今回は雨の影響もありますが 40% と低くなっていた 倍率も毎回 1.</description></item><item><title>Machine Learning Casual Talks #5 を開催しました</title><link>https://shunyaueta.com/posts/2018-07-15/</link><pubDate>Sun, 15 Jul 2018 09:31:28 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-07-15/</guid><description>2018/07/13 に MLCT #5 を開催してきたお話
Opening Talk by Aki Ariga
Machine Learning Casual Talks #5 (2018/07/13 19:30〜)
本イベントは株式会社メルカリにスポンサーとして会場と懇親会を提供を受け開催することができました。スポンサー依頼を快諾いただきありがとうございました。
発表資料はこちら 👉 here (YouTube 配信もあります)
この記事では、技術的なお話というよりも開催に至るまでの話をメインに書いていきます。
Start 構想開始時期は 2018/04 頃に考えていて、弊社開催の
MLOps Nightと呼ばれるイベントの準備を行っているときに、社内だけではなく
社外の人の機械学習の辛い話をうんうんと頷きながら聞きたいなぁ
と思ったのが事の始まりです。
そのあと、とりあえず日程と発表者は事前に集めておかねばと思い @hagino3000 さんにラブコールを送っていた。
発表依頼の様子
chezou さんとの出会いと MLCT 復活の狼煙 その後、
勉強会の名前どうしよう 🤔 運営の方針どうすべきか 🤔 を迷いつつ時間が過ぎていき業務の一環として機械学習工学キックオフシンポジウム に参加していたら、そういえば Aki Ariga さんって MLCT 開催してたよな、あの勉強会すごく参考になること多かったから復活できないかなと思い始め、気がついたら懇親会で hagino3000 さんに chezou さんを紹介してもらい
「MLCT 復活させたいです!!! 場所と運営準備は僕主体でやります!」
と提案したら、あっさりと快諾され運営者に混ぜてもらえることになりました
メッセージ投げかけから 1 分で承認される
あらためて、突然飛び込んできた見知らぬ人物の運営への参加を快諾してくださった、 @chezou さん、 @tetsuroito さん、 @komiya_atsushi さんありがとうございました 🙇</description></item><item><title>イベント運営に便利なsli.do の使いこなしかた</title><link>https://shunyaueta.com/posts/2018-06-17/</link><pubDate>Sun, 17 Jun 2018 15:03:27 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-06-17/</guid><description>イベント運営者必見 sli.do の使い方
sli.do のディスプレイ画面
sli.do という便利な質問投稿・回答サービスがあります。このサービスですが、イベント運営者あるあるの
オフラインだと活発に質問が出ない Twitter は盛り上がってるが実際の反応はわからない Google Form はいまいち回答率が悪い などの問題点を解決してくれるサービスです
Slido - Audience Interaction Made Easy
基本的な使い方は以下の公式動画がサクッとまとめられていて分かりやすいです
これ見れば sli.do の機能は全て俯瞰できる
UI が良く操作に迷うことはないので、各機能のスクショを貼りつつ紹介していきます
イベント設定 設定画面
イベントの名前や、 短縮コード(イベントのハッシュタグにしておくと分かりやすい)を設定して導線をわかりやすくできる
投票機能 無料版だと 3 つの投票までできる。大きなイベントでなければ十分。もちろん回答結果はシークレットにもできます。
3 つの投票機能
複数選択肢
自由記入式
星によるレーティング
各投票機能はアクティブにすると参加者は一つだけ投票可能になる
参加者からの質問・回答結果のライブ表示 右上のトグルボタンをクリックすると、投票結果をライブ表示できる。勉強会の発表中にサイドディスプレイがあれば常時表示しておくとライブ感が出て良いと思う
ライブ画面への切り替え
質問一覧
回答ライブ画面
上部のスイッチ画面から次の投票に切り替えることができる
回答解析機能 管理画面から回答のインフォグラフィックを生成することもできる
といたせりつくせりの機能が提供されています。
まとめると
イベント参加者からのオープンな質問投稿(匿名・非匿名) 各質問・回答のライブ表示 運営者からのサーベイ(イベントの感想など) の 3 点が sli.do では使えます
Tips 唯一惜しい機能としては、イベント管理者が単一ユーザーでしか管理できない点ですが共同アカウント作れば大丈夫そうです。
How do I add more admins to my event?
Google Slides でも QA 機能ありませんかとかありますが、sli.</description></item><item><title>[抄訳] Data engineers vs. data scientists</title><link>https://shunyaueta.com/posts/2018-04-24/</link><pubDate>Tue, 24 Apr 2018 02:18:46 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-04-24/</guid><description>データサイエンティストとデータエンジニアの定義とその誤解による悲劇、そしてそれを救う存在である機械学習エンジニア
紹介記事 Data engineers vs. data scientists
紹介記事を同僚から教えてもらい、面白かったので抄訳した
&amp;gt; Aki Ariga さんが言及していた記事と方向性が同一で面白かった。
Data Scientists : ビジネスサイドを理解し、他者にわかりやすく可視化と言語化できる職能。そして高度な数学的知識に基づいたモデリングやアルゴリズム提案スキルも持っている。Data Scientists には高度な Programming skill は必ずしも必須ではない、なぜならモデリングやアルゴリズムを実装するためにプログラミングを習得した人が多いからだ。システムデザインや Programming スキルは、Software Engineer や DataEngineer からみると見れたものではない(そしてそうでなくてはならない、なぜならスペシャリストだから)
Data Engineer : 分散プログラミングを意識して構築できる職能。DE は卓越したプログラミングスキルとシステム構成力を持つ。定義 : つまりビッグデータに対してシステム的に解決できるスキル。クラスタ設計までが Data Engineer の役割であり運用(Ops)はやらない
from : https://www.oreilly.com/ideas/data-engineers-vs-data-scientists
Data Scientists と Data Engineer の互いの特化したスキルは補完しあってこそ輝く。 Data Scientist がデータパイプラインを作ると悲劇が起きてしまう。多くの企業が Data Scientist を Data Engineer として雇っているが、それは Data Scientists のスペックを活かしきれず、20–30%の効率で働かせてしまっている。そしてその ROI はめちゃくちゃ悪い。Data Scientists は適切なツールと選択肢を熟知していない(そして Data Engineer はシステムデザインと熟知しているのでミスは侵さない) e.g. 実際著者が聞いたこんな話がある。 Data Scientists が Apache Spark を使って 10GB のデータ処理を行うのに 1 回 15m の時間がかかっていた。(だが RDBMS を使えば、10ms で終わる) Data Scientist は彼らの流儀を疑うこと無く 1 日に 16 回 Spark の処理を実行しており、15mx16=240m つまり 4h の時間を無駄にしてる。RDBMS を使えば、160ms で終わるというのに… Data Scientist が頑張ってシステムを構築するが、職能の限界で Data Engineer しか作れないシステムなので時間とお金の浪費になった 実情 : Data Scientist として雇われたのに、Data Engineer として働かざるを得ない人がほとんどだ 理想的な人材配置 Case : 初期の組織: 2–3 人の Data Engineer : DataScientist Group Case : 更に複雑な事に取り組みたい 4–5 人の Data Engineer : 1 Data Scientist Data Engineer change to Data Scientist の王道 → それが新しい職種 : Machine Learning Engineer!</description></item><item><title>Google Colaboratory で Mecab-ipadic-Neologd を使用可能にする</title><link>https://shunyaueta.com/posts/2018-04-23/</link><pubDate>Mon, 23 Apr 2018 15:38:10 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-04-23/</guid><description>Colabratory 上で 日本語に対する NLP をしたいときありませんか？
# install MeCab neologd !apt-get -q -y install sudo file mecab libmecab-dev mecab-ipadic-utf8 git curl python-mecab &amp;gt; /dev/null !git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git &amp;gt; /dev/null !echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 !pip install mecab-python3 &amp;gt; /dev/null インストールに成功しました。
Google Colabratory も以下で公開しているので参考にしてみてください
colab-mecab-ipadic-NEologd.ipynb</description></item><item><title>eBayのAR測定機能を試してみた</title><link>https://shunyaueta.com/posts/2018-04-16/</link><pubDate>Mon, 16 Apr 2018 14:57:41 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-04-16/</guid><description>eBay が ARCore を使った商品の梱包測定機能を提供しているので試した
梱包測定の仕組みとしては、ARCore(今回は Pixel2 XL で試した)で平面検出を行って、そこに eBay のダンボールオブジェクトを設置することで、ダンボールに入るかどうかを判定できる。
下のダンボールアイコンを選択して、検出された平面をタップするとダンボールオブジェクトを設置できる
今回例として用いた MBP の空箱だと ARCore が空箱自体を平面と認識してしまうという罠があるので、床で平面検知を終えてから商品を置くという裏技が必要
まとめ ARCore を用いた AR 機能をすぐ試せる組織体制なのは凄い。ハッカソンで作ったのかな? 実用性は 🙅、平面検出しかしてないので、荷物に合わせて最適なダンボールを選ぶのは結局ユーザー。そこまで自動化してこそ革新的な機能になるのではなかろうか Reference eBay uses augmented reality to help sellers find the right box for their product</description></item><item><title>Google, Facebookが提供する機械学習基盤まとめ</title><link>https://shunyaueta.com/posts/2018-04-09/</link><pubDate>Mon, 09 Apr 2018 13:55:44 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-04-09/</guid><description>Google, Facebook の機械学習基盤情報をまとめました
Podcast でも紹介しました
#2 Facebook と Google の機械学習基盤について at just4fun.fm
社内の勉強会で Google, Facebook が提供する機械学習基盤に関する論文を紹介したので、その資料を公開します
機械学習をサービスとして提供開始すると、継続的な学習やプロダクション環境での機械学習の提供はモデル構築以外にもいろいろと考える問題が多くなります ¹
[1] Hidden technical debt in Machine learning systems NIPS’15
要するに機械学習をサービスとして届けるには、実はめちゃんこ大変なんだよという話なんですが、みんな同じ問題にぶち当たります。
そのためプロダクションレディなレベルで機械学習を提供できるプラットフォームを各社が提案しておりその中でも Google, Facebook の事例を提供します。
TL; DR; FBLearner: MLaaS の事例として最初に読むべき論文、MLaaS をどのような戦略で提供しているかを抽象的にまなべるため、鳥瞰図として読みましょう TFX は逆に機械学習基盤が必要とする技術スタックや要件などを詳細に説明しており、教科書的な立ち位置です。社内で機械学習基盤を内製したい場合に詳しく読み込むこと必須 両社とも MLaaS をスケーラブルに提供する環境ができており、サービスのコアテクノロジーになっている Google : Tensorflow Expand TFX: A tensor flow-based production-scale machine learning platform
Facebook : FBLeaner Applied machine learning at facebook a datacenter infrastructure perspective HPCA18
ONNX を見ていると TensorFlow VS.</description></item><item><title>メルカリのTeam AI Meetup #1 に参加してきた #mercari_ai</title><link>https://shunyaueta.com/posts/2018-02-13/</link><pubDate>Tue, 13 Feb 2018 15:35:48 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-02-13/</guid><description>メルカリが主催する機械学習のミートアップに参加してきたので備忘録がてらメモ書きです。書きなぐったメモなので意訳として捉えて下さい
発表者の顔は隠しています。なにか問題があればお伝え下さい。
Team AI Meetup #1 (2018/02/13 19:00〜)
Twitter: #mercari_ai
山口さん Image Net と mercari の持ってるデータセットは似てるのでいけるのでは! ルカリはクラス数 over 1100 始期の推定値 Top5 29.3% エラー例 :画像からサイズを推定しないと男女のシューズを区別不可(人間でも不可能なエラー例が多い) 意外と認識がうまくいく事例がかなりある(クラス設計の影響で推定が上手く出来ていないらしい) データセットはユーザーが作成してるので最高、画像が正方形なのも Good 学習は GPU,推論は CPU 環境下で行っている 画像検索自体はプロトタイプは出来ているが、実運用は計算量やリアルタイム性を担保するのが難しいので一旦保留中 大筋は以下の記事と資料で把握できます。k8s で運用しているなどの実運用の構成が今回の発表では差分として語られていました。
画像での商品検索に向けて - Mercari Engineering Blog
【Mercari Summer Internship】商品画像の色推定を行いました! - Mercari Engineering Blog
工藤さん 運用を継続すると色んな問題が出てきたので、それを解決する基盤環境を作成しはじめた e.g. 学習データのバージョン管理、モデルのデプロイ, etc 最終的には OSS としての公開も考えているとのこと メルカリの今年 1 年間の機械学習の取り組みとこれから - Mercari Engineering Blog
ML Ops Study (仮) #1の発表内容も今回の機械学習の運用周りの Tips が共有されているので興味のある方はオススメです
機械学習基盤といえば、最近Polyaxonという OSS が公開されてました。</description></item><item><title>2018.01 KPT</title><link>https://shunyaueta.com/posts/2018-02-09/</link><pubDate>Fri, 09 Feb 2018 14:00:31 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-02-09/</guid><description>2018 年 1 月の振り返りをざっくりと
Keep Mercari Competition にて初 Kaggle コンペ参加。 Best 116 位まで言ったんですが、NLP 周りの知見が無いのと、Kaggle 周りの力不足で現在は 317 位… ブロンズまで引き戻せるか… ぬか喜びしている図
Coursera で Ng 先生のML コースを始めた。あと 5 日位で無事終わりそう。とても分かりやすい(何故もっと早く受けなかったのか…) 終わったら、How to Win a Data Science Competition: Learn from Top Kagglersか Ng 先生の deeplearning.ai を始める予定 本を 2 冊読めた。案外読む始めるのがハードル高いだけで、読み始めれば 1 日 30 分*5 日で読み終わることがわかったので今度から通勤途中に読むことにした。これで月 4 冊読んでいくようにしたい。2–3 月はメタ学習関連の本を読み進めていく。 学力の経済学
お金持ちになれる黄金の羽根の拾い方
Duolingo で英語学習を再開した。学習アプリとしてとても出来が良い。(名詞の複数形や冠詞などの細かい間違いを都度指摘されるのが好き。モバイルアプリ(iOS)は問題が重複して出題されるので PC メインで利用) 100%達成するぞ! Linkedin に成績が反映されなくなったのは残念。おそらく言語学習は継続性がないと意味がないのでそれを考慮してシステム変更したんだろうな
住信 SBI ネット銀行を開設した。ネット銀行最高。 Google Family **を始めた。**予定管理はTimeTreeを使ってデザインや使い勝手は不安が無かったんですが、Google Calendar に比べてアプリのインテグレーションや持続性(日本のベンチャー企業なのでいつまでそのサービスが持つのか)が不安になったので Google Family に乗り換えました。 Problem Kaggle のゴールドの壁を痛感。もっと精進せねば 論文読みが止まってしまってた。機械学習基盤とプロダクション環境における機械学習関連の論文をテーマにしてまとめて書き上げる Try 02 月から仕事が始まるので(初社会人、入社完了したらまた振り返り Blog を書く)、社会人としてのメタスキルを実践できるようにしておく(e.</description></item><item><title>2018年の抱負</title><link>https://shunyaueta.com/posts/2018-01-29/</link><pubDate>Mon, 29 Jan 2018 16:08:35 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-29/</guid><description>2018 年の抱負です。
Works 機械学習エンジニアとして六本木で働く事になりました。機械学習エンジニアとしてスペシャリストになれるように周辺スキルを伸ばしていきます。
Kaggle Master に到達(1 gold medal, 2 silver medals) 初参加のコンペもずるずる下降してしまいブロンズ圏外に…
Coursera, Udacity (MOOC)で CV, Robotics 周辺を学習していく Github で 50 star over の OSS を作る(CV or ML) 勉強会に登壇 or 主催 する メタ学習(学習の効率化)について小話
うまくなる技術¹などのメタ学習関連の本を色々と読み漁って学習のコツをいろいろ勉強してるんですが、外的指標(Github Star, Kaggle Rank, Toggl tracking,Coursera Certificate)を目的にすると人間気持ちよく継続できるらしいのでそれに沿った行動をするよう心がけています。後 5–6 冊メタ学習の本を読み終えてまとまったらまた記事にする。
サンシャイン丸の内さん¹や ふろむださん¹の記事も参考になるのでオススメです
個人的に最近心に響いたのはのじゃろりおじさんの勉強の姿勢です。
３ D や unity の勉強方法について。：ねこみみメモ
おそらく、やり続けて成功した人は「やり続ければ報われる！」と言うと思うのですが、年齢や経済状況や自分の才能を疑ったり等……現実は難しいと思います。
私は偶然このタイミングで「オリジナルモデルの Vyoutuber を出せた」から幸運に恵まれただけで、純粋な技術ではおそらく就職は無理だったのではないかと思います。2018~19 年で見切りつけて諦めなきゃなと思ってたぐらいです。
なので「やり続ければ報われる」とはとても言えません。ただ**「やり続けて報われなくてもいいと思える事は、やり続けた方がいい」**とは思います。
他者の評価がどうであれ、やてって楽しくて満足できるのであればある意味常に成功している状態で、やればやるほど成功続きなわけです。
English DMM 英会話 TOEFLE で 90 点、英語で働けるレベルを目指す 英語 Blog 記事を定期的に書く Health カラダステーションで内臓脂肪が少し高めになってたので走る(筋トレしかやってなかったツケが…) 筋肉量も左右でバラツキ(利き手側じゃないほうが 100g 程度筋肉量が少ない)があるので整える 筋トレはケトルベル 16kg で色々とやってるので継続する。</description></item><item><title>Where To Look: Focus Regions for Visual Question Answering (CVPR2016)を読んだ</title><link>https://shunyaueta.com/posts/2018-01-18/</link><pubDate>Thu, 18 Jan 2018 05:41:44 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-18/</guid><description>Kevin J. Shih, Saurabh Singh, Derek Hoiem, “Where To Look: Focus Regions for Visual Question Answering”, in CVPR2016 link
Summry
を読んだので、軽くメモ。
VQA(Visual Question Answer) 画像に対する質問に対して応答するタスクに対し、その質問クエリに対して画像のどの領域に注目すべきかのモデルの学習方法について論じた論文。
Contribution VQA datasetに対して、提案手法を適用。従来手法を全て上回った。 画像に対して CNN を用いて物体領域の検出を行った後にベクトル化、質問クエリはword2vecを用いてベクトル化を行う。 その 2 つのベクトルを用いて内積計算により重み付けを行うことで、どの領域に注目すべきかを計算する。 Comments 引用文献の訳 9 割が 2014–2015(直近 2 年間)で発表された論文で、改めてこの分野の最先端を駆け抜けるのは凄まじい能力が必要になるなと思いました。
そして相変わらず CVPR の論文のネーミングセンスは良いですね。(ジャケ買いならぬジャケ読み)
単純な質問なら、人間でも瞬間的に解答可能な物が多いなと感じた。
fig. 1
セマンティックな疑問(Fig.1 雨は降っていますか?)の場合、人間に注目した場合は傘をさしているから雨と判断しても良いがもっと広い範囲で画像を見てみると空は快晴なので人間に注目するのは筋が悪く VQA はとても難しくチャレンジングな問題だと書かれていた。(それでも充分すごい領域に到達しているなと思うが)</description></item><item><title>Data-driven Crowd Analysis in Videos (ICCV2011)を読んだ</title><link>https://shunyaueta.com/posts/2018-01-17/</link><pubDate>Wed, 17 Jan 2018 05:55:41 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-17/</guid><description>Data-driven Crowd Analysis in Videos (ICCV2011)を読んだ
Mikel Rodriguez, Josef Sivic, Ivan Laptev, Jean-Yves Audibert, “Data-driven Crowd Analysis in Videos”, in ICCV2011.
Project Page
を読んだので、メモです。
Summary
tl;dr 高密度な群集内の個人を追跡を転移学習によって精度を向上させる手法 Contribution 追跡の精度を転移学習によって向上させた 転移学習を行うためのデータセットとそのフレームワークを考案 論文内では、転移学習の例としてマラソンAの群集を対象に追跡する際に、以下の流れで転移学習を行う。
大域的な群衆状況のマッチング : 同じようなシーンを探索(この場合 DB 内にあるマラソン動画) 局所的な群衆状況のマッチング : 1でマッチした動画においてオプティカルフローが類似するパッチを探索して転移学習 また、Rare Events(デモの最中に群集を横断するカメラマンなど、群衆の流れに対して同調しない動きを行う人物)に対しても実験を行い評価。
Comments 転移学習は自分のイメージだと、自然言語処理のイメージ(一般的な文書を学習したモデルを法律文書に対して適用するなど)しかなかったので新鮮な気持ちで読めた。
動画なら転移学習を行ったとしても、直感的に良い特徴を学べそうなので、良い仮説を立てている論文でした。
最後に示されてる個人追跡における平均誤検出の単位がpixelだが、Ground-Truth と提案手法の追跡軌跡の重複度具合を見てると誤検出が更に高そうに見えるけどどうなんでしょうか？
(テストデータのみ学習が 58.82、転移学習を行った提案手法だと 46.88になっていてもっと相対的な差が出てくるはず?)</description></item><item><title>Slicing Convolutional Neural Network for Crowd Video Understanding (CVPR2016)を読んだ</title><link>https://shunyaueta.com/posts/2018-01-16/</link><pubDate>Tue, 16 Jan 2018 06:04:37 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-16/</guid><description>群衆解析の手法に興味があるので、サーベイの結果を放流しておきます。
Jing Shao, Chen Change Loy, Kai Kang, and Xiaogang Wang, “Slicing Convolutional Neural Network for Crowd Video Understanding”, in CVPR, 2016.
Project Page
Summary
一言説明 時系列・空間的特徴から CNN で特徴を学習、群衆の動画に対してstate-of-the-artを達成
3 個の CNN を用いて下記の３つの特徴を表現学習
xy- : 空間的特徴 xt- : x 軸の時系列特徴 yt- : y 軸の時系列特徴 Comments Dataset としてWWW Crowd Dataset
が公開されている。10,000 本の群衆の動画を収集公開しているとのこと。
Demo Movie
紹介動画を見てみたら分かるが、群衆の動画というよりも数が増大した結果一般的な画像認識のデモ動画になっている Jing Shaoさんは CVPR2014 から群衆解析のための descriptor を提案したりしてたんだけど、2016 年から Deep な手法での群衆解析の研究をやっているのは手が早いなと 所属グループは ISLVRC2015 の物体認識タスクで優勝した香港大学のグループ Multimedia Laboratory The Chinese University of Hong Kong データセット、実装コードを必ず公開しているのは尊敬、またそれくらいやらないとトップには通過しないんだろうな CNN のアーキテクチャ毎の比較実験と考察をかなり入念に行っていた。数年後には各データのフォーマットに合わせたベストな DNN のアーキテクチャが決まってくるんじゃないだろうか</description></item><item><title>Jupyter Notebookの差分を明瞭に確認する事ができるpackage : nbdime</title><link>https://shunyaueta.com/posts/2018-01-15/</link><pubDate>Mon, 15 Jan 2018 17:14:54 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-15/</guid><description>Jupyter notebook をご利用の皆さん、朗報です。
例えば、下記の２つの notebook の差分を比較したい際に、
nb_1.ipynb nb_2.ipynb diffコマンドを用いると下記のような結果になってしまいます。
diff nb_1.ipynb nb_2.ipynb [master] 14c14 &amp;amp;lt; “image/png”: “iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n”, — - &amp;amp;gt; “image/png”: “iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJIb+P2c9rHcimwD6AAAAAElFTkSuQmCC\n”, 16c16 &amp;amp;lt; “&amp;amp;lt;matplotlib.figure.Figure at 0x10ba48cc0&amp;amp;gt;” — - &amp;amp;gt; “&amp;amp;lt;matplotlib.figure.Figure at 0x11037dcc0&amp;amp;gt;” 34c34 &amp;amp;lt; “ax.fill(x, y, zorder=10,facecolor=’green’)\n”, — - &amp;amp;gt; “ax.fill(x, y, zorder=10,facecolor=’black’)\n”,` diffは単純な文字列の差分比較を行うだけなので、notebook がjsonで管理されており、matplotlibで生成される出力結果の保存内容にも差異がでるのでこうなってしまいます。
jupyter/nbdimeを用いることで、notebook 形式の json をパースしたうえでの差分比較が可能になります。
提供されるコマンド一覧
nbdiff : ノートブックの差分比較をターミナルで行う nbdiff-web : Notebook の差分をブラウザで行う 簡単な実行結果
差分比較 ターミナル上での差分比較 nbdiff nb_1.ipynb nb_2.ipynb nbdiff nb_1.ipynb nb_2.ipynb — — nb_1.ipynb 2017–02–02 11:00:48 +++ nb_2.</description></item><item><title>Analyzing Free-standing Conversational Groups: A Multimodal Approach (ACMMM15) を読んだ</title><link>https://shunyaueta.com/posts/2018-01-14/</link><pubDate>Sun, 14 Jan 2018 10:41:12 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-14/</guid><description>スタンディングディスカッション形式での会話を評価した研究
Summary Slide
X Alameda-Pineda, Y Yan, E Ricci, O Lanz, N Sebe
“Analyzing Free-standing Conversational Groups: A Multimodal Approach”, in 2015 ACM Multimedia Conference
link
を読んだので、軽くメモ。
マルチモーダル系の論文初めて読んだんですが、まとめるとコントリビューションが 5 つあると主張。
Contribution 音声・近接情報、そして監視カメラからの身体と頭の姿勢推定からマルチモーダルに解析 フリースタンディングディスカッションを身体・頭の姿勢推定から解析 カメラと音声・近接センサーからなるマルチモーダルな解析するためのフレームワークを提案 ラベリングされてないデータに対する行列補間問題の考案 SALSA(データ・セット)を公開・評価 SALSA というポスターセッションの動画と音声のデータも公開されている
SALSA: Synergetic sociAL Scene Analysis
動画は Google Drive で公開されていて時代の波を感じる。
データセットを公開 論文も読みやすい 新しい行列補完計画法(アルゴリズム)を提案 実問題に取り組む と盛り沢山な内容で面白かった。
スライド内のリンクは Google Slide で共有しているのでこちらを参照すると便利です。
X Alameda-Pineda, Y Yan, E Ricci, O Lanz, N Sebe &amp;quot;Analyzing Free-standing Conversational Groups: A…</description></item><item><title>PythonでGaussian Kernelのアニメーションを作成</title><link>https://shunyaueta.com/posts/2018-01-13/</link><pubDate>Sat, 13 Jan 2018 17:03:43 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-13/</guid><description>Python でアニメーションを作成したかったのでメモ
Gaussian Kernel GIF Animation
当然ながら、HTML5 の Video は再生されないので GIF に変換した結果が以下。
これで HTML5 で再生される。
**GIF**で表示する方法として %matplotlib nbagg
というオプションが存在しているが、Kernel が busy 状態を何度も繰り返すので、自分は mp4 で出力するようにした。
実験結果も以前は GIF で保存してたが、最近は全てmp4で管理するようにした。
あと、**np.linspace()**が iterable ではないので、イマイチな書き方になった。。
**np.arange()**を使うべきなのか…
References Embedding Matplotlib Animations in Jupyter Notebooks Jupyter 上で matplotlib のアニメーションを再生する - Qiita</description></item><item><title>Call center stress recognition with person-specific models を読んだ</title><link>https://shunyaueta.com/posts/2018-01-12/</link><pubDate>Fri, 12 Jan 2018 17:19:48 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-12/</guid><description>Affective Computing: 計算機と人間の感情や情緒の関係性を考える領域
MIT Media Lab Affective Computing Group のプロジェクト。
2 年前に MIT Media Lab へ訪問した際に、色々と見せてもらったけどかなり野心的な事に取り組んでいて感動してた。(デバイスも自分たちでプロトタイプを作りまくっていて、Deploy or Dieの意思を感じ取れる)
論文のまとめスライドは以下
One Slide Summary
HCI 系の論文は初めてまともに読んだんですが、
実験デザインが一番難しそう。人と計算機の関係を研究するので、必然的に人間の感性をどう評価する話にもつながってきてる? 手法に重きを置くというよりも、問題に重きを置いている印象 普段自分は、数値線形代数や機械学習、コンピュータビジョンを主にやっていて、精度をどれだけ出せるか、正解率をどれだけ向上や、速度をどれだけ上げれるかを理論的に保証、提案したりしていますが、面白い問題や興味深いデータを集めることも大事だなと思った。
実験計画法¹もかなり重要で、メンターの人から実験計画法の成り立ちを教えてもらってとてもおもしろかった。</description></item><item><title>FUSE: Full Spectral Clustering(KDD2016) を読んだ</title><link>https://shunyaueta.com/posts/2018-01-11/</link><pubDate>Thu, 11 Jan 2018 17:30:28 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-11/</guid><description>べき乗法と独立成分分析を用いたマルチスケールに頑強なクラスタリング手法の提案
べき乗法では近似固有ベクトル(Pseudo-eigenvectors)は複数の真の固有ベクトルの線形結合からなる。有益でない固有ベクトルも含まれるのでいかにそれを除去するか Fig.1 で言ってることがいまいちわからない。ｃ,ｄも変化がないように見える。論文で言及してる stripe が何を指してるかが不明 分かった。赤・青・黒の３つのクラスタで分かれている。最初は黒色がクラスタ境界面に見えた。論文内での multi scale というのは、データの幾何的な分布を指している？ 固有値計算は O(n³）かかるから計算量が~~って毎回言われるが、行列の状態に依存するので毎回最悪の場合を主張されてるも困る ZP self-turining spectral clustering をなぜ対抗馬にして比較してるのかは謎。 ICA¹を行ったあとにその行列に対して回転処理を行い情報量の最小化を狙う クラスタ数が多い場合、PIC では良い結果が出づらい multi scale なデータの場合標準の spectral clustering では失敗することが多々ある fig.2 (a) 見ればわかるがk-means では分離が困難 fig.2(b) ４－５本目の固有ベクトルを基底ベクトルにもつ空間ではクラスタのオーバーラップが少ない つまり１－５本目の固有ベクトル全て含めてクラスタリングすれば結果が良好になるのではないか？（仮説） fig.2 © ４回べき乗法を行った。結果が似てる。（縦軸が何を表してるかは不明）。四回が上から四本求めたのか、一番上の固有ベクトルを４回求めたのか分からない fig. (d) 提案手法を適用。k-means で分離可能 行列Vをp回べき乗法を行って構築 E=MVの最小化を行う ICA を最小化するために Jacobi Rotation を用いる。探索には貪欲法を採用 Contribution マルチスケール（多種多様な）データ分布に対してクラスタリングが可能 計算時間は従来（ncut)と同等 感想 PIC(Power Itetaion Clusterg)をまさか拡張してくるとは思わなかったなので、興味深い論文。(実装して再現実験したけど、Early stopping の段階で高確率でクラスタリングが失敗していて使い物にならなかった印象があるので…) データの分布が多様な場合、上位数本のベクトルではなく、そこから更に下の固有ベクトルに着目したほうが結果が良好になるのは面白い KDD の論文、相変わらず読みやすかった。</description></item><item><title>サイトのPWA化、ホスティングをGithub PagesからFirebaseへ移行</title><link>https://shunyaueta.com/posts/2018-01-09/</link><pubDate>Tue, 09 Jan 2018 18:59:59 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-09/</guid><description>PWA と FireBase を試してみたかった
firebase init で現れる画面、テンション上がる
Github Pages + CloudFlare で独自ドメインの shunyaueta.com をホスティングしてたんですが、Firebase でホスティングできると聞いて Firebase に移行しました。
PWA にしたのは完全に趣味です。
TL;DR; Web App を作ってる人は manifest.json を設置するだけでも Android の使用感が改善されそう 独自ドメインでお手軽に SSL ホスティングしたいなら Firebase hosting めっちゃおすすめです(1GB のホスティングは無料) FireBase Hosting だけだと Firebase 本来の旨味は味わえません PWA 1 年前ですが、簡潔に PWA の事が書かれています
プログレッシブウェブアプリ詳解 ─ 過去・現在・未来
左: PWA 化以前 右: PWA 化以降
ServiceWorker と manifest.json,あとは&amp;lt;meta name=”theme-color”&amp;gt;を指定すると PWA のスコアが 100 点になる 🎉
manihest.json によるホームアイコン作成誘導
Favicon の各画像の生成は下記のサイトが便利でした。要求される解像度毎の画像(Favicon,Home icon, Apple home icon)が生成されて mahifest.</description></item><item><title>HerokuのDBにpgadmin4で接続してローカルにデータをダウンロードする</title><link>https://shunyaueta.com/posts/2017-12-27/</link><pubDate>Wed, 27 Dec 2017 08:12:17 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-12-27/</guid><description>pyadmin4 で Heroku 上の DB に接続する記事が日本語になかったので、メモ
接続前の準備 Heroku にログインして、対象の App の DB のページへ
Heroku App DB page
そこから DB のセッティングページにある credential ボタンをクリック
click credential button
そこに記載されている各種情報を pgadmin4 に入力して Heroku 上の DB に接続する
Copy information
pgadmin4 で Heroku の DB に接続 以下のページから pgAdmin4 をダウンロード
Download
そこからアプリを開くと下記の画面になるので、Add new Serverをクリック
Click Add New Server
Heroku 上の DB の情報を入力していく。Server の名前は適当で大丈夫です。
接続されるとこんな感じになります。
Query Tool Query Toolを使うことで Heroku 上の DB に対して SQL クエリを投げる事ができます。
Query Toolは上部のツールバーからアクセス可能です。 注意) 左カラムのテーブルをクリックした後でないとアクティブになりません。</description></item><item><title>“Learning Deep Representations for Graph Clustering (AAAI2014)” を読んだ</title><link>https://shunyaueta.com/posts/2017-12-23/</link><pubDate>Sat, 23 Dec 2017 17:38:19 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-12-23/</guid><description>自己符号化器と Spectral Clusteing の関連性を示した論文
Paper link Author Fei Tian : http://home.ustc.edu.cn/~tianfei/ 中国科学技術大学 Ph.D １年生 MSRA と共同研究、2014 年に AAAI2 本,COLING1 本を 1st で通してる。 この資料も面白い。ILSVRC2015 で 152 層の Deep Residual Learning を提案し優勝(Error Rate : 3.57%) MSRA @ ILSVRC2015 資料 Motivation (研究背景・動機) Deep Learning が数多くの応用でめざましい成果をあげている。 音声認識 画像認識 自然言語処理 DL において Clustering に関する適切な調査が行われてない。 論文の目的として、DL における Clustering の調査を行う 概要 Graph Clustering はクラスタリングでも重要な手法の一つ Graph Clustering の応用 Image segmentation Community Detection VLSI Design 嬉しい点 : ベクトル空間におけるクラスタリングの問題 → データの類似度グラフ問題への変換が可能 自己符号化器と Spectral Clustering の類似性 Spectral Clustering : グラフラプラシアンに対して EVD を行い k 本の非零固有ベクトルを用いた空間に対して k-means を行ったもの。 自己符号化器 : 入力データを低次元化、情報が最大限になるようにデータの次元を再構築する 計算量 : 対象とするグラフは n 個のノードを持つ EVD : ナイーブに実装すると O(n3)の計算量、最速の実装は O(n2)の計算量 自己符号化器 : ノードがスパースな際は計算量は O(kn) スパース表現 : データが大きくなるならスパース性を有効活用したい EVD : 固有ベクトルが高い確率で密になるため、スパース性が保証されない 自己符号化器 : スパース性を用いるのは容易 既存研究で未検証な事柄、何を解決・解明したいのか？ Graph Clustering のための Deep Learning の活用方法と調査 自己符号化器と Spectral Clustering の類似性とその比較・検証 Method (提案手法) GraphEncoder(for graph clustering.</description></item><item><title>JupyterNotebookをリモートサーバー上で公開して、どこでも研究開発 &amp; 講義でJupyterhubを利用する</title><link>https://shunyaueta.com/posts/2017-12-22/</link><pubDate>Fri, 22 Dec 2017 17:48:12 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-12-22/</guid><description>JupyterNotebook をリモートサーバー上で公開して、どこでも研究開発。
講義で Jupyterhub を利用するお話です。
GIF 画像は下記の記事で知ったtqdmというパッケージを使いたくなったので載せてみた。
私が選ぶ 2015 年の”新しい”Python モジュール トップ 5 IPython データサイエンスクックブック ―対話型コンピューティングと可視化のためのレシピ集 IPython データサイエンスクックブックをキッカケに研究室でも JupyterNotebook の凄さを皆が知り、MATLAB の kernel を通して利用を始めたりしています。自分は Python2→MATLAB→MATLAB &amp;amp; Python3 という流れで移り変わっています。
JupyterNotebook をリモートサーバー上で公開 コードは以下の通りです。特に問題なく公開することができました。
環境 CentOS 7 系 下記の記事を参考にセットアップする。
pyenv と virtualenv で環境構築 今回は pyenv を使って Python3.5.1 でホストしています。
昨日この記事を読んで、Anaconda がオススメされているので今度セットアップするときに使ってみよう。
Running a public notebook server | JupyterNotebook Docment こまかい設定等は以下の記事で説明されています。IPython Notebook を対象にした記事ですが、ほとんど一緒なので問題ありません。(config.py 自体がコメントで丁寧に各設定が記述されています。)
IPython notebook サーバーを立ち上げる ipython notebook をリモートサーバ上で動かす。 参考記事 iPython notebook で研究開発生活 Juptyerhub : 講義で Jupyter を利用する。 JupyterNotebook を講義でも活用できるようにならないかなと先生と探していたのですが、Jupyternotebook を公開するだけだとユーザー管理が不可能です。例えば ~tarou/というディレクトリで jupyternotebook を公開すると~tarou/に notebook が沢山できだれがどのノートを作ったのかが把握できないという問題点があります。</description></item><item><title>CoreMLがTensorFlow Liteをサポート</title><link>https://shunyaueta.com/posts/2017-12-06/</link><pubDate>Wed, 06 Dec 2017 13:36:38 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-12-06/</guid><description>TensorFlow 無双
TensorFlow Lite meets CoreML!!
個人的にいま興味ある分野のうちの一つがスマホで動く機械学習なんですが、昨日 TensorFlow Lite が CoreML でサポートされるというアナウンスがありました!
Announcing Core ML support in TensorFlow Lite
CoreML の最大の利点は iPhone のアーキテクチャを最大限に利用した推論の高速化なので、Google も何かしらの手を打ってくると思っていましたがまさかそのまま CoreML にサポートされたのは驚きです。
個人的に keras2, Caffe¹だけがサポートされてる今の状態は選択肢が少なくて微妙だなと思っていたので良いことだと思います。
少し横道にそれますが、ONNX と呼ばれる Machine Leaning のモデルを相互変換できるプロジェクトも立ち上がっているので、近いうちにフレームワーク間の差異は消えていき、書きたいフレームワークで書き、動かしたい環境にモデルを変換して運用するという流れになる未来がくるかもしれません。
ONNX: Open Neural Network Exchange Format
Pixel²も iPhone8³以降に搭載されている A11 チップに機械学習の計算を高速化させるチップが採用されているのでこれから Machine Learning on Mobile はドンドン加速していくとおもいます。iOS11 の吉田さんが担当している CoreML の章を見てましたが、利点と欠点が明快に知れるのでオススメです。
iOS 11 Programming - PEAKS
TensorFlow Lite もデフォルトで Android をサポートしているので、こりゃほんとにプロダクション環境だと TensorFlow 一択になりつつありますね
にしても TensorFlow の勢いはほんとに凄い…</description></item><item><title>Visualized Approximate Eigen Vector by Power Iteration on 3 dimensions.</title><link>https://shunyaueta.com/posts/2017-12-05/</link><pubDate>Tue, 05 Dec 2017 13:20:41 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-12-05/</guid><description>You can intuitively lean Power Iteration by Visualization Power.
Animation of Power Iteration by MATLAB
Power iteration - Wikipedia
Finally you put a command line
&amp;gt; convert -layers optimize -loop 0 -delay 40 eigenvector*.png anim.gif</description></item><item><title>Edge-Weighted Personalized PageRank: Breaking A Decade-Old Performance Barrier を読んだ</title><link>https://shunyaueta.com/posts/2017-12-04/</link><pubDate>Mon, 04 Dec 2017 13:06:15 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-12-04/</guid><description>応用数理研究者が機械学習界に進出していく研究
youtube clip
応用数理界隈ではクラシックな解き方で PageRank が解かれているので最新の数値計算手法に置き換えることで劇的にパフォーマンスが向上して 10 年前のパフォーマンスの鎖を解き放った論文
KDD2015 Best student paper award Slide(PDF) Poster(PDF) Spectral network analysis wenleix/EdgePPR
Presentation Movie is uploaded in Youtube. Author
W. Xie Ph.D Candidate at Cornell University http://wenleix.github.io/ iterative computation on big graph data D. Bindel http://www.cs.cornell.edu/~bindel/ http://www.cs.cornell.edu/~bindel/talks.html He is frequently research activ like ideal young researcher. Nonlinear eigenvalue problem. Alan J. Demers Prof. Johannes Gehrke http://www.cs.cornell.edu/johannes/ Prof. VLDB,SIGMOD,KDD Motivation ページランクは重要な指標。遷移確率を求めるにはランダムサーファーモデル(ランダムウォーク)が必要。 様々な高速解法が提案されている。 Reseatch Question しかし 10 年以上前、PageRank の黎明期から Personalization based の手法は問題がある。 一般的な PageRank の解法の説明、その後に Model Reduction をベースにした約 5 倍の性能を誇る提案手法を説明。 提案手法の性能によって、パフォーマンス上のボトムネックは消えた。 Proposed Method PageRank 初期:WEBPage のランクに使用 → 現在:推薦、ソーシャルネットワーク Random Suffer Model Transition : α の確率で Random Walk(滞在ノードから無作為に遷移) Teleporting : 1−α Random Junmp(滞在ノードに依存せずに全てのノードを対象に無作為遷移) x(t+1)=αPxt+(1−α)v,where P=AD−1 v is represents telepotation probabilitie xt Walker の確率分布 サーファーが来る確率 = RandomWalk の確率_RandomWalk による遷移確率 + RandomJump の確率_RandomJump の遷移確率 = α× RandomWalk による遷移確率 + (1−α)×RandomJump の遷移確率 = α×+(1−α)×v x: Stationary vector(不動ベクトル、定常ベクトル、不動点定理など) x が定常状態になった際に、x の確率分布が PageRank を表す。 x(t),x(t+1)が同一(残差が無い)だと仮定することで、次式の線形方程式を解くことで Pagerank を求める。 Mx=b,where M=(I−αP),b=(1−α)v.</description></item><item><title>Machine Learning that Matters (ICML2012) を読んだ</title><link>https://shunyaueta.com/posts/2017-12-01/</link><pubDate>Fri, 01 Dec 2017 07:55:12 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-12-01/</guid><description>機械学習の研究してる人は全員読んだ方がいい。そう断言できるぐらい良い内容が書かれています。 ICML2012 で発表された最近の機械学習に関する研究の問題点を論じた論文。
Summaly
「あなたは現実世界で役立つデータに対して機械学習の研究を行っていますか?」
著者は NASA の JPL(ジェット推進研究所)、カリフォルニア工科大学に所属する Kiri L.
Kiri L. Wagstaff
発表動画を探してみたんですが、ICML2012 で発表した際のビデオはサーバのクラッシュにより喪失したとのこと。
The video for my controversial ICML 2012 talk is no longer available (lost in a server crash). However, you can read the original paper: Machine Learning that Matters (pdf, 6 pages, 234K) and see the slides from a subsequent invited AAAI talk: Challenges for Machine Learning Impact on the Real World (1.6M). PowerPoint は下記リンク先に配布されています。http://www.wkiri.com/research/papers/wagstaff-MLmatters-slides-AAAI.pptx</description></item><item><title>Jupyter上でSVGのイラストやアニメーションが作成できるプラグイン egel</title><link>https://shunyaueta.com/posts/2017-11-22/</link><pubDate>Wed, 22 Nov 2017 12:04:30 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-11-22/</guid><description>アイデアは面白い… けど easy drawing ではない
Jupyter 使ってると作図も Jupyter 上で完結させたいなぁ~って思うときがあるんですが、スクリプトで作図はけっこう辛いものがあります
そのため Jupyter 上でフリースタイルに作図できる機能ないかなと探してたら egal という面白そうな拡張機能があったので使ってみました
uclmr/egal
egal GIF animation
以下のリポジトリから $pip3 install git+https://github.com/uclmr/egal.gi
でクローンしてきて $jupyter nbextension install --py egal $jupyter nbextension enable --py egal
で拡張機能を有効にして使えるようになります。
ブラシアイコンをクリックすると新たなセルが生成される
ボタンをクリックすると各オブジェクトの詳細なプロパティが調整できる
フレーム毎にオブジェクトを設定してアニメーションっぽくもできる
5–6 分使ってみて感じましたが、めちゃくちゃ操作がしづらい…
やはりブラウザ上での図形作成はめちゃくちゃストレスたまるので、ローカルで keynote 使って図形作成したほうがマシな感じです。
遊んだ結果を notebook で github にアップしておきました。
残念ながら SVG が Github 上ではレンダリングされないので残念な感じになっております&amp;hellip; ローカルにクローンしてきて egal を有効にしておくと見れます。
hurutoriya/notebook
結論 Jupyter で全てを完結させるのは難しい</description></item><item><title>OpenCV 3.3から使えるDNNモジュールを使って物体検出</title><link>https://shunyaueta.com/posts/2017-11-14/</link><pubDate>Tue, 14 Nov 2017 11:36:43 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-11-14/</guid><description>OpenCV と MobileNet を使って物体検出を行った
Object Detection with OpenCV dnn modules and MobileNetSSD on Jupyter Notebook
Introduction 物体検出を Deep Leaning と OpenCV を用いて行う
OpenCV 3.3 からdnnモジュールが正式にリリースされた
The main news is that we promoted DNN module from opencv_contrib to the main repository, improved and accelerated it a lot. An external BLAS implementation is not needed anymore. For GPU there is experimental DNN acceleration using Halide (http://halide-lang.org_). The detailed information about the module can be found in our wiki: Deep Learning in OpenCV.</description></item><item><title>Djangoで顔認識の結果をJSONで返す最小構成のAPIサーバーを作った</title><link>https://shunyaueta.com/posts/2017-11-13/</link><pubDate>Mon, 13 Nov 2017 17:22:38 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-11-13/</guid><description>DEMO GitHub でコードを公開してます。
hurutoriya/face_detector_api
Django の勉強は、基本的なイントロダクションとしてオフィシャルサイトのドキュメントが充実しているのでオススメです。
pyimagesearch の Blog 記事で最小限の構成で顔検出を行う API サーバーを作る記事があり、今回はそれを基本に作成した。
以下所感
Django は Rails と比べるとそんなにレールが敷かれていない 日本語の記事がほぼ存在しないので、英語の記事を読む良い練習になった OpenCV や Scikit-lean がそのまま動くのは相当魅力的で、サーバからのレスポンスが帰ってきた時には地味に感動 API 設計や非同期処理なんかの知識が全く足りない 次の課題 今回の発展形として django-rest-framework を使って、モデルを組み込んで作り上げて Google Apps Engine 上で公開してみよう。 REST Framework はこの記事2を参考に画像をアップロードできる雛形は作り上げた。 後は OpenCV で処理を施す部分を書き上げたらいけそう。
django-rest-framework で使える管理画面
References hurutoriya/face_detector_api Django REST Framework を使って爆速で API を実装する,ChristianKreuzberger/django-rest-imageupload-example Creating a face detection API with Python and OpenCV (in just 5 minutes) Django 1.11 Documentation Django REST framework is a powerful and flexible toolkit for building Web APIs.</description></item><item><title>TexPadのおかげでLatex人生が変わりました</title><link>https://shunyaueta.com/posts/2017-10-08/</link><pubDate>Sun, 08 Oct 2017 02:22:24 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-10-08/</guid><description>Latex の煩わしい点が全て解決される Mac のソフトウェアです。
自動補完 synctex 対応(コマンド+クリックで PDF、tex ファイル同期) 自動タイプセット Texpad · Smoothest way to write LaTeX 以前は atom+latexmk で Latex を扱ってましたが、texpad の方が断トツに使い心地が最高です。
購入方法 Appstore か、クレジットカードで Appstore を経由せずに買うかの２つの方法があります。
Appstore はだいぶ前に更新を停止しているみたいなので、クレジットカードを持っている人はクレジットカードを使って MacAppstore を経由せずに購入することをオススメします。
$24.99 しましたが、それ以上の価値があるソフトウェアです。
2 週間の無料体験期間があるので是非お試し下さい。
下記のスクリーンショットのように、beamer も texpad で動くのは感動モノ。
beamer on texpad
日本語で TexPad を扱いたいときは下記のスクリプトを読み込んだら、bibtex のバグが治ります。</description></item><item><title>機械学習・コンピュータビジョンを活かしたビジネスを手掛ける株式会社ABEJAでインターンしてきた</title><link>https://shunyaueta.com/posts/2014-08-23/</link><pubDate>Sat, 23 Aug 2014 17:18:02 +0000</pubDate><guid>https://shunyaueta.com/posts/2014-08-23/</guid><description>株式会社 ABEJA という会社に 2013/8/25~2013/9/26 間に 2 週間弱インターンシップに参加してきました。
2013 年当時のサイトのスクショ
What’S ABEJA? ABEJA について詳しく知りたい方は下記のリンクを見るとわかりやすいです。
マーケティングから決済まで、人認証技術 × ビジネスプロデュースで未来を変える ABEJA の挑戦【連載:NEO ジェネ！】 いまそこにある、リアルタイムデータ解析。ぼくらの暮らしを変える、日本のスタートアップ 3 社 この会社をはじめて知ったのは、ミクシィでのインターンシップに参加してた時に別グループでインターンしていた知り合いの人に教えてもらったのがキッカケです。 機械学習や画像解析を用いて、現実世界の問題を解決して更にビジネスにまで昇華させている点に痺れました。
本来なら一ヶ月近く参加予定だったんですが、もう一つ挑戦していたリクルートのインターンに運良く合格したので結果的には 2 週間弱という短めのインターンになりました。
What do you doing in ABEJA intern? インターンの内容は Python を使って社内用のツールをゴニョゴニョしてました。
郷に従います。(StyleGuide 見てなかった…) / 他 2 コメント http://t.co/5I0nThs4rU “PEP 8 — Style Guide for Python Code” http://t.co/in7q9lD6cy&amp;gt; — UEDA (@hurutoriya) 2014, 9 月 25
普段は matlab か Ruby 書いてるんですが、普段書いてない言語を書くとあまりよろしくないコードになったので StyleGuide 導入しました。
_“vim で python 開発するとき pyflakes + PEP8 = flake8 が便利 _http://t.</description></item><item><title>ミクシィにインターンしてきた</title><link>https://shunyaueta.com/posts/2013-08-21/</link><pubDate>Fri, 23 Aug 2013 17:04:38 +0000</pubDate><guid>https://shunyaueta.com/posts/2013-08-21/</guid><description>株式会社ミクシイに 2013/8/9~2013/9/20 までインターンしてきました。 2013 年当時のスクリーンショットを探してたが、無かったので 2017/12/24 のを撮ってきた。良い意味であまり変わってない(ライさんの謎のくるまアプリとか)
Dive into mixi
なぜインターンに行こうと思ったのか 僕は高専から筑波大学の情報系に今年度から編入したんですが、
編入してから同期の編入生や先輩、内部生の人達に会って 「このままじゃダメだ、もっと面白く!もっと楽しく生きる!!」 と感じたので参加しました。
…つまり、面白そうな事をしたかったので参加しました。 選考過程 エントリーリーシートを提出、希望する配属先はここで提出します。 2 回の面接があるのですが、つくばから渋谷への道のりは遠いので一回にしてくれました。ありがとうございます！！
面接の服装は、スーツじゃなくて良いので楽です！(むしろスーツはやめてねと言われました)
自己紹介と自分のこれまでの成果物を面接官に説明した後に、質疑応答を 30 分、時間が 20 分ほど余ったので面接官の方から「気になってることをなんでも聞いて下さい」と言われて質問をしていると面接がいつの間にか終わりました。
合否発表は翌日に連絡がきて無事合格することができました、嬉しい!!
配属先 僕は第一希望のDeployGateに配属されました。
DeployGate チームは社員二人、インターン三人という謎構成でした。
「DepoyGate」とは、ミクシィ社の新規事業第 1 弾として登場した Android アプリ提供者向けのテスト版アプリ配信サービスです。 アプリをワイヤレスで配布することができ、アップデータ配信や動作ログがリアルタイムに取得できるので、プロジェクトメンバー全員が常に最新版アプリに触れることができます。 2012 年 9 月のサービス開始から、世界 93 ヵ国 3600 以上のアプリ開発に利用され、そのユーザーの 76％は英語圏というグローバルなサービスでもあります。 「DepoyGate」エンジニアからの発案で生まれたサービスです。 最新の技術に触れ、一緒に開発を進めていきたいという、あなたのチャレンジをお待ちしております。### メリット
今回のミクシィインターンは 6 週間を超える長期のインターンで実際に提供されているサービスの開発に参加すること t ができます。
デメリット 基本的に無いです。
強いて言うなら夏休みが 4/5 ほど持ってかれたことですね。
何をやった？ 基本的に Github に issue に上がってるチケットを消化していく感じでした。 自分でこれがあったら便利だなと思う機能を追加したり、不便な箇所を改修したりして、GO サインが出たら Depoloy していきます。
今年度のインターン生は何人? 内定生のインターンを除くと両手で数えられるほどでした。</description></item><item><title>Archive</title><link>https://shunyaueta.com/archives/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shunyaueta.com/archives/</guid><description>archives</description></item><item><title>著者について</title><link>https://shunyaueta.com/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://shunyaueta.com/about/</guid><description>上田隼也 (a.k.a. @hurutoriya) のブログです。
検索技術領域、機械学習の実応用やプロダクト開発に興味があります。
現在は Software Engineer として東京で働いています。
Opinions are my own.
Linkedin: https://www.linkedin.com/in/hurutoriya GitHub: https://github.com/hurutoriya Twitter: https://twitter.com/hurutoriya Speaker Deck: https://speakerdeck.com/hurutoriya Google Scholar: https://scholar.google.com.au/citations?hl=en&amp;amp;user=ghbIA8gAAAAJ 活動履歴 主な登壇歴 2020.08.07 Auto Content Moderation in C2C e-Commerce at OpML20 機械学習による C2C マーケットプレイスでの商品監視改善成果が MLOps の査読付き国際会議 OpML'20 にて登壇 YouTube Slide 執筆 2021.08.18 機械学習エンジニアの学会での論文発表のススメ。応募から査読通過までの流れ Offers magazine というメディアに、業務での実績の論文化について寄稿 2020.08.07 Auto Content Moderation in C2C e-Commerce at OpML20 機械学習による C2C マーケットプレイスでの商品監視改善成果が MLOps の査読付き国際会議 OpML'20 にて論文が採択 PDF 2020.07.08 データ分析の進め方及び AI・機械学習導入の指南 ～データ収集・前処理・分析・評価結果の実務レベル対応～ マルチモーダルによる規約違反出品検知への応用と運用について を共著にて執筆 コミュニティ運営活動 Machine Learning Casual Talks 第 5 回から運営者として、機械学習の実応用をテーマにしたコミュニティを運営しています。 パターン認識と機械学習の勉強会 @筑波大学 大学在学時に 2015.</description></item></channel></rss>