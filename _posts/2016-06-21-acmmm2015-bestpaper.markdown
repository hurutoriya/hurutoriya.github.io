---
layout: post
title:  "ACMMM2015 Best Paper: Analyzing Free-standing Conversational Groups: A Multimodal Approach "
date:   2016-06-19
tag: research computervision paper multimedia
---

どうも、こんにちは :raised_hand: @hurutoriya です。

X Alameda-Pineda, Y Yan, E Ricci, O Lanz, N Sebe
“Analyzing Free-standing Conversational Groups: A Multimodal Approach”, in 2015 ACM Multimedia Conference

[link](http://xavirema.eu/wp-content/papercite-data/pdf/Alameda-ACMMM-2015.pdf)

を読んだので、軽くメモ。


<iframe src="https://docs.google.com/presentation/d/1G6zfzV4jIm7qj4LkHkm3Gk_qHEml0SWZExkNuqw0ef8/embed?start=true&loop=true&delayms=1000" frameborder="0" width="960" height="569" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>

マルチモーダル系の論文初めて読んだんですが、まとめるとコントリビューションが5つあると主張。

## Contribution

- 音声・近接情報、そして監視カメラからの身体と頭の姿勢推定からマルチモーダルに解析
- フリースタンディングディスカッションを身体・頭の姿勢推定から解析
- カメラと音声・近接センサーからなるマルチモーダルな解析するためのフレームワークを提案
- ラベリングされてないデータに対する行列補間問題の考案
- SALSA(データ・セット)を公開・評価

SALSAというポスターセッションの動画と音声のデータも公開されている。

> [SALSA: Synergetic sociAL Scene Analysis](http://tev.fbk.eu/salsa)

動画はGoogle Driveで公開されていて時代の波を感じる。

- データセットを公開
- 論文も読みやすい
- 新しい行列補完計画法(アルゴリズム)を提案
- 実問題に取り組む

と盛り沢山な内容で面白かった。
