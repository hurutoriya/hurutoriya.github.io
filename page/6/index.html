<!doctype html><html lang=ja dir=auto><head><meta name=generator content="Hugo 0.111.3"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>hurutoriya</title><meta name=description content="Shunya Ueta's blog"><meta name=author content="Shunya Ueta"><link rel=canonical href=https://shunyaueta.com/><link crossorigin=anonymous href=/assets/css/stylesheet.6a98292fb8fa8cf0f3ba4042d4b75515c04267550f3ad49ff6271b5af9562443.css integrity="sha256-apgpL7j6jPDzukBC1LdVFcBCZ1UPOtSf9icbWvlWJEM=" rel="preload stylesheet" as=style><link rel=icon href=https://shunyaueta.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://shunyaueta.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://shunyaueta.com/favicon-32x32.png><link rel=apple-touch-icon href=https://shunyaueta.com/apple-touch-icon.png><link rel=mask-icon href=https://shunyaueta.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://shunyaueta.com/index.xml><link rel=alternate type=application/json href=https://shunyaueta.com/index.json><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-JMJRQJT0Q3"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-JMJRQJT0Q3")</script><meta property="og:title" content><meta property="og:description" content="Shunya Ueta's blog"><meta property="og:type" content="website"><meta property="og:url" content="https://shunyaueta.com/"><meta property="og:image" content="https://shunyaueta.com/ogp.jpg"><meta property="og:site_name" content="Shunya Ueta"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://shunyaueta.com/ogp.jpg"><meta name=twitter:title content><meta name=twitter:description content="Shunya Ueta's blog"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"hurutoriya","url":"https://shunyaueta.com/","description":"Shunya Ueta\u0026#39;s blog","thumbnailUrl":"https://shunyaueta.com/favicon.ico","sameAs":["https://github.com/hurutoriya","https://twitter.com/hurutoriya","https://mstdn.jp/web/@hurutoriya","https://www.linkedin.com/in/hurutoriya/","https://www.buymeacoffee.com/hurutoriya","index.xml"]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://shunyaueta.com/ accesskey=h title="hurutoriya (Alt + H)">hurutoriya</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://shunyaueta.com/archives title=Archive><span>Archive</span></a></li><li><a href=https://shunyaueta.com/about title=About><span>About</span></a></li><li><a href=https://searchengineeringnewsletter.substack.com/ title=Newsletter><span>Newsletter</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://shunyaueta.com/index.xml title=RSS><span>RSS</span></a></li></ul></nav></header><main class=main><article class=post-entry><header class=entry-header><h2>pip 実行時に sys.stderr.write(f"ERROR: {exc} ") とエラーが出てpipを実行できないときの対処方法</h2></header><div class=entry-content><p>新しいマシンでpipをセットアップして実行しようとすると
1 2 3 4 5 6 7 8 9 10 11 12 13 14 >> pip Traceback (most recent call last): File "/usr/local/bin/pip", line 11, in &lt;module> load_entry_point('pip==21.0', 'console_scripts', 'pip')() File "/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/pkg_resources/__init__.py", line 489, in load_entry_point return get_distribution(dist).load_entry_point(group, name) File "/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/pkg_resources/__init__.py", line 2843, in load_entry_point return ep.load() File "/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/pkg_resources/__init__.py", line 2434, in load return self.resolve() File "/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/pkg_resources/__init__.py", line 2440, in resolve module = __import__(self.module_name, fromlist=['__name__'], level=0) File "/Library/Python/2.7/site-packages/pip-21.0-py2.7.egg/pip/_internal/cli/main.py", line 60 sys....</p></div><footer class=entry-footer><span title='2021-02-08 23:29:12 +0900 +0900'>2月 8, 2021</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label='post link to pip 実行時に sys.stderr.write(f"ERROR: {exc} ") とエラーが出てpipを実行できないときの対処方法' href=https://shunyaueta.com/posts/2021-02-08/></a></article><article class=post-entry><header class=entry-header><h2>TFXの歴史を振り返りつつ機械学習エンジニアリングを提案する論文「Towards ML Engineering: A Brief History Of TensorFlow Extended (TFX)」</h2></header><div class=entry-content><p>この記事はMLOps Advent Calendar 2020の 25 日目の記事です。(盛大に遅れました)
KDD2019 の招待講演で Google が TFX の歴史について発表されており、TFX 信者の自分としては発表内容が以前から気になっていたが、公開はされておらずなんとかして見れないかな~と思っていましたが、TensorFlow の Blogで該当の招待講演が論文化されたことを知ったのでメモがてら抄訳として残しておく。
注意)この翻訳記事は原著論文の著者陣からレビューはされていません Shunya Ueta, are providing a translation and abridgment, which has not been reviewed by the authors. Citation Karmarkar, A., Altay, A., Zaks, A., Polyzotis, N., Ramesh, A., Mathes, B., … & Li, Z. (2020). Towards ML Engineering: A Brief History Of TensorFlow Extended (TFX). arXiv preprint arXiv:2010.02013. ***
Towards ML Engineering with TensorFlow Extended (TFX) at KDD2019 Towards ML Engineering with TensorFlow Extended (TFX) ACM PDF は arxiv でも閲覧可能 https://arxiv....</p></div><footer class=entry-footer><span title='2021-01-17 00:18:47 +0900 +0900'>1月 17, 2021</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to TFXの歴史を振り返りつつ機械学習エンジニアリングを提案する論文「Towards ML Engineering: A Brief History Of TensorFlow Extended (TFX)」" href=https://shunyaueta.com/posts/2021-01-17/></a></article><article class=post-entry><header class=entry-header><h2>PythonでApache beam 入門</h2></header><div class=entry-content><p>TensorFlowの勉強をしていたら、Apache beam を前処理に採用していたケースがあり、興味を持ったので深堀りしてみます。
興味が湧いたモチベーションとしては、
データ量が増加しても前処理部分を難なくスケールできそう(前処理部分をスケールさせて高速に実験を回したい、並列化などはすべて良い感じにbeamに任せれそう バッチとストリーミングの両者に対応可能なので、柔軟な機械学習の推論サービスが提供できるのでは? (GCPの参考資料 Data preprocessing for machine learning: options and recommendations) Apache beam を触りつつ分散データ処理を学びたい https://github.com/jhuangtw/xg2xg#services
を見てみるとGoogle 内部のFlume という並列データパイプライン技術がApache beam として公開されているみたいです。
Apache beam について端的に説明すると
Apache beam は3つの考えを基礎にしています。
Unified ストリーミング、バッチの両者のケースに一つのプログラミングモデルで対応可能な統一性 Portable 実行パイプラインが複数の実行環境で実行可能な可搬性 Extensible 新しいSDK、IO Connectorsや変換ライブラリなどをを書いて共有することができる拡張性 Java, Python, Go やScalaを使ってBeam Model を作成して任意のruntime で実行する流れです。
自分はPythonが一眼手軽に書けるのでこの記事ではPythonで紹介していきます。
Version 2.14.0 からPython 3がサポートされたのは非常にありがたいですね。それまではPython 2のみをサポートしており、その影響で技術選定時に採用しづらかったのでは無いのでしょうか?
Spotify が作成しているApach BeamとDataflowのScala APIであるscioが開発されており、そちらも気になっています。
https://github.com/spotify/scio https://engineering.atspotify.com/2017/10/16/big-data-processing-at-spotify-the-road-to-scio-part-1/ では、まずは実際に動かしながら学んでみようということで
https://beam.apache.org/get-started/try-apache-beam/
を参考にApache Beam をPython SDKで試してみます
COLABで実行を試せるので便利ですね
ですが、Python2で実行されるように設定されているのでPython3で実行してみました。
実行したcolab のコードを見ていきます。
環境準備 apache-beam のinstallとGCSからApache beamで処理を行うテキストファイルをダウンロードします。...</p></div><footer class=entry-footer><span title='2020-12-26 00:41:30 +0900 +0900'>12月 26, 2020</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to PythonでApache beam 入門" href=https://shunyaueta.com/posts/2020-12-26/></a></article><article class=post-entry><header class=entry-header><h2>機械学習・ソフトウェアエンジニアリングをテーマにしたPodcast just4fun.fm を始めてみた</h2></header><div class=entry-content><p>機械学習エンジニアをしている hurutoriya が機械学習、Software Engineering 周りに関する学んだことなど最近楽しいと思っていることを発信していくPodcast です
扱うトピックとしては、普段学んだ機械学習、ソフトウェアエンジニアリング、読んだ論文やデータ分析などについて扱っていきます。 もし、ご興味あれば購読お願いします。主要なPodcast Platformで購読可能です。
just4fun.fm Google Podcasts Apple Podcasts Pocket Casts ご感想などは Twitter ハッシュタグ #just4funfm でお待ちしております
なぜ Podcast なのか？ 以前からPodcastは日常的に聴いていて、自分の中でもすごく好きなメディアのうちの一つです。 前からやってみようかなと思っていたんですが、周りの人たちがPodcastを始めたのを機によし自分もやるかと始めてみました
Blogと比べてみると、
ブログ書くよりかはサラッと配信できる、音声で配信するのも新鮮で面白い その代わり、換気扇とかの音が気になり音源環境とかはめちゃくちゃ気を使う 発表レベルの構造化したトークよりも雑談レベルでワイワイするほうがPodcastは向いてる感じはする。前者だと準備やらなんやらで公開できずに死の谷に落ちそう 喋っているうちに思考が洗練されていくので、あまり気負いすぎずに喋りたい事を発信していくのが良さそう しばらく試験的に続けていきたいと思います。
Anchor 凄い AnchorでPodcastを始めると、自動的にAppole Podcast, Google Podcast, Pocket CastなどPodcastのプラットフォームに自動配信される。 Google Podcastは、配信開始と通知が来ても実際は2-3日後に視聴可能になると問い合わせたら返信がきた Support here. Sorry for the confusion with your podcast on Google. Allow me to explain this to you. We have noted that for some users the podcast link takes a week or so to become active, so it should begin working soon!...</p></div><footer class=entry-footer><span title='2020-09-27 21:57:47 +0900 +0900'>9月 27, 2020</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to 機械学習・ソフトウェアエンジニアリングをテーマにしたPodcast just4fun.fm を始めてみた" href=https://shunyaueta.com/posts/2020-09-27/></a></article><article class=post-entry><header class=entry-header><h2>自分なりの機械学習エンジニアスキル構成論</h2></header><div class=entry-content><p>機械学習エンジニアとして働き始めて2年7ヶ月が経過した。
機械学習エンジニアというロールは会社によって期待される内容が異なってくるが、今の会社で働いてきた経験に基づき自分の中の機械学習エンジニアスキル構成論を整理してみる。
TL; DR 人によって考える理想のスキル論は違うので他の人の持論を聞いてみたい テクいことをやりたい気持ちはあるが、地道なやるべきことがたくさんあるのがこの世界 自分の中で機械学習エンジニアにとって大事なスキル Software Engineer 40% 機械学習サービス実装スキル Product Manager 30% 機械学習プロジェクト自体を成功に導くスキル Data Scientist 30% データに基づき、意思決定し改善していくスキル Machine Learning Engineer as Software Engineer なぜSWEの比率が一番上なのか？
どれだけ良いモデルができたとしてもそれが活用されるシステムがなければ成果を出せないからです
データを活用してインパクトの大きい課題を解決するための、サービスを実装して、運用して改善していく どの方法がベストか考えた上で、それを実現していく 例えば、R&amp;Dスタイルでモデル開発と実装者を完全に分ける組織構造もあると思いますが、このスタイルはいろんな会社のお話を聞く限りは、組織構造がよほど洗練されていないとうまく稼働しないじゃないかなと思っている
Full Cycle Developers at Netflixでは、システム開発のライフサイクルである
design, development, test, deploy, operate, support
を1チームが一気通貫で責任を持つスタイルをNetflixが提唱している。
今所属している会社もMicro Serviceでの開発に注力していて、まさにFull Cycleスタイルで機械学習サービス開発を行っている。 個人的に機械学習プロジェクトとこの方式の相性の良いところは、例えば、職能ごとにモデル開発、システム開発と運用を行うメンバーを分割すると、
モデルを作ってデプロイはしたが運用は他人任せになってしまい継続的な改善が回しづらい 役割が分離されていることで、モデルの詳細を完全に把握できないので実際のトラブル発生時に対応が困難 運用を考えてモデルがデザインされていないので運用者にしわ寄せがくる などアンチパターンが数多く存在する
Micro Serviceでの開発は上記の課題を解決して、作って終わりではなく自分たちでシステムデザインからサポートまで行うことで、そのサービスの継続的な改善に責任と自由を手にして開発することできる また、プロジェクトデザインの段階からシステム開発・運用を念頭に動くことができるので、やってみてうまく動かないなどの不確実性を大きく減少させる
Machine Learning Engineer as Product Manager 機械学習プロジェクトは、POCなどで検証を行いプロジェクトが始まりますが最初の壁である
機械学習で解ける余地のある大きなインパクト(やる価値)のある問題 をまず自分たちのサービスで発見する必要があります。(正直コレが一番難しい)
CourseraでHow Google does Machine Learning の講義を修了したの講義でもGoogleでの機械学習プロジェクトのマネジメントについて言及されていますが、
そもそもデータがない Human In The Loopを導入していない(継続的なデータの自浄作用が存在しない) などそれらの要素が欠けるだけで簡単にプロジェクトは失敗します。...</p></div><footer class=entry-footer><span title='2020-09-21 00:13:08 +0900 +0900'>9月 21, 2020</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to 自分なりの機械学習エンジニアスキル構成論" href=https://shunyaueta.com/posts/2020-09-21/></a></article><article class=post-entry><header class=entry-header><h2>GitHub codeowners でGithubグループを指定しても反映されない時の対処方法</h2></header><div class=entry-content><p>GitHub の CODEOWNERS という機能を使えば、レポジトリに対する PR では設定された CODEOWNER が APPROVE を出さないとマージされないようにできます。
この機能を使うことで、例えばそのリポジトリのオーナーであるグループが必ず PR を確認しないとマージできないようにすることでコードのクオリティを保つ仕組みが作れます。
TL;DR GitHub codeowners で特定のグループを CODEOWNERS に設定したいときは、そのグループをレポジトリの /settings/accessで Maintain として追加しないと GitHub PR で自動的に reviwer に追加されない リポジトリで.github/CODEOWNERS のファイルを作成して、以下の形式で GitHub group を追加する 1 * @octo-org/codeowners-team リポジトリの設定の/settings/accessにアクセスして、@octo-org/codeowners-team を Maintain として追加する。 *試していないのですが、Write や Triage 権限でも問題ないかもしれません。
この設定をしたあとに、GitHub PR を新たに作成すると、自動的に CODEOWNERS の approve がないとマージされないように設定されるはずです。
自分自身がハマった経緯 グループ全体のアカウントが追加されているa-group/allという Github Group がすでにリポジトリのアクセス権限に Write 権限として追加されており、全員が write 権限をもっているなら codeowners としての権限も問題ないだろうと思っていたらハマりました。
CODEOWNERS の仕組みを知ると理解できるのですが、a-group/all が指定したいグループの包含関係にあるからといって、そのように取り扱ってくれるわけではないということですね。</p></div><footer class=entry-footer><span title='2020-09-19 11:31:36 +0900 +0900'>9月 19, 2020</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to GitHub codeowners でGithubグループを指定しても反映されない時の対処方法" href=https://shunyaueta.com/posts/2020-09-19/></a></article><article class=post-entry><header class=entry-header><h2>pandas を使って特定のディレクトリのCSVファイルをすべて連結して一つのCSVファイルを作成</h2></header><div class=entry-content><p>目的 複数の同じフォーマットの CSV ファイルが特定のディレクトリに配置されており、その CSV ファイル群を一つの CSV ファイルに連結したい
今回は、Python の Pandas と pathlib を使って上記の目的を実現します。
実行環境 1 2 3 4 5 6 7 In [1]: import pandas as pd In [2]: pd.__version__ Out[2]: '1.1.2 In [3]: import sys ...: print(sys.version) 3.8.2 (default, Jul 19 2020, 07:23:27) [Clang 11.0.3 (clang-1103.0.32.62)] 目的となる csv ファイルは tmp ディレクトリに以下のような形式で配置されているとする
1 2 3 4 tmp ├── 1.csv ├── 2.csv └── 3.csv 各ファイルはこのような形式で保存されています。
1 2 3 4 id name created 1 John 2020/09/10 2 bob 2020/09/10 3 taro 2020/09/11 以下の Python スクリプトを実行...</p></div><footer class=entry-footer><span title='2020-09-09 23:49:37 +0900 +0900'>9月 9, 2020</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to pandas を使って特定のディレクトリのCSVファイルをすべて連結して一つのCSVファイルを作成" href=https://shunyaueta.com/posts/2020-09-09/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://shunyaueta.com/posts/2020-09-06/images/1.png alt="C2C eコマースにおける機械学習を活用した商品監視"></figure><header class=entry-header><h2>MLOps の国際会議 OpML'20 に、機械学習を活用した商品監視の改善に関する論文が採択されたので登壇してきた</h2></header><div class=entry-content><p>MLOps の査読付き国際会議 2020 USENIX Conference on Operational Machine Learning (略称 OpML'20)に論文が採択されたので、登壇してきた。
Podcast でも紹介しました。
#1 MLOps の国際会議 OpML20 について at just4fun.fm
MLOps の査読付き国際会議と OpML の立ち位置 機械学習エンジニアリング・MLOps の領域の会議でも一番有名なものとして 2018 年に発足したMLSysがあります。(ちなみに最初は SysML という名前でした) このカンファレンスの傾向としては、アカデミアの研究者主体の発足経緯からアカデミアからインダストリーへの橋渡し的立ち位置となっています。 具体的には、発表者はアカデミアの方が大半でハードウェアから、モデルの OSS 公開など幅広く機械学習エンジニアリング・MLOps の周辺領域をカバーしています。
OpML はその一年後に、USENIXが母体の会議として MLOps を軸にした会議として誕生しました。 USENIX は SRECON、OSDI などを開催している団体です。 学術的なスタイルに則り、先端的な計算機システムの成果を論文として公開されています。MLSys と対称的にこちらはインダストリーからアカデミアへの橋渡し的立ち位置となっています。発表内容は企業での発表者が多く、実際の運用で得られた各企業の MLOps のベストプラクティスなどがメインで話されています。 個人的には OpML のほうが、MLOps のど真ん中を主体に置いているので MLSys よりも盛り上がってほしいなと思っています。
OpML'19 がどのような様子だったかは、以下の記事がわかりやすいです。
OpML ‘19 参加レポート The first conference of Operational Machine Learning: OpML ‘19 自分自身、機械学習エンジニアリングや MLOps 周りのカンファレンス情報などを追いかけていますが、この分野で査読付きかつ論文として残せる形式の国際会議は主に上記の２つの認識です。...</p></div><footer class=entry-footer><span title='2020-09-06 23:31:03 +0900 +0900'>9月 6, 2020</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to MLOps の国際会議 OpML'20 に、機械学習を活用した商品監視の改善に関する論文が採択されたので登壇してきた" href=https://shunyaueta.com/posts/2020-09-06/></a></article><article class=post-entry><header class=entry-header><h2>Python の内包表記とジェネレータ式のメモリ使用量比較</h2></header><div class=entry-content><p>リストを構築する際に Python ではリスト内包表記とジェネレータ式の２種類が存在する。 今回、リスト構築時にメモリ使用量にどれだけ差異が発生するのか調査をしてみた。 メモリ使用量の調査には、memory_profilerというパッケージを使用した。
まず、２つのリストのデカルト積のタプルを表示するプログラムでの比較
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 from memory_profiler import profile @profile def main(): """ Comparision List comprehension VS generator memory usage """ colors = "colors" * 1000 sizes = "S" * 100 for shirts in ((color, size) for color in colors for size in sizes): print(shirts) [print((color, size)) for color in colors for size in sizes] if __name__ == "__main__": main() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 Filename: src/listcomp_vs_generator....</p></div><footer class=entry-footer><span title='2020-08-23 21:28:10 +0900 +0900'>8月 23, 2020</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to Python の内包表記とジェネレータ式のメモリ使用量比較" href=https://shunyaueta.com/posts/2020-08-23/></a></article><article class=post-entry><header class=entry-header><h2>AOJの「ITP I」40問をPythonで解いた</h2></header><div class=entry-content><p>はじめに コーディングの腕をもっと磨きたいなと思ったので、以下の記事を参考に始めてみた
https://qiita.com/e869120/items/f1c6f98364d1443148b3 全部で 44 問ありますが、最後の 4 問は競プロとはあまり関係ないので、ITP1_1-A から ITP1_10-D までの 40 問を解くことをお勧めします。
まずは最初におすすめされた、AOJ の ITP1_1-A から ITP1_10-D までの 40 問を解いてみた 無料でこのサービスが提供されてるの素晴らしい 標準入力、出力の整形が少し手間取ったけど、あとは愚直に解いていった
http://judge.u-aizu.ac.jp/onlinejudge/ 感想としては、
やってみたら、意外と楽しい。特に自分で諦めずに試行錯誤して、オンラインで一発で AC もらえるとめちゃくちゃ嬉しい テストケースに通る、すなわち正しい、それが書けたら達成感がある 何かしらのお題に沿って、コードを書くという動機ができるので、書くことに慣れたい場合も有用そう toggl で時間計測しながら、やって見直してみたら 15h46m 費やしていた。大体 1 問 25m くらい
次の目標、
AtCoder で水色を目指す!!! データ構造周りや、アルゴリズム周りはまだまだ弱いのでそこらへんを抑えていきたい 当面は、以下の２つに投資していきます
機械学習だけに縛られない、SWE としてスキル底上げ 機械学習関係の確固たる基礎知識と実装力 以下に自分が書いた回答例を放流しておきます。
Rule 15 分試行錯誤しても、緒がわからない場合は諦める わからなかったとき、もっと上手な書き方は以下を参考にしました https://qiita.com/cmtennis1042/items/5f1e7f071081176e857f ITP1_1_A: Hello World 1 print('Hello world') ITP1_1_B: X Cubic 1 2 x = input() print(x ** 3) ITP1_1_C: Rectangle 1 2 a, b = map(int, input()....</p></div><footer class=entry-footer><span title='2020-08-04 03:38:58 +0900 +0900'>8月 4, 2020</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to AOJの「ITP I」40問をPythonで解いた" href=https://shunyaueta.com/posts/2020-08-04/></a></article><article class=post-entry><header class=entry-header><h2>How to write the UnitTest with stdin at Pytest</h2></header><div class=entry-content><p>If you want to write UnitTest when using stdin in Python. Pytest provide setattr function in monkeypatch
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 from io import StringIO import sys def divide(): input = sys.stdin.readline return list(input()) def gather(): input = sys.stdin.readline return sum(list(map(int, input().split()))) def test_divide(monkeypatch): monkeypatch.setattr('sys.stdin', StringIO('abc')) assert divide() == ['a', 'b', 'c'] def test_gather(monkeypatch): monkeypatch....</p></div><footer class=entry-footer><span title='2020-07-25 03:18:14 +0900 +0900'>7月 25, 2020</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to How to write the UnitTest with stdin at Pytest" href=https://shunyaueta.com/posts/2020-07-25/></a></article><article class=post-entry><header class=entry-header><h2>Machine Learning Casual Talks # 12 を開催しました</h2></header><div class=entry-content><p>Machine Learning Casual Talks 第 12 回を開催しました。 前回から少し開きがあり、7 ヶ月ぶりの開催となりました。
https://mlct.connpass.com/event/172550/
今回の個人的なテーマはベストプラクティスとアンチパターンです。
@keigohtr さんには、AWS の各種サービスを使った機械学習実験基盤をアベジャの適用事例と重ね合わせて、説得力のあるベストプラクティスを語っていただきました。 @yuzutas0 さんには、機械学習の前に、データのマネジメントがいかに必要かを語っていただきました。建設的に改善していこうぜという未来が語られていて、個人的にお話を依頼した甲斐がありました 同僚の @overs_5121 さんには、メルカリ : TensorFlow Lite で、気付きにくい便利機能をユーザーに提唱 の裏話や、適用までの泥臭い事例をお話していただきました。 登壇者の皆様、改めて登壇の依頼をご快諾いただきありがとうございました。
また、コロナウイルスの影響もあり試験的ですが完全なオンライン開催となりました。 配信面は今回は完全に @chezou さんに頼らせていただきました。 プロフェッショナルな配信ありがとうございました！ 配信のベストプラクティスや様子などは、こちらを御覧ください
Google Meet と YouTube Live でオンラインミートアップの配信をした
勉強会の資料と動画 資料ページ Machine Learning Casual Talks #12 - YouTube 所感としては、以前から配信 NG の発表以外は積極的に YouTube で公開していたのだが、参加者の皆様からはオンライン開催でありがたいと声が大きく、個人的に驚きました。
自分が思うに、オンライン参加も配信動画を後から見るのも、リアルタイムで質問ができないこと以外は大きな差異が無いと思っていたのだが、参加者側からすると大きく異なるようで新鮮だった。
オンライン勉強会開催側のコツ 最低でも
配信者 司会者 配信の監視を行う監視者 の 3 役がいないとオンライン開催は難しいことがわかった
ライブ配信視聴者数は、以下のような遷移となりました。 500 人参加申込みがあり、最大視聴者数が 252 人とギリギリ 5 割を超えました。
今までのオフラインでの開催は 6-8 割くらいだったので、それと比較すると上出来かなと思います。 また、オンライン開催はオフライン開催と比べて会場の確保コストや懇親会おじさんの発生などを抑えられるので、その点もありがたかったです。 オフライン開催だと、会場撤収が効率的に終わっても 22:00、家に帰ると 23:00 なので、イベント主催者にとっても開催しやすい気がしますね。...</p></div><footer class=entry-footer><span title='2020-06-13 23:06:44 +0900 +0900'>6月 13, 2020</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to Machine Learning Casual Talks # 12 を開催しました" href=https://shunyaueta.com/posts/2020-06-13/></a></article><article class=post-entry><header class=entry-header><h2>自走プログラマーを読み終えた</h2></header><div class=entry-content><p>自走プログラマーを読み終えた。
読み始めたきっかけとして、自分は機械学習エンジニアとして現在働いているが、できることの幅を広げるために最近はソフトウェアエンジニアとしてのスキルをもっと伸ばしたいと考えている。
自走プログラマーは、Python を使ったアプリケーション開発のアンチパターンとベストプラクティスを例示して学ぶことができる書籍で、今回の自分の状況にすごくフィットしていて楽しく学習することができた。
Python 独特のはまりどころは、Kindle: The Hitchhiker’s Guide to Python, The Hitchhiker’s Guide to Python でも数多く参照されていて、こっちも後から読んでおきたいなと思いました。
次は、ちゃんとした Pythonista になれるように、Fluent Python を読みます。@ynqa さん、以前この本を教えて下さり、ありがとうございました。
長らく積ん読になっていますが、毎日読み進めていきます。
20 歳頃の寝る間を惜しんで、ウェブアプリを開発していたときのワクワク感が徐々に蘇ってきた気がしています。
ある程度書けるようになってきたら、なにかアプリとか作って公開したいなと思っています！</p></div><footer class=entry-footer><span title='2020-05-10 17:13:34 +0900 +0900'>5月 10, 2020</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to 自走プログラマーを読み終えた" href=https://shunyaueta.com/posts/2020-05-10/></a></article><article class=post-entry><header class=entry-header><h2>ソフトウェア開発における Upstream と Downstream の意味</h2></header><div class=entry-content><p>Upstream Upstream はそのシステムが依存しているジョブ Upstream のデザインが変わることで、システムも影響をうける Downstream Downstream はそのシステムが影響を与える影響を与える部分 例えば、Web Application などでは、データベースは Downstream となる
e.g. Web service→ Databese という流れでデータが作成される
References https://reflectoring.io/upstream-downstream/ https://softwareengineering.stackexchange.com/questions/71080/what-does-downstream-upstream-design-mean/83686 https://en.wikipedia.org/wiki/Upstream_(software_development) https://en.wikipedia.org/wiki/Downstream_(software_development)</p></div><footer class=entry-footer><span title='2020-04-27 23:55:42 +0900 +0900'>4月 27, 2020</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to ソフトウェア開発における Upstream と Downstream の意味" href=https://shunyaueta.com/posts/2020-04-27/></a></article><article class=post-entry><header class=entry-header><h2>Pythonの関数のデフォルト引数はmutable(上書きされる)</h2></header><div class=entry-content><p>例えば以下のように、デフォルト引数で初期化を行い、文字列を追加する関数があるとする。
1 2 3 def append_to(values=[]): values.append("Hoge") return values 期待する振る舞いとしては。
1 2 3 4 5 6 7 8 9 10 In [14]: def append_to(values=[]): ...: values.append("Hoge") ...: return values ...: In [17]: append_to() Out[17]: ['Hoge'] In [18]: append_to() Out[18]: ['Hoge'] と関数呼び出しごとに、values は空のリストに初期化されるので上記のように返ってきてほしい
だが、実際に表示されるのは
1 2 3 4 5 6 7 8 9 10 In [14]: def append_to(values=[]): ...: values.append("Hoge") ...: return values ...: In [17]: append_to() Out[17]: ['Hoge'] In [18]: append_to() Out[18]: ['Hoge', 'Hoge'] である。...</p></div><footer class=entry-footer><span title='2020-04-26 12:04:13 +0900 +0900'>4月 26, 2020</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to Pythonの関数のデフォルト引数はmutable(上書きされる)" href=https://shunyaueta.com/posts/2020-04-26/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://shunyaueta.com/posts/2020-04-25/images/fig-1.png alt=機械学習システムはテストとモニタリングへの投資が大事></figure><header class=entry-header><h2>機械学習システムの信頼性を数値化し、技術的負債を解消する論文「 The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction」</h2></header><div class=entry-content><p>[抄訳] What’s your ML test score? A rubric for ML production systemsで紹介した論文の続編があったので読んでみました。
注意)この翻訳記事は原著論文の著者陣からレビューはされていません Shunya Ueta, are providing a translation and abridgment, which has not been reviewed by the authors. Change log 2021/02/03 ML Test Score を簡単に計算できるGoogle Spread Sheets を公開 2020/06/24 著者の Eric Breck さんに連絡をし、抄訳の公開を快諾していただきました。ありがとうございます。 完全な citation 情報を追記しました。 この翻訳記事が著者のレビューを受けていないことを追記しました。 Citation Eric Breck, Shanqing Cai, Michael Salib, . The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction. In 2017 IEEE International Conference on Big Data (Big Data) (pp....</p></div><footer class=entry-footer><span title='2020-04-25 01:35:20 +0900 +0900'>4月 25, 2020</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to 機械学習システムの信頼性を数値化し、技術的負債を解消する論文「 The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction」" href=https://shunyaueta.com/posts/2020-04-25/></a></article><article class=post-entry><header class=entry-header><h2>機械学習システムの信頼性を数値化する論文「 What’s your ML test score? A rubric for ML production systems」</h2></header><div class=entry-content><p>NIPS206 にて開催された Reliable Machine Learning in the Wild - NIPS 2016 Workshop (2016) という、現実世界でどうやって信頼性の高い機械学習に取り組んでいくかについてのワークショップがある。
ここで Google から発表された What’s your ML test score? A rubric for ML production systems がとても面白く、身になるものが多かったのでメモがてら抄訳を残しておく。
PDF Slide 発表動画もワークショップページにて公開されています。 change logs 2021-04-25 この原著論文の完全版になっている論文の抄訳を新たに公開しています。 [抄訳]: The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction 概略 現実世界のプロダクションシステムで機械学習を使う際に、機械学習の研究実験と異なる、小さなもしくは小さくない問題がある テストとモニタリングはプロダクションレディの機械学習システムにとって必要不可欠 しかし、どれくらいのテストとモニタリングをすれば十分と言えるのだろうか? この論文では、それらの問題を解決する ML Test Score という基準を提案する Introduciton Google 内で積み重ねたベストプラクティスをもとに、実行可能なテスト、そしてその機械学習システムがどのていどプロダクションレディなのかを示すスコアシステムを提案
このスコアは、機械学習を始めたばかるのチームからエキスパートがあつまるチームまで幅広く適用可能
注意: 一般的な Sofware Engineering のベストプラクティスは含んでいない
そのかわり、学習とサービングのための Unit Test Coverage の計算方法など機械学習に必要不可欠な点を抑えている...</p></div><footer class=entry-footer><span title='2020-04-19 22:18:10 +0900 +0900'>4月 19, 2020</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to 機械学習システムの信頼性を数値化する論文「 What’s your ML test score? A rubric for ML production systems」" href=https://shunyaueta.com/posts/2020-04-19/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://shunyaueta.com/posts/2020-04-18/images/1.png alt="Coursera の証明書"></figure><header class=entry-header><h2>CourseraでHow Google does Machine Learning の講義を修了した</h2></header><div class=entry-content><p>Coursera でHow Google does Machine Learning の講義を修了した
Certificate はこちら
7 割が、機械学習プロジェクトの始め方、実際のハマりどころなどが Google 内の実例などに基づいて語られていて面白かった。 特に、
Secret Sourse ML Sutprise の部分が、アンチパターンや成功方法などが語られていて実際に実務で機械学習をやっている自分としてはわかる~~~~と共感がすごくできて面白かった。初めて機械学習プロジェクトを担当する PM の方にも良い教材なのではと思いました。
残りの 3 割は、qwiklab を使って、Notebook を立ち上げたり、Google BQ 叩いたり、Pandas, Google Cloud Vison API など各 ML 系の API を触るといった感じで、初心者過ぎて自分にはレベル感が少しあいませんでしたが、これも非エンジニアの方が機械学習ってこんな感じかと学ぶきっかけにはすごく良さそうです。
最初の 7 割の部分は、改めてデータ利活用を前提にしたプロジェクトを牽引していく際にここで見つめ直す形になってよかったです。
最近、Cousera での講義を始める機会があり Andrew Ng 先生の機械学習コースぶりに Coursera をやっているが、勉強のペースメーカーが決められるのと講義内容の質も高いので自分にとってはすごく相性が良い。
技術書を読むときも同じペースで、実行できないかなと画策したい</p></div><footer class=entry-footer><span title='2020-04-18 00:59:23 +0900 +0900'>4月 18, 2020</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to CourseraでHow Google does Machine Learning の講義を修了した" href=https://shunyaueta.com/posts/2020-04-18/></a></article><article class=post-entry><header class=entry-header><h2>Courseraで Getting Started with Google Kubernetes Engine の講義を修了した</h2></header><div class=entry-content><p>表題のとおりですが、Getting Started with Google Kubernetes Engine という Coursera の講義を終了しました
業務で k8s を本格的に使い始め、ちゃんと理解したいな~と思いこのコースを取りました。
半年前に Kubernetes 完全ガイド impress top gear シリーズ をサラッと読んではいたのですが、やはり手を動かして学んでいないと実際に kubectl command など完全に忘れているし、スキルとして身についていない感半端なかったので、良い機会なので Hands-on が提供うされている Coursera を使って学んでみました。
個人的にこの講義がめちゃくちゃオススメなのが、 GKE の講義なので Google が提供する qwiklab が使えます。 一時的に GCP プロジェクトが作成され、そこでハンズオンができるのですがこれが実際に手を動かしながら学ぶという形式にすごく良いのと k8s の構築もすべてクラウドでできえるので変に環境構築でハマることなく快適に学習に集中できました。
もう、これがめちゃくちゃ快適でハンズオンとしてすごく快適に手を動かせなら、k8s の初歩的な概念や Command line などを学べました。
実際に手を動かしながら学ぶべきものだと思うので、このハンズオン形式の講義はありがたかったです!
後は学ぶにつれて、 k8s の凄さがわかってきたので理解して使いこなせるようになればスケールするシステムを個人でも作れそうなので、頑張っていきます。</p></div><footer class=entry-footer><span title='2020-04-12 00:59:23 +0900 +0900'>4月 12, 2020</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to Courseraで Getting Started with Google Kubernetes Engine の講義を修了した" href=https://shunyaueta.com/posts/2020-04-12/></a></article><article class=post-entry><header class=entry-header><h2>遅すぎる `pandas.read_gbq` を使わずに、Google BigQueryから高速にデータを読み込む</h2></header><div class=entry-content><p>pandas.read_gbq 便利ですよね。 クレデンシャルファイルを認証画面からコピペすれば Jupyter Notebook 上で簡単に認証され、Google BigQuery が実行されてその結果がそのままデータフレームとして扱えます。 Jupyter Notebook と Google BigQuery を連携させたいときは愛用していました(過去形)。
問題点 そこそこ大きなデータを持ってこようとすると、めちゃくちゃ遅くてストレスが凄い 解決方法として、Google BigQuery で巨大なデータをダウンロードする方法について書きます。
実は Google の公式ドキュメントでも推奨されています。
https://cloud.google.com/bigquery/docs/pandas-gbq-migration https://cloud.google.com/bigquery/docs/bigquery-storage-python-pandas 方法は以下の２つ。
google-cloud-bigquery をインストールして、マジックコマンドで Google BQ を実行 BQ 実行 →BigQuery table として保存 →GCS へ保存 → gsutil でマシンへコピー 1 番目は、Jupyter 上でマジックコマンドで Google BQ が実行できて、速度も pandas.rad_gbq よりも高速です 2 番目はそもそも実行結果が巨大な場合で、目安としては1GB以上なら 2 番目の方法を使えば楽です。
1, google-cloud-bigquery をインストールして、Jupyter Notebook のマジックコマンドで Google BQ を実行 1 pip install --upgrade google-cloud-bigquery[bqstorage,pandas] magic command を実行
1 %load_ext google....</p></div><footer class=entry-footer><span title='2019-10-03 23:52:54 +0900 +0900'>10月 3, 2019</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to 遅すぎる `pandas.read_gbq` を使わずに、Google BigQueryから高速にデータを読み込む" href=https://shunyaueta.com/posts/2019-10-03/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://shunyaueta.com/page/5/>«&nbsp;前へ&nbsp;</a>
<a class=next href=https://shunyaueta.com/page/7/>次へ&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2023 <a href=https://shunyaueta.com/>hurutoriya</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>