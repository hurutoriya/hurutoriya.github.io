<!doctype html><html lang=ja dir=auto><head><meta name=generator content="Hugo 0.111.3"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>hurutoriya</title><meta name=description content="Shunya Ueta's blog"><meta name=author content="Shunya Ueta"><link rel=canonical href=https://shunyaueta.com/><link crossorigin=anonymous href=/assets/css/stylesheet.6a98292fb8fa8cf0f3ba4042d4b75515c04267550f3ad49ff6271b5af9562443.css integrity="sha256-apgpL7j6jPDzukBC1LdVFcBCZ1UPOtSf9icbWvlWJEM=" rel="preload stylesheet" as=style><link rel=icon href=https://shunyaueta.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://shunyaueta.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://shunyaueta.com/favicon-32x32.png><link rel=apple-touch-icon href=https://shunyaueta.com/apple-touch-icon.png><link rel=mask-icon href=https://shunyaueta.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://shunyaueta.com/index.xml><link rel=alternate type=application/json href=https://shunyaueta.com/index.json><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-JMJRQJT0Q3"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-JMJRQJT0Q3")</script><meta property="og:title" content><meta property="og:description" content="Shunya Ueta's blog"><meta property="og:type" content="website"><meta property="og:url" content="https://shunyaueta.com/"><meta property="og:image" content="https://shunyaueta.com/ogp.jpg"><meta property="og:site_name" content="Shunya Ueta"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://shunyaueta.com/ogp.jpg"><meta name=twitter:title content><meta name=twitter:description content="Shunya Ueta's blog"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"hurutoriya","url":"https://shunyaueta.com/","description":"Shunya Ueta\u0026#39;s blog","thumbnailUrl":"https://shunyaueta.com/favicon.ico","sameAs":["https://github.com/hurutoriya","https://twitter.com/hurutoriya","https://mstdn.jp/web/@hurutoriya","https://www.linkedin.com/in/hurutoriya/","https://www.buymeacoffee.com/hurutoriya","index.xml"]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://shunyaueta.com/ accesskey=h title="hurutoriya (Alt + H)">hurutoriya</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://shunyaueta.com/archives title=Archive><span>Archive</span></a></li><li><a href=https://shunyaueta.com/about title=About><span>About</span></a></li><li><a href=https://searchengineeringnewsletter.substack.com/ title=Newsletter><span>Newsletter</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://shunyaueta.com/index.xml title=RSS><span>RSS</span></a></li></ul></nav></header><main class=main><article class=post-entry><header class=entry-header><h2>Jupyter Notebook上にTensorboard を わずか2行で表示させる</h2></header><div class=entry-content><p>Pytorch 1.2 からは公式に Tensorboard がサポートされている
Tensorboard とは、学習の状況を可視化できる TensorFlow Family の一種
Jupyte Notebook 上で学習状況を確認したい場合に Tensorboard をそのまま表示して確認できれば楽なので、試してみる
sample code: https://pytorch.org/docs/stable/tensorboard.html 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 import torch import torchvision from torch.utils.tensorboard import SummaryWriter from torchvision import datasets, transforms # Writer will output to ./runs/ directory by default writer = SummaryWriter() transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]) trainset = datasets....</p></div><footer class=entry-footer><span title='2019-09-25 23:16:07 +0900 +0900'>9月 25, 2019</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to Jupyter Notebook上にTensorboard を わずか2行で表示させる" href=https://shunyaueta.com/posts/2019-09-25/></a></article><article class=post-entry><header class=entry-header><h2>How to connect the Google Compute Engine via Visual Studio Code</h2></header><div class=entry-content><p>1. Generate SSH config file using gcloud command line 1 gcloud compute config-ssh https://cloud.google.com/sdk/gcloud/reference/compute/config-ssh
You cant get ssh config for your Google Compute Engine project!
Notice: you need choose target GCP project before run below command.
1 gcloud config set project &lt;your-project-id> 2. Install Remote SSH extention in Visual Studio Code. https://code.visualstudio.com/blogs/2019/07/25/remote-ssh
3. Press ⇧⌘P & Select target connection in Visual Studio Code! Finaly you can connect in Visual Studio Code....</p></div><footer class=entry-footer><span title='2019-09-24 17:35:05 +0900 +0900'>9月 24, 2019</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to How to connect the Google Compute Engine via Visual Studio Code" href=https://shunyaueta.com/posts/2019-09-24/></a></article><article class=post-entry><header class=entry-header><h2>ビジネスでインパクトが出せるデータサイエンティストになるには</h2></header><div class=entry-content><p>@pseudo_finite さんから
「ビジネスでインパクトが出せるデータサイエンティストになるためには」
をご恵贈していただいたので、感想をここに記します。
経営システム誌に寄稿したものができました。30 部あるので欲しい方はお声がけください。
私の 10 年間の経験を整理して中堅のデータサイエンティスト向けに書いたものになります。批判的なフィードバックなどいただけると嬉しいです。(@pseudo_finite) tweet January 18, 2019
批評 1. データサイエンティストが力を発揮する場 データサイエンティストとして成果を発揮するには、事業ドメイン・そしてデータの規模と質に依存する
圧倒的に同意です。自分も現職に就職する際には、データ規模・質・種類や社内のデータに関する文化などを考慮して会社を選びました。 最後の一文も完全に同意で、良いデータさえあれば基本的に問題は解きやすく簡単になると思っています。
2. 課題設定 データサイエンティストの仕事の肝は適切な課題設定
本質的な課題設定とはそもそもなんなのかと考えてみます。
ここで、本質的な課題設定を解明するための大きな障壁になるのは、
自社が事業会社か ドッグフーディングできるサービスを運営しているか どうかではないでしょうか?
日常的に自社のサービスを使っていると、顧客視点での改善点や課題点などを見つけることができる。 また、サービスをより深く知ることで深い考察や客観的な観察をすることができる。 スタートアップ界隈では浸透している リーンスタートアップの考え方は、本質的な課題の発見に非常に相性が良いと思っています。
また、データ分析では、単なる集計や相関ではなく、顧客がどんな状況で何をしたいのかを考えてユーザーリサーチをすることも非常に重要です。 ジョブ理論 イノベーションを予測可能にする消費のメカニズム で語られているトピックですが、非常に勉強になります。
3. 解決方法の設定 自然なモデリングと実現可能性のあるモデリング
自分はデータサイエンティストではなく、機械学習エンジニアとして働いているので、その立場からの視点です。 実感するのはまず何よりも実装力が大事だと思います。
実装ができるからこそ、実験ができる。その実験から知見を得て改善のサイクルが回り始める。
関連する暦本先生の tweet が面白かったので、ご参考まで
深層学習時代になってますますですが研究者のコード書きは開発というより未解決の問題や仮説に決着をつける行為、サイエンスにおける実験そのものなのでコード書かない人がどうやって研究してるのか想像つかないです🤔 https://t.co/mojhTqHqmx
— Jun Rekimoto : 暦本純一 (@rkmt) September 16, 2019 4. 検証 施策実行後の検証は必須
個人的には自分が最も重要だと思う点はここである。 確かに施策が成功したら、燃え尽きたくなる気持ちはわかるが、なぜ成功したのかを解明して再現性を担保しなければ知見としてストックされない。 そして知見の溜め込みの速さ・多さこそがビジネスとしての優位性につながるのではないのだろうか? これこそ、まさに科学的思考の本幹ですね。
5. 育成 データサイエンティストの育成は非常に難しい
育成の点は、自分も最近考えていたことですが、
例えば研究室のセミナーや論文の赤入れなどで議論をしたからこそ科学的思考方法が身についたのか? を考えていました。
僕の結論では、 強い相関はあれど研究室での議論により全員が身科学的思考方法を会得するのは難しいのではないかと思っています。 (もちろん全員が身につけることこそ、研究室の本懐だと思います)...</p></div><footer class=entry-footer><span title='2019-09-23 18:48:47 +0900 +0900'>9月 23, 2019</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to ビジネスでインパクトが出せるデータサイエンティストになるには" href=https://shunyaueta.com/posts/2019-09-23/></a></article><article class=post-entry><header class=entry-header><h2>How to concat image using skimage</h2></header><div class=entry-content><p>When you need to concat same size image to make figure.
skimage & numpy combination is too powerfull to concat images.
This is sample script.
1 2 3 4 5 6 7 8 from skimage import data, io import numpy as np img = skimage.data.astronaut() imgs= [img for i in range(10)] skimage.io.imsave("sample_h.png",np.hstack(imgs)) skimage.io.imsave("sample_v.png",np.vstack(imgs)) After that you can get below images.
Via Gist: https://gist.github.com/hurutoriya/fedf059ad3db5c67b16d8d5dd6d3df70</p></div><footer class=entry-footer><span title='2019-06-17 00:07:33 +0900 +0900'>6月 17, 2019</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to How to concat image using skimage" href=https://shunyaueta.com/posts/2019-06-17/></a></article><article class=post-entry><header class=entry-header><h2>Hugo Tips</h2></header><div class=entry-content><p>Hugo 0.32から page bundle が使用可能に この機能で画像ファイルを以下のファイル構成で構築できる 1 2 3 - hoge/ - index.md - hoge.png これにより、markdown とアセットファイルが同一ディレクトリ内に収まるのでアセットファイルの管理が簡単になる
hugo new で特定のエディタを開くには? 1 hugo new posts/hoge.md --editor="code" 作成時にslug に日付を含める 今回は2020-09-09の形式で slug を作成する 1 hugo new posts/$(date '+%Y-%m-%d')/index.md page をビルドして結果を確認する 1 hugo server 下書きも含めてビルドする 1 hugo server -D</p></div><footer class=entry-footer><span title='2019-06-16 23:09:18 +0900 +0900'>6月 16, 2019</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to Hugo Tips" href=https://shunyaueta.com/posts/2019-06-16/></a></article><article class=post-entry><header class=entry-header><h2>Machine Learning Casual Talks #10 を開催しました</h2></header><div class=entry-content><p>MLCT #10 を開催しました。
Machine Learning Casual Talks とは
実サービスにおける機械学習の経験をカジュアルに語り合おう
を目的としたコミュニティです。
スポンサー 前回と同じく本イベントは株式会社メルカリにスポンサーとして会場と懇親会の提供を受け開催することができました。 スポンサー依頼を快諾いただきありがとうございました!
配信動画はこちら!
Sli.do がパネルディスカッションでめっちゃ便利な件 今回は、パネルディスカッションで sli.do をスクリーンにフルスクリーンで表示してモデレーションを行いました。
手元のスマートフォンで質問をハイライトして、回答を終えたものはアーカイブという運用でしたが、とても快適なのでみなさんぜひお試しください。 スクリーンでの表示画面が SPA で同期されているので、手元のスマートフォンで更新すればリアルタイムで同期されるのがとても便利です。</p></div><footer class=entry-footer><span title='2019-06-15 22:01:27 +0900 +0900'>6月 15, 2019</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to Machine Learning Casual Talks #10 を開催しました" href=https://shunyaueta.com/posts/2019-06-15/></a></article><article class=post-entry><header class=entry-header><h2>Machine Learning Casual Talks #8 を開催しました</h2></header><div class=entry-content><p>Machine Learning Casual Talks 第 8 回の開催を無事終えました
MLCT とは
実サービスにおける機械学習の経験をカジュアルに語り合う
コミュニティです
スポンサー 今回も同じく本イベントは株式会社メルカリにスポンサーとして会場と懇親会を提供を受け開催することができました!
Machine Learning Casual Talks #8 (2019/01/28 18:30〜)
当日の配信動画はこちら
当日の発表資料はすべてこちらにあります
Machine Learning Casual Talks #8 - 資料一覧 - connpass
エムスリー 西場さん
BEDORE すみのさん
TL;DR; エムスリーの西場さん、すべてをこなす toB の機械学習サービス、システムアーキテクチャデザインかなり考えないとキツイ 懇親会での 🍣 の需給予測失敗しかけた 次回挑戦したいこと 今回会場撤収時に有志の参加者、登壇者の方が撤収作業を手伝っていただき非常に助かりました。次回は有志で会場撤収ボランティアの参加枠を作ろうかなと思いました。運営コストを下げるのは、継続で一番大事だなと思っているので、お手伝いいただいた皆様ありがとうございました。助かるという感情が出てくる前に、素直にめちゃくちゃ嬉しかったです!
参加率も 8 割を超えていて欠席率が非常に少なかったのも継続していきたい</p></div><footer class=entry-footer><span title='2019-02-02 18:41:32.474 +0000 UTC'>2月 2, 2019</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to Machine Learning Casual Talks #8 を開催しました" href=https://shunyaueta.com/posts/2019-02-02/></a></article><article class=post-entry><header class=entry-header><h2>Machine Learning Casual Talks #7 を開催しました</h2></header><div class=entry-content><p>Machine Learning Casual Talks 第七回を無事開催しました
Machine Learning Casual Talks #7 (2018/11/20 18:30〜)
MLCT とは
実サービスにおける機械学習の経験をカジュアルに語り合おう
というコミュニティです。
スポンサー 今回も同じく本イベントは株式会社メルカリにスポンサーとして会場と懇親会を提供を受け開催することができました。スポンサー依頼を快諾いただきありがとうございました!
遺伝異常により髪が青く変色してしまったタカヤナギ=サン
ABEJA の機械学習導入事例と辛い話を大田黒さんにお話していただきました!
今回の勉強会資料は以下にまとまっています。
Machine Learning Casual Talks #7 — 資料一覧 — connpass
今回の内容を今北産業
機械学習エンジニアとしてのキャリアのお話を タカヤナギ=サン 実世界に根付いた IOT と機械学習サービスはかなり辛い 各社の機械学習エンジニアの定義が揺らいでいるので、世界が壊れる 今回の改善点 参加枠の多様性 絶対参加するぞ枠 一般参加枠 初回参加枠 SNS 枠 Blog 枠 と今までは一つの枠で扱っていたものを、5 つの枠に分散して用意してみました。
なぜかというとドタキャンやノーショーの方の影響で本当に参加したい方や初回参加の方の機会が喪失してしまうのはいただけないので、それを解決したなと思ったのが始まりです。
初回参加枠を設けることで、新規参加者が増えて内輪感が解消されるのも狙ってみました。その影響か前回と比較して 2 割ほど参加率が増えてよかったです :)
パネルディスカッション 登壇者 2 名と僕がモデレーターを行い、パネルディスカッションを行いました。単なる発表保の質疑応答時よりも話が盛り上がってなによりでした~
次回予告 次回 MLCT 第 8 回は 2019/01/28 に参加予定です!
現実世界での機械学習の辛みを共有したい・語りたいという方はゼヒご参加ください~
Machine Learning Casual Talks #8 (2019/01/28 18:30〜)</p></div><footer class=entry-footer><span title='2018-12-15 19:29:59.546 +0000 UTC'>12月 15, 2018</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to Machine Learning Casual Talks #7 を開催しました" href=https://shunyaueta.com/posts/2018-12-15/></a></article><article class=post-entry><header class=entry-header><h2>Machine Learning Casual Talks #6 を開催しました</h2></header><div class=entry-content><p>機械学習の信頼性が熱いよねというお話
柚餅子 さんの発表風景
2018/09/25 の MLCT #6 を開催しました。
MLCT とは
実務における機械学習の話や経験をカジュアルに語り合おう
というコミュニティです。
スポンサー 今回も同じく本イベントは株式会社メルカリにスポンサーとして会場と懇親会を提供を受け開催することができました。スポンサー依頼を快諾いただきありがとうございました!
Machine Learning Casual Talks #6 (2018/09/25 19:00〜)
発表資料一覧 👇(スライドと配信動画) Machine Learning Casual Talks #6 - 資料一覧 - connpass
柚餅子さん リブセンスにおける機械学習システムの信頼性エンジニアリング SRE の考えを機械学習システムに取り入れるというお話ですが、筋が良さそう。特に SLO 周りはうちでも取り入れないなぁと思いました Naomichi Agata さん ユーザーフィードバックと機械学習 半教師あり学習で解くというアプローチは非常に筋が良さそうで気になった。技術書典の書籍も気になる 👀 gamella さん マーケット予測モデルの PCDA の回し方 ms 単位のデータを学習データにして株価の UP/DOWN を予測する。。。。適用するドメインの難易度が鬼ゲーすぎて、ハラハラしそうだけど解きがいがありそう @yu-ya4 さん Big Query ML を使ってみた話 さらっと BQML を試して成果が出ましたと言っていたが、良い問題を探し出す嗅覚がすごいなと思いました。実際 BQ だけで過不足なくモデリングが終わるなら理想の世界ですね~ Kosuke Kitahara さん 発表資料は後日公開されます。謎の力により Youtube 配信はされていません KPT Keep 動画配信を問題なく完了できた 魅力ある発表内容を維持できた Problem 参加率が低かった。前回は 65%程度の参加率でしたが、今回は雨の影響もありますが 40% と低くなっていた 倍率も毎回 1....</p></div><footer class=entry-footer><span title='2018-10-14 03:01:01.91 +0000 UTC'>10月 14, 2018</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to Machine Learning Casual Talks #6 を開催しました" href=https://shunyaueta.com/posts/2018-10-14/></a></article><article class=post-entry><header class=entry-header><h2>Machine Learning Casual Talks #5 を開催しました</h2></header><div class=entry-content><p>2018/07/13 に MLCT #5 を開催してきたお話
Opening Talk by Aki Ariga
Machine Learning Casual Talks #5 (2018/07/13 19:30〜)
本イベントは株式会社メルカリにスポンサーとして会場と懇親会を提供を受け開催することができました。スポンサー依頼を快諾いただきありがとうございました。
発表資料はこちら 👉 here (YouTube 配信もあります)
この記事では、技術的なお話というよりも開催に至るまでの話をメインに書いていきます。
Start 構想開始時期は 2018/04 頃に考えていて、弊社開催の
MLOps Nightと呼ばれるイベントの準備を行っているときに、社内だけではなく
社外の人の機械学習の辛い話をうんうんと頷きながら聞きたいなぁ
と思ったのが事の始まりです。
そのあと、とりあえず日程と発表者は事前に集めておかねばと思い @hagino3000 さんにラブコールを送っていた。
発表依頼の様子
chezou さんとの出会いと MLCT 復活の狼煙 その後、
勉強会の名前どうしよう 🤔 運営の方針どうすべきか 🤔 を迷いつつ時間が過ぎていき業務の一環として機械学習工学キックオフシンポジウム に参加していたら、そういえば Aki Ariga さんって MLCT 開催してたよな、あの勉強会すごく参考になること多かったから復活できないかなと思い始め、気がついたら懇親会で hagino3000 さんに chezou さんを紹介してもらい
「MLCT 復活させたいです!!! 場所と運営準備は僕主体でやります!」
と提案したら、あっさりと快諾され運営者に混ぜてもらえることになりました
メッセージ投げかけから 1 分で承認される
あらためて、突然飛び込んできた見知らぬ人物の運営への参加を快諾してくださった、 @chezou さん、 @tetsuroito さん、 @komiya_atsushi さんありがとうございました 🙇...</p></div><footer class=entry-footer><span title='2018-07-15 09:31:28.466 +0000 UTC'>7月 15, 2018</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to Machine Learning Casual Talks #5 を開催しました" href=https://shunyaueta.com/posts/2018-07-15/></a></article><article class=post-entry><header class=entry-header><h2>イベント運営に便利なsli.do の使いこなしかた</h2></header><div class=entry-content><p>イベント運営者必見 sli.do の使い方
sli.do のディスプレイ画面
sli.do という便利な質問投稿・回答サービスがあります。このサービスですが、イベント運営者あるあるの
オフラインだと活発に質問が出ない Twitter は盛り上がってるが実際の反応はわからない Google Form はいまいち回答率が悪い などの問題点を解決してくれるサービスです
Slido - Audience Interaction Made Easy
基本的な使い方は以下の公式動画がサクッとまとめられていて分かりやすいです
これ見れば sli.do の機能は全て俯瞰できる
UI が良く操作に迷うことはないので、各機能のスクショを貼りつつ紹介していきます
イベント設定 設定画面
イベントの名前や、 短縮コード(イベントのハッシュタグにしておくと分かりやすい)を設定して導線をわかりやすくできる
投票機能 無料版だと 3 つの投票までできる。大きなイベントでなければ十分。もちろん回答結果はシークレットにもできます。
3 つの投票機能
複数選択肢
自由記入式
星によるレーティング
各投票機能はアクティブにすると参加者は一つだけ投票可能になる
参加者からの質問・回答結果のライブ表示 右上のトグルボタンをクリックすると、投票結果をライブ表示できる。勉強会の発表中にサイドディスプレイがあれば常時表示しておくとライブ感が出て良いと思う
ライブ画面への切り替え
質問一覧
回答ライブ画面
上部のスイッチ画面から次の投票に切り替えることができる
回答解析機能 管理画面から回答のインフォグラフィックを生成することもできる
といたせりつくせりの機能が提供されています。
まとめると
イベント参加者からのオープンな質問投稿(匿名・非匿名) 各質問・回答のライブ表示 運営者からのサーベイ(イベントの感想など) の 3 点が sli.do では使えます
Tips 唯一惜しい機能としては、イベント管理者が単一ユーザーでしか管理できない点ですが共同アカウント作れば大丈夫そうです。
How do I add more admins to my event?
Google Slides でも QA 機能ありませんかとかありますが、sli....</p></div><footer class=entry-footer><span title='2018-06-17 15:03:27.683 +0000 UTC'>6月 17, 2018</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to イベント運営に便利なsli.do の使いこなしかた" href=https://shunyaueta.com/posts/2018-06-17/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://shunyaueta.com/posts/2018-04-24/images/1.png alt></figure><header class=entry-header><h2>[抄訳] Data engineers vs. data scientists</h2></header><div class=entry-content><p>データサイエンティストとデータエンジニアの定義とその誤解による悲劇、そしてそれを救う存在である機械学習エンジニア
紹介記事 Data engineers vs. data scientists
紹介記事を同僚から教えてもらい、面白かったので抄訳した
> Aki Ariga さんが言及していた記事と方向性が同一で面白かった。
Data Scientists : ビジネスサイドを理解し、他者にわかりやすく可視化と言語化できる職能。そして高度な数学的知識に基づいたモデリングやアルゴリズム提案スキルも持っている。Data Scientists には高度な Programming skill は必ずしも必須ではない、なぜならモデリングやアルゴリズムを実装するためにプログラミングを習得した人が多いからだ。システムデザインや Programming スキルは、Software Engineer や DataEngineer からみると見れたものではない(そしてそうでなくてはならない、なぜならスペシャリストだから)
Data Engineer : 分散プログラミングを意識して構築できる職能。DE は卓越したプログラミングスキルとシステム構成力を持つ。定義 : つまりビッグデータに対してシステム的に解決できるスキル。クラスタ設計までが Data Engineer の役割であり運用(Ops)はやらない
from : https://www.oreilly.com/ideas/data-engineers-vs-data-scientists
Data Scientists と Data Engineer の互いの特化したスキルは補完しあってこそ輝く。 Data Scientist がデータパイプラインを作ると悲劇が起きてしまう。多くの企業が Data Scientist を Data Engineer として雇っているが、それは Data Scientists のスペックを活かしきれず、20–30%の効率で働かせてしまっている。そしてその ROI はめちゃくちゃ悪い。Data Scientists は適切なツールと選択肢を熟知していない(そして Data Engineer はシステムデザインと熟知しているのでミスは侵さない) e.g. 実際著者が聞いたこんな話がある。 Data Scientists が Apache Spark を使って 10GB のデータ処理を行うのに 1 回 15m の時間がかかっていた。(だが RDBMS を使えば、10ms で終わる) Data Scientist は彼らの流儀を疑うこと無く 1 日に 16 回 Spark の処理を実行しており、15mx16=240m つまり 4h の時間を無駄にしてる。RDBMS を使えば、160ms で終わるというのに… Data Scientist が頑張ってシステムを構築するが、職能の限界で Data Engineer しか作れないシステムなので時間とお金の浪費になった 実情 : Data Scientist として雇われたのに、Data Engineer として働かざるを得ない人がほとんどだ 理想的な人材配置 Case : 初期の組織: 2–3 人の Data Engineer : DataScientist Group Case : 更に複雑な事に取り組みたい 4–5 人の Data Engineer : 1 Data Scientist Data Engineer change to Data Scientist の王道 → それが新しい職種 : Machine Learning Engineer!...</p></div><footer class=entry-footer><span title='2018-04-24 02:18:46.954 +0000 UTC'>4月 24, 2018</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to [抄訳] Data engineers vs. data scientists" href=https://shunyaueta.com/posts/2018-04-24/></a></article><article class=post-entry><header class=entry-header><h2>Google Colaboratory で Mecab-ipadic-Neologd を使用可能にする</h2></header><div class=entry-content><p>Colabratory 上で 日本語に対する NLP をしたいときありませんか？
1 2 3 4 5 # install MeCab neologd !apt-get -q -y install sudo file mecab libmecab-dev mecab-ipadic-utf8 git curl python-mecab > /dev/null !git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git > /dev/null !echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n > /dev/null 2>&amp;1 !pip install mecab-python3 > /dev/null インストールに成功しました。
Google Colabratory も以下で公開しているので参考にしてみてください
colab-mecab-ipadic-NEologd.ipynb</p></div><footer class=entry-footer><span title='2018-04-23 15:38:10.151 +0000 UTC'>4月 23, 2018</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to Google Colaboratory で Mecab-ipadic-Neologd を使用可能にする" href=https://shunyaueta.com/posts/2018-04-23/></a></article><article class=post-entry><header class=entry-header><h2>eBayのAR測定機能を試してみた</h2></header><div class=entry-content><p>eBay が ARCore を使った商品の梱包測定機能を提供しているので試した
梱包測定の仕組みとしては、ARCore(今回は Pixel2 XL で試した)で平面検出を行って、そこに eBay のダンボールオブジェクトを設置することで、ダンボールに入るかどうかを判定できる。
下のダンボールアイコンを選択して、検出された平面をタップするとダンボールオブジェクトを設置できる
今回例として用いた MBP の空箱だと ARCore が空箱自体を平面と認識してしまうという罠があるので、床で平面検知を終えてから商品を置くという裏技が必要
まとめ ARCore を用いた AR 機能をすぐ試せる組織体制なのは凄い。ハッカソンで作ったのかな? 実用性は 🙅、平面検出しかしてないので、荷物に合わせて最適なダンボールを選ぶのは結局ユーザー。そこまで自動化してこそ革新的な機能になるのではなかろうか Reference eBay uses augmented reality to help sellers find the right box for their product</p></div><footer class=entry-footer><span title='2018-04-16 14:57:41.155 +0000 UTC'>4月 16, 2018</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to eBayのAR測定機能を試してみた" href=https://shunyaueta.com/posts/2018-04-16/></a></article><article class=post-entry><header class=entry-header><h2>Google, Facebookが提供する機械学習基盤まとめ</h2></header><div class=entry-content><p>Google, Facebook の機械学習基盤情報をまとめました
Podcast でも紹介しました
#2 Facebook と Google の機械学習基盤について at just4fun.fm
社内の勉強会で Google, Facebook が提供する機械学習基盤に関する論文を紹介したので、その資料を公開します
機械学習をサービスとして提供開始すると、継続的な学習やプロダクション環境での機械学習の提供はモデル構築以外にもいろいろと考える問題が多くなります ¹
[1] Hidden technical debt in Machine learning systems NIPS’15
要するに機械学習をサービスとして届けるには、実はめちゃんこ大変なんだよという話なんですが、みんな同じ問題にぶち当たります。
そのためプロダクションレディなレベルで機械学習を提供できるプラットフォームを各社が提案しておりその中でも Google, Facebook の事例を提供します。
TL; DR; FBLearner: MLaaS の事例として最初に読むべき論文、MLaaS をどのような戦略で提供しているかを抽象的にまなべるため、鳥瞰図として読みましょう TFX は逆に機械学習基盤が必要とする技術スタックや要件などを詳細に説明しており、教科書的な立ち位置です。社内で機械学習基盤を内製したい場合に詳しく読み込むこと必須 両社とも MLaaS をスケーラブルに提供する環境ができており、サービスのコアテクノロジーになっている Google : Tensorflow Expand TFX: A tensor flow-based production-scale machine learning platform
Facebook : FBLeaner Applied machine learning at facebook a datacenter infrastructure perspective HPCA18
ONNX を見ていると TensorFlow VS....</p></div><footer class=entry-footer><span title='2018-04-09 13:55:44.389 +0000 UTC'>4月 9, 2018</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to Google, Facebookが提供する機械学習基盤まとめ" href=https://shunyaueta.com/posts/2018-04-09/></a></article><article class=post-entry><header class=entry-header><h2>メルカリのTeam AI Meetup #1 に参加してきた #mercari_ai</h2></header><div class=entry-content><p>メルカリが主催する機械学習のミートアップに参加してきたので備忘録がてらメモ書きです。書きなぐったメモなので意訳として捉えて下さい
発表者の顔は隠しています。なにか問題があればお伝え下さい。
Team AI Meetup #1 (2018/02/13 19:00〜)
Twitter: #mercari_ai
山口さん Image Net と mercari の持ってるデータセットは似てるのでいけるのでは! ルカリはクラス数 over 1100 始期の推定値 Top5 29.3% エラー例 :画像からサイズを推定しないと男女のシューズを区別不可(人間でも不可能なエラー例が多い) 意外と認識がうまくいく事例がかなりある(クラス設計の影響で推定が上手く出来ていないらしい) データセットはユーザーが作成してるので最高、画像が正方形なのも Good 学習は GPU,推論は CPU 環境下で行っている 画像検索自体はプロトタイプは出来ているが、実運用は計算量やリアルタイム性を担保するのが難しいので一旦保留中 大筋は以下の記事と資料で把握できます。k8s で運用しているなどの実運用の構成が今回の発表では差分として語られていました。
画像での商品検索に向けて - Mercari Engineering Blog
【Mercari Summer Internship】商品画像の色推定を行いました! - Mercari Engineering Blog
工藤さん 運用を継続すると色んな問題が出てきたので、それを解決する基盤環境を作成しはじめた e.g. 学習データのバージョン管理、モデルのデプロイ, etc 最終的には OSS としての公開も考えているとのこと メルカリの今年 1 年間の機械学習の取り組みとこれから - Mercari Engineering Blog
ML Ops Study (仮) #1の発表内容も今回の機械学習の運用周りの Tips が共有されているので興味のある方はオススメです
機械学習基盤といえば、最近Polyaxonという OSS が公開されてました。...</p></div><footer class=entry-footer><span title='2018-02-13 15:35:48.521 +0000 UTC'>2月 13, 2018</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to メルカリのTeam AI Meetup #1 に参加してきた #mercari_ai" href=https://shunyaueta.com/posts/2018-02-13/></a></article><article class=post-entry><header class=entry-header><h2>2018.01 KPT</h2></header><div class=entry-content><p>2018 年 1 月の振り返りをざっくりと
Keep Mercari Competition にて初 Kaggle コンペ参加。 Best 116 位まで言ったんですが、NLP 周りの知見が無いのと、Kaggle 周りの力不足で現在は 317 位… ブロンズまで引き戻せるか… ぬか喜びしている図
Coursera で Ng 先生のML コースを始めた。あと 5 日位で無事終わりそう。とても分かりやすい(何故もっと早く受けなかったのか…) 終わったら、How to Win a Data Science Competition: Learn from Top Kagglersか Ng 先生の deeplearning.ai を始める予定 本を 2 冊読めた。案外読む始めるのがハードル高いだけで、読み始めれば 1 日 30 分*5 日で読み終わることがわかったので今度から通勤途中に読むことにした。これで月 4 冊読んでいくようにしたい。2–3 月はメタ学習関連の本を読み進めていく。 学力の経済学
お金持ちになれる黄金の羽根の拾い方
Duolingo で英語学習を再開した。学習アプリとしてとても出来が良い。(名詞の複数形や冠詞などの細かい間違いを都度指摘されるのが好き。モバイルアプリ(iOS)は問題が重複して出題されるので PC メインで利用) 100%達成するぞ! Linkedin に成績が反映されなくなったのは残念。おそらく言語学習は継続性がないと意味がないのでそれを考慮してシステム変更したんだろうな
住信 SBI ネット銀行を開設した。ネット銀行最高。 Google Family **を始めた。**予定管理はTimeTreeを使ってデザインや使い勝手は不安が無かったんですが、Google Calendar に比べてアプリのインテグレーションや持続性(日本のベンチャー企業なのでいつまでそのサービスが持つのか)が不安になったので Google Family に乗り換えました。 Problem Kaggle のゴールドの壁を痛感。もっと精進せねば 論文読みが止まってしまってた。機械学習基盤とプロダクション環境における機械学習関連の論文をテーマにしてまとめて書き上げる Try 02 月から仕事が始まるので(初社会人、入社完了したらまた振り返り Blog を書く)、社会人としてのメタスキルを実践できるようにしておく(e....</p></div><footer class=entry-footer><span title='2018-02-09 14:00:31.85 +0000 UTC'>2月 9, 2018</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to 2018.01 KPT" href=https://shunyaueta.com/posts/2018-02-09/></a></article><article class=post-entry><header class=entry-header><h2>2018年の抱負</h2></header><div class=entry-content><p>2018 年の抱負です。
Works 機械学習エンジニアとして六本木で働く事になりました。機械学習エンジニアとしてスペシャリストになれるように周辺スキルを伸ばしていきます。
Kaggle Master に到達(1 gold medal, 2 silver medals) 初参加のコンペもずるずる下降してしまいブロンズ圏外に…
Coursera, Udacity (MOOC)で CV, Robotics 周辺を学習していく Github で 50 star over の OSS を作る(CV or ML) 勉強会に登壇 or 主催 する メタ学習(学習の効率化)について小話
うまくなる技術¹などのメタ学習関連の本を色々と読み漁って学習のコツをいろいろ勉強してるんですが、外的指標(Github Star, Kaggle Rank, Toggl tracking,Coursera Certificate)を目的にすると人間気持ちよく継続できるらしいのでそれに沿った行動をするよう心がけています。後 5–6 冊メタ学習の本を読み終えてまとまったらまた記事にする。
サンシャイン丸の内さん¹や ふろむださん¹の記事も参考になるのでオススメです
個人的に最近心に響いたのはのじゃろりおじさんの勉強の姿勢です。
３ D や unity の勉強方法について。：ねこみみメモ
おそらく、やり続けて成功した人は「やり続ければ報われる！」と言うと思うのですが、年齢や経済状況や自分の才能を疑ったり等……現実は難しいと思います。
私は偶然このタイミングで「オリジナルモデルの Vyoutuber を出せた」から幸運に恵まれただけで、純粋な技術ではおそらく就職は無理だったのではないかと思います。2018~19 年で見切りつけて諦めなきゃなと思ってたぐらいです。
なので「やり続ければ報われる」とはとても言えません。ただ**「やり続けて報われなくてもいいと思える事は、やり続けた方がいい」**とは思います。
他者の評価がどうであれ、やてって楽しくて満足できるのであればある意味常に成功している状態で、やればやるほど成功続きなわけです。
English DMM 英会話 TOEFLE で 90 点、英語で働けるレベルを目指す 英語 Blog 記事を定期的に書く Health カラダステーションで内臓脂肪が少し高めになってたので走る(筋トレしかやってなかったツケが…) 筋肉量も左右でバラツキ(利き手側じゃないほうが 100g 程度筋肉量が少ない)があるので整える 筋トレはケトルベル 16kg で色々とやってるので継続する。...</p></div><footer class=entry-footer><span title='2018-01-29 16:08:35.698 +0000 UTC'>1月 29, 2018</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to 2018年の抱負" href=https://shunyaueta.com/posts/2018-01-29/></a></article><article class=post-entry><header class=entry-header><h2>Where To Look: Focus Regions for Visual Question Answering (CVPR2016)を読んだ</h2></header><div class=entry-content><p>Kevin J. Shih, Saurabh Singh, Derek Hoiem, “Where To Look: Focus Regions for Visual Question Answering”, in CVPR2016 link
Summry
を読んだので、軽くメモ。
VQA(Visual Question Answer) 画像に対する質問に対して応答するタスクに対し、その質問クエリに対して画像のどの領域に注目すべきかのモデルの学習方法について論じた論文。
Contribution VQA datasetに対して、提案手法を適用。従来手法を全て上回った。 画像に対して CNN を用いて物体領域の検出を行った後にベクトル化、質問クエリはword2vecを用いてベクトル化を行う。 その 2 つのベクトルを用いて内積計算により重み付けを行うことで、どの領域に注目すべきかを計算する。 Comments 引用文献の訳 9 割が 2014–2015(直近 2 年間)で発表された論文で、改めてこの分野の最先端を駆け抜けるのは凄まじい能力が必要になるなと思いました。
そして相変わらず CVPR の論文のネーミングセンスは良いですね。(ジャケ買いならぬジャケ読み)
単純な質問なら、人間でも瞬間的に解答可能な物が多いなと感じた。
fig. 1
セマンティックな疑問(Fig.1 雨は降っていますか?)の場合、人間に注目した場合は傘をさしているから雨と判断しても良いがもっと広い範囲で画像を見てみると空は快晴なので人間に注目するのは筋が悪く VQA はとても難しくチャレンジングな問題だと書かれていた。(それでも充分すごい領域に到達しているなと思うが)</p></div><footer class=entry-footer><span title='2018-01-18 05:41:44.616 +0000 UTC'>1月 18, 2018</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to Where To Look: Focus Regions for Visual Question Answering (CVPR2016)を読んだ" href=https://shunyaueta.com/posts/2018-01-18/></a></article><article class=post-entry><header class=entry-header><h2>Data-driven Crowd Analysis in Videos (ICCV2011)を読んだ</h2></header><div class=entry-content><p>Data-driven Crowd Analysis in Videos (ICCV2011)を読んだ
Mikel Rodriguez, Josef Sivic, Ivan Laptev, Jean-Yves Audibert, “Data-driven Crowd Analysis in Videos”, in ICCV2011.
Project Page
を読んだので、メモです。
Summary
tl;dr 高密度な群集内の個人を追跡を転移学習によって精度を向上させる手法 Contribution 追跡の精度を転移学習によって向上させた 転移学習を行うためのデータセットとそのフレームワークを考案 論文内では、転移学習の例としてマラソンAの群集を対象に追跡する際に、以下の流れで転移学習を行う。
大域的な群衆状況のマッチング : 同じようなシーンを探索(この場合 DB 内にあるマラソン動画) 局所的な群衆状況のマッチング : 1でマッチした動画においてオプティカルフローが類似するパッチを探索して転移学習 また、Rare Events(デモの最中に群集を横断するカメラマンなど、群衆の流れに対して同調しない動きを行う人物)に対しても実験を行い評価。
Comments 転移学習は自分のイメージだと、自然言語処理のイメージ(一般的な文書を学習したモデルを法律文書に対して適用するなど)しかなかったので新鮮な気持ちで読めた。
動画なら転移学習を行ったとしても、直感的に良い特徴を学べそうなので、良い仮説を立てている論文でした。
最後に示されてる個人追跡における平均誤検出の単位がpixelだが、Ground-Truth と提案手法の追跡軌跡の重複度具合を見てると誤検出が更に高そうに見えるけどどうなんでしょうか？
(テストデータのみ学習が 58.82、転移学習を行った提案手法だと 46.88になっていてもっと相対的な差が出てくるはず?)</p></div><footer class=entry-footer><span title='2018-01-17 05:55:41.861 +0000 UTC'>1月 17, 2018</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to Data-driven Crowd Analysis in Videos (ICCV2011)を読んだ" href=https://shunyaueta.com/posts/2018-01-17/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://shunyaueta.com/page/6/>«&nbsp;前へ&nbsp;</a>
<a class=next href=https://shunyaueta.com/page/8/>次へ&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2023 <a href=https://shunyaueta.com/>hurutoriya</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>