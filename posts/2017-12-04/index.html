<!doctype html><html lang=ja><head><meta http-equiv=x-clacks-overhead content="GNU Terry Pratchett"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Edge-Weighted Personalized PageRank: Breaking A Decade-Old Performance Barrier を読んだ | hurutoriya</title><meta name=title content="Edge-Weighted Personalized PageRank: Breaking A Decade-Old Performance Barrier を読んだ"><meta name=description content="応用数理研究者が機械学習界に進出していく研究
youtube clip
応用数理界隈ではクラシックな解き方で PageRank が解かれているので最新の数値計算手法に置き換えることで劇的にパフォーマンスが向上して 10 年前のパフォーマンスの鎖を解き放った論文
KDD2015 Best student paper award Slide(PDF) Poster(PDF) Spectral network analysis wenleix/EdgePPR
Presentation Movie is uploaded in Youtube. Author
W. Xie Ph.D Candidate at Cornell University http://wenleix.github.io/ iterative computation on big graph data D. Bindel http://www.cs.cornell.edu/~bindel/ http://www.cs.cornell.edu/~bindel/talks.html He is frequently research activ like ideal young researcher. Nonlinear eigenvalue problem. Alan J. Demers Prof. Johannes Gehrke http://www.cs.cornell.edu/johannes/ Prof. VLDB,SIGMOD,KDD Motivation ページランクは重要な指標。遷移確率を求めるにはランダムサーファーモデル(ランダムウォーク)が必要。 様々な高速解法が提案されている。 Reseatch Question しかし 10 年以上前、PageRank の黎明期から Personalization based の手法は問題がある。 一般的な PageRank の解法の説明、その後に Model Reduction をベースにした約 5 倍の性能を誇る提案手法を説明。 提案手法の性能によって、パフォーマンス上のボトムネックは消えた。 Proposed Method PageRank 初期:WEBPage のランクに使用 → 現在:推薦、ソーシャルネットワーク Random Suffer Model Transition : α の確率で Random Walk(滞在ノードから無作為に遷移) Teleporting : 1−α Random Junmp(滞在ノードに依存せずに全てのノードを対象に無作為遷移) x(t+1)=αPxt+(1−α)v,where P=AD−1 v is represents telepotation probabilitie xt Walker の確率分布 サーファーが来る確率 = RandomWalk の確率_RandomWalk による遷移確率 + RandomJump の確率_RandomJump の遷移確率 = α× RandomWalk による遷移確率 + (1−α)×RandomJump の遷移確率 = α×+(1−α)×v x: Stationary vector(不動ベクトル、定常ベクトル、不動点定理など) x が定常状態になった際に、x の確率分布が PageRank を表す。 x(t),x(t+1)が同一(残差が無い)だと仮定することで、次式の線形方程式を解くことで Pagerank を求める。 Mx=b,where M=(I−αP),b=(1−α)v."><meta name=keywords content="machinelearning,paper,"><meta property="og:title" content="Edge-Weighted Personalized PageRank: Breaking A Decade-Old Performance Barrier を読んだ"><meta property="og:description" content="応用数理研究者が機械学習界に進出していく研究
youtube clip
応用数理界隈ではクラシックな解き方で PageRank が解かれているので最新の数値計算手法に置き換えることで劇的にパフォーマンスが向上して 10 年前のパフォーマンスの鎖を解き放った論文
KDD2015 Best student paper award Slide(PDF) Poster(PDF) Spectral network analysis wenleix/EdgePPR
Presentation Movie is uploaded in Youtube. Author
W. Xie Ph.D Candidate at Cornell University http://wenleix.github.io/ iterative computation on big graph data D. Bindel http://www.cs.cornell.edu/~bindel/ http://www.cs.cornell.edu/~bindel/talks.html He is frequently research activ like ideal young researcher. Nonlinear eigenvalue problem. Alan J. Demers Prof. Johannes Gehrke http://www.cs.cornell.edu/johannes/ Prof. VLDB,SIGMOD,KDD Motivation ページランクは重要な指標。遷移確率を求めるにはランダムサーファーモデル(ランダムウォーク)が必要。 様々な高速解法が提案されている。 Reseatch Question しかし 10 年以上前、PageRank の黎明期から Personalization based の手法は問題がある。 一般的な PageRank の解法の説明、その後に Model Reduction をベースにした約 5 倍の性能を誇る提案手法を説明。 提案手法の性能によって、パフォーマンス上のボトムネックは消えた。 Proposed Method PageRank 初期:WEBPage のランクに使用 → 現在:推薦、ソーシャルネットワーク Random Suffer Model Transition : α の確率で Random Walk(滞在ノードから無作為に遷移) Teleporting : 1−α Random Junmp(滞在ノードに依存せずに全てのノードを対象に無作為遷移) x(t+1)=αPxt+(1−α)v,where P=AD−1 v is represents telepotation probabilitie xt Walker の確率分布 サーファーが来る確率 = RandomWalk の確率_RandomWalk による遷移確率 + RandomJump の確率_RandomJump の遷移確率 = α× RandomWalk による遷移確率 + (1−α)×RandomJump の遷移確率 = α×+(1−α)×v x: Stationary vector(不動ベクトル、定常ベクトル、不動点定理など) x が定常状態になった際に、x の確率分布が PageRank を表す。 x(t),x(t+1)が同一(残差が無い)だと仮定することで、次式の線形方程式を解くことで Pagerank を求める。 Mx=b,where M=(I−αP),b=(1−α)v."><meta property="og:type" content="article"><meta property="og:url" content="https://shunyaueta.com/posts/2017-12-04/"><meta property="og:image" content="https://shunyaueta.com/ogp.jpg"><meta property="article:section" content="posts"><meta property="article:published_time" content="2017-12-04T13:06:15+00:00"><meta property="article:modified_time" content="2019-06-16T18:16:09+09:00"><meta property="og:site_name" content="Shunya Ueta"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://shunyaueta.com/ogp.jpg"><meta name=twitter:title content="Edge-Weighted Personalized PageRank: Breaking A Decade-Old Performance Barrier を読んだ"><meta name=twitter:description content="応用数理研究者が機械学習界に進出していく研究
youtube clip
応用数理界隈ではクラシックな解き方で PageRank が解かれているので最新の数値計算手法に置き換えることで劇的にパフォーマンスが向上して 10 年前のパフォーマンスの鎖を解き放った論文
KDD2015 Best student paper award Slide(PDF) Poster(PDF) Spectral network analysis wenleix/EdgePPR
Presentation Movie is uploaded in Youtube. Author
W. Xie Ph.D Candidate at Cornell University http://wenleix.github.io/ iterative computation on big graph data D. Bindel http://www.cs.cornell.edu/~bindel/ http://www.cs.cornell.edu/~bindel/talks.html He is frequently research activ like ideal young researcher. Nonlinear eigenvalue problem. Alan J. Demers Prof. Johannes Gehrke http://www.cs.cornell.edu/johannes/ Prof. VLDB,SIGMOD,KDD Motivation ページランクは重要な指標。遷移確率を求めるにはランダムサーファーモデル(ランダムウォーク)が必要。 様々な高速解法が提案されている。 Reseatch Question しかし 10 年以上前、PageRank の黎明期から Personalization based の手法は問題がある。 一般的な PageRank の解法の説明、その後に Model Reduction をベースにした約 5 倍の性能を誇る提案手法を説明。 提案手法の性能によって、パフォーマンス上のボトムネックは消えた。 Proposed Method PageRank 初期:WEBPage のランクに使用 → 現在:推薦、ソーシャルネットワーク Random Suffer Model Transition : α の確率で Random Walk(滞在ノードから無作為に遷移) Teleporting : 1−α Random Junmp(滞在ノードに依存せずに全てのノードを対象に無作為遷移) x(t+1)=αPxt+(1−α)v,where P=AD−1 v is represents telepotation probabilitie xt Walker の確率分布 サーファーが来る確率 = RandomWalk の確率_RandomWalk による遷移確率 + RandomJump の確率_RandomJump の遷移確率 = α× RandomWalk による遷移確率 + (1−α)×RandomJump の遷移確率 = α×+(1−α)×v x: Stationary vector(不動ベクトル、定常ベクトル、不動点定理など) x が定常状態になった際に、x の確率分布が PageRank を表す。 x(t),x(t+1)が同一(残差が無い)だと仮定することで、次式の線形方程式を解くことで Pagerank を求める。 Mx=b,where M=(I−αP),b=(1−α)v."><meta itemprop=name content="Edge-Weighted Personalized PageRank: Breaking A Decade-Old Performance Barrier を読んだ"><meta itemprop=description content="応用数理研究者が機械学習界に進出していく研究
youtube clip
応用数理界隈ではクラシックな解き方で PageRank が解かれているので最新の数値計算手法に置き換えることで劇的にパフォーマンスが向上して 10 年前のパフォーマンスの鎖を解き放った論文
KDD2015 Best student paper award Slide(PDF) Poster(PDF) Spectral network analysis wenleix/EdgePPR
Presentation Movie is uploaded in Youtube. Author
W. Xie Ph.D Candidate at Cornell University http://wenleix.github.io/ iterative computation on big graph data D. Bindel http://www.cs.cornell.edu/~bindel/ http://www.cs.cornell.edu/~bindel/talks.html He is frequently research activ like ideal young researcher. Nonlinear eigenvalue problem. Alan J. Demers Prof. Johannes Gehrke http://www.cs.cornell.edu/johannes/ Prof. VLDB,SIGMOD,KDD Motivation ページランクは重要な指標。遷移確率を求めるにはランダムサーファーモデル(ランダムウォーク)が必要。 様々な高速解法が提案されている。 Reseatch Question しかし 10 年以上前、PageRank の黎明期から Personalization based の手法は問題がある。 一般的な PageRank の解法の説明、その後に Model Reduction をベースにした約 5 倍の性能を誇る提案手法を説明。 提案手法の性能によって、パフォーマンス上のボトムネックは消えた。 Proposed Method PageRank 初期:WEBPage のランクに使用 → 現在:推薦、ソーシャルネットワーク Random Suffer Model Transition : α の確率で Random Walk(滞在ノードから無作為に遷移) Teleporting : 1−α Random Junmp(滞在ノードに依存せずに全てのノードを対象に無作為遷移) x(t+1)=αPxt+(1−α)v,where P=AD−1 v is represents telepotation probabilitie xt Walker の確率分布 サーファーが来る確率 = RandomWalk の確率_RandomWalk による遷移確率 + RandomJump の確率_RandomJump の遷移確率 = α× RandomWalk による遷移確率 + (1−α)×RandomJump の遷移確率 = α×+(1−α)×v x: Stationary vector(不動ベクトル、定常ベクトル、不動点定理など) x が定常状態になった際に、x の確率分布が PageRank を表す。 x(t),x(t+1)が同一(残差が無い)だと仮定することで、次式の線形方程式を解くことで Pagerank を求める。 Mx=b,where M=(I−αP),b=(1−α)v."><meta itemprop=datePublished content="2017-12-04T13:06:15+00:00"><meta itemprop=dateModified content="2019-06-16T18:16:09+09:00"><meta itemprop=wordCount content="223"><meta itemprop=image content="https://shunyaueta.com/ogp.jpg"><meta itemprop=keywords content="machinelearning,paper,"><meta name=referrer content="no-referrer-when-downgrade"><style>body{font-family:Verdana,sans-serif;margin:auto;padding:20px;max-width:720px;text-align:left;background-color:#fff;word-wrap:break-word;overflow-wrap:break-word;line-height:1.5;color:#444}h1,h2,h3,h4,h5,h6,strong,b{color:#222}a{color:#3273dc}.title{text-decoration:none;border:0}.title span{font-weight:400}nav a{margin-right:10px}textarea{width:100%;font-size:16px}input{font-size:16px}content{line-height:1.6}table{width:100%}img{max-width:100%}code{padding:2px 5px;background-color:#f2f2f2}pre code{color:#222;display:block;padding:20px;white-space:pre-wrap;font-size:14px;overflow-x:auto}div.highlight pre{background-color:initial;color:initial}div.highlight code{background-color:unset;color:unset}blockquote{border-left:1px solid #999;color:#222;padding-left:20px;font-style:italic}footer{padding:25px;text-align:center}.helptext{color:#777;font-size:small}.errorlist{color:#eba613;font-size:small}ul.blog-posts{list-style-type:none;padding:unset}ul.blog-posts li{display:flex}ul.blog-posts li span{flex:0 0 130px}ul.blog-posts li a:visited{color:#8b6fcb}@media(prefers-color-scheme:dark){body{background-color:#333;color:#ddd}h1,h2,h3,h4,h5,h6,strong,b{color:#eee}a{color:#8cc2dd}code{background-color:#777}pre code{color:#ddd}blockquote{color:#ccc}textarea,input{background-color:#252525;color:#ddd}.helptext{color:#aaa}}</style><script async src="https://www.googletagmanager.com/gtag/js?id=G-JMJRQJT0Q3"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-JMJRQJT0Q3")</script></head><body><header><a href=/ class=title><h2>hurutoriya</h2></a><nav><a href=/index.xml>RSS</a>
<a href=/about/>著者について</a></nav></header><main><h1>Edge-Weighted Personalized PageRank: Breaking A Decade-Old Performance Barrier を読んだ</h1><p><i><time datetime=2017-12-04 pubdate>2017-12-04</time></i></p><content><p>応用数理研究者が機械学習界に進出していく研究</p><p><img src=/posts/2017-12-04/images/1.png alt=image></p><p>youtube clip</p><p>応用数理界隈ではクラシックな解き方で PageRank が解かれているので最新の数値計算手法に置き換えることで劇的にパフォーマンスが向上して 10 年前のパフォーマンスの鎖を解き放った論文</p><ul><li>KDD2015 Best student paper award</li><li><a href=http://www.cs.cornell.edu/~bindel/present/2015-08-kdd-talk_kdd-aug15.pdf>Slide(PDF)</a></li><li><a href=http://www.cs.cornell.edu/~bindel/present/2015-08-kdd-poster_poster-kdd-pr.pdf>Poster(PDF)</a>
<a href=http://www.cs.cornell.edu/~bindel//blurbs/graphspec.html>Spectral network analysis</a></li></ul><p><a href=https://github.com/wenleix/EdgePPR>wenleix/EdgePPR</a></p><ul><li>Presentation Movie is uploaded in Youtube.</li></ul><p>Author</p><ul><li>W. Xie</li><li>Ph.D Candidate at Cornell University</li><li><a href=http://wenleix.github.io/>http://wenleix.github.io/</a></li><li>iterative computation on big graph data</li><li>D. Bindel</li><li><a href=http://www.cs.cornell.edu/~bindel/>http://www.cs.cornell.edu/~bindel/</a></li><li><a href=http://www.cs.cornell.edu/~bindel/talks.html>http://www.cs.cornell.edu/~bindel/talks.html</a></li><li>He is frequently research activ like ideal young researcher.</li><li>Nonlinear eigenvalue problem.</li><li>Alan J. Demers</li><li>Prof.</li><li>Johannes Gehrke</li><li><a href=http://www.cs.cornell.edu/johannes/>http://www.cs.cornell.edu/johannes/</a></li><li>Prof.</li><li>VLDB,SIGMOD,KDD</li></ul><h3 id=motivation>Motivation</h3><ul><li>ページランクは重要な指標。遷移確率を求めるにはランダムサーファーモデル(ランダムウォーク)が必要。</li><li>様々な高速解法が提案されている。</li></ul><h3 id=reseatch-question>Reseatch Question</h3><ul><li>しかし 10 年以上前、PageRank の黎明期から Personalization based の手法は問題がある。</li><li>一般的な PageRank の解法の説明、その後に Model Reduction をベースにした約 5 倍の性能を誇る提案手法を説明。</li><li>提案手法の性能によって、パフォーマンス上のボトムネックは消えた。</li></ul><h3 id=proposed-method>Proposed Method</h3><ul><li>PageRank</li><li>初期:WEBPage のランクに使用 → 現在:推薦、ソーシャルネットワーク</li><li>Random Suffer Model</li><li>Transition : α の確率で Random Walk(滞在ノードから無作為に遷移)</li><li>Teleporting : 1−α Random Junmp(滞在ノードに依存せずに全てのノードを対象に無作為遷移)</li><li>x(t+1)=αPxt+(1−α)v,where P=AD−1</li><li>v is represents telepotation probabilitie</li><li>xt Walker の確率分布</li><li>サーファーが来る確率 = RandomWalk の確率_RandomWalk による遷移確率 + RandomJump の確率_RandomJump の遷移確率</li><li>= α× RandomWalk による遷移確率 + (1−α)×RandomJump の遷移確率</li><li>= α×+(1−α)×v</li><li>x: Stationary vector(不動ベクトル、定常ベクトル、不動点定理など)</li><li>x が定常状態になった際に、x の確率分布が PageRank を表す。</li><li>x(t),x(t+1)が同一(残差が無い)だと仮定することで、次式の線形方程式を解くことで Pagerank を求める。</li><li>Mx=b,where M=(I−αP),b=(1−α)v.</li></ul><h4 id=standard-pagerank>Standard PageRank</h4><ul><li>グラフの構造(幾何性)を利用</li><li>多くのグラフでは、ノードやエッジに重みが存在する</li></ul><h4 id=personalized-pagerank>Personalized PageRank</h4><ul><li>PageRank を特定のユーザやクエリに合わせたランク</li><li>Node wighted graph</li><li>Mx(w)=(1−α)v(w),w∈ℝ𝕕</li><li>w: 特定の個人、クエリに合わせたパラメータ</li><li>Edge weighted graph</li><li>M(w)x(w)=(I−α)v,w∈ℝ𝕕</li><li>Node Weight, Edge Weight 共に Personalized PageRank は重要だが、２つの問題がある。</li><li>Node Weight に関する論文:多い Edge Weight:少ない</li><li>計算コストが高い</li><li>Edge weighted Personalized PageRank における x(w)を求める高速手法を提案</li><li>提案手法は計算量が準線形的。</li><li>予備知識</li><li>xt+1:べき乗法</li><li>Mx=b:ヤコビ法</li><li>x(w)=(1−α)M−1Vw.</li><li>v≈Vwwhere V∈ℝ𝕟×𝕕</li><li>M−1V:O(n) 、x(w)の再構築に O(d)、PageRank を求めるには O(nd)が要求される。</li><li>v が疎なら計算量は準線形へ。</li></ul><h3 id=model-resuction-method>MODEL RESUCTION METHOD</h3><ol><li>k 次元の次元の削減された空間を構築</li><li>k 次元を近似するために k 個の等式が必要</li><li>次元削減の問題を解く(PageRank のベクトルは一部分が重要だという仮説)</li></ol><ul><li>Reduced Space Construction</li><li>{w(j)}rj=1(ベクトルの集合)に対応する PageRank {x(j)}rj=1(ベクトルの集合)を求める。</li><li>w は乱数によって決定する</li><li>k 次元の空間 υ を探索する</li></ul><h2>関連しているかもしれない記事</h2><ul><li><a href=/posts/2017-12-01/>Machine Learning that Matters (ICML2012) を読んだ</a></li><li><a href=/posts/2017-11-14/>OpenCV 3.3から使えるDNNモジュールを使って物体検出</a></li></ul><h2>Support</h2>記事をお読みくださりありがとうございます。
このウェブサイトの運営を支援していただける方を募集しています。
もしよろしければ、<a href=https://www.buymeacoffee.com/hurutoriya>Buy Me a Coffee</a> からサポート(投げ銭)していただけると、記事の執筆、情報発信のモチベーションに繋がります✨<p>--</p>記事を楽しめましたか？
<a href=/index.xml>RSS</a>で更新情報を配信しているので、お好きなフィードリーダーで購読してみてください。</br>また、記事へのリアクションやコメントなどを、以下のGitHub を利用したコメントシステムからしていただけると執筆の励みになります。</content><p><a href=https://shunyaueta.com/tags/machinelearning/>#machinelearning</a>
<a href=https://shunyaueta.com/tags/paper/>#paper</a></p><script src=https://giscus.app/client.js data-repo=hurutoriya/hurutoriya.github.io data-repo-id="MDEwOlJlcG9zaXRvcnk2MDgyNTY1Nw==" data-category=Comments data-category-id=DIC_kwDOA6AgOc4CAQTX data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=0 data-theme=dark data-lang=ja crossorigin=anonymous async></script></main><footer>Made with <a href=https://github.com/janraasch/hugo-bearblog/>Hugo ʕ•ᴥ•ʔ Bear</a></footer></body></html>