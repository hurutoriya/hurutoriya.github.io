<!doctype html><html lang=ja prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb#"><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><meta name=description content><meta name=HandheldFriendly content="True"><meta name=MobileOptimized content="320"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=keywords content="Computer Vision,
CVPR,
Paper,"><meta property="og:type" content="article"><meta property="og:description" content><meta property="og:title" content="Slicing Convolutional Neural Network for Crowd Video Understanding (CVPR2016)を読んだ"><meta property="og:site_name" content><meta property="og:image" content><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content><meta property="og:image:height" content><meta property="og:url" content="https://shunyaueta.com/posts/2018-01-17_slicing-convolutional-neural-network-for-crowd-video-understanding-cvpr2016%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/"><meta property="og:locale" content="ja"><meta property="article:published_time" content="2018-01-17"><meta property="article:modified_time" content="2018-01-17"><meta property="article:tag" content="Computer Vision"><meta property="article:tag" content="CVPR"><meta property="article:tag" content="Paper"><meta name=twitter:card content="summary"><meta name=twitter:site content="@hurutoriya"><meta name=twitter:creator content="@hurutoriya"><meta name=twitter:title content="Slicing Convolutional Neural Network for Crowd Video Understanding (CVPR2016)を読んだ |"><meta name=twitter:description content="群衆解析の手法に興味があるので、サーベイの結果を放流しておきます。
Jing Shao, Chen Change Loy, Kai Kang, and Xiaogang Wang, “Slicing Convolutional Neural Network for Crowd Video Understanding”, in CVPR, 2016.
Project Page
Summary
一言説明 時系列・空間的特徴から CNN で特徴を学習、群衆の動画に対してstate-of-the-artを達成
3 個の CNN を用いて下記の３つの特徴を表現学習
 xy- : 空間的特徴 xt- : x 軸の時系列特徴 yt- : y 軸の時系列特徴  Comments Dataset としてWWW Crowd Dataset
が公開されている。10,000 本の群衆の動画を収集公開しているとのこと。
Demo Movie
 紹介動画を見てみたら分かるが、群衆の動画というよりも数が増大した結果一般的な画像認識のデモ動画になっている Jing Shaoさんは CVPR2014 から群衆解析のための descriptor を提案したりしてたんだけど、2016 年から Deep な手法での群衆解析の研究をやっているのは手が早いなと 所属グループは ISLVRC2015 の物体認識タスクで優勝した香港大学のグループ Multimedia Laboratory The Chinese University of Hong Kong データセット、実装コードを必ず公開しているのは尊敬、またそれくらいやらないとトップには通過しないんだろうな CNN のアーキテクチャ毎の比較実験と考察をかなり入念に行っていた。数年後には各データのフォーマットに合わせたベストな DNN のアーキテクチャが決まってくるんじゃないだろうか  |"><meta name=twitter:image:src content><meta name=twitter:domain content="https://shunyaueta.com/posts/2018-01-17_slicing-convolutional-neural-network-for-crowd-video-understanding-cvpr2016%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/"><title>Slicing Convolutional Neural Network for Crowd Video Understanding (CVPR2016)を読んだ</title><link rel=canonical href=https://shunyaueta.com/posts/2018-01-17_slicing-convolutional-neural-network-for-crowd-video-understanding-cvpr2016%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/><link rel=stylesheet href=https://unpkg.com/tachyons@4.11.1/css/tachyons.min.css><link rel=stylesheet href=https://shunyaueta.com/css/style.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/highlightjs@9.12.0/styles/github-gist.css><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-39994406-11','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><link rel="shortcut icon" href=/favicon.ico type=image/x-icon><link rel=apple-touch-icon href=/apple-touch-icon.png></head><body lang=ja class="sans-serif w-90 w-60-ns center center-ns mv2 mv5-ns" itemscope itemtype=http://schema.org/Article><span class=b>/</span>
<a href=https://shunyaueta.com/ class="b bb bw1 pb1 no-underline black"></a><section id=main class=mt5><h1 itemprop=name id=title>Slicing Convolutional Neural Network for Crowd Video Understanding (CVPR2016)を読んだ</h1><article itemprop=articleBody id=content class="w-90 lh-copy"><p>群衆解析の手法に興味があるので、サーベイの結果を放流しておきます。</p><p>Jing Shao, Chen Change Loy, Kai Kang, and Xiaogang Wang, “Slicing Convolutional Neural Network for Crowd Video Understanding”, in CVPR, 2016.</p><p><a href=http://www.ee.cuhk.edu.hk/~jshao/SCNN.html>Project Page</a></p><p><img src=/posts/2018-01-17_slicing-convolutional-neural-network-for-crowd-video-understanding-cvpr2016%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/images/1.png alt=image></p><p>Summary</p><h3 id=一言説明>一言説明</h3><p>時系列・空間的特徴から CNN で特徴を学習、群衆の動画に対して<code>state-of-the-art</code>を達成</p><p>3 個の CNN を用いて下記の３つの特徴を表現学習</p><ul><li>xy- : 空間的特徴</li><li>xt- : x 軸の時系列特徴</li><li>yt- : y 軸の時系列特徴</li></ul><h3 id=comments>Comments</h3><p>Dataset として<a href=http://www.ee.cuhk.edu.hk/~jshao/WWWCrowdDataset.html>WWW Crowd Dataset</a><br>が公開されている。10,000 本の群衆の動画を収集公開しているとのこと。</p><p>Demo Movie</p><ul><li>紹介動画を見てみたら分かるが、群衆の動画というよりも数が増大した結果一般的な画像認識のデモ動画になっている</li><li><a href=http://www.ee.cuhk.edu.hk/~jshao/>Jing Shao</a>さんは CVPR2014 から群衆解析のための descriptor を提案したりしてたんだけど、2016 年から Deep な手法での群衆解析の研究をやっているのは手が早いなと</li><li>所属グループは ISLVRC2015 の物体認識タスクで優勝した香港大学のグループ</li><li><a href=http://mmlab.ie.cuhk.edu.hk/index.html>Multimedia Laboratory The Chinese University of Hong Kong</a></li><li>データセット、実装コードを必ず公開しているのは尊敬、またそれくらいやらないとトップには通過しないんだろうな</li><li>CNN のアーキテクチャ毎の比較実験と考察をかなり入念に行っていた。数年後には各データのフォーマットに合わせたベストな DNN のアーキテクチャが決まってくるんじゃないだろうか</li></ul></article></section><footer><div><p class="f6 gray mt6 lh-copy">© 2016-20 <a href=https://twitter.com/hurutoriya>@hurutoriya</a>.</p></div></footer><script src=//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.14.2/highlight.min.js></script><script>hljs.initHighlightingOnLoad();</script></body></html>