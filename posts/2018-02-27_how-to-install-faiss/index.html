<!doctype html><html lang=ja prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb#"><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><meta name=description content><meta name=HandheldFriendly content="True"><meta name=MobileOptimized content="320"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=keywords content="Python,"><meta property="og:type" content="article"><meta property="og:description" content><meta property="og:title" content="How to install faiss"><meta property="og:site_name" content><meta property="og:image" content><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content><meta property="og:image:height" content><meta property="og:url" content="https://shunyaueta.com/posts/2018-02-27_how-to-install-faiss/"><meta property="og:locale" content="ja"><meta property="article:published_time" content="2018-02-27"><meta property="article:modified_time" content="2018-02-27"><meta property="article:tag" content="Python"><meta name=twitter:card content="summary"><meta name=twitter:site content="@hurutoriya"><meta name=twitter:creator content="@hurutoriya"><meta name=twitter:title content="How to install faiss |"><meta name=twitter:description content="faiss : Billion-scale similarity search with GPUs
faiss : Billion-scale similarity search with GPUs
You mainly follow : https://github.com/facebookresearch/faiss/blob/master/INSTALL.md
Env : Mac OS X 10.12.6
Not Tag, Note commit hash:commit cd884114d0a8e1789f257b524e5345bc5b26e6b2 ``_2018.02.24 : New version of Faiss!
What's new?
 Support for on-disk inverted lists (see https://github.com/…/f…/blob/master/demos/demo_ondisk_ivf.py). Enables handling of datasets that do not fit in RAM. We tested it on up to 53B vectors, with a 2TB index. Tutorial and examples for using Faiss on one or more GPUs (see https://github.|"><meta name=twitter:image:src content><meta name=twitter:domain content="https://shunyaueta.com/posts/2018-02-27_how-to-install-faiss/"><title>How to install faiss</title><link rel=canonical href=https://shunyaueta.com/posts/2018-02-27_how-to-install-faiss/><link rel=stylesheet href=https://unpkg.com/tachyons@4.11.1/css/tachyons.min.css><link rel=stylesheet href=https://shunyaueta.com/css/style.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/highlightjs@9.12.0/styles/github-gist.css><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-39994406-11','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><link rel="shortcut icon" href=/favicon.ico type=image/x-icon><link rel=apple-touch-icon href=/apple-touch-icon.png></head><body lang=ja class="sans-serif w-90 w-60-ns center center-ns mv2 mv5-ns" itemscope itemtype=http://schema.org/Article><span class=b>/</span>
<a href=https://shunyaueta.com/ class="b bb bw1 pb1 no-underline black"></a><section id=main class=mt5><h1 itemprop=name id=title>How to install faiss</h1><article itemprop=articleBody id=content class="w-90 lh-copy"><p>faiss : Billion-scale similarity search with GPUs</p><p><img src=/posts/2018-02-27_how-to-install-faiss/images/1.png alt=image></p><p>faiss : Billion-scale similarity search with GPUs</p><p>You mainly follow : <a href=https://github.com/facebookresearch/faiss/blob/master/INSTALL.md>https://github.com/facebookresearch/faiss/blob/master/INSTALL.md</a></p><p>Env : <code>Mac OS X 10.12.6</code><br>Not Tag, Note commit hash:<code>commit cd884114d0a8e1789f257b524e5345bc5b26e6b2</code>
``_2018.02.24 : New version of Faiss!<br>What's new?</p><ul><li>Support for on-disk inverted lists (see <a href=https://github.com/>https://github.com/</a>…/f…/blob/master/demos/demo_ondisk_ivf.py). Enables handling of datasets that do not fit in RAM. We tested it on up to 53B vectors, with a 2TB index.</li><li>Tutorial and examples for using Faiss on one or more GPUs (see <a href=https://github.com/facebookresea>https://github.com/facebookresea</a>…/faiss/wiki/Running-on-GPUs).</li><li>Macports package (math/libfaiss) - more packages soon.</li><li>Minor bug fixes._``</li></ul><p>Let’s start.
<code>$ git clone https://github.com/facebookresearch/faiss.git $ cd faiss $ mv example_makefiles/makefile.inc.Mac.brew ./makefile.inc</code></p><h3 id=compile-c-faiss>Compile C++ faiss</h3><ul><li>Firstly you install BLAS and LAPACK. : <a href=https://pheiter.wordpress.com/2012/09/04/howto-installing-lapack-and-blas-on-mac-os/>Install BLAS,LAPACK</a><code>$ `brew install llvm `$ brew install gcc $ make tests/test_blas /usr/local/opt/llvm/bin/clang++ -fPIC -m64 -Wall -g -O3 -msse4 -mpopcnt -fopenmp -Wno-sign-compare -I/usr/local/opt/llvm/include -std=c++11 tests/test_blas.cpp -o tests/test_blas -g -fPIC -fopenmp -L/usr/local/opt/llvm/lib -L/usr/local/Cellar/llvm/5.0.1/lib -framework Accelerate -DFINTEGER=int````$ ./tests/test_blas BLAS test errors= 0.000 -0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 -0.000 -0.000 -0.000 0.000 0.000 0.000 0.000 -0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 -0.000 0.000 -0.000 0.000 0.000 -0.000 0.000 0.000 0.000 -0.000 0.000 0.000 0.000 0.000 -0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 -0.000 0.000 0.000 0.000 0.000 0.000 0.000 -0.000 -0.000 -0.000 0.000 0.000 0.000 -0.000 -0.000 -0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 -0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 -0.000 0.000 0.000 0.000 -0.000 -0.000 0.000 0.000 0.000 0.000 0.000 -0.000 0.000 0.000 -0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 -0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 -0.000 0.000 0.000 0.000 0.000 -0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 -0.000 -0.000 0.000 0.000 0.000 0.000 0.000 -0.000 0.000 -0.000 0.000 0.000 0.000 0.000 0.000 -0.000 0.000 0.000 -0.000 -0.000 0.000 -0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 -0.000 0.000 -0.000 0.000 0.000 0.000 0.000 0.000 0.000 -0.000 0.000 0.000 0.000 -0.000 0.000 0.000 -0.000 -0.000 0.000 -0.000 0.000 -0.000 0.000 0.000 -0.000 Intentional Lapack error (appears only for 64-bit INTEGER): info=0000064b00000000 Lapack uses 32-bit integers</code></li></ul><p>This is not error. : <a href=https://github.com/facebookresearch/faiss/issues/101>link</a>
``$ make<br>/usr/local/opt/llvm/bin/clang++ -fPIC -m64 -Wall -g -O3 -msse4 -mpopcnt -fopenmp -Wno-sign-compare -I/usr/local/opt/llvm/include -std=c++11 -c hamming.cpp -o hamming.o<code>...</code>IndexScalarQuantizer.cpp -o IndexScalarQuantizer.o<br>IndexScalarQuantizer.cpp:14:10: fatal error: 'malloc.h' file not found</p><h1 id=include-ltmallochgt>include &lt;malloc.h></h1><pre><code>     ^~~~~~~~~~
</code></pre><p>1 error generated.<br>make: *** [IndexScalarQuantizer.o] Error 1``</p><p><code>IndexScalarQuantizer.cpp</code>
<code># include &amp;lt;malloc.h&amp;gt;</code></p><p>↓
<code># include &amp;lt;sys/malloc.h&amp;gt;</code></p><p>Ref (<a href=https://tbr8.org/install-faiss-on-mac-os/>https://tbr8.org/install-faiss-on-mac-os/</a>)
<code>$ make /usr/local/opt/llvm/bin/clang++ -fPIC -m64 -Wall -g -O3 -msse4 -mpopcnt -fopenmp -Wno-sign-compare -I/usr/local/opt/llvm/include -std=c++11 -c IndexScalarQuantizer.cpp -o IndexScalarQuantizer.o````...````ar: creating archive libfaiss.a /usr/local/opt/llvm/bin/clang++ -o demos/demo_ivfpq_indexing -fPIC -m64 -Wall -g -O3 -msse4 -mpopcnt -fopenmp -Wno-sign-compare -I/usr/local/opt/llvm/include -std=c++11 demos/demo_ivfpq_indexing.cpp libfaiss.a -g -fPIC -fopenmp -L/usr/local/opt/llvm/lib -L/usr/local/Cellar/llvm/5.0.1/lib -framework Accelerate````$ demos/demo_ivfpq_indexing [0.000 s] Generating 100000 vectors in 128D for training [0.165 s] Training the index Training level-1 quantizer Training level-1 quantizer on 100000 vectors in 128D Training IVF residual Input training set too big (max size is 65536), sampling 65536 / 100000 vectors computing residuals training 4x256 product quantizer on 65536 vectors in 128D Training PQ slice 0/4 Clustering 65536 points in 32D to 256 clusters, redo 1 times, 25 iterations Preprocessing in 0.01 s Iteration 24 (0.87 s, search 0.84 s): objective=113241 imbalance=1.004 nsplit=0 Training PQ slice 1/4 Clustering 65536 points in 32D to 256 clusters, redo 1 times, 25 iterations Preprocessing in 0.01 s Iteration 24 (0.84 s, search 0.81 s): objective=113353 imbalance=1.004 nsplit=0 Training PQ slice 2/4 Clustering 65536 points in 32D to 256 clusters, redo 1 times, 25 iterations Preprocessing in 0.01 s Iteration 24 (0.82 s, search 0.79 s): objective=113274 imbalance=1.004 nsplit=0 Training PQ slice 3/4 Clustering 65536 points in 32D to 256 clusters, redo 1 times, 25 iterations Preprocessing in 0.01 s Iteration 24 (0.88 s, search 0.86 s): objective=113141 imbalance=1.004 nsplit=0 precomputing IVFPQ tables type 1 [8.453 s] storing the pre-trained index to /tmp/index_trained.faissindex [8.456 s] Building a dataset of 200000 vectors to index [8.818 s] Adding the vectors to the index IndexIVFPQ::add_core_o: adding 0:32768 / 200000 add_core times: 157.094 111.340 4.048 IndexIVFPQ::add_core_o: adding 32768:65536 / 200000 add_core times: 161.185 104.820 2.199 IndexIVFPQ::add_core_o: adding 65536:98304 / 200000 add_core times: 156.851 105.808 2.865 IndexIVFPQ::add_core_o: adding 98304:131072 / 200000 add_core times: 163.588 113.381 2.311 IndexIVFPQ::add_core_o: adding 131072:163840 / 200000 add_core times: 195.370 110.669 2.505 IndexIVFPQ::add_core_o: adding 163840:196608 / 200000 add_core times: 155.380 106.777 2.499 IndexIVFPQ::add_core_o: adding 196608:200000 / 200000 add_core times: 18.895 11.918 0.296 [10.518 s] imbalance factor: 1.23721 [10.532 s] Searching the 5 nearest neighbors of 9 vectors in the index [10.533 s] Query results (vector ids, then distances): query 0: 1234 196783 151072 184097 59404 dis: 7.59448 8.73569 9.32671 9.40073 9.8221 query 1: 1235 143169 153018 103432 14870 dis: 6.70634 8.11071 8.82516 9.40931 9.43434 query 2: 1236 75075 188719 85363 10999 dis: 6.89075 9.39095 9.82474 9.92888 10.0297 query 3: 1237 16172 134049 105294 169581 dis: 8.32598 11.3405 11.4758 11.6785 11.7097 query 4: 1238 88419 108591 54396 52208 dis: 8.34287 10.4571 10.4597 11.1477 11.6777 query 5: 1239 43646 195506 35780 113330 dis: 7.46891 9.0416 9.65232 9.82861 9.84448 query 6: 1240 160333 170467 71739 61290 dis: 6.86489 9.4142 9.74915 9.81607 9.85242 query 7: 1241 115632 122785 168251 173845 dis: 6.05343 8.749 8.90397 9.01914 9.07404 query 8: 1242 78102 179175 37071 89957 dis: 7.46019 9.95651 10.0036 10.0071 10.1378 note that the nearest neighbor is not at distance 0 due to quantization errors</code></p><h3 id=python-interface>Python Interface</h3><p><code>$ make py /usr/local/opt/llvm/bin/clang++ -I. -fPIC -m64 -Wall -g -O3 -msse4 -mpopcnt -fopenmp -Wno-sign-compare -I/usr/local/opt/llvm/include -std=c++11 -g -fPIC -fopenmp -L/usr/local/opt/llvm/lib -L/usr/local/Cellar/llvm/5.0.1/lib -I/System/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 -I/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy/core/include -Wl,-F. -bundle -undefined dynamic_lookup \ -o python/_swigfaiss.so python/swigfaiss_wrap.cxx libfaiss.a -framework Accelerate In file included from python/swigfaiss_wrap.cxx:3241: ./IndexHNSW.h:215:1: warning: &amp;#39;IndexHNSW&amp;#39; defined as a struct here but previously declared as a class [-Wmismatched-tags] struct IndexHNSW: Index { ^ ./IndexHNSW.h:169:1: note: did you mean struct here? class IndexHNSW; ^~~~~ struct 1 warning generated. cp python/_swigfaiss.so python/swigfaiss.py .````$ python -c &amp;#34;import faiss&amp;#34; Failed to load GPU Faiss: No module named swigfaiss_gpu Faiss falling back to CPU-only.</code></p><p>Done!### LAPACK, BLAS ver.</p><ul><li><a href=http://www.netlib.org/lapack/>http://www.netlib.org/lapack/</a></li><li>Download: lapack-3.8.0.tar.gz</li><li><a href=http://www.netlib.org/blas/>http://www.netlib.org/blas/</a></li><li>Download blas-3.8.0.tgz</li></ul><h3 id=next>Next.</h3><p>Switch to wrapper of <em>Python3…</em></p></article></section><footer><div><p class="f6 gray mt6 lh-copy">© 2016-20 <a href=https://twitter.com/hurutoriya>@hurutoriya</a>.</p></div></footer><script src=//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.14.2/highlight.min.js></script><script>hljs.initHighlightingOnLoad();</script></body></html>