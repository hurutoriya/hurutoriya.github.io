<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Software Engineer as Data Scientist</title><link>https://shunyaueta.com/posts/</link><description>Recent content in Posts on Software Engineer as Data Scientist</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Wed, 09 Sep 2020 23:49:37 +0900</lastBuildDate><atom:link href="https://shunyaueta.com/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>pandas を使って特定のディレクトリのCSVファイルをすべて連結して一つのCSVファイルを作成</title><link>https://shunyaueta.com/posts/2020-09-09/</link><pubDate>Wed, 09 Sep 2020 23:49:37 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-09-09/</guid><description>目的 複数の同じフォーマットのCSVファイルが特定のディレクトリに配置されており、そのCSVファイル群を一つのCSVファイルに連結したい
今回は、PythonのPandas とpathlibを使って上記の目的を実現します。
実行環境 In [1]: import pandas as pd In [2]: pd.__version__ Out[2]: &amp;#39;1.1.2 In [3]: import sys ...: print(sys.version) 3.8.2 (default, Jul 19 2020, 07:23:27) [Clang 11.0.3 (clang-1103.0.32.62)] 目的となるcsvファイルは tmp ディレクトリに以下のような形式で配置されているとする
tmp ├── 1.csv ├── 2.csv └── 3.csv 各ファイルはこのような形式で保存されています。
id name created 1 John 2020/09/10 2 bob 2020/09/10 3 taro 2020/09/11 以下のPythonスクリプトを実行
import pathlib import pandas as pd def contcat_csv(f_path:str): # pathlibのitedir()で対象とするディレクトリのCSVファイル一覧をジェネレーターとして取得 csvs = [pd.read_csv(str(path)) for path in pathlib.</description></item><item><title>MLOps の国際会議 OpML'20 に論文が採択されたので登壇してきた</title><link>https://shunyaueta.com/posts/2020-09-06/</link><pubDate>Sun, 06 Sep 2020 23:31:03 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-09-06/</guid><description>MLOpsの査読付き国際会議 2020 USENIX Conference on Operational Machine Learning (略称 OpML&amp;rsquo;20)に論文が採択されたので、登壇してきた。
MLOpsの査読付き国際会議とOpMLの立ち位置 機械学習エンジニアリング・MLOpsの領域の会議でも一番有名なものとして2018年に発足したMLSysがあります。(ちなみに最初はSysMLという名前でした) このカンファレンスの傾向としては、アカデミアの研究者主体の発足経緯からアカデミアからインダストリーへの橋渡し的立ち位置となっています。具体的には、発表者はアカデミアの方が大半でハードウェアから、モデルのOSS公開など幅広く機械学習エンジニアリング・MLOpsの周辺トピックをカバーしています。
OpMLはその一年後に、MLOpsを軸にしたUSENIXが母体の会議として誕生しました。 USENIXはSRECON、OSDIなどを開催している団体です。学会的なスタイルに則り、先端的な計算機システムの成果を論文として公開されています。MLSysと対称的にこちらはインダストリーからアカデミアへの橋渡し的立ち位置となっています。発表内容は企業での発表者が多く、実際の運用で得られた各企業のMLOpsのベストプラクティスなどがメインで話されています。 個人的にはOpMLのほうが、MLOpsのど真ん中を主体に置いているのでMLSysよりも盛り上がってほしいなと思っています。
OpML&amp;rsquo;19がどのような様子だったかは、以下の記事がわかりやすいです。
OpML ‘19参加レポート The first conference of Operational Machine Learning: OpML ‘19 自分自身、機械学習エンジニアリングやMLOps周りのカンファレンス情報などを追いかけていますが、この分野で査読付きかつ論文として残せる形式の国際会議は主に上記の２つの認識です。
KDDやCOLING、NAACLなどの国際会議でもインダストリートラックが常設されるようになって久しいですが、最近ではインダストリートラックだけではなく、積極的に実応用前提のワークショップ(ECNLP at ACL2020, IRS2020 at KDD2020など)が開催されており機械学習の理論と実応用の融合が進んでいます。
OpML&amp;rsquo;20への投稿と採択で得られたもの OpML&amp;rsquo;20では下記２つの発表枠があり、投稿者がどちらかを選んで発表を行います。
査読付きで20mの口頭発表 2ページの査読付き論文+20mの口頭発表 OpML20で推奨されるトピックでも、自分たちが持っているネタで
New model introduction into production (e.g., staging, A/B test)
においてNoveltyがあると考えて、ここからストーリーを組み立てていきました。
スケジュール感として投稿締切が2020/02/25で、その1ヶ月前の1月末から毎日1時間、Google Calendarで時間を抑えて同僚と集中的に論文の執筆を行いました。 最初にガッと3ページほど書いて、その後洗練させて2ページに圧縮して投稿しました。 あらめて添削や執筆をともに行ってくれた同僚たちに感謝します。
そして投稿の1ヶ月後に通知メールが来て採択を知りました。 添削を何度も繰り返して時間が迫るなかなんとか投稿できたという状態で、とりあえず投稿できて良かったなと感じていた最中だったので、採択通知が来て本当におどきました。
査読システムの良い点として、自分たちの投稿内容がその会議で発表足り得るものかがレビュアーからレビューされることです。 自分自身機械学習エンジニアとして働いていますが、その成果が査読を通して同じ分野で働いているエキスパートの第三者に認められたという事実が自分の仕事への自信に繋がりました。
その後Reviwerの方に指摘された点を意識しつつ修正を行って、Camera Readyを無事に提出しました。 また今回は急遽オンライン開催へと変更されたので、動画投稿も必須になり初めての収録もなかなか難産でしたが無事提出することができました。
OpML&amp;rsquo;20で採択された論文 採択された内容は以下のページにまとまっているので、もしご興味があればご覧ください。 内容を簡単にまとめると、</description></item><item><title>Python の内包表記とジェネレータ式のメモリ使用量比較</title><link>https://shunyaueta.com/posts/2020-08-23/</link><pubDate>Sun, 23 Aug 2020 21:28:10 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-08-23/</guid><description>リストを構築する際にPythonではリスト内包表記とジェネレータ式の２種類が存在する。 今回、リスト構築時にメモリ使用量にどれだけ差異が発生するのか調査をしてみた。 メモリ使用量の調査には、memory_profilerというパッケージを使用した。
まず、２つのリストのデカルト積のタプルを表示するプログラムでの比較
from memory_profiler import profile @profile def main(): &amp;#34;&amp;#34;&amp;#34; Comparision List comprehension VS generator memory usage &amp;#34;&amp;#34;&amp;#34; colors = &amp;#34;colors&amp;#34; * 1000 sizes = &amp;#34;S&amp;#34; * 100 for shirts in ((color, size) for color in colors for size in sizes): print(shirts) [print((color, size)) for color in colors for size in sizes] if __name__ == &amp;#34;__main__&amp;#34;: main() Filename: src/listcomp_vs_generator.py Line # Mem usage Increment Line Contents ================================================ 4 10.</description></item><item><title>AOJの「ITP I」40問をpythonで解いた</title><link>https://shunyaueta.com/posts/2020-08-04/</link><pubDate>Tue, 04 Aug 2020 03:38:58 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-08-04/</guid><description>はじめに コーディングの腕をもっと磨きたいなと思ったので、以下の記事を参考に始めてみた
https://qiita.com/e869120/items/f1c6f98364d1443148b3 全部で 44 問ありますが、最後の 4 問は競プロとはあまり関係ないので、ITP1_1-A から ITP1_10-D までの 40 問を解くことをお勧めします。
まずは最初におすすめされた、AOJのITP1_1-A から ITP1_10-D までの 40 問を解いてみた 無料でこのサービスが提供されてるの素晴らしい 標準入力、出力の整形が少し手間取ったけど、あとは愚直に解いていった
http://judge.u-aizu.ac.jp/onlinejudge/ 感想としては、
やってみたら、意外と楽しい。特に自分で諦めずに試行錯誤して、オンラインで一発でACもらえるとめちゃくちゃ嬉しい テストケースに通る、すなわち正しい、それが書けたら達成感がある 何かしらのお題に沿って、コードを書くという動機ができるので、書くことに慣れたい場合も有用そう togglで時間計測しながら、やって見直してみたら15h46m 費やしていた。大体1問25mくらい
次の目標、
AtCoder で水色を目指す!!! データ構造周りや、アルゴリズム周りはまだまだ弱いのでそこらへんを抑えていきたい 当面は、以下の２つに投資していきます
機械学習だけに縛られない、SWEとしてスキル底上げ 機械学習関係の確固たる基礎知識と実装力 以下に自分が書いた回答例を放流しておきます。
Rule 15分試行錯誤しても、緒がわからない場合は諦める わからなかったとき、もっと上手な書き方は以下を参考にしました https://qiita.com/cmtennis1042/items/5f1e7f071081176e857f ITP1_1_A: Hello World print(&amp;#39;Hello world&amp;#39;) ITP1_1_B: X Cubic x = input() print(x ** 3) ITP1_1_C: Rectangle a, b = map(int, input().</description></item><item><title>How to write the UnitTest with stdin at Pytest</title><link>https://shunyaueta.com/posts/2020-07-25/</link><pubDate>Sat, 25 Jul 2020 03:18:14 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-07-25/</guid><description>If you want to write UnitTest when using stdin in Python. Pytest provide setattr function in monkeypatch
from io import StringIO import sys def divide(): input = sys.stdin.readline return list(input()) def gather(): input = sys.stdin.readline return sum(list(map(int, input().split()))) def test_divide(monkeypatch): monkeypatch.setattr(&amp;#39;sys.stdin&amp;#39;, StringIO(&amp;#39;abc&amp;#39;)) assert divide() == [&amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;c&amp;#39;] def test_gather(monkeypatch): monkeypatch.setattr(&amp;#39;sys.stdin&amp;#39;, StringIO(&amp;#39;1 2 3&amp;#39;)) assert gather() == 6 Reference Monkeypatching/mocking modules and environments I want to use stdin in a pytest test https://gist.</description></item><item><title>#MLCT 12 を開催しました</title><link>https://shunyaueta.com/posts/2020-06-13/</link><pubDate>Sat, 13 Jun 2020 23:06:44 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-06-13/</guid><description>Machine Learning Casual Talks 第12回を開催しました。 前回から少し開きがあり、7ヶ月ぶりの開催となりました。
https://mlct.connpass.com/event/172550/
今回の個人的なテーマはベストプラクティスとアンチパターンです。
@keigohtr さんには、AWSの各種サービスを使った機械学習実験基盤をアベジャの適用事例と重ね合わせて、説得力のあるベストプラクティスを語っていただきました。 @yuzutas0 さんには、機械学習の前に、データのマネジメントがいかに必要かを語っていただきました。建設的に改善していこうぜという未来が語られていて、個人的にお話を依頼した甲斐がありました 同僚の @overs_5121 さんには、メルカリ : TensorFlow Lite で、気付きにくい便利機能をユーザーに提唱 の裏話や、適用までの泥臭い事例をお話していただきました。 登壇者の皆様、改めて登壇の依頼をご快諾いただきありがとうございました。
また、コロナウイルスの影響もあり試験的ですが完全なオンライン開催となりました。 配信面は今回は完全に @chezou さんに頼らせていただきました。 プロフェッショナルな配信ありがとうございました！ 配信のベストプラクティスや様子などは、こちらを御覧ください
Google MeetとYouTube Liveでオンラインミートアップの配信をした
勉強会の資料と動画 資料ページ Machine Learning Casual Talks #12 - YouTube 所感としては、以前から配信NGの発表以外は積極的にYouTubeで公開していたのだが、参加者の皆様からはオンライン開催でありがたいと声が大きく、個人的に驚きました。
自分が思うに、オンライン参加も配信動画を後から見るのも、リアルタイムで質問ができないこと以外は大きな差異が無いと思っていたのだが、参加者側からすると大きく異なるようで新鮮だった。
オンライン勉強会開催側のコツ 最低でも
配信者 司会者 配信の監視を行う監視者 の3役がいないとオンライン開催は難しいことがわかった
ライブ配信視聴者数は、以下のような遷移となりました。 500人参加申込みがあり、最大視聴者数が252人とギリギリ5割を超えました。
今までのオフラインでの開催は6-8割くらいだったので、それと比較すると上出来かなと思います。 また、オンライン開催はオフライン開催と比べて会場の確保コストや懇親会おじさんの発生などを抑えられるので、その点もありがたかったです。 オフライン開催だと、会場撤収が効率的に終わっても22:00、家に帰ると23:00なので、イベント主催者にとっても開催しやすい気がしますね。
改善点としては、質問の数が少なめだったことと、オフラインでの交流を補うような要素(パネルディスカッションなど）をもう少し入れたいなと思っています。
オンライン開催は、開催コストが高くて継続できないというイベント主催者あるあるの問題を解決する一つのきっかけにもなるんじゃないのかなぁと思いました。
では、また次回のMLCT 開催をお待ち下さい!!</description></item><item><title>自走プログラマーを読み終えた</title><link>https://shunyaueta.com/posts/2020-05-10/</link><pubDate>Sun, 10 May 2020 17:13:34 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-05-10/</guid><description>自走プログラマーを読み終えた。
読み始めたきっかけとして、自分は機械学習エンジニアとして現在働いているが、できることの幅を広げるために最近はソフトウェアエンジニアとしてのスキルをもっと伸ばしたいと考えている。
自走プログラマーは、Pythonを使ったアプリケーション開発のアンチパターンとベストプラクティスを例示して学ぶことができる書籍で、今回の自分の状況にすごくフィットしていて楽しく学習することができた。
Python独特のはまりどころは、Kindle: The Hitchhiker’s Guide to Python, The Hitchhiker’s Guide to Python でも数多く参照されていて、こっちも後から読んでおきたいなと思いました。
次は、ちゃんとした Pythonista になれるように、Fluent Python を読みます。@ynqa さん、以前この本を教えて下さり、ありがとうございました。
長らく積ん読になっていますが、毎日読み進めていきます。
20歳頃の寝る間を惜しんで、ウェブアプリを開発していたときのワクワク感が徐々に蘇ってきた気がしています。
ある程度書けるようになってきたら、なにかアプリとか作って公開したいなと思っています！</description></item><item><title>ソフトウェア開発における Upstream と Downstream の意味</title><link>https://shunyaueta.com/posts/2020-04-27/</link><pubDate>Mon, 27 Apr 2020 23:55:42 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-04-27/</guid><description> Upstream Upstream はそのシステムが依存しているジョブ Upstream のデザインが変わることで、システムも影響をうける Downstream Downstream はそのシステムが影響を与える影響を与える部分 例えば、Web Application などでは、データベースは Downstream となる
e.g. Web service→ Databese という流れでデータが作成される
Ref https://reflectoring.io/upstream-downstream/ https://softwareengineering.stackexchange.com/questions/71080/what-does-downstream-upstream-design-mean/83686 https://en.wikipedia.org/wiki/Upstream_(software_development) https://en.wikipedia.org/wiki/Downstream_(software_development)</description></item><item><title>Pythonの関数のデフォルト引数はmutable(上書きされる)</title><link>https://shunyaueta.com/posts/2020-04-26/</link><pubDate>Sun, 26 Apr 2020 12:04:13 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-04-26/</guid><description>例えば以下のように、デフォルト引数で初期化を行い、文字列を追加する関数があるとする。
def append_to(values=[]): values.append(&amp;#34;Hoge&amp;#34;) return values 期待する振る舞いとしては。
In [14]: def append_to(values=[]): ...: values.append(&amp;#34;Hoge&amp;#34;) ...: return values ...: In [17]: append_to() Out[17]: [&amp;#39;Hoge&amp;#39;] In [18]: append_to() Out[18]: [&amp;#39;Hoge&amp;#39;] と関数呼び出しごとに、values は空のリストに初期化されるので上記のように返ってきてほしい
だが、実際に表示されるのは
In [14]: def append_to(values=[]): ...: values.append(&amp;#34;Hoge&amp;#34;) ...: return values ...: In [17]: append_to() Out[17]: [&amp;#39;Hoge&amp;#39;] In [18]: append_to() Out[18]: [&amp;#39;Hoge&amp;#39;, &amp;#39;Hoge&amp;#39;] である。
実際に内部で何が起きているかというと
In [23]: def append_to(values=[]): ...: values.append(&amp;#34;Hoge&amp;#34;) ...: return values ...: In [24]: pinfo append_to Signature: append_to(values=[]) Docstring: &amp;lt;no docstring&amp;gt; File: ~/&amp;lt;ipython-input-23-4530a91351ab&amp;gt; Type: function In [25]: append_to() Out[25]: [&amp;#39;Hoge&amp;#39;] In [26]: pinfo append_to Signature: append_to(values=[&amp;#39;Hoge&amp;#39;]) Docstring: &amp;lt;no docstring&amp;gt; File: ~/&amp;lt;ipython-input-23-4530a91351ab&amp;gt; Type: function In [27]: append_to() Out[27]: [&amp;#39;Hoge&amp;#39;, &amp;#39;Hoge&amp;#39;] In [28]: pinfo append_to Signature: append_to(values=[&amp;#39;Hoge&amp;#39;, &amp;#39;Hoge&amp;#39;]) Docstring: &amp;lt;no docstring&amp;gt; File: ~/&amp;lt;ipython-input-23-4530a91351ab&amp;gt; Type: function が起きている。 pinfo は ipython上で、オブジェクトの情報が確認できる便利コマンドです。 関数呼び出しごとに、デフォルト引数のvalues が上書きされていっていることがわかります。 これは、Pythonのデフォルト引数が、関数が定義されたときのみ評価され、毎回毎回評価されるわけではない。(Ruby は評価される) ここでわかるのは、mutable</description></item><item><title>The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction</title><link>https://shunyaueta.com/posts/2020-04-25/</link><pubDate>Sat, 25 Apr 2020 01:35:20 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-04-25/</guid><description>[抄訳] What’s your ML test score? A rubric for ML production systemsで紹介した論文の続編があったので読んでみました。
注意)この翻訳記事は原著論文の著者陣からレビューはされていません Shunya Ueta, are providing a translation and abridgment, which has not been reviewed by the authors. Change log 2020/06/24 著者のEric Breck さんに連絡をし、抄訳の公開を快諾していただきました。ありがとうございます。 完全な citation 情報を追記しました。 この翻訳記事が著者のレビューを受けていないことを追記しました。 Citation Eric Breck, Shanqing Cai, Michael Salib, . The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction. In 2017 IEEE International Conference on Big Data (Big Data) (pp.</description></item><item><title>What’s your ML test score? A rubric for ML production systems</title><link>https://shunyaueta.com/posts/2020-04-19/</link><pubDate>Sun, 19 Apr 2020 22:18:10 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-04-19/</guid><description>NIPS206にて開催された Reliable Machine Learning in the Wild - NIPS 2016 Workshop (2016) という、現実世界でどうやって信頼性の高い機械学習に取り組んでいくかについてのワークショップがある
ここで Google から発表された What’s your ML test score? A rubric for ML production systems がとても面白く、身になるものが多かったのでメモがてら抄訳を残しておく
PDF Slide 発表動画もワークショップページにて公開されています。 概略 現実世界のプロダクションシステムで機械学習を使う際に、機械学習の研究実験と異なる、小さなもしくは小さくない問題がある テストとモニタリングはプロダクションレディの機械学習システムにとって必要不可欠 しかし、どれくらいのテストとモニタリングをすれば十分と言えるのだろうか? この論文では、それらの問題を解決する ML Test Score という基準を提案する Introduciton Google 内で積み重ねたベストプラクティスをもとに、実行可能なテスト、そしてその機械学習システムがどのていどプロダクションレディなのかを示すスコアシステムを提案
このスコアは、機械学習を始めたばかるのチームからエキスパートがあつまるチームまで幅広く適用可能
注意: 一般的なSofware Engineering のベストプラクティスは含んでいない
そのかわり、学習とサービングのためのUnit Test Coverage の計算方法など機械学習に必要不可欠な点を抑えている
ML Test Score の計算方法 各テストの加点基準 1pt: 手動で実行し、その結果を文章として共有済 2pt: CIに組み込まれ、自動的に反復実行済 最終的なML Score は以下の基準となる 0pt : プロダクション向けというよりも研究プロジェクト 1-2pt : テストが少しはされているが、プロダクションではもっと深刻な罠がある可能性あり 3-4pt : 最初のプロダクションレディへの第一歩。しかし、さらなる投資が必要 5-6pt : 適切なテストがされているが、もっと自動化してみよう 7-10pt : 自動化されたテストとモニタリングが整備されている。重要なシステムでも適切なレベルに達している 12+pt : 卓越した自動化されたテストとモニタリング 前提条件 システムアーキテクチャの前提として、生データから特徴量を抽出し、学習システムに流し込まれる。そして推論のためにサービングされ、その機能は顧客に影響を与える。また、ソースリポジトリやCIを通したテスト、実験のバージョン管理なども可能 特徴量とデータセット 各特徴量の分布が期待した値になっているか?</description></item><item><title>CourseraでHow Google does Machine Learning の講義を修了した</title><link>https://shunyaueta.com/posts/2020-04-18/</link><pubDate>Sat, 18 Apr 2020 00:59:23 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-04-18/</guid><description>Coursera でHow Google does Machine Learning の講義を修了した
Certificate はこちら
7割が、機械学習プロジェクトの始め方、実際のハマりどころなどがGoogle 内の実例などに基づいて語られていて面白かった。 特に、
Secret Sourse ML Sutprise の部分が、アンチパターンや成功方法などが語られていて実際に実務で機械学習をやっている自分としてはわかる~~~~と共感がすごくできて面白かった。初めて機械学習プロジェクトを担当するPMの方にも良い教材なのではと思いました。
残りの3割は、qwiklab を使って、Notebookを立ち上げたり、Google BQ叩いたり、Pandas, Google Cloud Vison APIなど各ML系のAPIを触るといった感じで、初心者過ぎて自分にはレベル感が少しあいませんでしたが、これも非エンジニアの方が機械学習ってこんな感じかと学ぶきっかけにはすごく良さそうです。
最初の7割の部分は、改めてデータ利活用を前提にしたプロジェクトを牽引していく際にここで見つめ直す形になってよかったです。
最近、Cousera での講義を始める機会がありAndrew Ng先生の機械学習コースぶりにCourseraをやっているが、勉強のペースメーカーが決められるのと講義内容の質も高いので自分にとってはすごく相性が良い。
技術書を読むときも同じペースで、実行できないかなと画策したい</description></item><item><title>Getting Started with Google Kubernetes Engine の講義を修了した</title><link>https://shunyaueta.com/posts/2020-04-12/</link><pubDate>Sun, 12 Apr 2020 00:59:23 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-04-12/</guid><description>表題のとおりですが、Getting Started with Google Kubernetes Engine という Coursera の講義を終了しました
業務で k8s を本格的に使い始め、ちゃんと理解したいな~と思いこのコースを取りました。
半年前に Kubernetes完全ガイド impress top gearシリーズ をサラッと読んではいたのですが、やはり手を動かして学んでいないと実際に kubectl command など完全に忘れているし、スキルとして身についていない感半端なかったので、良い機会なのでHands-on が提供うされているCourseraを使って学んでみました。
個人的にこの講義がめちゃくちゃオススメなのが、 GKE の講義なので Google が提供する qwiklab が使えます。 一時的に GCP プロジェクトが作成され、そこでハンズオンができるのですがこれが実際に手を動かしながら学ぶという形式にすごく良いのと k8s の構築もすべてクラウドでできえるので変に環境構築でハマることなく快適に学習に集中できました。
もう、これがめちゃくちゃ快適でハンズオンとしてすごく快適に手を動かせなら、k8s の初歩的な概念や Command line などを学べました。
実際に手を動かしながら学ぶべきものだと思うので、このハンズオン形式の講義はありがたかったです!
後は学ぶにつれて、 k8s の凄さがわかってきたので理解して使いこなせるようになればスケールするシステムを個人でも作れそうなので、頑張っていきます。</description></item><item><title>pandas.read_gbq を使わずに、Google BigQueryから高速にData ETL</title><link>https://shunyaueta.com/posts/2019-10-03/</link><pubDate>Thu, 03 Oct 2019 23:52:54 +0900</pubDate><guid>https://shunyaueta.com/posts/2019-10-03/</guid><description>pandas.read_gbq 便利ですよね。 クレデンシャルファイルを認証画面からコピペすれば Jupyter 上でさっと動き、Google Big Query が実行されてその結果がそのままデータフレームとして扱えます。 Jupyter と Google BQ を連携させたいときはいつも使っています
問題点 そこそこ大きなデータを持ってこようとすると、めちゃくちゃ遅くてストレスが半端ない 解決方法として、Google Big Query で巨大なデータをダウンロードする方法について書く
実は Google の公式ドキュメントでも推奨されています
https://cloud.google.com/bigquery/docs/pandas-gbq-migration https://cloud.google.com/bigquery/docs/bigquery-storage-python-pandas 方法は以下の２つ。
google-cloud-bigquery をインストールして、マジックコマンドで Google BQ を実行 BQ 実行 →BigQuery table として保存 →GCS へ保存 → gsutil でマシンへコピー 1 番目は、Jupyter 上でマジックコマンドで Google BQ が実行できて、速度も pandas.rad_gbq よりも高速です 2 番目はそもそも実行結果が巨大な場合で、目安としては1GB以上なら 2 番目の方法を使えば楽です。
1, google-cloud-bigquery をインストールして、マジックコマンドで Google BQ を実行 pip install --upgrade google-cloud-bigquery[bqstorage,pandas] magic command を実行</description></item><item><title>Tensorboard を わずか2行で Jupyter Notebook上で表示</title><link>https://shunyaueta.com/posts/2019-09-25/</link><pubDate>Wed, 25 Sep 2019 23:16:07 +0900</pubDate><guid>https://shunyaueta.com/posts/2019-09-25/</guid><description>Pytorch 1.2 からは公式に Tensorboard がサポートされている
Tensorboard とは、学習の状況を可視化できる TensorFlow Family の一種
Jupyte Notebook 上で学習状況を確認したい場合に Tensorboard をそのまま表示して確認できれば楽なので、試してみる
sample code: https://pytorch.org/docs/stable/tensorboard.html
import torch import torchvision from torch.utils.tensorboard import SummaryWriter from torchvision import datasets, transforms # Writer will output to ./runs/ directory by default writer = SummaryWriter() transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]) trainset = datasets.MNIST(&amp;#39;mnist_train&amp;#39;, train=True, download=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) model = torchvision.models.resnet50(False) # Have ResNet model take in grayscale rather than RGB model.</description></item><item><title>How to connect the Google Compute Engine via Visual Studio Code</title><link>https://shunyaueta.com/posts/2019-09-24/</link><pubDate>Tue, 24 Sep 2019 17:35:05 +0900</pubDate><guid>https://shunyaueta.com/posts/2019-09-24/</guid><description>1. Generate SSH config file using gcloud command line gcloud compute config-ssh https://cloud.google.com/sdk/gcloud/reference/compute/config-ssh
You cant get ssh config for your Google Compute Engine project!
Notice: you need choose target GCP project before run below command.
gcloud config set project &amp;lt;your-project-id&amp;gt; 2. Install Remote SSH extention in Visual Studio Code. https://code.visualstudio.com/blogs/2019/07/25/remote-ssh 3. Press ⇧⌘P &amp;amp; Select target connection in Visual Studio Code! Finaly you can connect in Visual Studio Code.</description></item><item><title>ビジネスでインパクトが出せるデータサイエンティストになるには</title><link>https://shunyaueta.com/posts/2019-09-23/</link><pubDate>Mon, 23 Sep 2019 18:48:47 +0900</pubDate><guid>https://shunyaueta.com/posts/2019-09-23/</guid><description>@pseudo_finite さんから
「ビジネスでインパクトが出せるデータサイエンティストになるためには」
をご恵贈していただいたので、感想をここに記します。
批評 1. データサイエンティストが力を発揮する場 データサイエンティストとして成果を発揮するには、事業ドメイン・そしてデータの規模と質に依存する
圧倒的に同意です。自分も現職に就職する際には、データ規模・質・種類や社内のデータに関する文化などを考慮して会社を選びました。 最後の一文も完全に同意で、良いデータさえあれば基本的に問題は解きやすく簡単になると思っています。
2. 課題設定 データサイエンティストの仕事の肝は適切な課題設定
本質的な課題設定とはそもそもなんなのかと考えてみます。
ここで、本質的な課題設定を解明するための大きな障壁になるのは、
自社が事業会社か ドッグフーディングできるサービスを運営しているか どうかではないでしょうか?
日常的に自社のサービスを使っていると、顧客視点での改善点や課題点などを見つけることができる。 また、サービスをより深く知ることで深い考察や客観的な観察をすることができる。 スタートアップ界隈では浸透している リーンスタートアップの考え方は、本質的な課題の発見に非常に相性が良いと思っています。
また、データ分析では、単なる集計や相関ではなく、顧客がどんな状況で何をしたいのかを考えてユーザーリサーチをすることも非常に重要です。 ジョブ理論 イノベーションを予測可能にする消費のメカニズム で語られているトピックですが、非常に勉強になります。
3. 解決方法の設定 自然なモデリングと実現可能性のあるモデリング
自分はデータサイエンティストではなく、機械学習エンジニアとして働いているので、その立場からの視点です。 実感するのはまず何よりも実装力が大事だと思います。
実装ができるからこそ、実験ができる。その実験から知見を得て改善のサイクルが回り始める。
関連する暦本先生の tweet が面白かったので、ご参考まで
4. 検証 施策実行後の検証は必須
個人的には自分が最も重要だと思う点はここである。 確かに施策が成功したら、燃え尽きたくなる気持ちはわかるが、なぜ成功したのかを解明して再現性を担保しなければ知見としてストックされない。 そして知見の溜め込みの速さ・多さこそがビジネスとしての優位性につながるのではないのだろうか? これこそ、まさに科学的思考の本幹ですね。
5. 育成 データサイエンティストの育成は非常に難しい
育成の点は、自分も最近考えていたことですが、
例えば研究室のセミナーや論文の赤入れなどで議論をしたからこそ科学的思考方法が身についたのか? を考えていました。
僕の結論では、 強い相関はあれど研究室での議論により全員が身科学的思考方法を会得するのは難しいのではないかと思っています。 (もちろん全員が身につけることこそ、研究室の本懐だと思います)
Software Enginnering やアカデミアの世界では、レビュー文化を体験してあくまで内容に関する批判であり、 フィードバックを受け入れて改善する姿勢を身に着けていることも大事だなと最近感じています。
Team Geek ―Google のギークたちはいかにしてチームを作るのか の書籍で語られる HRT の精神ですね。</description></item><item><title>How to concat image using skimage</title><link>https://shunyaueta.com/posts/2019-06-17/</link><pubDate>Mon, 17 Jun 2019 00:07:33 +0900</pubDate><guid>https://shunyaueta.com/posts/2019-06-17/</guid><description>When you need to concat same size image to make figure.
skimage &amp;amp; numpy combination is too powerfull to concat images.
This is sample script.
from skimage import data, io import numpy as np img = skimage.data.astronaut() imgs= [img for i in range(10)] skimage.io.imsave(&amp;#34;sample_h.png&amp;#34;,np.hstack(imgs)) skimage.io.imsave(&amp;#34;sample_v.png&amp;#34;,np.vstack(imgs)) After that you can get below images.
Via Gist: https://gist.github.com/hurutoriya/fedf059ad3db5c67b16d8d5dd6d3df70</description></item><item><title>Hugo Tips</title><link>https://shunyaueta.com/posts/2019-06-16/</link><pubDate>Sun, 16 Jun 2019 23:09:18 +0900</pubDate><guid>https://shunyaueta.com/posts/2019-06-16/</guid><description> Hugo 0.32から page bundle が使用可能に この機能で画像ファイルを以下のファイル構成で構築できる - hoge/ - index.md - hoge.png これにより、markdown とアセットファイルが同一ディレクトリ内に収まるのでアセットファイルの管理が簡単になる
hugo new で特定のエディタを開くには? hugo new posts/hoge.md --editor=&amp;#34;code&amp;#34; 作成時にslug に日付を含める 今回は2020-09-09の形式で slug を作成する hugo new posts/$(date &amp;#39;+%Y-%m-%d&amp;#39;)/index.md page をビルドして結果を確認する hugo server 下書きも含めてビルドする hugo server -D</description></item><item><title>Machine Learning Casual Talks #10 を開催しました #MLCT</title><link>https://shunyaueta.com/posts/2019-06-15/</link><pubDate>Sat, 15 Jun 2019 22:01:27 +0900</pubDate><guid>https://shunyaueta.com/posts/2019-06-15/</guid><description>MLCT #10 を開催しました。
Machine Learning Casual Talks とは
実サービスにおける機械学習の経験をカジュアルに語り合おう
を目的としたコミュニティです。
スポンサー 前回と同じく本イベントは株式会社メルカリにスポンサーとして会場と懇親会の提供を受け開催することができました。 スポンサー依頼を快諾いただきありがとうございました!
配信動画はこちら!
Sli.do がパネルディスカッションでめっちゃ便利な件 今回は、パネルディスカッションで sli.do をスクリーンにフルスクリーンで表示してモデレーションを行いました。
手元のスマートフォンで質問をハイライトして、回答を終えたものはアーカイブという運用でしたが、とても快適なのでみなさんぜひお試しください。 スクリーンでの表示画面が SPA で同期されているので、手元のスマートフォンで更新すればリアルタイムで同期されるのがとても便利です。</description></item><item><title>Machine Learning Casual Talks #8 を開催しました #MLCT</title><link>https://shunyaueta.com/posts/2019-02-02/</link><pubDate>Sat, 02 Feb 2019 18:41:32 +0000</pubDate><guid>https://shunyaueta.com/posts/2019-02-02/</guid><description>Machine Learning Casual Talks 第 8 回の開催を無事終えました
MLCT とは
実サービスにおける機械学習の経験をカジュアルに語り合う
コミュニティです
スポンサー 今回も同じく本イベントは株式会社メルカリにスポンサーとして会場と懇親会を提供を受け開催することができました!
Machine Learning Casual Talks #8 (2019/01/28 18:30〜)
当日の配信動画はこちら
当日の発表資料はすべてこちらにあります
Machine Learning Casual Talks #8 - 資料一覧 - connpass
エムスリー 西場さん
BEDORE すみのさん
TL;DR; エムスリーの西場さん、すべてをこなす toB の機械学習サービス、システムアーキテクチャデザインかなり考えないとキツイ 懇親会での 🍣 の需給予測失敗しかけた 次回挑戦したいこと 今回会場撤収時に有志の参加者、登壇者の方が撤収作業を手伝っていただき非常に助かりました。次回は有志で会場撤収ボランティアの参加枠を作ろうかなと思いました。運営コストを下げるのは、継続で一番大事だなと思っているので、お手伝いいただいた皆様ありがとうございました。助かるという感情が出てくる前に、素直にめちゃくちゃ嬉しかったです!
参加率も 8 割を超えていて欠席率が非常に少なかったのも継続していきたい</description></item><item><title>Machine Learning Casual Talks #7 を開催しました #MLCT</title><link>https://shunyaueta.com/posts/2018-12-15/</link><pubDate>Sat, 15 Dec 2018 19:29:59 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-12-15/</guid><description>Machine Learning Casual Talks 第七回を無事開催しました
Machine Learning Casual Talks #7 (2018/11/20 18:30〜)
MLCT とは
実サービスにおける機械学習の経験をカジュアルに語り合おう
というコミュニティです。
スポンサー 今回も同じく本イベントは株式会社メルカリにスポンサーとして会場と懇親会を提供を受け開催することができました。スポンサー依頼を快諾いただきありがとうございました!
遺伝異常により髪が青く変色してしまったタカヤナギ=サン
ABEJA の機械学習導入事例と辛い話を大田黒さんにお話していただきました!
今回の勉強会資料は以下にまとまっています。
Machine Learning Casual Talks #7 — 資料一覧 — connpass
今回の内容を今北産業
機械学習エンジニアとしてのキャリアのお話を タカヤナギ=サン 実世界に根付いた IOT と機械学習サービスはかなり辛い 各社の機械学習エンジニアの定義が揺らいでいるので、世界が壊れる 今回の改善点 参加枠の多様性 絶対参加するぞ枠 一般参加枠 初回参加枠 SNS 枠 Blog 枠 と今までは一つの枠で扱っていたものを、5 つの枠に分散して用意してみました。
なぜかというとドタキャンやノーショーの方の影響で本当に参加したい方や初回参加の方の機会が喪失してしまうのはいただけないので、それを解決したなと思ったのが始まりです。
初回参加枠を設けることで、新規参加者が増えて内輪感が解消されるのも狙ってみました。その影響か前回と比較して 2 割ほど参加率が増えてよかったです :)
パネルディスカッション 登壇者 2 名と僕がモデレーターを行い、パネルディスカッションを行いました。単なる発表保の質疑応答時よりも話が盛り上がってなによりでした~
次回予告 次回 MLCT 第 8 回は 2019/01/28 に参加予定です!</description></item><item><title>Machine Learning Casual Talks #6 を開催しました #MLCT</title><link>https://shunyaueta.com/posts/2018-10-14/</link><pubDate>Sun, 14 Oct 2018 03:01:01 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-10-14/</guid><description>機械学習の信頼性が熱いよねというお話
柚餅子 さんの発表風景
2018/09/25 の MLCT #6 を開催しました。
MLCT とは
実務における機械学習の話や経験をカジュアルに語り合おう
というコミュニティです。
スポンサー 今回も同じく本イベントは株式会社メルカリにスポンサーとして会場と懇親会を提供を受け開催することができました。スポンサー依頼を快諾いただきありがとうございました!
Machine Learning Casual Talks #6 (2018/09/25 19:00〜)
発表資料一覧 👇(スライドと配信動画) Machine Learning Casual Talks #6 - 資料一覧 - connpass
柚餅子さん リブセンスにおける機械学習システムの信頼性エンジニアリング SRE の考えを機械学習システムに取り入れるというお話ですが、筋が良さそう。特に SLO 周りはうちでも取り入れないなぁと思いました Naomichi Agata さん ユーザーフィードバックと機械学習 半教師あり学習で解くというアプローチは非常に筋が良さそうで気になった。技術書典の書籍も気になる 👀 gamella さん マーケット予測モデルの PCDA の回し方 ms 単位のデータを学習データにして株価の UP/DOWN を予測する。。。。適用するドメインの難易度が鬼ゲーすぎて、ハラハラしそうだけど解きがいがありそう @yu-ya4 さん Big Query ML を使ってみた話 さらっと BQML を試して成果が出ましたと言っていたが、良い問題を探し出す嗅覚がすごいなと思いました。実際 BQ だけで過不足なくモデリングが終わるなら理想の世界ですね~ Kosuke Kitahara さん 発表資料は後日公開されます。謎の力により Youtube 配信はされていません KPT Keep 動画配信を問題なく完了できた 魅力ある発表内容を維持できた Problem 参加率が低かった。前回は 65%程度の参加率でしたが、今回は雨の影響もありますが 40% と低くなっていた 倍率も毎回 1.</description></item><item><title>Machine Learning Casual Talks #5 を開催しました #MLCT</title><link>https://shunyaueta.com/posts/2018-07-15/</link><pubDate>Sun, 15 Jul 2018 09:31:28 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-07-15/</guid><description>2018/07/13 に MLCT #5 を開催してきたお話
Opening Talk by Aki Ariga
Machine Learning Casual Talks #5 (2018/07/13 19:30〜)
本イベントは株式会社メルカリにスポンサーとして会場と懇親会を提供を受け開催することができました。スポンサー依頼を快諾いただきありがとうございました。
発表資料はこちら 👉 here (YouTube 配信もあります)* この記事では、技術的なお話というよりも開催に至るまでの話をメインに書いていきます。
Start 構想開始時期は 2018/04 頃に考えていて、弊社開催の
MLOps Nightと呼ばれるイベントの準備を行っているときに、社内だけではなく
*社外の人の機械学習の辛い話をうんうんと頷きながら聞きたいなぁ
*と思ったのが事の始まりです
そのあと、とりあえず日程と発表者は事前に集めておかねばと思いTakashi Nishibayashi さんにラブコールを送っていた
発表依頼の様子
chezou さんとの出会いと MLCT 復活の狼煙 その後、
勉強会の名前どうしよう 🤔 運営の方針どうすべきか 🤔 を迷いつつ時間が過ぎていき業務の一環として機械学習工学キックオフシンポジウム に参加していたら、そういえば Aki Ariga さんって MLCT 開催してたよな、あの勉強会すごく参考になること多かったから復活できないかなと思い始め、気がついたら懇親会で hagino3000 さんに chezou さんを紹介してもらい
「MLCT 復活させたいです!!! 場所と運営準備は僕主体でやります!」
と提案したら、あっさりと快諾され運営者に混ぜてもらえることになりました
メッセージ投げかけから 1 分で承認される
あらためて、突然飛び込んできた見知らぬ人物の運営への参加を快諾してくださった、 Aki Ariga, Atsushi KOMIYA, @tetsuroito さんありがとうございました 🙇</description></item><item><title>イベント運営に便利なsli.do の使いこなしかた</title><link>https://shunyaueta.com/posts/2018-06-17/</link><pubDate>Sun, 17 Jun 2018 15:03:27 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-06-17/</guid><description>イベント運営者必見 sli.do の使い方
sli.do のディスプレイ画面
sli.do という便利な質問投稿・回答サービスがあります。このサービスですが、イベント運営者あるあるの
オフラインだと活発に質問が出ない Twitter は盛り上がってるが実際の反応はわからない Google Form はいまいち回答率が悪い などの問題点を解決してくれるサービスです
Slido - Audience Interaction Made Easy
基本的な使い方は以下の公式動画がサクッとまとめられていて分かりやすいです
これ見れば sli.do の機能は全て俯瞰できる
UI が良く操作に迷うことはないので、各機能のスクショを貼りつつ紹介していきます
イベント設定 設定画面
イベントの名前や、 短縮コード(イベントのハッシュタグにしておくと分かりやすい)を設定して導線をわかりやすくできる
投票機能 無料版だと 3 つの投票までできる。大きなイベントでなければ十分。もちろん回答結果はシークレットにもできます。
3 つの投票機能
複数選択肢
自由記入式
星によるレーティング
各投票機能はアクティブにすると参加者は一つだけ投票可能になる
参加者からの質問・回答結果のライブ表示 右上のトグルボタンをクリックすると、投票結果をライブ表示できる。勉強会の発表中にサイドディスプレイがあれば常時表示しておくとライブ感が出て良いと思う
ライブ画面への切り替え
質問一覧
回答ライブ画面
上部のスイッチ画面から次の投票に切り替えることができる
回答解析機能 管理画面から回答のインフォグラフィックを生成することもできる
といたせりつくせりの機能が提供されています。
まとめると
イベント参加者からのオープンな質問投稿(匿名・非匿名) 各質問・回答のライブ表示 運営者からのサーベイ(イベントの感想など) の 3 点が sli.do では使えます
Tips 唯一惜しい機能としては、イベント管理者が単一ユーザーでしか管理できない点ですが共同アカウント作れば大丈夫そうです。
How do I add more admins to my event?</description></item><item><title>[抄訳] Data engineers vs. data scientists</title><link>https://shunyaueta.com/posts/2018-04-24/</link><pubDate>Tue, 24 Apr 2018 02:18:46 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-04-24/</guid><description>データサイエンティストとデータエンジニアの定義とその誤解による悲劇、そしてそれを救う存在である機械学習エンジニア
紹介記事 Data engineers vs. data scientists
紹介記事を同僚から教えてもらい、面白かったので抄訳した
[](https://twitter.com/chezou/status/980349709339394048) &amp;gt; Aki Ariga さんが言及していた記事と方向性が同一で面白かった。
Data Scientists : ビジネスサイドを理解し、他者にわかりやすく可視化と言語化できる職能。そして高度な数学的知識に基づいたモデリングやアルゴリズム提案スキルも持っている。Data Scientists には高度な Programming skill は必ずしも必須ではない、なぜならモデリングやアルゴリズムを実装するためにプログラミングを習得した人が多いからだ。システムデザインや Programming スキルは、Software Engineer や DataEngineer からみると見れたものではない(そしてそうでなくてはならない、なぜならスペシャリストだから)
Data Engineer : 分散プログラミングを意識して構築できる職能。DE は卓越したプログラミングスキルとシステム構成力を持つ。定義 : つまりビッグデータに対してシステム的に解決できるスキル。クラスタ設計までが Data Engineer の役割であり運用(Ops)はやらない
from : https://www.oreilly.com/ideas/data-engineers-vs-data-scientists
Data Scientists と Data Engineer の互いの特化したスキルは補完しあってこそ輝く。 Data Scientist がデータパイプラインを作ると悲劇が起きてしまう。多くの企業が Data Scientist を Data Engineer として雇っているが、それは Data Scientists のスペックを活かしきれず、20–30%の効率で働かせてしまっている。そしてその ROI はめちゃくちゃ悪い。Data Scientists は適切なツールと選択肢を熟知していない(そして Data Engineer はシステムデザインと熟知しているのでミスは侵さない) e.g. 実際著者が聞いたこんな話がある。 Data Scientists が Apache Spark を使って 10GB のデータ処理を行うのに 1 回 15m の時間がかかっていた。(だが RDBMS を使えば、10ms で終わる) Data Scientist は彼らの流儀を疑うこと無く 1 日に 16 回 Spark の処理を実行しており、15mx16=240m つまり 4h の時間を無駄にしてる。RDBMS を使えば、160ms で終わるというのに… Data Scientist が頑張ってシステムを構築するが、職能の限界で Data Engineer しか作れないシステムなので時間とお金の浪費になった 実情 : Data Scientist として雇われたのに、Data Engineer として働かざるを得ない人がほとんどだ 理想的な人材配置 Case : 初期の組織: 2–3 人の Data Engineer : DataScientist Group Case : 更に複雑な事に取り組みたい 4–5 人の Data Engineer : 1 Data Scientist Data Engineer change to Data Scientist の王道 → それが新しい職種 : Machine Learning Engineer!</description></item><item><title>Google Colaboratory で Mecab-ipadic-Neologd を使うまで</title><link>https://shunyaueta.com/posts/2018-04-23/</link><pubDate>Mon, 23 Apr 2018 15:38:10 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-04-23/</guid><description>Colab 上で 日本語の NLP をしたいときありませんか？
Success
Code Google Colabratory https://colab.research.google.com/drive/1YK8XFnfD29775lEYWhwz3wh4h8boR9iE</description></item><item><title>eBayのAR測定機能を試してみた</title><link>https://shunyaueta.com/posts/2018-04-16/</link><pubDate>Mon, 16 Apr 2018 14:57:41 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-04-16/</guid><description>eBay が ARCore を使った商品の梱包測定機能を提供しているので試した
梱包測定の仕組みとしては、ARCore(今回は Pixel2 XL で試した)で平面検出を行って、そこに eBay のダンボールオブジェクトを設置することで、ダンボールに入るかどうかを判定できる。
下のダンボールアイコンを選択して、検出された平面をタップするとダンボールオブジェクトを設置できる
今回例として用いた MBP の空箱だと ARCore が空箱自体を平面と認識してしまうという罠があるので、床で平面検知を終えてから商品を置くという裏技が必要
まとめ ARCore を用いた AR 機能の UX としては 🙆 実用性は 🙅、平面検出しかしてないので、荷物に合わせて最適なダンボールを選ぶのは結局ユーザー。そこまで自動化してこそ革新的な機能になると思った Related Post
eBay uses augmented reality to help sellers find the right box for their product</description></item><item><title>Google, Facebookが提供する機械学習基盤まとめ</title><link>https://shunyaueta.com/posts/2018-04-09/</link><pubDate>Mon, 09 Apr 2018 13:55:44 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-04-09/</guid><description>Google, Facebook の機械学習基盤情報をまとめました
TFX
社内の勉強会で Google, Facebook が提供する機械学習基盤に関する論文を紹介したので、その資料を公開します#### 経緯
機械学習をサービスとして提供開始すると、継続的な学習やプロダクション環境での機械学習の提供はモデル構築以外にもいろいろと考える問題が多くなります ¹
[1] Hidden technical debt in Machine learning systems NIPS’15
要するに機械学習をサービスとして届けるには、実はめちゃんこ大変なんだよという話なんですが、みんな同じ問題にぶち当たります。
そのためプロダクションレディなレベルで機械学習を提供できるプラットフォームを各社が提案しておりその中でも Google, Facebook の事例を提供します。
TL; DR; FBLearner: MLaaS の事例として最初に読むべき論文、MLaaS をどのような戦略で提供しているかを抽象的にまなべるため、鳥瞰図として読みましょう TFX は逆に機械学習基盤が必要とする技術スタックや要件などを詳細に説明しており、教科書的な立ち位置です。社内で機械学習基盤を内製したい場合に詳しく読み込むこと必須 両社とも MLaaS をスケーラブルに提供する環境ができており、サービスのコアテクノロジーになっている Google : Tensorflow Expand TFX: A tensor flow-based production-scale machine learning platform
Facebook : FBLeaner Applied machine learning at facebook a datacenter infrastructure perspective HPCA18
ONNX を見ていると TensorFlow VS. ONNX 陣営が出来つつありどちらのプラットフォームに乗るかの戦略が大事だなと思います。
Google はモバイル上の ML から超大規模分散学習まで TF シリーズで提供、実際のサービング環境も TFServing というスタックを提供しはじめていて個人的に TensorFlow が何歩も先にいっているという所感</description></item><item><title>メルカリのTeam AI Meetup #1 に参加してきた #mercari_ai</title><link>https://shunyaueta.com/posts/2018-02-13/</link><pubDate>Tue, 13 Feb 2018 15:35:48 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-02-13/</guid><description>メルカリが主催する機械学習のミートアップに参加してきたので備忘録がてらメモ書きです。書きなぐったメモなので意訳として捉えて下さい
発表者の顔は隠しています。なにか問題があればお伝え下さい。
Team AI Meetup #1 (2018/02/13 19:00〜)
Twitter: #mercari_ai
山口さん Image Net と mercari の持ってるデータセットは似てるのでいけるのでは! ルカリはクラス数 over 1100 始期の推定値 Top5 29.3% エラー例 :画像からサイズを推定しないと男女のシューズを区別不可(人間でも不可能なエラー例が多い) 意外と認識がうまくいく事例がかなりある(クラス設計の影響で推定が上手く出来ていないらしい) データセットはユーザーが作成してるので最高、画像が正方形なのも Good 学習は GPU,推論は CPU 環境下で行っている 画像検索自体はプロトタイプは出来ているが、実運用は計算量やリアルタイム性を担保するのが難しいので一旦保留中 大筋は以下の記事と資料で把握できます。k8s で運用しているなどの実運用の構成が今回の発表では差分として語られていました。
画像での商品検索に向けて - Mercari Engineering Blog
【Mercari Summer Internship】商品画像の色推定を行いました! - Mercari Engineering Blog
工藤さん 運用を継続すると色んな問題が出てきたので、それを解決する基盤環境を作成しはじめた e.g. 学習データのバージョン管理、モデルのデプロイ, etc 最終的には OSS としての公開も考えているとのこと メルカリの今年 1 年間の機械学習の取り組みとこれから - Mercari Engineering Blog
ML Ops Study (仮) #1の発表内容も今回の機械学習の運用周りの Tips が共有されているので興味のある方はオススメです</description></item><item><title>2018.01 KPT</title><link>https://shunyaueta.com/posts/2018-02-09/</link><pubDate>Fri, 09 Feb 2018 14:00:31 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-02-09/</guid><description>2018 年 1 月の振り返りをざっくりと
Keep Mercari Competition にて初 Kaggle コンペ参加。 Best 116 位まで言ったんですが、NLP 周りの知見が無いのと、Kaggle 周りの力不足で現在は 317 位… ブロンズまで引き戻せるか… [](https://twitter.com/hurutoriya/status/952573577357770753) ぬか喜びしている図
Coursera で Ng 先生のML コースを始めた。あと 5 日位で無事終わりそう。とても分かりやすい(何故もっと早く受けなかったのか…) 終わったら、How to Win a Data Science Competition: Learn from Top Kagglersか Ng 先生の deeplearning.ai を始める予定 本を 2 冊読めた。案外読む始めるのがハードル高いだけで、読み始めれば 1 日 30 分*5 日で読み終わることがわかったので今度から通勤途中に読むことにした。これで月 4 冊読んでいくようにしたい。2–3 月はメタ学習関連の本を読み進めていく。 学力の経済学
[](https://twitter.com/hurutoriya/status/960525598610268160)
お金持ちになれる黄金の羽根の拾い方
[](https://twitter.com/hurutoriya/status/952046931307458560)
Duolingo で英語学習を再開した。学習アプリとしてとても出来が良い。(名詞の複数形や冠詞などの細かい間違いを都度指摘されるのが好き。モバイルアプリ(iOS)は問題が重複して出題されるので PC メインで利用) 100%達成するぞ!</description></item><item><title>2018 resolution</title><link>https://shunyaueta.com/posts/2018-01-29/</link><pubDate>Mon, 29 Jan 2018 16:08:35 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-29/</guid><description>2018 年の抱負です。
Works 機械学習エンジニアとして六本木で働く事になりました。機械学習エンジニアとしてスペシャリストになれるように周辺スキルを伸ばしていきます。
Kaggle Master に到達(1 gold medal, 2 silver medals) 初参加のコンペもずるずる下降してしまいブロンズ圏外に…
Coursera, Udacity (MOOC)で CV, Robotics 周辺を学習していく Github で 50 star over の OSS を作る(CV or ML) 勉強会に登壇 or 主催 する メタ学習(学習の効率化)について小話
うまくなる技術¹などのメタ学習関連の本を色々と読み漁って学習のコツをいろいろ勉強してるんですが、外的指標(Github Star, Kaggle Rank, Toggl tracking,Coursera Certificate)を目的にすると人間気持ちよく継続できるらしいのでそれに沿った行動をするよう心がけています。後 5–6 冊メタ学習の本を読み終えてまとまったらまた記事にする。
サンシャイン丸の内さん¹や ふろむださん¹の記事も参考になるのでオススメです
個人的に最近心に響いたのはのじゃろりおじさんの勉強の姿勢です。
３ D や unity の勉強方法について。：ねこみみメモ
おそらく、やり続けて成功した人は「やり続ければ報われる！」と言うと思うのですが、年齢や経済状況や自分の才能を疑ったり等……現実は難しいと思います。
私は偶然このタイミングで「オリジナルモデルの Vyoutuber を出せた」から幸運に恵まれただけで、純粋な技術ではおそらく就職は無理だったのではないかと思います。2018~19 年で見切りつけて諦めなきゃなと思ってたぐらいです。
なので「やり続ければ報われる」とはとても言えません。ただ**「やり続けて報われなくてもいいと思える事は、やり続けた方がいい」**とは思います。
他者の評価がどうであれ、やてって楽しくて満足できるのであればある意味常に成功している状態で、やればやるほど成功続きなわけです。
English DMM 英会話 TOEFLE で 90 点、英語で働けるレベルを目指す 英語 Blog 記事を定期的に書く Health カラダステーションで内臓脂肪が少し高めになってたので走る(筋トレしかやってなかったツケが…) 筋肉量も左右でバラツキ(利き手側じゃないほうが 100g 程度筋肉量が少ない)があるので整える 筋トレはケトルベル 16kg で色々とやってるので継続する。</description></item><item><title>Where To Look: Focus Regions for Visual Question Answering (CVPR2016)を読んだ</title><link>https://shunyaueta.com/posts/2018-01-18/</link><pubDate>Thu, 18 Jan 2018 05:41:44 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-18/</guid><description>Kevin J. Shih, Saurabh Singh, Derek Hoiem, “Where To Look: Focus Regions for Visual Question Answering”, in CVPR2016 link
Summry
を読んだので、軽くメモ。
VQA(Visual Question Answer) 画像に対する質問に対して応答するタスクに対し、その質問クエリに対して画像のどの領域に注目すべきかのモデルの学習方法について論じた論文。
Contribution VQA datasetに対して、提案手法を適用。従来手法を全て上回った。 画像に対して CNN を用いて物体領域の検出を行った後にベクトル化、質問クエリはword2vecを用いてベクトル化を行う。 その 2 つのベクトルを用いて内積計算により重み付けを行うことで、どの領域に注目すべきかを計算する。 Comments 引用文献の訳 9 割が 2014–2015(直近 2 年間)で発表された論文で、改めてこの分野の最先端を駆け抜けるのは凄まじい能力が必要になるなと思いました。
そして相変わらず CVPR の論文のネーミングセンスは良いですね。(ジャケ買いならぬジャケ読み)
単純な質問なら、人間でも瞬間的に解答可能な物が多いなと感じた。
fig. 1
セマンティックな疑問(Fig.1 雨は降っていますか?)の場合、人間に注目した場合は傘をさしているから雨と判断しても良いがもっと広い範囲で画像を見てみると空は快晴なので人間に注目するのは筋が悪く VQA はとても難しくチャレンジングな問題だと書かれていた。(それでも充分すごい領域に到達しているなと思うが)</description></item><item><title>Data-driven Crowd Analysis in Videos (ICCV2011)を読んだ</title><link>https://shunyaueta.com/posts/2018-01-17/</link><pubDate>Wed, 17 Jan 2018 05:55:41 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-17/</guid><description>Data-driven Crowd Analysis in Videos (ICCV2011)を読んだ
Mikel Rodriguez, Josef Sivic, Ivan Laptev, Jean-Yves Audibert, “Data-driven Crowd Analysis in Videos”, in ICCV2011.
Project Page
を読んだので、メモです。
Summary
tl;dr 高密度な群集内の個人を追跡を転移学習によって精度を向上させる手法 Contribution 追跡の精度を転移学習によって向上させた 転移学習を行うためのデータセットとそのフレームワークを考案 論文内では、転移学習の例としてマラソンAの群集を対象に追跡する際に、以下の流れで転移学習を行う。
大域的な群衆状況のマッチング : 同じようなシーンを探索(この場合 DB 内にあるマラソン動画) 局所的な群衆状況のマッチング : 1でマッチした動画においてオプティカルフローが類似するパッチを探索して転移学習 また、Rare Events(デモの最中に群集を横断するカメラマンなど、群衆の流れに対して同調しない動きを行う人物)に対しても実験を行い評価。
Comments 転移学習は自分のイメージだと、自然言語処理のイメージ(一般的な文書を学習したモデルを法律文書に対して適用するなど)しかなかったので新鮮な気持ちで読めた。
動画なら転移学習を行ったとしても、直感的に良い特徴を学べそうなので、良い仮説を立てている論文でした。
最後に示されてる個人追跡における平均誤検出の単位がpixelだが、Ground-Truth と提案手法の追跡軌跡の重複度具合を見てると誤検出が更に高そうに見えるけどどうなんでしょうか？
(テストデータのみ学習が 58.82、転移学習を行った提案手法だと 46.88[pixel]になっていてもっと相対的な差が出てくるはず?)</description></item><item><title>Slicing Convolutional Neural Network for Crowd Video Understanding (CVPR2016)を読んだ</title><link>https://shunyaueta.com/posts/2018-01-16/</link><pubDate>Tue, 16 Jan 2018 06:04:37 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-16/</guid><description>群衆解析の手法に興味があるので、サーベイの結果を放流しておきます。
Jing Shao, Chen Change Loy, Kai Kang, and Xiaogang Wang, “Slicing Convolutional Neural Network for Crowd Video Understanding”, in CVPR, 2016.
Project Page
Summary
一言説明 時系列・空間的特徴から CNN で特徴を学習、群衆の動画に対してstate-of-the-artを達成
3 個の CNN を用いて下記の３つの特徴を表現学習
xy- : 空間的特徴 xt- : x 軸の時系列特徴 yt- : y 軸の時系列特徴 Comments Dataset としてWWW Crowd Dataset
が公開されている。10,000 本の群衆の動画を収集公開しているとのこと。
Demo Movie
紹介動画を見てみたら分かるが、群衆の動画というよりも数が増大した結果一般的な画像認識のデモ動画になっている Jing Shaoさんは CVPR2014 から群衆解析のための descriptor を提案したりしてたんだけど、2016 年から Deep な手法での群衆解析の研究をやっているのは手が早いなと 所属グループは ISLVRC2015 の物体認識タスクで優勝した香港大学のグループ Multimedia Laboratory The Chinese University of Hong Kong データセット、実装コードを必ず公開しているのは尊敬、またそれくらいやらないとトップには通過しないんだろうな CNN のアーキテクチャ毎の比較実験と考察をかなり入念に行っていた。数年後には各データのフォーマットに合わせたベストな DNN のアーキテクチャが決まってくるんじゃないだろうか</description></item><item><title>Jupyter Notebookの差分を明瞭に確認する事ができるpackage : nbdime</title><link>https://shunyaueta.com/posts/2018-01-15/</link><pubDate>Mon, 15 Jan 2018 17:14:54 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-15/</guid><description>Jupyter notebook をご利用の皆さん、朗報です。
例えば、下記の２つの notebook の差分を比較したい際に、
nb_1.ipynb nb_2.ipynb diffコマンドを用いると下記のような結果になってしまいます。 &amp;amp;gt;&amp;amp;gt; diff nb_1.ipynb nb_2.ipynb [master] 14c14 &amp;amp;lt; “image/png”: “iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n”, — - &amp;amp;gt; “image/png”: “iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJIb+P2c9rHcimwD6AAAAAElFTkSuQmCC\n”, 16c16 &amp;amp;lt; “&amp;amp;lt;matplotlib.figure.Figure at 0x10ba48cc0&amp;amp;gt;” — - &amp;amp;gt; “&amp;amp;lt;matplotlib.figure.Figure at 0x11037dcc0&amp;amp;gt;” 34c34 &amp;amp;lt; “ax.fill(x, y, zorder=10,facecolor=’green’)\n”, — - &amp;amp;gt; “ax.fill(x, y, zorder=10,facecolor=’black’)\n”,
diffは単純な文字列の差分比較を行うだけなので、notebook がjsonで管理されており、matplotlibで生成される出力結果の保存内容にも差異がでるのでこうなってしまいます。
jupyter/nbdimeを用いることで、notebook 形式の json をパースしたうえでの差分比較が可能になります。
提供されるコマンド一覧
nbdiff : ノートブックの差分比較をターミナルで行う nbdiff-web : Notebook の差分をブラウザで行う 簡単な実行結果
差分比較 ターミナル上での差分比較 `&amp;gt;&amp;gt; nbdiff nb_1.ipynb nb_2.ipynb</description></item><item><title>Analyzing Free-standing Conversational Groups: A Multimodal Approach (ACMMM15) を読んだ</title><link>https://shunyaueta.com/posts/2018-01-14/</link><pubDate>Sun, 14 Jan 2018 10:41:12 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-14/</guid><description>スタンディングディスカッション形式での会話を評価した研究
Summary Slide
X Alameda-Pineda, Y Yan, E Ricci, O Lanz, N Sebe
“Analyzing Free-standing Conversational Groups: A Multimodal Approach”, in 2015 ACM Multimedia Conference
link
を読んだので、軽くメモ。
マルチモーダル系の論文初めて読んだんですが、まとめるとコントリビューションが 5 つあると主張。
Contribution 音声・近接情報、そして監視カメラからの身体と頭の姿勢推定からマルチモーダルに解析 フリースタンディングディスカッションを身体・頭の姿勢推定から解析 カメラと音声・近接センサーからなるマルチモーダルな解析するためのフレームワークを提案 ラベリングされてないデータに対する行列補間問題の考案 SALSA(データ・セット)を公開・評価 SALSA というポスターセッションの動画と音声のデータも公開されている
SALSA: Synergetic sociAL Scene Analysis
動画は Google Drive で公開されていて時代の波を感じる。
データセットを公開 論文も読みやすい 新しい行列補完計画法(アルゴリズム)を提案 実問題に取り組む と盛り沢山な内容で面白かった。
スライド内のリンクは Google Slide で共有しているのでこちらを参照すると便利です。
X Alameda-Pineda, Y Yan, E Ricci, O Lanz, N Sebe &amp;quot;Analyzing Free-standing Conversational Groups: A…</description></item><item><title>PythonでGaussian Kernelのアニメーションを作成</title><link>https://shunyaueta.com/posts/2018-01-13/</link><pubDate>Sat, 13 Jan 2018 17:03:43 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-13/</guid><description>Python でアニメーションを作成したかったのでメモ
Gaussian Kernel GIF Animation
当然ながら、HTML5 の Video は再生されないので GIF に変換した結果が以下。
これで HTML5 で再生される。
**GIF**で表示する方法として %matplotlib nbagg
というオプションが存在しているが、Kernel が busy 状態を何度も繰り返すので、自分は mp4 で出力するようにした。
実験結果も以前は GIF で保存してたが、最近は全てmp4で管理するようにした。
あと、**np.linspace()**が iterable ではないので、イマイチな書き方になった。。
**np.arange()**を使うべきなのか…
Thanks Embedding Matplotlib Animations in Jupyter Notebooks
Jupyter 上で matplotlib のアニメーションを再生する - Qiita</description></item><item><title>Call center stress recognition with person-specific models を読んだ</title><link>https://shunyaueta.com/posts/2018-01-12/</link><pubDate>Fri, 12 Jan 2018 17:19:48 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-12/</guid><description>Affective Computing: 計算機と人間の感情や情緒の関係性を考える領域
MIT Media Lab Affective Computing Group のプロジェクト。
2 年前に MIT Media Lab へ訪問した際に、色々と見せてもらったけどかなり野心的な事に取り組んでいて感動してた。(デバイスも自分たちでプロトタイプを作りまくっていて、Deploy or Dieの意思を感じ取れる)
論文のまとめスライドは以下
One Slide Summary
HCI 系の論文は初めてまともに読んだんですが、
実験デザインが一番難しそう 人と計算機の関係を研究するので、必然的に人間の感性をどう評価する話にもつながってきてる? 手法に重きを置くというよりも、問題に重きを置いている印象 普段自分は、数値線形代数や機械学習、コンピュータビジョンを主にやっていて、精度をどれだけ出せるか、正解率をどれだけ向上や、速度をどれだけ上げれるかを理論的に保証、提案したりしていますが、面白い問題や興味深いデータを集めることも大事だなと思った。
実験計画法¹もかなり重要で、メンターの人から実験計画法の成り立ちを教えてもらってとてもおもしろかった。
実験計画法についてのまとめスライド</description></item><item><title>FUSE: Full Spectral Clustering(KDD2016) を読んだ</title><link>https://shunyaueta.com/posts/2018-01-11/</link><pubDate>Thu, 11 Jan 2018 17:30:28 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-11/</guid><description>べき乗法と独立成分分析を用いたマルチスケールに頑強なクラスタリング手法の提案
べき乗法では近似固有ベクトル(Pseudo-eigenvectors)は複数の真の固有ベクトルの線形結合からなる。有益でない固有ベクトルも含まれるのでいかにそれを除去するか Fig.1 で言ってることがいまいちわからない。ｃ,ｄも変化がないように見える。論文で言及してる stripe が何を指してるかが不明 分かった。赤・青・黒の３つのクラスタで分かれている。最初は黒色がクラスタ境界面に見えた。論文内での multi scale というのは、データの幾何的な分布を指している？ 固有値計算は O(n³）かかるから計算量が~~って毎回言われるが、行列の状態に依存するので毎回最悪の場合を主張されてるも困る ZP self-turining spectral clustering をなぜ対抗馬にして比較してるのかは謎。 ICA¹を行ったあとにその行列に対して回転処理を行い情報量の最小化を狙う クラスタ数が多い場合、PIC では良い結果が出づらい multi scale なデータの場合標準の spectral clustering では失敗することが多々ある fig.2 (a) 見ればわかるがk-means では分離が困難 fig.2(b) ４－５本目の固有ベクトルを基底ベクトルにもつ空間ではクラスタのオーバーラップが少ない つまり１－５本目の固有ベクトル全て含めてクラスタリングすれば結果が良好になるのではないか？（仮説） fig.2 © ４回べき乗法を行った。結果が似てる。（縦軸が何を表してるかは不明）。四回が上から四本求めたのか、一番上の固有ベクトルを４回求めたのか分からない fig. (d) 提案手法を適用。k-means で分離可能 行列Vをp回べき乗法を行って構築 E=MVの最小化を行う ICA を最小化するために Jacobi Rotation を用いる。探索には貪欲法を採用 Contribution マルチスケール（多種多様な）データ分布に対してクラスタリングが可能 計算時間は従来（ncut)と同等 感想 PIC(Power Itetaion Clusterg)をまさか拡張してくるとは思わなかったなので、興味深い論文。(実装して再現実験したけど、Early stopping の段階で高確率でクラスタリングが失敗していて使い物にならなかった印象があるので…) データの分布が多様な場合、上位数本のベクトルではなく、そこから更に下の固有ベクトルに着目したほうが結果が良好になるのは面白い KDD の論文、相変わらず読みやすかった。</description></item><item><title>サイトのPWA化、ホスティングをGithub PagesからFirebaseへ移行</title><link>https://shunyaueta.com/posts/2018-01-09/</link><pubDate>Tue, 09 Jan 2018 18:59:59 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-09/</guid><description>PWA と FireBase を試してみたかった
firebase init で現れる画面、テンション上がる
Github Pages + CloudFlare で独自ドメインの shunyaueta.com をホスティングしてたんですが、Firebase でホスティングできると聞いて Firebase に移行しました。
PWA にしたのは完全に趣味です。
TL;DR; Web App を作ってる人は manifest.json を設置するだけでも Android の使用感が改善されそう 独自ドメインでお手軽に SSL ホスティングしたいなら Firebase hosting めっちゃおすすめです(1GB のホスティングは無料) FireBase Hosting だけだと Firebase 本来の旨味は味わえません PWA 1 年前ですが、簡潔に PWA の事が書かれています
プログレッシブウェブアプリ詳解 ─ 過去・現在・未来
左: PWA 化以前 右: PWA 化以降
ServiceWorker と manifest.json,あとは&amp;lt;meta name=”theme-color”&amp;gt;を指定すると PWA のスコアが 100 点になる 🎉
manihest.json によるホームアイコン作成誘導
Favicon の各画像の生成は下記のサイトが便利でした。要求される解像度毎の画像(Favicon,Home icon, Apple home icon)が生成されて mahifest.</description></item><item><title>HerokuのDBにpgadmin4で接続してローカルにデータをダウンロードする</title><link>https://shunyaueta.com/posts/2017-12-27/</link><pubDate>Wed, 27 Dec 2017 08:12:17 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-12-27/</guid><description>pyadmin4 で Heroku 上の DB に接続する記事が日本語になかったので、メモ
接続前の準備 Heroku にログインして、対象の App の DB のページへ
Heroku App DB page
そこから DB のセッティングページにある credential ボタンをクリック
click credential button
そこに記載されている各種情報を pgadmin4 に入力して Heroku 上の DB に接続する
Copy information
pgadmin4 で Heroku の DB に接続 以下のページから pgAdmin4 をダウンロード
Download
そこからアプリを開くと下記の画面になるので、Add new Serverをクリック
Click Add New Server
Heroku 上の DB の情報を入力していく。Server の名前は適当で大丈夫です。
接続されるとこんな感じになります。
Query Tool Query Toolを使うことで Heroku 上の DB に対して SQL クエリを投げる事ができます。
Query Toolは上部のツールバーからアクセス可能です。 注意) 左カラムのテーブルをクリックした後でないとアクティブになりません。</description></item><item><title>“Learning Deep Representations for Graph Clustering (AAAI2014)” を読んだ</title><link>https://shunyaueta.com/posts/2017-12-23/</link><pubDate>Sat, 23 Dec 2017 17:38:19 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-12-23/</guid><description>自己符号化器と Spectral Clusteing の関連性を示した論文
Paper link Author Fei Tian : http://home.ustc.edu.cn/~tianfei/ 中国科学技術大学 Ph.D １年生 MSRA と共同研究、2014 年に AAAI2 本,COLING1 本を 1st で通してる。 この資料も面白い。ILSVRC2015 で 152 層の Deep Residual Learning を提案し優勝(Error Rate : 3.57%) MSRA @ ILSVRC2015 資料 Motivation (研究背景・動機) Deep Learning が数多くの応用でめざましい成果をあげている。 音声認識 画像認識 自然言語処理 DL において Clustering に関する適切な調査が行われてない。 論文の目的として、DL における Clustering の調査を行う 概要 Graph Clustering はクラスタリングでも重要な手法の一つ Graph Clustering の応用 Image segmentation Community Detection VLSI Design 嬉しい点 : ベクトル空間におけるクラスタリングの問題 → データの類似度グラフ問題への変換が可能 自己符号化器と Spectral Clustering の類似性 Spectral Clustering : グラフラプラシアンに対して EVD を行い k 本の非零固有ベクトルを用いた空間に対して k-means を行ったもの。 自己符号化器 : 入力データを低次元化、情報が最大限になるようにデータの次元を再構築する 計算量 : 対象とするグラフは n 個のノードを持つ EVD : ナイーブに実装すると O(n3)の計算量、最速の実装は O(n2)の計算量 自己符号化器 : ノードがスパースな際は計算量は O(kn) スパース表現 : データが大きくなるならスパース性を有効活用したい EVD : 固有ベクトルが高い確率で密になるため、スパース性が保証されない 自己符号化器 : スパース性を用いるのは容易 既存研究で未検証な事柄、何を解決・解明したいのか？ Graph Clustering のための Deep Learning の活用方法と調査 自己符号化器と Spectral Clustering の類似性とその比較・検証 Method (提案手法) GraphEncoder(for graph clustering.</description></item><item><title>JupyterNotebookをリモートサーバー上で公開して、どこでも研究開発 &amp; 講義でJupyterhubを利用する</title><link>https://shunyaueta.com/posts/2017-12-22/</link><pubDate>Fri, 22 Dec 2017 17:48:12 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-12-22/</guid><description>JupyterNotebook をリモートサーバー上で公開して、どこでも研究開発 &amp;amp; 講義で Jupyterhub を利用するお話です。
GIF 画像は下記の記事で知ったtqdmというパッケージを使いたくなった衝動の成れの果てです。
私が選ぶ 2015 年の”新しい”Python モジュール トップ 5 IPython データサイエンスクックブック ―対話型コンピューティングと可視化のためのレシピ集 IPython データサイエンスクックブックをキッカケに研究室でも JupyterNotebook の凄さを皆が知り、MATLAB の kernel を通して利用を始めたりしています。自分は Python2→MATLAB→MATLAB &amp;amp; Python3 という流れで移り変わっています。
JupyterNotebook をリモートサーバー上で公開 コードは以下の通りです。特に問題なく公開することができました。
環境 CentOS 7 系 下記の記事を参考にセットアップする。
pyenv と virtualenv で環境構築 今回は pyenv を使って Python3.5.1 でホストしています。
昨日この記事を読んで、Anaconda がオススメされているので今度セットアップするときに使ってみよう。
Running a public notebook server | JupyterNotebook Docment こまかい設定等は以下の記事で説明されています。IPython Notebook を対象にした記事ですが、ほとんど一緒なので問題ありません。(config.py 自体がコメントで丁寧に各設定が記述されています。)
IPython notebook サーバーを立ち上げる ipython notebook をリモートサーバ上で動かす。 参考記事 iPython notebook で研究開発生活 Juptyerhub : 講義で Jupyter を利用する。 JupyterNotebook を講義でも活用できるようにならないかなと先生と探していたのですが、Jupyternotebook を公開するだけだとユーザー管理が不可能です。例えば ~tarou/というディレクトリで jupyternotebook を公開すると~tarou/に notebook が沢山できだれがどのノートを作ったのかが把握できないという問題点があります。</description></item><item><title>CoreMLがTensorFlow Liteをサポート</title><link>https://shunyaueta.com/posts/2017-12-06/</link><pubDate>Wed, 06 Dec 2017 13:36:38 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-12-06/</guid><description>TensorFlow 無双
TensorFlow Lite meets CoreML!!
個人的にいま興味ある分野のうちの一つがスマホで動く機械学習なんですが、昨日 TensorFlow Lite が CoreML でサポートされるというアナウンスがありました!
[](https://twitter.com/TensorFlow/status/938127069095002112)
Announcing Core ML support in TensorFlow Lite
CoreML の最大の利点は iPhone のアーキテクチャを最大限に利用した推論の高速化なので、Google も何かしらの手を打ってくると思っていましたがまさかそのまま CoreML にサポートされたのは驚きです。
個人的に keras2, Caffe¹だけがサポートされてる今の状態は選択肢が少なくて微妙だなと思っていたので良いことだと思います。
少し横道にそれますが、ONNX と呼ばれる Machine Leaning のモデルを相互変換できるプロジェクトも立ち上がっているので、近いうちにフレームワーク間の差異は消えていき、書きたいフレームワークで書き、動かしたい環境にモデルを変換して運用するという流れになる未来がくるかもしれません。
ONNX: Open Neural Network Exchange Format
Pixel²も iPhone8³以降に搭載されている A11 チップに機械学習の計算を高速化させるチップが採用されているのでこれから Machine Learning on Mobile はドンドン加速していくとおもいます。iOS11 の吉田さんが担当している CoreML の章を見てましたが、利点と欠点が明快に知れるのでオススメです。
iOS 11 Programming - PEAKS
TensorFlow Lite もデフォルトで Android をサポートしているので、こりゃほんとにプロダクション環境だと TensorFlow 一択になりつつありますね
にしても TensorFlow の勢いはほんとに凄い…</description></item><item><title>Visualized Approximate Eigen Vector by Power Iteration on 3 dimensions.</title><link>https://shunyaueta.com/posts/2017-12-05/</link><pubDate>Tue, 05 Dec 2017 13:20:41 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-12-05/</guid><description>You can intuitively lean Power Iteration by Visualization Power.
Animation of Power Iteration by MATLAB
Power iteration - Wikipedia
Finally you put a command line $ convert -layers optimize -loop 0 -delay 40 eigenvector*.png anim.gif</description></item><item><title>Edge-Weighted Personalized PageRank: Breaking A Decade-Old Performance Barrier を読んだ</title><link>https://shunyaueta.com/posts/2017-12-04/</link><pubDate>Mon, 04 Dec 2017 13:06:15 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-12-04/</guid><description>応用数理研究者が機械学習界に進出していく研究
youtube clip
応用数理界隈ではクラシックな解き方で PageRank が解かれているので最新の数値計算手法に置き換えることで劇的にパフォーマンスが向上して 10 年前のパフォーマンスの鎖を解き放った論文
KDD2015 Best student paper award Slide(PDF) Poster(PDF) Spectral network analysis wenleix/EdgePPR
Presentation Movie is uploaded in Youtube. Author
W. Xie Ph.D Candidate at Cornell University http://wenleix.github.io/ iterative computation on big graph data D. Bindel http://www.cs.cornell.edu/~bindel/ http://www.cs.cornell.edu/~bindel/talks.html He is frequently research activ like ideal young researcher. Nonlinear eigenvalue problem. Alan J. Demers Prof. Johannes Gehrke http://www.cs.cornell.edu/johannes/ Prof. VLDB,SIGMOD,KDD Motivation ページランクは重要な指標。遷移確率を求めるにはランダムサーファーモデル(ランダムウォーク)が必要。 様々な高速解法が提案されている。 Reseatch Question しかし 10 年以上前、PageRank の黎明期から Personalization based の手法は問題がある。 一般的な PageRank の解法の説明、その後に Model Reduction をベースにした約 5 倍の性能を誇る提案手法を説明。 提案手法の性能によって、パフォーマンス上のボトムネックは消えた。 Proposed Method PageRank 初期:WEBPage のランクに使用 → 現在:推薦、ソーシャルネットワーク Random Suffer Model Transition : α の確率で Random Walk(滞在ノードから無作為に遷移) Teleporting : 1−α Random Junmp(滞在ノードに依存せずに全てのノードを対象に無作為遷移) x(t+1)=αPxt+(1−α)v,where P=AD−1 v is represents telepotation probabilitie xt Walker の確率分布 サーファーが来る確率 = RandomWalk の確率_RandomWalk による遷移確率 + RandomJump の確率_RandomJump の遷移確率 = α× RandomWalk による遷移確率 + (1−α)×RandomJump の遷移確率 = α×+(1−α)×v x: Stationary vector(不動ベクトル、定常ベクトル、不動点定理など) x が定常状態になった際に、x の確率分布が PageRank を表す。 x(t),x(t+1)が同一(残差が無い)だと仮定することで、次式の線形方程式を解くことで Pagerank を求める。 Mx=b,where M=(I−αP),b=(1−α)v.</description></item><item><title>Machine Learning that Matters (ICML2012) を読んだ</title><link>https://shunyaueta.com/posts/2017-12-01/</link><pubDate>Fri, 01 Dec 2017 07:55:12 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-12-01/</guid><description>機械学習の研究してる人は全員読んだ方がいい。そう断言できるぐらい良い内容が書かれています。 ICML2012 で発表された最近の機械学習に関する研究の問題点を論じた論文。
Summaly
「あなたは現実世界で役立つデータに対して機械学習の研究を行っていますか?」
著者は NASA の JPL(ジェット推進研究所)、カリフォルニア工科大学に所属する Kiri L.
Kiri L. Wagstaff
発表動画を探してみたんですが、ICML2012 で発表した際のビデオはサーバのクラッシュにより喪失したとのこと。
The video for my controversial ICML 2012 talk is no longer available (lost in a server crash). However, you can read the original paper: Machine Learning that Matters (pdf, 6 pages, 234K) and see the slides from a subsequent invited AAAI talk: Challenges for Machine Learning Impact on the Real World (1.6M). PowerPoint は下記リンク先に配布されています。http://www.</description></item><item><title>Jupyter上でSVGのイラストやアニメーションが作成できるプラグイン egel</title><link>https://shunyaueta.com/posts/2017-11-22/</link><pubDate>Wed, 22 Nov 2017 12:04:30 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-11-22/</guid><description>アイデアは面白い… けど easy drawing ではない
Jupyter 使ってると作図も Jupyter 上で完結させたいなぁ~って思うときがあるんですが、スクリプトで作図はけっこう辛いものがあります
そのため Jupyter 上でフリースタイルに作図できる機能ないかなと探してたら egal という面白そうな拡張機能があったので使ってみました
uclmr/egal
egal GIF animation
以下のリポジトリから $pip3 install git+https://github.com/uclmr/egal.gi
でクローンしてきて $jupyter nbextension install --py egal $jupyter nbextension enable --py egal
で拡張機能を有効にして使えるようになります。
ブラシアイコンをクリックすると新たなセルが生成される
👉 ボタンをクリックすると各オブジェクトの詳細なプロパティが調整できる
フレーム毎にオブジェクトを設定してアニメーションっぽくもできる
5–6 分使ってみて感じましたが、めちゃくちゃ操作がしづらい…
やはりブラウザ上での図形作成はめちゃくちゃストレスたまるので、ローカルで keynote 使って図形作成したほうがマシな感じです。
遊んだ結果を notebook で github にアップしておきました。
残念ながら SVG が Github 上ではレンダリングされないので残念な感じになっております&amp;hellip; ローカルにクローンしてきて egal を有効にしておくと見れます。
hurutoriya/notebook
結論 Jupyter で全てを完結させるのは難しい</description></item><item><title>OpenCV 3.3から使えるDNNモジュールを使って物体検出</title><link>https://shunyaueta.com/posts/2017-11-14/</link><pubDate>Tue, 14 Nov 2017 11:36:43 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-11-14/</guid><description>OpenCV と MobileNet を使って物体検出を行った
Object Detection with OpenCV dnn modules and MobileNetSSD on Jupyter Notebook
Introduction 物体検出を Deep Leaning と OpenCV を用いて行う
OpenCV 3.3 からdnnモジュールが正式にリリースされた
The main news is that we promoted DNN module from opencv_contrib to the main repository, improved and accelerated it a lot. An external BLAS implementation is not needed anymore. For GPU there is experimental DNN acceleration using Halide (http://halide-lang.org_). The detailed information about the module can be found in our wiki: Deep Learning in OpenCV.</description></item><item><title>Djangoで顔認識の結果をJSONで返す最小構成のAPIサーバーを作った</title><link>https://shunyaueta.com/posts/2017-11-13/</link><pubDate>Mon, 13 Nov 2017 17:22:38 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-11-13/</guid><description>DEMO
github でコードを公開してます。
hurutoriya/face_detector_api
Django の勉強は、基本的なイントロダクションとしてオフィシャルサイトのドキュメントが充実しているのでオススメです 。
pyimagesearch の Blog 記事で最小限の構成で顔検出を行う API サーバーを作る記事があり、今回はそれを基本に作成した。
以下所感です。
Django は Rails と比べるとそんなにレールが敷かれていない 日本語の記事がほぼ存在しないので、英語の記事を読む良い練習になった OpenCV や Scikit-lean がそのまま動くのは相当魅力的で、サーバからのレスポンスが帰ってきた時には地味に感動 API 設計や非同期処理なんかの知識が全く足りない 次の課題 今回の発展形として django-rest-framework を使って、モデルを組み込んで作り上げて Google Apps Engine 上で公開してみよう。 REST Framework はこの記事2を参考に画像をアップロードできる雛形は作り上げた。 後は OpenCV で処理を施す部分を書き上げたらいけそう。
django-rest-framework で使える管理画面
Thanks hurutoriya/face_detector_api Django REST Framework を使って爆速で API を実装する,ChristianKreuzberger/django-rest-imageupload-example Creating a face detection API with Python and OpenCV (in just 5 minutes) Django 1.11 Documentation Django REST framework is a powerful and flexible toolkit for building Web APIs.</description></item><item><title>TexPadのおかげでLatex人生が変わりました</title><link>https://shunyaueta.com/posts/2017-10-08/</link><pubDate>Sun, 08 Oct 2017 02:22:24 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-10-08/</guid><description>Latex の煩わしい点が全て解決される Mac のソフトウェアです。
自動補完 synctex 対応(コマンド+クリックで PDF、tex ファイル同期) 自動タイプセット Texpad · Smoothest way to write LaTeX 以前は atom+latexmk で Latex を扱ってましたが、texpad の方が断トツに使い心地が最高です。
購入方法 Appstore か、クレジットカードで Appstore を経由せずに買うかの２つの方法があります。
Appstore はだいぶ前に更新を停止しているみたいなので、クレジットカードを持っている人はクレジットカードを使って MacAppstore を経由せずに購入することをオススメします。
$24.99 しましたが、それ以上の価値があるソフトウェアです。
2 週間の無料体験期間があるので是非お試し下さい。
下記のスクリーンショットのように、beamer も texpad で動くのは感動モノ。
beamer on texpad
日本語で TexPad を扱いたいときは下記のスクリプトを読み込んだら、bibtex のバグが治ります。</description></item><item><title>ミクシィにインターンしてきた #2013 #DeployGate</title><link>https://shunyaueta.com/posts/2013-12-23/</link><pubDate>Mon, 23 Dec 2013 17:04:38 +0000</pubDate><guid>https://shunyaueta.com/posts/2013-12-23/</guid><description>株式会社ミクシイに 2013/8/9~2013/9/20 までインターンしてきました。 2013 年当時のスクリーンショットを探してたが、無かったので 2017/12/24 のを撮ってきた。良い意味であまり変わってない(ライさんの謎のくるまアプリとか)
Dive into mixi
なぜインターンに行こうと思ったのか 僕は高専から筑波大学の情報系に今年度から編入したんですが、
編入してから同期の編入生や先輩、内部生の人達に会って 「このままじゃダメだ、もっと面白く!もっと楽しく生きる!!」 と感じたので参加しました。
…つまり、面白そうな事をしたかったので参加しました。 選考過程 エントリーリーシートを提出、希望する配属先はここで提出します。 2 回の面接があるのですが、つくばから渋谷への道のりは遠いので一回にしてくれました。ありがとうございます！！
面接の服装は、スーツじゃなくて良いので楽です！(むしろスーツはやめてねと言われました)
自己紹介と自分のこれまでの成果物を面接官に説明した後に、質疑応答を 30 分、時間が 20 分ほど余ったので面接官の方から「気になってることをなんでも聞いて下さい」と言われて質問をしていると面接がいつの間にか終わりました。
合否発表は翌日に連絡がきて無事合格することができました、嬉しい!!
配属先 僕は第一希望のDeployGateに配属されました。
DeployGate チームは社員二人、インターン三人という謎構成でした。
「DepoyGate」とは、ミクシィ社の新規事業第 1 弾として登場した Android アプリ提供者向けのテスト版アプリ配信サービスです。 アプリをワイヤレスで配布することができ、アップデータ配信や動作ログがリアルタイムに取得できるので、プロジェクトメンバー全員が常に最新版アプリに触れることができます。 2012 年 9 月のサービス開始から、世界 93 ヵ国 3600 以上のアプリ開発に利用され、そのユーザーの 76％は英語圏というグローバルなサービスでもあります。 「DepoyGate」エンジニアからの発案で生まれたサービスです。 最新の技術に触れ、一緒に開発を進めていきたいという、あなたのチャレンジをお待ちしております。### メリット
今回のミクシィインターンは 6 週間を超える長期のインターンで実際に提供されているサービスの開発に参加すること t ができます。
デメリット 基本的に無いです。
強いて言うなら夏休みが 4/5 ほど持ってかれたことですね。
何をやった？ 基本的に Github に issue に上がってるチケットを消化していく感じでした。 自分でこれがあったら便利だなと思う機能を追加したり、不便な箇所を改修したりして、GO サインが出たら Depoloy していきます。</description></item><item><title>機械学習・コンピュータビジョンを活かしたビジネスを手掛ける株式会社ABEJAでインターンしてきた</title><link>https://shunyaueta.com/posts/2013-08-23/</link><pubDate>Fri, 23 Aug 2013 17:18:02 +0000</pubDate><guid>https://shunyaueta.com/posts/2013-08-23/</guid><description>株式会社 ABEJA という会社に 2013/8/25~2013/9/26 間に 2 週間弱インターンシップに参加してきました。
2013 年当時のサイトのスクショ
What’S ABEJA? ABEJA について詳しく知りたい方は下記のリンクを見るとわかりやすいです。
マーケティングから決済まで、人認証技術 × ビジネスプロデュースで未来を変える ABEJA の挑戦【連載:NEO ジェネ！】 いまそこにある、リアルタイムデータ解析。ぼくらの暮らしを変える、日本のスタートアップ 3 社 この会社をはじめて知ったのは、ミクシィでのインターンシップに参加してた時に別グループでインターンしていた知り合いの人に教えてもらったのがキッカケです。 機械学習や画像解析を用いて、現実世界の問題を解決して更にビジネスにまで昇華させている点に痺れました。
本来なら一ヶ月近くコミットできる予定だったんですが、もう一つ挑戦していた別のインターンに運良く合格したので結果的には 2 週間弱という短めのインターンになりました。
What do you doing in ABEJA intern? インターンの内容は Python を使って社内用のツールをゴニョゴニョしてました。
郷に従います。(StyleGuide 見てなかった…) / 他 2 コメント http://t.co/5I0nThs4rU “PEP 8 — Style Guide for Python Code” http://t.co/in7q9lD6cy&amp;gt; — UEDA (@hurutoriya) 2014, 9 月 25
普段は matlab か Ruby 書いてるんですが、普段書いてない言語を書くとあまりよろしくないコードになったので StyleGuide 導入しました。</description></item></channel></rss>