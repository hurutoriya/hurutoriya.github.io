<!doctype html><html lang=ja dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Amazon の製品検索で使われるロバストなキャッシュ手法の論文「ROSE: Robust Caches for Amazon Product Search」 | 🦅 hurutoriya</title><meta name=keywords content="search,machinelearning,paper"><meta name=description content="Web 検索とデータマイニングのトップカンファレンス WSDM2022 のワークショップで The First International Workshop on INTERACTIVE AND SCALABLE INFORMATION RETRIEVAL METHODS FOR ECOMMERCE (ISIR-ecom) が先日開催された。
テーマは e コマース上での検索において
 検索システムのスケーラビリティ どうやって適合性(Relevancy)をシステムで改善したか システムの改善  についてをテーマにした検索エンジニアなら垂涎もののワークショップとなっている。
同様の検索システムや実応用に注目したワークショップでは、以下のようなワークショップがある。
 SIGIR Workshop On eCommerce 2017 年から毎年開催。累計 5 回開催 International Workshop on Industrial Recommendation Systems 2020 年から開催。累計二回  歴史としては、 SIGIR ecom が長く、これだけの期間継続開催してくれているのはありがたい限り。
機械学習系の国際会議でも手法ではなく、どう現実世界に適用したかに注目したワークショップが益々誕生しており非常に良い流れ。
ACCEPTED PAPERS は 5 本あり、
 Amazon: 2 eBay: 1 The Home depot: 2  と企業関係者による論文が 100%となっている。
https://github.com/ISIR-eCom/ISIR-eCom.github.io/tree/main/papers 最後の PDF 番号が 9 なので、最低でも 9 本の投稿はあった模様。"><meta name=author content="Shunya Ueta"><link rel=canonical href=https://shunyaueta.com/posts/2022-03-03/><link crossorigin=anonymous href=/assets/css/stylesheet.min.f00f189851525f5dc525fa12dfc10fa3656c6cc16f26285e5f7347522031587e.css integrity="sha256-8A8YmFFSX13FJfoS38EPo2VsbMFvJiheX3NHUiAxWH4=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.27cd435cc9ed6abb4b496581b151804f79f366c412620272bb94e2f5f598ebcc.js integrity="sha256-J81DXMntartLSWWBsVGAT3nzZsQSYgJyu5Ti9fWY68w=" onload=hljs.initHighlightingOnLoad();></script><link rel=icon href=https://shunyaueta.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://shunyaueta.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://shunyaueta.com/favicon-32x32.png><link rel=apple-touch-icon href=https://shunyaueta.com/apple-touch-icon.png><link rel=mask-icon href=https://shunyaueta.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme: rgb(29, 30, 32);--entry: rgb(46, 46, 51);--primary: rgb(218, 218, 219);--secondary: rgb(155, 156, 157);--tertiary: rgb(65, 66, 68);--content: rgb(196, 196, 197);--hljs-bg: rgb(46, 46, 51);--code-bg: rgb(55, 56, 62);--border: rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','UA-39994406-11','auto');ga('send','pageview');}</script><meta property="og:title" content="Amazon の製品検索で使われるロバストなキャッシュ手法の論文「ROSE: Robust Caches for Amazon Product Search」"><meta property="og:description" content="Web 検索とデータマイニングのトップカンファレンス WSDM2022 のワークショップで The First International Workshop on INTERACTIVE AND SCALABLE INFORMATION RETRIEVAL METHODS FOR ECOMMERCE (ISIR-ecom) が先日開催された。
テーマは e コマース上での検索において
 検索システムのスケーラビリティ どうやって適合性(Relevancy)をシステムで改善したか システムの改善  についてをテーマにした検索エンジニアなら垂涎もののワークショップとなっている。
同様の検索システムや実応用に注目したワークショップでは、以下のようなワークショップがある。
 SIGIR Workshop On eCommerce 2017 年から毎年開催。累計 5 回開催 International Workshop on Industrial Recommendation Systems 2020 年から開催。累計二回  歴史としては、 SIGIR ecom が長く、これだけの期間継続開催してくれているのはありがたい限り。
機械学習系の国際会議でも手法ではなく、どう現実世界に適用したかに注目したワークショップが益々誕生しており非常に良い流れ。
ACCEPTED PAPERS は 5 本あり、
 Amazon: 2 eBay: 1 The Home depot: 2  と企業関係者による論文が 100%となっている。
https://github.com/ISIR-eCom/ISIR-eCom.github.io/tree/main/papers 最後の PDF 番号が 9 なので、最低でも 9 本の投稿はあった模様。"><meta property="og:type" content="article"><meta property="og:url" content="https://shunyaueta.com/posts/2022-03-03/"><meta property="og:image" content="https://shunyaueta.com/posts/2022-03-03/images/fig-1.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-03-03T09:35:29+09:00"><meta property="article:modified_time" content="2022-05-10T22:59:57+09:00"><meta property="og:site_name" content="Shunya Ueta"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://shunyaueta.com/posts/2022-03-03/images/fig-1.png"><meta name=twitter:title content="Amazon の製品検索で使われるロバストなキャッシュ手法の論文「ROSE: Robust Caches for Amazon Product Search」"><meta name=twitter:description content="Web 検索とデータマイニングのトップカンファレンス WSDM2022 のワークショップで The First International Workshop on INTERACTIVE AND SCALABLE INFORMATION RETRIEVAL METHODS FOR ECOMMERCE (ISIR-ecom) が先日開催された。
テーマは e コマース上での検索において
 検索システムのスケーラビリティ どうやって適合性(Relevancy)をシステムで改善したか システムの改善  についてをテーマにした検索エンジニアなら垂涎もののワークショップとなっている。
同様の検索システムや実応用に注目したワークショップでは、以下のようなワークショップがある。
 SIGIR Workshop On eCommerce 2017 年から毎年開催。累計 5 回開催 International Workshop on Industrial Recommendation Systems 2020 年から開催。累計二回  歴史としては、 SIGIR ecom が長く、これだけの期間継続開催してくれているのはありがたい限り。
機械学習系の国際会議でも手法ではなく、どう現実世界に適用したかに注目したワークショップが益々誕生しており非常に良い流れ。
ACCEPTED PAPERS は 5 本あり、
 Amazon: 2 eBay: 1 The Home depot: 2  と企業関係者による論文が 100%となっている。
https://github.com/ISIR-eCom/ISIR-eCom.github.io/tree/main/papers 最後の PDF 番号が 9 なので、最低でも 9 本の投稿はあった模様。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Amazon の製品検索で使われるロバストなキャッシュ手法の論文「ROSE: Robust Caches for Amazon Product Search」","item":"https://shunyaueta.com/posts/2022-03-03/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Amazon の製品検索で使われるロバストなキャッシュ手法の論文「ROSE: Robust Caches for Amazon Product Search」","name":"Amazon の製品検索で使われるロバストなキャッシュ手法の論文「ROSE: Robust Caches for Amazon Product Search」","description":"Web 検索とデータマイニングのトップカンファレンス WSDM2022 のワークショップで The First International Workshop on INTERACTIVE AND SCALABLE INFORMATION RETRIEVAL METHODS FOR ECOMMERCE (ISIR-ecom) が先日開催された。\nテーマは e コマース上での検索において\n 検索システムのスケーラビリティ どうやって適合性(Relevancy)をシステムで改善したか システムの改善  についてをテーマにした検索エンジニアなら垂涎もののワークショップとなっている。\n同様の検索システムや実応用に注目したワークショップでは、以下のようなワークショップがある。\n SIGIR Workshop On eCommerce 2017 年から毎年開催。累計 5 回開催 International Workshop on Industrial Recommendation Systems 2020 年から開催。累計二回  歴史としては、 SIGIR ecom が長く、これだけの期間継続開催してくれているのはありがたい限り。\n機械学習系の国際会議でも手法ではなく、どう現実世界に適用したかに注目したワークショップが益々誕生しており非常に良い流れ。\nACCEPTED PAPERS は 5 本あり、\n Amazon: 2 eBay: 1 The Home depot: 2  と企業関係者による論文が 100%となっている。\nhttps://github.com/ISIR-eCom/ISIR-eCom.github.io/tree/main/papers 最後の PDF 番号が 9 なので、最低でも 9 本の投稿はあった模様。","keywords":["search","machinelearning","paper"],"articleBody":"Web 検索とデータマイニングのトップカンファレンス WSDM2022 のワークショップで The First International Workshop on INTERACTIVE AND SCALABLE INFORMATION RETRIEVAL METHODS FOR ECOMMERCE (ISIR-ecom) が先日開催された。\nテーマは e コマース上での検索において\n 検索システムのスケーラビリティ どうやって適合性(Relevancy)をシステムで改善したか システムの改善  についてをテーマにした検索エンジニアなら垂涎もののワークショップとなっている。\n同様の検索システムや実応用に注目したワークショップでは、以下のようなワークショップがある。\n SIGIR Workshop On eCommerce 2017 年から毎年開催。累計 5 回開催 International Workshop on Industrial Recommendation Systems 2020 年から開催。累計二回  歴史としては、 SIGIR ecom が長く、これだけの期間継続開催してくれているのはありがたい限り。\n機械学習系の国際会議でも手法ではなく、どう現実世界に適用したかに注目したワークショップが益々誕生しており非常に良い流れ。\nACCEPTED PAPERS は 5 本あり、\n Amazon: 2 eBay: 1 The Home depot: 2  と企業関係者による論文が 100%となっている。\nhttps://github.com/ISIR-eCom/ISIR-eCom.github.io/tree/main/papers 最後の PDF 番号が 9 なので、最低でも 9 本の投稿はあった模様。\n素晴らしいワークショップなので、来年も是非継続して開催してほしい。\nすべての採択論文が面白そうだったが、今回は Amazon Search が公開した Chen Luo らの「ROSE: Robust Caches for Amazon Product Search」を紹介する。\n私的な感想やコメントは NOTE: で始める文章で書き留めています。\n一言で説明 クエリの書き換え(誤植を修正する)と深層学習モデルの結果のキャッシュを同時に行えるキャッシュシステム ROSE を提案して、検索システムの応答速度と検索性能を改善。\nCitation  ROSE: Robust Caches for Amazon Product Search, Chen Luo, Vihan Lakshman, Anshumali Shrivastava, Tianyu Cao, Sreyashi Nag, Rahul Goutam, Hanqing Lu, Yiwei Song and Bing Yin, Proceedings of the International Workshop on Interactive and Scalable Information Retrieval methods for eCommerce (ISIR-eCom), 2022.\n 概要 Amazon Search のような商品検索エンジンはしばしばキャッシュを利用する。 キャッシュによって Amazon の製品検索での顧客体験を向上させることができる。 顧客体験だけではなく、検索システムのレイテンシも大幅に向上する。\nだが、検索トラフィックが増大しキャッシュサイズが大きくなりすぎると検索システム全体のパフォーマンスが劣化してしまう。 また、誤字やスペルミス、現実世界で見られる冗長な表現のクエリは不必要なキャッシュミスを引き起こし、キャッシュの効率性を低下させる。\n「RObuSt cachE(ROSE)」はロックアップコストはそのままにスペルミスや誤字を許容可能なキャッシュシステムを提案。 ROSE はあらゆるクエリの意図、誤字、文法ミスに対して理論的な頑健性が保証されている。 現実世界のデータセットにより ROSE を評価して、有効性と効率は検証を行った。 ROSE はすでに Amazon の検索エンジンにデプロイされており、既存のキャッシュシステムと比較しても大きくビジネス指標を改善している。\nINTRODUCTION 検索エンジンで大事な２つのパフォーマンス指標\n 顧客化からのリクエストに対するレスポンスタイム 顧客の意図に適合した高品質な検索結果  現代的な製品検索エンジンでは通常、計算不可が高い機械学習モデルが多く使われている。\nNOTE: [1, 8, 9, 13, 20, 28, 29, 31] の参考文献が、検索改善のための機械学習適用の文献リストとして有用そうだった。 [18] relevance matching models。[2] ranking models。[27] query annotation models。\nレイテンシの制限とコストの考慮により、実際の製品検索エンジンでは、計算コストが高い深層学習モデルをサービングして検索トラフィック全体を処理することは禁止されている[14]。そのため、深層学習モデルの推論結果をサービングする代わりに、より実践的な解決方法として頻繁にリクエストがくるクエリに対して深層学習モデルの結果をキャッシュしておく。\n従来のキャッシュは以下のようなトレードオフの問題がある\nキャッシュミス率とキャッシュサイズの関係: 小さいキャッシュサイズでは、高いキャッシュミス率となる。一方で製品検索エンジンの規模で頻繁に検索されるクエリに対してキャッシュを作成したとして異常にキャッシュサイズが大きくなってしまう。また、 ”Nike shoes”, “Nike shoe”, and “Nike’s shoe” のような同じ意図のクエリだが、形態素的には異なるそれらのクエリはすべて別のキャッシュとしてキャッシュされてしまう。\nまた、 Query rewrite for null and low search results in eCommerce. In eCOM@ SIGIR. [24]でも示されている通り、検索結果の品質を下げている要因のほとんどが 誤植)。 これらの検索品質が低いクエリは、高品質な検索結果を提供する頻繁に検索されるクエリと語彙的(Lexically) または意味的 (semantically)に似ている。\nよって、もし我々が低品質な検索結果を提供する誤植のクエリを、同じ意図を持つクエリへキャッシングの仕組みにより紐付ける(map する)ことができたなら、検索品質を向上させることができる。また、レイテンシも大幅に向上させ、キャッシュサイズも大幅に抑えることができる。\nFig. 1: ROSE は検索品質と検索速度を向上させる\n キャッシュによるクエリの書き換え(query rewrite)によって検索品質の向上 ROSE が大半の通信をカバーすることで、検索速度の向上。キャッシュヒットしないような少数派のクエリに対しては、深層学習モデルによって直接サービングを行う。  ３つの貢献点  運用システム: 製品検索のクエリをキャッシュするための、ROSE を提案。定数時間と定数メモリで web 検索規模のデータのインデックスを作成してルックアップを実行可能 技術的革新: local-sensitive hashing, reservoir sampling, count-based k-selection など複数の強力な乱択アルゴリズム技術を組み合わせたシステムを開発。これにより、定数時間での検索を維持しながら ROSE を大規模なクエリセットにスケールアップが可能になった。 現実世界での効果: Amazon 検索に ROSE をデプロイしており、既存手法と比べてパフォーマンス、ビジネス指標ともに改善された。  BACKGROUND AND RELATED WORK Robust Cashes 検索エンジンやデータベースなど応答速度がクリティカルなアプリケーションではキャッシュはとても有効なアプローチ。 hash-tables と Bloom fillters によって、キャッシュは完全一致によるキャッシュなどが考案されている[16]。 だが完全一致に注目しているため誤植に弱く従来の完全一致キャッシュでは、キャッシュヒット率が低くなってしまう。 逆に従来の単語のゆらぎに頑健(ロバスト)なキャッシュ手法は、キャッシュの文字列の類似距離を計算するコストが非常に高かった。\n定数時間と定数メモリで実行可能なロバストなキャッシュの仕組みである「ROSE」提案する。\nLocality-Sensitive Hasing LSH の解説資料はこちらの資料がわかりやすかった。\nLocality Sensitive Hashing\n他にも LSH の発展形として Jaccard 類似度を使った LSH である Minwise Hasing(MinHash) や Densified One Permutation Hashing (DOPH) なども紹介されていた。\nNOTE: 時間が足りないので一旦深い解説は割愛する。ここらへんは自分の知識が浅い部分なのでちゃんと理解しておきたい。\n問題の定式化 ROSE のフレームワーク解説\n クエリキーワードからロバストなキャッシュインデックス生成 オンライン検索: 入力されたクエリをキャッシュ上の別のクエリにマッピングする  ROSE: ROBUST CACHE VIA RANDOMIZED HASHING ROSE Index Generation ROSE のインデックス生成時には２つの条件\n 誤植や意味的に同じだが異なるクエリでもロバストな性能のために、キャッシュのルックアップ時に入力クエリの類似度を計算してマップする 大規模な製品検索エンジンなので、キャッシュサイズはクエリの量に応じてスケーリングすることを回避する必要がある  LSH のアプローチでは、データの規模に対して線形にハッシュテーブルのサイズが増加する課題がある[23]。 この課題は web 規模のデータを扱うと容易にメモリが爆発を引き起こす。 その課題を解決するために reservoir sampling algorithm[25] を使って解決している。\nreservoir sampling algorithm の日本語の解説記事はこちら\n大量のテキストからランダムに少数の行を抽出したい - Reservoir Sampling\nNOTE: ここ完全に理解不足なので言葉だけ理解。\nB はハッシュテーブルハッシュテーブルのバケットの数、Iq はハッシュ関数により生成されたインデックス。 Rand(0,B)は-から B までの乱数を生成する関数。\nROSE Online Retrieval クエリが入力された際に、ROSE は Count-based 𝑘-selection [15]という手法を使って、計算コストの高い 2 点間の類似度(pairwise-similarity)の計算を避けている。 ROSE のオンライン検索が定数時間で終わることは、3.5 Theoretical Analysisにて解説。\nLexical Preserving Hashing Lexical Preserving Hashing は語彙的な類似度を保持したハッシュ手法を指す。 クエリ間の類似度は Jacard 類似度を使って計算する。(つまるところ minhash?) 実際に計算する際には DOPS を使って minhash を算出する。\nROSE による誤植修正のための Lexical Preserving Hashing によるマッピング例: 「red nike shoos」 → 「red nike shoes」\nProduct Type Preserving Hashing 製品検索エンジンでは、クエリの製品タイプを理解することが関連した高品質な検索結果を提供するためにとても重要である。\n具体例: 「red nike shoes」 のクエリの製品タイプは 「SHOES」\nここで製品タイプをクエリから抽出するために、クエリのトークンに対して製品タイプの重みを計算する。製品タイプのトークンは QUEACO: Borrowing Treasures from Weakly-labeled Behavior Data for Query Attribute Value Extraction[30] という NER モデルによって抽出される。\n製品タイプトークンが存在しなかった場合の重みは 1、1 より以上の場合は製品タイプトークンが抽出できたことになる。 製品タイプトークンの重み付けは W 1 で与え、チューニングした結果 W=10 が最も結果が良好製品タイプトークンは W というしきい値で管理される。\nTheoretical Analysis アルゴリズムの理論解析について。 だが、知識がまったくないので、割愛することにした。\nオフラインでの実験 データセット 約 6 億の検索品質が高いクエリを Amazon 検索からサンプリングして、評価のためのキャッシュ対象にする。 ここでは、Xichuan ら A Dual Heterogeneous Graph Attention Network to Improve Long-Tail Performance for Shop Search in E-Commerce. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \u0026 Data Mining. 3405–3415 [19]と同じ評価の枠組みで評価を行った。\nクエリの評価データセットは頻度ごとに分割された３つのバケットを用意\n NQ(Normal Queries): 頻度が上位 33%(1 つめの 3 分位数)のクエリ HQ(Hard queries): 頻度が上位 34%-66% (1 つめの 3 分位数)のクエリ LTQ(Long-tail queries): 頻度が上位 67%-100% (3 つめの 3 分位数)のクエリ  ランダムに上記のクエリを一ヶ月以上の検索ログから選択して収集する。３つのバケットは 1000 のクエリが存在してる。ドメインエキスパートによる判断により、ROSE の仕組みにより re-map された結果が元のクエリが書き換えられても意図が同一かどうかの 2 値(relevant or irrelevant)によって評価。\n実験デザイン ２つの指標に対する仮設\n Robustness: どれぐらい ROSE は正確か? Efficnency: どれぐらい ROSE のインデキシングと検索処理は効率的か?  それらの仮設検証のために\n R-LP: 提案手法。ROSE の lecical preserving hasing。 ハッシュテーブルの数は L=3 6 かつ、ハッシュの数は $K=3$ R-PT: 提案手法。ROSE の product type preserving hasing EC: 完全一致によるキャッシュ実装 BF: ROSE の検索アルゴリズムを力まかせ探索に置き換えた手法。類似度の尺度として DP を使って編集距離を計算する。 FC: FAISS のアルゴリズムを使って ROSE のインデキシングと検索アルゴリズムを置き換えた手法。クエリの埋め込み空間は Semantic Product Search を使って用意。  評価指標としては、一般的な Precision, Recall, F1 を採用。\n各指標の具体例としては、 例えば「red nike shoes」という original intent となるクエリが存在するとする。この「red nike shoes」と original intent は同一だが、語彙的な誤りによって「red nike shoos」、「red nike shooes」などのクエリが存在する。\nこれら、「red nike shoes」を original intent とするクエリ数が 20 件あり、以下のような分布になっている。\n 「red nike shoes」: 10 件  「red nike shoos」: 5 件 「red nike shooes」: 5 件    例えば、完全一致キャッシュでは、「red nike shoes」とう文字列に対して lool up を行い、\n precision: 100% recall: 50%  となる。\nそして、ROSE-LP が 「red nike shoos」を「red nike shoes」に対して map ができたとする。(「red nike shooes」の map は失敗)\n precision: 100% recall: 75%  となる。\n上記のように誤植が含まれるクエリをどれだけ各種手法で書き換えることができたかが、評価指標となっている。\n全体を通した実験結果 検索性能 NQ, HQ に対しては ROSE-PT が最も性能が良く、LTQ に対しては ROSE-LP の性能が良かった。\nシステム性能 ROSE-LP は 60m でインデックス生成を完了。ROSE-PT は 75m。\nNOTE: 論文中だとシステム性能としても性能が良いと書いてあるが、他の手法のほうが早いのでこの書き方は実際どうなんだろう。と思いつつも、検索性能がこれだけ上がって cache index 作成も 65m だけで済んでいるなら全く問題なさそう。\n検索面では、力まかせ探索だと 65m(ms ではない)検索に時間がかかるらしいので、使い物にならなさそう。FAISS が 120ms 必要な中で ROSE は LP, PT ともに 3ms 以下という驚異的な速度。\n図 3 では、ROSE が担っている２つのコンポーネントを解説。\n (a) 誤植の問題を解決するクエリ書き換え。「nike shoos」という誤植のクエリが来た際に、「nike shoes」に書き換え (b) 深層学習モデル高速化のためのキャッシュ上での製品タイプ予測。Cash Hit した場合、ROSE によってクエリ(q)の製品タイプ(PT)を返す。キャッシュヒットしなかった場合は、深層学習モデルによってクエリに製品タイプの推論を行い、返す。  SYSTEM DEPLOYMENT IN AMAZON ROSE for Query Rewrite 顧客が誤植によるクエリクエリを入力してきた際にクエリ書き換えを行うために実際に ROSE をデプロイ。使った手法は ROSE-LP。これによって、検索結果がそもそも低品質なクエリが高品質な検索結果として提示されるようになった。\nオンラインのクエリ書き換えの結果はドメインエキスパートにり測定・評価され、良好な結果となった。 また、複数のビジネス指標も有意に改善された。\nNOTE: CTR +7%ってすごくないですか…? 今までも、Amazon なのでもちろん Query Understanding に取り組んでいたと思うんだが、従来のクエリ書き換えよりも更に良くなったということだろうか?実際は ROSE によって検索の応答速度も改善されているので、変数は２つとなり難しいところではある。 また、Amazon の規模での利益 0.42% 上昇って半端ないですね。深層学習モデルのキャッシュでもあるので、特徴量の前処理改善にもなっていることに気がついた。\nROSE for Product Type Annotation 「red nike shoes」のようなクエリは、クエリから正しい製品タイプを特定することで、正しい製品を検索できたり、製品タイプによって検索結果を変更することが可能。\n500 万-1000 万の規模の高頻度なクエリに対して、クエリから特定の製品タイプへマッピングする ROSE を実装。\nROSE は受け取った tail query に対して、そのクエリをキャッシュされたいくつかのクエリにマッピングし、そのクエリと紐付いている製品タイプを tail query の製品タイプの予測結果として使用する。\n検索体験への影響を評価するため、ROSE の商品タイプ予測モデルを用いて、誤った商品タイプを持つ無関係な検索結果をフィルタリングし、このシステムを Amazon.com にデプロイし商品検索エンジンにおいて、ROSE により商品タイプを認識した場合としない場合の検索結果の不具合率(Defects Rate)を測定。\n製品タイプ不良率(Product type defect rate)とは、検索結果の上位 16 件に含まれる商品のうち、製品タイプが誤っている数として定義。\n表 2 より、ROSE による製品タイプを予測することで、欠陥率が 1.7%減少し、ユーザーエクスペリエンスが大幅に改善されたことがわかる。\n図 4 では ROSE によって予測された製品タイプのフィルターを通した結果の違いが示されている。\nNOTE: でもこの部分ではビジネス指標について触れていないということは、欠陥率しか改善しなかったのかなと邪推した。(それでも十分凄いけど)\n 社内の検索勉強会の発表順が回ってきたので、最近見つけた面白そうな論文である ROSE を読んでみた。 読んでいて非常に面白い論文で手法もさることながらビジネス指標もリフトさせているの本当にすごいし、価値がありますね。 この成果を公開してくれた Amazon に感謝\n面白い論文は、引用する論文もイケているので周辺知識を深堀りしたい際に辞書的に使えるのもありがたい。\nクエリの書き換えをキャッシュ(ROSE)に搭載して、システム的に密結合になったり、運用面で大変になったりしないのかなと思いつつも、これだけ性能が良いのならそれらを補って良い事だらけではと感じた。\n振り返ってみると最近 Amazon が公開してくれている検索ネタを今回含めて 3 連続で読んで解説していたが\n Daria Sorokina さんによる、 Amazon の検索ランキングについて at MLconf SF 2016 Amazon が e コマース検索を Lucene により、どうスケールさせているか at Berlin Buzzwords 2019  それくらい面白い論文が多いのと e コマース検索だと飛び抜けて先進的な取り組みをしている印象。\n次は The First International Workshop on INTERACTIVE AND SCALABLE INFORMATION RETRIEVAL METHODS FOR ECOMMERCE (ISIR-ecom) の別の採択論文を読む。\nおそらく次に読むのは\n E-commerce Product Attribute Value Validation and Correction Based on Transformers: Le Yu, Haozheng Tian, Yun Zhu, Simon Hughes and Aleksandar Velkoski\n ","wordCount":"803","inLanguage":"ja","image":"https://shunyaueta.com/posts/2022-03-03/images/fig-1.png","datePublished":"2022-03-03T09:35:29+09:00","dateModified":"2022-05-10T22:59:57+09:00","author":{"@type":"Person","name":"Shunya Ueta"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://shunyaueta.com/posts/2022-03-03/"},"publisher":{"@type":"Organization","name":"🦅 hurutoriya","logo":{"@type":"ImageObject","url":"https://shunyaueta.com/favicon.ico"}}}</script></head><body id=top><script>if(localStorage.getItem("pref-theme")==="dark"){document.body.classList.add('dark');}else if(localStorage.getItem("pref-theme")==="light"){document.body.classList.remove('dark')}else if(window.matchMedia('(prefers-color-scheme: dark)').matches){document.body.classList.add('dark');}</script><header class=header><nav class=nav><div class=logo><a href=https://shunyaueta.com/ accesskey=h title="🦅 hurutoriya (Alt + H)">🦅 hurutoriya</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://shunyaueta.com/archives title=Archive><span>Archive</span></a></li><li><a href=https://shunyaueta.com/about title=About><span>About</span></a></li><li><a href=https://shunyaueta.com/index.xml title=RSS><span>RSS</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Amazon の製品検索で使われるロバストなキャッシュ手法の論文「ROSE: Robust Caches for Amazon Product Search」</h1><div class=post-meta><span title="2022-03-03 09:35:29 +0900 +0900">March 3, 2022</span>&nbsp;·&nbsp;Shunya Ueta&nbsp;|&nbsp;<a href=https://github.com/hurutoriya/hurutoriya.github.io/tree/source/content/posts/2022-03-03/index.md rel="noopener noreferrer" target=_blank>Edit this post (この記事を編集する)</a></div></header><figure class=entry-cover><img loading=lazy src=https://shunyaueta.com/posts/2022-03-03/images/fig-1.png alt="ROSE の概要"><p>ROSE の概要</p></figure><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>目次</span></summary><div class=inner><ul><li><a href=#%e4%b8%80%e8%a8%80%e3%81%a7%e8%aa%ac%e6%98%8e aria-label=一言で説明>一言で説明</a></li><li><a href=#citation aria-label=Citation>Citation</a></li><li><a href=#%e6%a6%82%e8%a6%81 aria-label=概要>概要</a></li><li><a href=#introduction aria-label=INTRODUCTION>INTRODUCTION</a><ul><li><a href=#%ef%bc%93%e3%81%a4%e3%81%ae%e8%b2%a2%e7%8c%ae%e7%82%b9 aria-label=３つの貢献点>３つの貢献点</a></li></ul></li><li><a href=#background-and-related-work aria-label="BACKGROUND AND RELATED WORK">BACKGROUND AND RELATED WORK</a><ul><li><a href=#robust-cashes aria-label="Robust Cashes">Robust Cashes</a></li><li><a href=#locality-sensitive-hasing aria-label="Locality-Sensitive Hasing">Locality-Sensitive Hasing</a></li><li><a href=#%e5%95%8f%e9%a1%8c%e3%81%ae%e5%ae%9a%e5%bc%8f%e5%8c%96 aria-label=問題の定式化>問題の定式化</a></li></ul></li><li><a href=#rose-robust-cache-via-randomized-hashing aria-label="ROSE: ROBUST CACHE VIA RANDOMIZED HASHING">ROSE: ROBUST CACHE VIA RANDOMIZED HASHING</a><ul><li><a href=#rose-index-generation aria-label="ROSE Index Generation">ROSE Index Generation</a></li><li><a href=#rose-online-retrieval aria-label="ROSE Online Retrieval">ROSE Online Retrieval</a></li><li><a href=#lexical-preserving-hashing aria-label="Lexical Preserving Hashing">Lexical Preserving Hashing</a></li><li><a href=#product-type-preserving-hashing aria-label="Product Type Preserving Hashing">Product Type Preserving Hashing</a></li><li><a href=#theoretical-analysis aria-label="Theoretical Analysis">Theoretical Analysis</a></li></ul></li><li><a href=#%e3%82%aa%e3%83%95%e3%83%a9%e3%82%a4%e3%83%b3%e3%81%a7%e3%81%ae%e5%ae%9f%e9%a8%93 aria-label=オフラインでの実験>オフラインでの実験</a><ul><li><a href=#%e3%83%87%e3%83%bc%e3%82%bf%e3%82%bb%e3%83%83%e3%83%88 aria-label=データセット>データセット</a></li><li><a href=#%e5%ae%9f%e9%a8%93%e3%83%87%e3%82%b6%e3%82%a4%e3%83%b3 aria-label=実験デザイン>実験デザイン</a><ul><li><a href=#%e5%85%a8%e4%bd%93%e3%82%92%e9%80%9a%e3%81%97%e3%81%9f%e5%ae%9f%e9%a8%93%e7%b5%90%e6%9e%9c aria-label=全体を通した実験結果>全体を通した実験結果</a><ul><li><a href=#%e6%a4%9c%e7%b4%a2%e6%80%a7%e8%83%bd aria-label=検索性能>検索性能</a></li><li><a href=#%e3%82%b7%e3%82%b9%e3%83%86%e3%83%a0%e6%80%a7%e8%83%bd aria-label=システム性能>システム性能</a></li></ul></li></ul></li></ul></li><li><a href=#system-deployment-in-amazon aria-label="SYSTEM DEPLOYMENT IN AMAZON">SYSTEM DEPLOYMENT IN AMAZON</a><ul><li><a href=#rose-for-query-rewrite aria-label="ROSE for Query Rewrite">ROSE for Query Rewrite</a></li><li><a href=#rose-for-product-type-annotation aria-label="ROSE for Product Type Annotation">ROSE for Product Type Annotation</a></li></ul></li></ul></div></details></div><div class=post-content><p>Web 検索とデータマイニングのトップカンファレンス WSDM2022 のワークショップで
<a href=https://isir-ecom.github.io/>The First International Workshop on INTERACTIVE AND SCALABLE INFORMATION RETRIEVAL METHODS FOR ECOMMERCE (ISIR-ecom)</a> が先日開催された。</p><p>テーマは e コマース上での検索において</p><ul><li>検索システムのスケーラビリティ</li><li>どうやって適合性(Relevancy)をシステムで改善したか</li><li>システムの改善</li></ul><p>についてをテーマにした検索エンジニアなら垂涎もののワークショップとなっている。</p><p>同様の検索システムや実応用に注目したワークショップでは、以下のようなワークショップがある。</p><ul><li><a href=https://sigir-ecom.github.io/>SIGIR Workshop On eCommerce</a> 2017 年から毎年開催。累計 5 回開催</li><li><a href=https://irsworkshop.github.io/2021/>International Workshop on Industrial Recommendation Systems</a> 2020 年から開催。累計二回</li></ul><p>歴史としては、 SIGIR ecom が長く、これだけの期間継続開催してくれているのはありがたい限り。</p><p>機械学習系の国際会議でも手法ではなく、どう現実世界に適用したかに注目したワークショップが益々誕生しており非常に良い流れ。</p><p>ACCEPTED PAPERS は 5 本あり、</p><ul><li>Amazon: 2</li><li>eBay: 1</li><li>The Home depot: 2</li></ul><p>と企業関係者による論文が 100%となっている。</p><p><a href=https://github.com/ISIR-eCom/ISIR-eCom.github.io/tree/main/papers>https://github.com/ISIR-eCom/ISIR-eCom.github.io/tree/main/papers</a> 最後の PDF 番号が 9 なので、最低でも 9 本の投稿はあった模様。</p><p>素晴らしいワークショップなので、来年も是非継続して開催してほしい。</p><p>すべての採択論文が面白そうだったが、今回は Amazon Search が公開した Chen Luo らの「ROSE: Robust Caches for Amazon Product Search」を紹介する。</p><p>私的な感想やコメントは <code>NOTE</code>: で始める文章で書き留めています。</p><h2 id=一言で説明>一言で説明<a hidden class=anchor aria-hidden=true href=#一言で説明>#</a></h2><p>クエリの書き換え(誤植を修正する)と深層学習モデルの結果のキャッシュを同時に行えるキャッシュシステム <code>ROSE</code> を提案して、検索システムの応答速度と検索性能を改善。</p><h2 id=citation>Citation<a hidden class=anchor aria-hidden=true href=#citation>#</a></h2><blockquote><p>ROSE: Robust Caches for Amazon Product Search, Chen Luo, Vihan Lakshman, Anshumali Shrivastava, Tianyu Cao, Sreyashi Nag, Rahul Goutam, Hanqing Lu, Yiwei Song and Bing Yin, Proceedings of the International Workshop on Interactive and Scalable Information Retrieval methods for eCommerce (ISIR-eCom), 2022.</p></blockquote><h2 id=概要>概要<a hidden class=anchor aria-hidden=true href=#概要>#</a></h2><p>Amazon Search のような商品検索エンジンはしばしばキャッシュを利用する。
キャッシュによって Amazon の製品検索での顧客体験を向上させることができる。
顧客体験だけではなく、検索システムのレイテンシも大幅に向上する。</p><p>だが、検索トラフィックが増大しキャッシュサイズが大きくなりすぎると検索システム全体のパフォーマンスが劣化してしまう。
また、誤字やスペルミス、現実世界で見られる冗長な表現のクエリは不必要なキャッシュミスを引き起こし、キャッシュの効率性を低下させる。</p><p>「RObuSt cachE(ROSE)」はロックアップコストはそのままにスペルミスや誤字を許容可能なキャッシュシステムを提案。
ROSE はあらゆるクエリの意図、誤字、文法ミスに対して理論的な頑健性が保証されている。
現実世界のデータセットにより ROSE を評価して、有効性と効率は検証を行った。
ROSE はすでに Amazon の検索エンジンにデプロイされており、既存のキャッシュシステムと比較しても大きくビジネス指標を改善している。</p><h2 id=introduction>INTRODUCTION<a hidden class=anchor aria-hidden=true href=#introduction>#</a></h2><p>検索エンジンで大事な２つのパフォーマンス指標</p><ul><li>顧客化からのリクエストに対するレスポンスタイム</li><li>顧客の意図に適合した高品質な検索結果</li></ul><p>現代的な製品検索エンジンでは通常、計算不可が高い機械学習モデルが多く使われている。</p><p><code>NOTE</code>: [1, 8, 9, 13, 20, 28, 29, 31] の参考文献が、検索改善のための機械学習適用の文献リストとして有用そうだった。
[18] relevance matching models。[2] ranking models。[27] query annotation models。</p><p>レイテンシの制限とコストの考慮により、実際の製品検索エンジンでは、計算コストが高い深層学習モデルをサービングして検索トラフィック全体を処理することは禁止されている[14]。そのため、深層学習モデルの推論結果をサービングする代わりに、より実践的な解決方法として頻繁にリクエストがくるクエリに対して深層学習モデルの結果をキャッシュしておく。</p><p>従来のキャッシュは以下のようなトレードオフの問題がある</p><p>キャッシュミス率とキャッシュサイズの関係: 小さいキャッシュサイズでは、高いキャッシュミス率となる。一方で製品検索エンジンの規模で頻繁に検索されるクエリに対してキャッシュを作成したとして異常にキャッシュサイズが大きくなってしまう。また、 ”Nike shoes”, “Nike shoe”, and “Nike’s shoe” のような同じ意図のクエリだが、形態素的には異なるそれらのクエリはすべて別のキャッシュとしてキャッシュされてしまう。</p><p>また、 <code>Query rewrite for null and low search results in eCommerce. In eCOM@ SIGIR.</code> [24]でも示されている通り、検索結果の品質を下げている要因のほとんどが 誤植)。
これらの検索品質が低いクエリは、高品質な検索結果を提供する頻繁に検索されるクエリと語彙的(Lexically) または意味的 (semantically)に似ている。</p><p>よって、もし我々が低品質な検索結果を提供する誤植のクエリを、同じ意図を持つクエリへキャッシングの仕組みにより紐付ける(map する)ことができたなら、検索品質を向上させることができる。また、レイテンシも大幅に向上させ、キャッシュサイズも大幅に抑えることができる。</p><p><img loading=lazy src=/posts/2022-03-03/images/fig-1.png alt="ROSE Figure 1"></p><p>Fig. 1: ROSE は検索品質と検索速度を向上させる</p><ul><li>キャッシュによるクエリの書き換え(query rewrite)によって検索品質の向上</li><li>ROSE が大半の通信をカバーすることで、検索速度の向上。キャッシュヒットしないような少数派のクエリに対しては、深層学習モデルによって直接サービングを行う。</li></ul><h3 id=３つの貢献点>３つの貢献点<a hidden class=anchor aria-hidden=true href=#３つの貢献点>#</a></h3><ul><li>運用システム: 製品検索のクエリをキャッシュするための、ROSE を提案。定数時間と定数メモリで web 検索規模のデータのインデックスを作成してルックアップを実行可能</li><li>技術的革新: local-sensitive hashing, reservoir sampling, count-based k-selection など複数の強力な乱択アルゴリズム技術を組み合わせたシステムを開発。これにより、定数時間での検索を維持しながら ROSE を大規模なクエリセットにスケールアップが可能になった。</li><li>現実世界での効果: Amazon 検索に ROSE をデプロイしており、既存手法と比べてパフォーマンス、ビジネス指標ともに改善された。</li></ul><h2 id=background-and-related-work>BACKGROUND AND RELATED WORK<a hidden class=anchor aria-hidden=true href=#background-and-related-work>#</a></h2><h3 id=robust-cashes>Robust Cashes<a hidden class=anchor aria-hidden=true href=#robust-cashes>#</a></h3><p>検索エンジンやデータベースなど応答速度がクリティカルなアプリケーションではキャッシュはとても有効なアプローチ。
hash-tables と Bloom fillters によって、キャッシュは完全一致によるキャッシュなどが考案されている[16]。
だが完全一致に注目しているため誤植に弱く従来の完全一致キャッシュでは、キャッシュヒット率が低くなってしまう。
逆に従来の単語のゆらぎに頑健(ロバスト)なキャッシュ手法は、キャッシュの文字列の類似距離を計算するコストが非常に高かった。</p><p>定数時間と定数メモリで実行可能なロバストなキャッシュの仕組みである「ROSE」提案する。</p><h3 id=locality-sensitive-hasing>Locality-Sensitive Hasing<a hidden class=anchor aria-hidden=true href=#locality-sensitive-hasing>#</a></h3><p>LSH の解説資料はこちらの資料がわかりやすかった。</p><p><a href=https://www.slideshare.net/yaruki_nil/lsh>Locality Sensitive Hashing</a></p><p>他にも LSH の発展形として Jaccard 類似度を使った LSH である Minwise Hasing(MinHash) や Densified One Permutation Hashing (DOPH) なども紹介されていた。</p><p><code>NOTE</code>: 時間が足りないので一旦深い解説は割愛する。ここらへんは自分の知識が浅い部分なのでちゃんと理解しておきたい。</p><h3 id=問題の定式化>問題の定式化<a hidden class=anchor aria-hidden=true href=#問題の定式化>#</a></h3><p><img loading=lazy src=/posts/2022-03-03/images/fig-2.png alt="ROSE Figure 2"></p><p>ROSE のフレームワーク解説</p><ol><li>クエリキーワードからロバストなキャッシュインデックス生成</li><li>オンライン検索: 入力されたクエリをキャッシュ上の別のクエリにマッピングする</li></ol><h2 id=rose-robust-cache-via-randomized-hashing>ROSE: ROBUST CACHE VIA RANDOMIZED HASHING<a hidden class=anchor aria-hidden=true href=#rose-robust-cache-via-randomized-hashing>#</a></h2><h3 id=rose-index-generation>ROSE Index Generation<a hidden class=anchor aria-hidden=true href=#rose-index-generation>#</a></h3><p>ROSE のインデックス生成時には２つの条件</p><ul><li>誤植や意味的に同じだが異なるクエリでもロバストな性能のために、キャッシュのルックアップ時に入力クエリの類似度を計算してマップする</li><li>大規模な製品検索エンジンなので、キャッシュサイズはクエリの量に応じてスケーリングすることを回避する必要がある</li></ul><p>LSH のアプローチでは、データの規模に対して線形にハッシュテーブルのサイズが増加する課題がある[23]。
この課題は web 規模のデータを扱うと容易にメモリが爆発を引き起こす。
その課題を解決するために reservoir sampling algorithm[25] を使って解決している。</p><p>reservoir sampling algorithm の日本語の解説記事はこちら</p><p><a href=https://sucrose.hatenablog.com/entry/2014/01/11/004615>大量のテキストからランダムに少数の行を抽出したい - Reservoir Sampling</a></p><p><code>NOTE</code>: ここ完全に理解不足なので言葉だけ理解。</p><p><img loading=lazy src=/posts/2022-03-03/images/alg-1.png alt="ROSE Alg 1"></p><p>B はハッシュテーブルハッシュテーブルのバケットの数、Iq はハッシュ関数により生成されたインデックス。
Rand(0,B)は-から B までの乱数を生成する関数。</p><h3 id=rose-online-retrieval>ROSE Online Retrieval<a hidden class=anchor aria-hidden=true href=#rose-online-retrieval>#</a></h3><p>クエリが入力された際に、ROSE は Count-based 𝑘-selection [15]という手法を使って、計算コストの高い 2 点間の類似度(pairwise-similarity)の計算を避けている。
ROSE のオンライン検索が定数時間で終わることは、<code>3.5 Theoretical Analysis</code>にて解説。</p><h3 id=lexical-preserving-hashing>Lexical Preserving Hashing<a hidden class=anchor aria-hidden=true href=#lexical-preserving-hashing>#</a></h3><p>Lexical Preserving Hashing は語彙的な類似度を保持したハッシュ手法を指す。
クエリ間の類似度は Jacard 類似度を使って計算する。(つまるところ minhash?)
実際に計算する際には DOPS を使って minhash を算出する。</p><p>ROSE による誤植修正のための Lexical Preserving Hashing によるマッピング例: 「red nike shoos」 → 「red nike shoes」</p><h3 id=product-type-preserving-hashing>Product Type Preserving Hashing<a hidden class=anchor aria-hidden=true href=#product-type-preserving-hashing>#</a></h3><p>製品検索エンジンでは、クエリの製品タイプを理解することが関連した高品質な検索結果を提供するためにとても重要である。</p><p>具体例: 「red nike shoes」 のクエリの製品タイプは 「SHOES」</p><p>ここで製品タイプをクエリから抽出するために、クエリのトークンに対して製品タイプの重みを計算する。製品タイプのトークンは <code>QUEACO: Borrowing Treasures from Weakly-labeled Behavior Data for Query Attribute Value Extraction</code>[30] という NER モデルによって抽出される。</p><p>製品タイプトークンが存在しなかった場合の重みは 1、1 より以上の場合は製品タイプトークンが抽出できたことになる。
製品タイプトークンの重み付けは W >1 で与え、チューニングした結果 W=10 が最も結果が良好製品タイプトークンは W というしきい値で管理される。</p><h3 id=theoretical-analysis>Theoretical Analysis<a hidden class=anchor aria-hidden=true href=#theoretical-analysis>#</a></h3><p>アルゴリズムの理論解析について。
だが、知識がまったくないので、割愛することにした。</p><h2 id=オフラインでの実験>オフラインでの実験<a hidden class=anchor aria-hidden=true href=#オフラインでの実験>#</a></h2><h3 id=データセット>データセット<a hidden class=anchor aria-hidden=true href=#データセット>#</a></h3><p>約 6 億の検索品質が高いクエリを Amazon 検索からサンプリングして、評価のためのキャッシュ対象にする。
ここでは、Xichuan ら <code>A Dual Heterogeneous Graph Attention Network to Improve Long-Tail Performance for Shop Search in E-Commerce. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 3405–3415</code> [19]と同じ評価の枠組みで評価を行った。</p><p>クエリの評価データセットは頻度ごとに分割された３つのバケットを用意</p><ul><li><code>NQ</code>(Normal Queries): 頻度が上位 33%(1 つめの 3 分位数)のクエリ</li><li><code>HQ</code>(Hard queries): 頻度が上位 34%-66% (1 つめの 3 分位数)のクエリ</li><li><code>LTQ</code>(Long-tail queries): 頻度が上位 67%-100% (3 つめの 3 分位数)のクエリ</li></ul><p>ランダムに上記のクエリを一ヶ月以上の検索ログから選択して収集する。３つのバケットは 1000 のクエリが存在してる。ドメインエキスパートによる判断により、ROSE の仕組みにより re-map された結果が元のクエリが書き換えられても意図が同一かどうかの 2 値(relevant or irrelevant)によって評価。</p><h3 id=実験デザイン>実験デザイン<a hidden class=anchor aria-hidden=true href=#実験デザイン>#</a></h3><p>２つの指標に対する仮設</p><ul><li>Robustness: どれぐらい ROSE は正確か?</li><li>Efficnency: どれぐらい ROSE のインデキシングと検索処理は効率的か?</li></ul><p>それらの仮設検証のために</p><ul><li><code>R-LP</code>: 提案手法。ROSE の lecical preserving hasing。 ハッシュテーブルの数は L=3 6 かつ、ハッシュの数は $K=3$</li><li><code>R-PT</code>: 提案手法。ROSE の product type preserving hasing</li><li><code>EC</code>: 完全一致によるキャッシュ実装</li><li><code>BF</code>: ROSE の検索アルゴリズムを力まかせ探索に置き換えた手法。類似度の尺度として DP を使って編集距離を計算する。</li><li><code>FC</code>: <a href=https://arxiv.org/abs/1702.08734>FAISS</a> のアルゴリズムを使って ROSE のインデキシングと検索アルゴリズムを置き換えた手法。クエリの埋め込み空間は <a href=https://arxiv.org/abs/1907.00937>Semantic Product Search</a> を使って用意。</li></ul><p>評価指標としては、一般的な Precision, Recall, F1 を採用。</p><p>各指標の具体例としては、
例えば「red nike shoes」という original intent となるクエリが存在するとする。この「red nike shoes」と original intent は同一だが、語彙的な誤りによって「red nike shoos」、「red nike shooes」などのクエリが存在する。</p><p>これら、「red nike shoes」を original intent とするクエリ数が 20 件あり、以下のような分布になっている。</p><ul><li>「red nike shoes」: 10 件<ul><li>「red nike shoos」: 5 件</li><li>「red nike shooes」: 5 件</li></ul></li></ul><p>例えば、完全一致キャッシュでは、「red nike shoes」とう文字列に対して lool up を行い、</p><ul><li>precision: 100%</li><li>recall: 50%</li></ul><p>となる。</p><p>そして、ROSE-LP が 「red nike shoos」を「red nike shoes」に対して map ができたとする。(「red nike shooes」の map は失敗)</p><ul><li>precision: 100%</li><li>recall: 75%</li></ul><p>となる。</p><p>上記のように誤植が含まれるクエリをどれだけ各種手法で書き換えることができたかが、評価指標となっている。</p><h4 id=全体を通した実験結果>全体を通した実験結果<a hidden class=anchor aria-hidden=true href=#全体を通した実験結果>#</a></h4><h5 id=検索性能>検索性能<a hidden class=anchor aria-hidden=true href=#検索性能>#</a></h5><p><img loading=lazy src=/posts/2022-03-03/images/table-1.png alt="ROSE Table 1"></p><p>NQ, HQ に対しては ROSE-PT が最も性能が良く、LTQ に対しては ROSE-LP の性能が良かった。</p><h5 id=システム性能>システム性能<a hidden class=anchor aria-hidden=true href=#システム性能>#</a></h5><p>ROSE-LP は 60m でインデックス生成を完了。ROSE-PT は 75m。</p><p><code>NOTE</code>: 論文中だとシステム性能としても性能が良いと書いてあるが、他の手法のほうが早いのでこの書き方は実際どうなんだろう。と思いつつも、検索性能がこれだけ上がって cache index 作成も 65m だけで済んでいるなら全く問題なさそう。</p><p>検索面では、力まかせ探索だと 65m(ms ではない)検索に時間がかかるらしいので、使い物にならなさそう。FAISS が 120ms 必要な中で ROSE は LP, PT ともに 3ms 以下という驚異的な速度。</p><p><img loading=lazy src=/posts/2022-03-03/images/fig-3.png alt="ROSE Figure 3"></p><p>図 3 では、ROSE が担っている２つのコンポーネントを解説。</p><ul><li>(a) 誤植の問題を解決するクエリ書き換え。「nike shoos」という誤植のクエリが来た際に、「nike shoes」に書き換え</li><li>(b) 深層学習モデル高速化のためのキャッシュ上での製品タイプ予測。Cash Hit した場合、ROSE によってクエリ(q)の製品タイプ(PT)を返す。キャッシュヒットしなかった場合は、深層学習モデルによってクエリに製品タイプの推論を行い、返す。</li></ul><h2 id=system-deployment-in-amazon>SYSTEM DEPLOYMENT IN AMAZON<a hidden class=anchor aria-hidden=true href=#system-deployment-in-amazon>#</a></h2><h3 id=rose-for-query-rewrite>ROSE for Query Rewrite<a hidden class=anchor aria-hidden=true href=#rose-for-query-rewrite>#</a></h3><p>顧客が誤植によるクエリクエリを入力してきた際にクエリ書き換えを行うために実際に ROSE をデプロイ。使った手法は ROSE-LP。これによって、検索結果がそもそも低品質なクエリが高品質な検索結果として提示されるようになった。</p><p>オンラインのクエリ書き換えの結果はドメインエキスパートにり測定・評価され、良好な結果となった。
また、複数のビジネス指標も有意に改善された。</p><p><img loading=lazy src=/posts/2022-03-03/images/table-2.png alt="ROSE Table 2"></p><p><code>NOTE</code>: CTR +7%ってすごくないですか&mldr;? 今までも、Amazon なのでもちろん Query Understanding に取り組んでいたと思うんだが、従来のクエリ書き換えよりも更に良くなったということだろうか?実際は ROSE によって検索の応答速度も改善されているので、変数は２つとなり難しいところではある。 また、Amazon の規模での利益 0.42% 上昇って半端ないですね。深層学習モデルのキャッシュでもあるので、特徴量の前処理改善にもなっていることに気がついた。</p><h3 id=rose-for-product-type-annotation>ROSE for Product Type Annotation<a hidden class=anchor aria-hidden=true href=#rose-for-product-type-annotation>#</a></h3><p>「red nike shoes」のようなクエリは、クエリから正しい製品タイプを特定することで、正しい製品を検索できたり、製品タイプによって検索結果を変更することが可能。</p><p>500 万-1000 万の規模の高頻度なクエリに対して、クエリから特定の製品タイプへマッピングする ROSE を実装。</p><p>ROSE は受け取った tail query に対して、そのクエリをキャッシュされたいくつかのクエリにマッピングし、そのクエリと紐付いている製品タイプを tail query の製品タイプの予測結果として使用する。</p><p>検索体験への影響を評価するため、ROSE の商品タイプ予測モデルを用いて、誤った商品タイプを持つ無関係な検索結果をフィルタリングし、このシステムを Amazon.com にデプロイし商品検索エンジンにおいて、ROSE により商品タイプを認識した場合としない場合の検索結果の不具合率(Defects Rate)を測定。</p><p>製品タイプ不良率(Product type defect rate)とは、検索結果の上位 16 件に含まれる商品のうち、製品タイプが誤っている数として定義。</p><p><img loading=lazy src=/posts/2022-03-03/images/table-2.png alt="ROSE Table 2"></p><p>表 2 より、ROSE による製品タイプを予測することで、欠陥率が 1.7%減少し、ユーザーエクスペリエンスが大幅に改善されたことがわかる。</p><p><img loading=lazy src=/posts/2022-03-03/images/fig-4.png alt="ROSE Fig 4"></p><p>図 4 では ROSE によって予測された製品タイプのフィルターを通した結果の違いが示されている。</p><p><code>NOTE</code>: でもこの部分ではビジネス指標について触れていないということは、欠陥率しか改善しなかったのかなと邪推した。(それでも十分凄いけど)</p><hr><p>社内の検索勉強会の発表順が回ってきたので、最近見つけた面白そうな論文である ROSE を読んでみた。
読んでいて非常に面白い論文で手法もさることながらビジネス指標もリフトさせているの本当にすごいし、価値がありますね。
この成果を公開してくれた Amazon に感謝</p><p>面白い論文は、引用する論文もイケているので周辺知識を深堀りしたい際に辞書的に使えるのもありがたい。</p><p>クエリの書き換えをキャッシュ(ROSE)に搭載して、システム的に密結合になったり、運用面で大変になったりしないのかなと思いつつも、これだけ性能が良いのならそれらを補って良い事だらけではと感じた。</p><p>振り返ってみると最近 Amazon が公開してくれている検索ネタを今回含めて 3 連続で読んで解説していたが</p><ul><li><a href=https://shunyaueta.com/posts/2021-12-26/>Daria Sorokina さんによる、 Amazon の検索ランキングについて at MLconf SF 2016</a></li><li><a href=https://shunyaueta.com/posts/2021-11-26/>Amazon が e コマース検索を Lucene により、どうスケールさせているか at Berlin Buzzwords 2019</a></li></ul><p>それくらい面白い論文が多いのと e コマース検索だと飛び抜けて先進的な取り組みをしている印象。</p><p>次は <a href=https://isir-ecom.github.io/>The First International Workshop on INTERACTIVE AND SCALABLE INFORMATION RETRIEVAL METHODS FOR ECOMMERCE (ISIR-ecom)</a> の別の採択論文を読む。</p><p>おそらく次に読むのは</p><blockquote><p>E-commerce Product Attribute Value Validation and Correction Based on Transformers: Le Yu, Haozheng Tian, Yun Zhu, Simon Hughes and Aleksandar Velkoski</p></blockquote><h2>See Also</h2><ul><li><a href=/posts/2021-12-26/>Daria Sorokina さんによる、 Amazon の検索ランキングについて at MLconf SF 2016</a></li><li><a href=/posts/2021-10-09/>クエリ分類(Query Classification) について社内の勉強会で話してきた</a></li><li><a href=/posts/2021-01-17/>TFXの歴史を振り返りつつ機械学習エンジニアリングを提案する論文「Towards ML Engineering: A Brief History Of TensorFlow Extended (TFX)」</a></li><li><a href=/posts/2020-04-25/>機械学習システムの信頼性を数値化し、技術的負債を解消する論文「 The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction」</a></li><li><a href=/posts/2020-04-19/>機械学習システムの信頼性を数値化する論文「 What’s your ML test score? A rubric for ML production systems」</a></li></ul><h2>Support</h2>記事をお読みくださりありがとうございます。このウェブサイトの運営を支援していただける方を募集しています。
もしよろしければ、下のボタンからサポート(投げ銭)していただけると、ブログ執筆、情報発信のモチベーションに繋がります✨
<a href=https://www.buymeacoffee.com/hurutoriya><img src="https://img.buymeacoffee.com/button-api/?text=Buy me a coffee&emoji=☕&slug=hurutoriya&button_colour=FFDD00&font_colour=000000&font_family=Inter&outline_colour=000000&coffee_colour=ffffff"></a></div><footer class=post-footer><ul class=post-tags><li><a href=https://shunyaueta.com/tags/search/>search</a></li><li><a href=https://shunyaueta.com/tags/machinelearning/>machinelearning</a></li><li><a href=https://shunyaueta.com/tags/paper/>paper</a></li></ul><nav class=paginav><a class=prev href=https://shunyaueta.com/posts/2022-03-04/><span class=title>« 前のページ</span><br><span>デスクトップのGoogle 検索の検索フォームUIがかなり変化していた</span></a>
<a class=next href=https://shunyaueta.com/posts/2022-03-01/><span class=title>次のページ »</span><br><span>Web 検索とデータマイニングのトップカンファレンス WSDM2022 で気になった研究</span></a></nav></footer><script src=https://giscus.app/client.js data-repo=hurutoriya/hurutoriya.github.io data-repo-id="MDEwOlJlcG9zaXRvcnk2MDgyNTY1Nw==" data-category=Comments data-category-id=DIC_kwDOA6AgOc4CAQTX data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=0 data-theme=dark data-lang=ja crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2022 <a href=https://shunyaueta.com/>🦅 hurutoriya</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z" /></svg></a><script>let menu=document.getElementById('menu')
if(menu){menu.scrollLeft=localStorage.getItem("menu-scroll-position");menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft);}}
document.querySelectorAll('a[href^="#"]').forEach(anchor=>{anchor.addEventListener("click",function(e){e.preventDefault();var id=this.getAttribute("href").substr(1);if(!window.matchMedia('(prefers-reduced-motion: reduce)').matches){document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({behavior:"smooth"});}else{document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();}
if(id==="top"){history.replaceState(null,null," ");}else{history.pushState(null,null,`#${id}`);}});});</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){if(document.body.scrollTop>800||document.documentElement.scrollTop>800){mybutton.style.visibility="visible";mybutton.style.opacity="1";}else{mybutton.style.visibility="hidden";mybutton.style.opacity="0";}};</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{if(document.body.className.includes("dark")){document.body.classList.remove('dark');localStorage.setItem("pref-theme",'light');}else{document.body.classList.add('dark');localStorage.setItem("pref-theme",'dark');}})</script><script>document.querySelectorAll('pre > code').forEach((codeblock)=>{const container=codeblock.parentNode.parentNode;const copybutton=document.createElement('button');copybutton.classList.add('copy-code');copybutton.innerText='copy';function copyingDone(){copybutton.innerText='copied!';setTimeout(()=>{copybutton.innerText='copy';},2000);}
copybutton.addEventListener('click',(cb)=>{if('clipboard'in navigator){navigator.clipboard.writeText(codeblock.textContent);copyingDone();return;}
const range=document.createRange();range.selectNodeContents(codeblock);const selection=window.getSelection();selection.removeAllRanges();selection.addRange(range);try{document.execCommand('copy');copyingDone();}catch(e){};selection.removeRange(range);});if(container.classList.contains("highlight")){container.appendChild(copybutton);}else if(container.parentNode.firstChild==container){}else if(codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"){codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);}else{codeblock.parentNode.appendChild(copybutton);}});</script></body></html>