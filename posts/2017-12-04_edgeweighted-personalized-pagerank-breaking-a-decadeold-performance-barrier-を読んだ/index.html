<!doctype html><html lang=ja prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb#"><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><meta name=description content><meta name=HandheldFriendly content="True"><meta name=MobileOptimized content="320"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=keywords content="Machine Learning,
KDD,
Paper,"><meta property="og:type" content="article"><meta property="og:description" content><meta property="og:title" content="Edge-Weighted Personalized PageRank: Breaking A Decade-Old Performance Barrier を読んだ"><meta property="og:site_name" content><meta property="og:image" content><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content><meta property="og:image:height" content><meta property="og:url" content="https://shunyaueta.com/posts/2017-12-04_edgeweighted-personalized-pagerank-breaking-a-decadeold-performance-barrier-%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/"><meta property="og:locale" content="ja"><meta property="article:published_time" content="2017-12-04"><meta property="article:modified_time" content="2017-12-04"><meta property="article:tag" content="Machine Learning"><meta property="article:tag" content="KDD"><meta property="article:tag" content="Paper"><meta name=twitter:card content="summary"><meta name=twitter:site content="@hurutoriya"><meta name=twitter:creator content="@hurutoriya"><meta name=twitter:title content="Edge-Weighted Personalized PageRank: Breaking A Decade-Old Performance Barrier を読んだ |"><meta name=twitter:description content="応用数理研究者が機械学習界に進出していく研究
youtube clip
応用数理界隈ではクラシックな解き方で PageRank が解かれているので最新の数値計算手法に置き換えることで劇的にパフォーマンスが向上して 10 年前のパフォーマンスの鎖を解き放った論文
 KDD2015 Best student paper award Slide(PDF) Poster(PDF) Spectral network analysis  wenleix/EdgePPR
 Presentation Movie is uploaded in Youtube.  Author
 W. Xie Ph.D Candidate at Cornell University http://wenleix.github.io/ iterative computation on big graph data D. Bindel http://www.cs.cornell.edu/~bindel/ http://www.cs.cornell.edu/~bindel/talks.html He is frequently research activ like ideal young researcher. Nonlinear eigenvalue problem. Alan J. Demers Prof. Johannes Gehrke http://www.cs.cornell.edu/johannes/ Prof. VLDB,SIGMOD,KDD  Motivation  ページランクは重要な指標。遷移確率を求めるにはランダムサーファーモデル(ランダムウォーク)が必要。 様々な高速解法が提案されている。  Reseatch Question  しかし 10 年以上前、PageRank の黎明期から Personalization based の手法は問題がある。 一般的な PageRank の解法の説明、その後に Model Reduction をベースにした約 5 倍の性能を誇る提案手法を説明。 提案手法の性能によって、パフォーマンス上のボトムネックは消えた。  Proposed Method  PageRank 初期:WEBPage のランクに使用 → 現在:推薦、ソーシャルネットワーク Random Suffer Model Transition : α の確率で Random Walk(滞在ノードから無作為に遷移) Teleporting : 1−α Random Junmp(滞在ノードに依存せずに全てのノードを対象に無作為遷移) x(t+1)=αPxt+(1−α)v,where P=AD−1 v is represents telepotation probabilitie xt Walker の確率分布 サーファーが来る確率 = RandomWalk の確率_RandomWalk による遷移確率 + RandomJump の確率_RandomJump の遷移確率 = α× RandomWalk による遷移確率 + (1−α)×RandomJump の遷移確率 = α×+(1−α)×v x: Stationary vector(不動ベクトル、定常ベクトル、不動点定理など) x が定常状態になった際に、x の確率分布が PageRank を表す。 x(t),x(t+1)が同一(残差が無い)だと仮定することで、次式の線形方程式を解くことで Pagerank を求める。 Mx=b,where M=(I−αP),b=(1−α)v.|"><meta name=twitter:image:src content><meta name=twitter:domain content="https://shunyaueta.com/posts/2017-12-04_edgeweighted-personalized-pagerank-breaking-a-decadeold-performance-barrier-%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/"><title>Edge-Weighted Personalized PageRank: Breaking A Decade-Old Performance Barrier を読んだ</title><link rel=canonical href=https://shunyaueta.com/posts/2017-12-04_edgeweighted-personalized-pagerank-breaking-a-decadeold-performance-barrier-%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/><link rel=stylesheet href=https://unpkg.com/tachyons@4.11.1/css/tachyons.min.css><link rel=stylesheet href=https://shunyaueta.com/css/style.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/highlightjs@9.12.0/styles/github-gist.css><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-39994406-11','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><link rel="shortcut icon" href=/favicon.ico type=image/x-icon><link rel=apple-touch-icon href=/apple-touch-icon.png></head><body lang=ja class="sans-serif w-90 w-60-ns center center-ns mv2 mv5-ns" itemscope itemtype=http://schema.org/Article><span class=b>/</span>
<a href=https://shunyaueta.com/ class="b bb bw1 pb1 no-underline black"></a><section id=main class=mt5><h1 itemprop=name id=title>Edge-Weighted Personalized PageRank: Breaking A Decade-Old Performance Barrier を読んだ</h1><article itemprop=articleBody id=content class="w-90 lh-copy"><p>応用数理研究者が機械学習界に進出していく研究</p><p><img src=/posts/2017-12-04_edgeweighted-personalized-pagerank-breaking-a-decadeold-performance-barrier-%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/images/1.png alt=image></p><p>youtube clip</p><p>応用数理界隈ではクラシックな解き方で PageRank が解かれているので最新の数値計算手法に置き換えることで劇的にパフォーマンスが向上して 10 年前のパフォーマンスの鎖を解き放った論文</p><ul><li>KDD2015 Best student paper award</li><li><a href=http://www.cs.cornell.edu/~bindel/present/2015-08-kdd-talk_kdd-aug15.pdf>Slide(PDF)</a></li><li><a href=http://www.cs.cornell.edu/~bindel/present/2015-08-kdd-poster_poster-kdd-pr.pdf>Poster(PDF)</a>
<a href=http://www.cs.cornell.edu/~bindel//blurbs/graphspec.html>Spectral network analysis</a></li></ul><p><a href=https://github.com/wenleix/EdgePPR>wenleix/EdgePPR</a></p><ul><li>Presentation Movie is uploaded in Youtube.</li></ul><p>Author</p><ul><li>W. Xie</li><li>Ph.D Candidate at Cornell University</li><li><a href=http://wenleix.github.io/>http://wenleix.github.io/</a></li><li>iterative computation on big graph data</li><li>D. Bindel</li><li><a href=http://www.cs.cornell.edu/~bindel/>http://www.cs.cornell.edu/~bindel/</a></li><li><a href=http://www.cs.cornell.edu/~bindel/talks.html>http://www.cs.cornell.edu/~bindel/talks.html</a></li><li>He is frequently research activ like ideal young researcher.</li><li>Nonlinear eigenvalue problem.</li><li>Alan J. Demers</li><li>Prof.</li><li>Johannes Gehrke</li><li><a href=http://www.cs.cornell.edu/johannes/>http://www.cs.cornell.edu/johannes/</a></li><li>Prof.</li><li>VLDB,SIGMOD,KDD</li></ul><h3 id=motivation>Motivation</h3><ul><li>ページランクは重要な指標。遷移確率を求めるにはランダムサーファーモデル(ランダムウォーク)が必要。</li><li>様々な高速解法が提案されている。</li></ul><h3 id=reseatch-question>Reseatch Question</h3><ul><li>しかし 10 年以上前、PageRank の黎明期から Personalization based の手法は問題がある。</li><li>一般的な PageRank の解法の説明、その後に Model Reduction をベースにした約 5 倍の性能を誇る提案手法を説明。</li><li>提案手法の性能によって、パフォーマンス上のボトムネックは消えた。</li></ul><h3 id=proposed-method>Proposed Method</h3><ul><li>PageRank</li><li>初期:WEBPage のランクに使用 → 現在:推薦、ソーシャルネットワーク</li><li>Random Suffer Model</li><li>Transition : α の確率で Random Walk(滞在ノードから無作為に遷移)</li><li>Teleporting : 1−α Random Junmp(滞在ノードに依存せずに全てのノードを対象に無作為遷移)</li><li>x(t+1)=αPxt+(1−α)v,where P=AD−1</li><li>v is represents telepotation probabilitie</li><li>xt Walker の確率分布</li><li>サーファーが来る確率 = RandomWalk の確率_RandomWalk による遷移確率 + RandomJump の確率_RandomJump の遷移確率</li><li>= α× RandomWalk による遷移確率 + (1−α)×RandomJump の遷移確率</li><li>= α×+(1−α)×v</li><li>x: Stationary vector(不動ベクトル、定常ベクトル、不動点定理など)</li><li>x が定常状態になった際に、x の確率分布が PageRank を表す。</li><li>x(t),x(t+1)が同一(残差が無い)だと仮定することで、次式の線形方程式を解くことで Pagerank を求める。</li><li>Mx=b,where M=(I−αP),b=(1−α)v.</li></ul><h4 id=standard-pagerank>Standard PageRank</h4><ul><li>グラフの構造(幾何性)を利用</li><li>多くのグラフでは、ノードやエッジに重みが存在する</li></ul><h4 id=personalized-pagerank>Personalized PageRank</h4><ul><li>PageRank を特定のユーザやクエリに合わせたランク</li><li>Node wighted graph</li><li>Mx(w)=(1−α)v(w),w∈ℝ𝕕</li><li>w: 特定の個人、クエリに合わせたパラメータ</li><li>Edge weighted graph</li><li>M(w)x(w)=(I−α)v,w∈ℝ𝕕</li><li>Node Weight, Edge Weight 共に Personalized PageRank は重要だが、２つの問題がある。</li><li>Node Weight に関する論文:多い Edge Weight:少ない</li><li>計算コストが高い</li><li>Edge weighted Personalized PageRank における x(w)を求める高速手法を提案</li><li>提案手法は計算量が準線形的。</li><li>予備知識</li><li>xt+1:べき乗法</li><li>Mx=b:ヤコビ法</li><li>x(w)=(1−α)M−1Vw.</li><li>v≈Vwwhere V∈ℝ𝕟×𝕕</li><li>M−1V:O(n) 、x(w)の再構築に O(d)、PageRank を求めるには O(nd)が要求される。</li><li>v が疎なら計算量は準線形へ。</li></ul><h3 id=model-resuction-method>MODEL RESUCTION METHOD</h3><ol><li>k 次元の次元の削減された空間を構築</li><li>k 次元を近似するために k 個の等式が必要</li><li>次元削減の問題を解く(PageRank のベクトルは一部分が重要だという仮説)</li></ol><ul><li>Reduced Space Construction</li><li>{w(j)}rj=1(ベクトルの集合)に対応する PageRank {x(j)}rj=1(ベクトルの集合)を求める。</li><li>w は乱数によって決定する</li><li>k 次元の空間 υ を探索する</li></ul></article></section><footer><div><p class="f6 gray mt6 lh-copy">© 2016-20 <a href=https://twitter.com/hurutoriya>@hurutoriya</a>.</p></div></footer><script src=//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.14.2/highlight.min.js></script><script>hljs.initHighlightingOnLoad();</script></body></html>