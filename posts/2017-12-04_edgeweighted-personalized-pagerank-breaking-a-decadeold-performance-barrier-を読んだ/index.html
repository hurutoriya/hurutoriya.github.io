<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="応用数理研究者が機械学習界に進出していく研究
youtube clip
応用数理界隈ではクラシックな解き方で PageRank が解かれているので最新の数値計算手法に置き換えることで劇的にパフォーマンスが向上して 10 年前のパフォーマンスの鎖を解き放った論文
 KDD2015 Best student paper award Slide(PDF) Poster(PDF) Spectral network analysis  wenleix/EdgePPR
 Presentation Movie is uploaded in Youtube.  Author
 W. Xie Ph.D Candidate at Cornell University http://wenleix.github.io/ iterative computation on big graph data D. Bindel http://www.cs.cornell.edu/~bindel/ http://www.cs.cornell.edu/~bindel/talks.html He is frequently research activ like ideal young researcher. Nonlinear eigenvalue problem. Alan J. Demers Prof. Johannes Gehrke http://www.cs.cornell.edu/johannes/ Prof. VLDB,SIGMOD,KDD  Motivation  ページランクは重要な指標。遷移確率を求めるにはランダムサーファーモデル(ランダムウォーク)が必要。 様々な高速解法が提案されている。  Reseatch Question  しかし 10 年以上前、PageRank の黎明期から Personalization based の手法は問題がある。 一般的な PageRank の解法の説明、その後に Model Reduction をベースにした約 5 倍の性能を誇る提案手法を説明。 提案手法の性能によって、パフォーマンス上のボトムネックは消えた。  Proposed Method  PageRank 初期:WEBPage のランクに使用 → 現在:推薦、ソーシャルネットワーク Random Suffer Model Transition : α の確率で Random Walk(滞在ノードから無作為に遷移) Teleporting : 1−α Random Junmp(滞在ノードに依存せずに全てのノードを対象に無作為遷移) x(t+1)=αPxt+(1−α)v,where P=AD−1 v is represents telepotation probabilitie xt Walker の確率分布 サーファーが来る確率 = RandomWalk の確率_RandomWalk による遷移確率 + RandomJump の確率_RandomJump の遷移確率 = α× RandomWalk による遷移確率 + (1−α)×RandomJump の遷移確率 = α×+(1−α)×v x: Stationary vector(不動ベクトル、定常ベクトル、不動点定理など) x が定常状態になった際に、x の確率分布が PageRank を表す。 x(t),x(t+1)が同一(残差が無い)だと仮定することで、次式の線形方程式を解くことで Pagerank を求める。 Mx=b,where M=(I−αP),b=(1−α)v."><meta name=theme-color content="#d3381c"><meta property="og:title" content="Edge-Weighted Personalized PageRank: Breaking A Decade-Old Performance Barrier を読んだ • Software Engineer as Data Scientist"><meta property="og:description" content="応用数理研究者が機械学習界に進出していく研究
youtube clip
応用数理界隈ではクラシックな解き方で PageRank が解かれているので最新の数値計算手法に置き換えることで劇的にパフォーマンスが向上して 10 年前のパフォーマンスの鎖を解き放った論文
 KDD2015 Best student paper award Slide(PDF) Poster(PDF) Spectral network analysis  wenleix/EdgePPR
 Presentation Movie is uploaded in Youtube.  Author
 W. Xie Ph.D Candidate at Cornell University http://wenleix.github.io/ iterative computation on big graph data D. Bindel http://www.cs.cornell.edu/~bindel/ http://www.cs.cornell.edu/~bindel/talks.html He is frequently research activ like ideal young researcher. Nonlinear eigenvalue problem. Alan J. Demers Prof. Johannes Gehrke http://www.cs.cornell.edu/johannes/ Prof. VLDB,SIGMOD,KDD  Motivation  ページランクは重要な指標。遷移確率を求めるにはランダムサーファーモデル(ランダムウォーク)が必要。 様々な高速解法が提案されている。  Reseatch Question  しかし 10 年以上前、PageRank の黎明期から Personalization based の手法は問題がある。 一般的な PageRank の解法の説明、その後に Model Reduction をベースにした約 5 倍の性能を誇る提案手法を説明。 提案手法の性能によって、パフォーマンス上のボトムネックは消えた。  Proposed Method  PageRank 初期:WEBPage のランクに使用 → 現在:推薦、ソーシャルネットワーク Random Suffer Model Transition : α の確率で Random Walk(滞在ノードから無作為に遷移) Teleporting : 1−α Random Junmp(滞在ノードに依存せずに全てのノードを対象に無作為遷移) x(t+1)=αPxt+(1−α)v,where P=AD−1 v is represents telepotation probabilitie xt Walker の確率分布 サーファーが来る確率 = RandomWalk の確率_RandomWalk による遷移確率 + RandomJump の確率_RandomJump の遷移確率 = α× RandomWalk による遷移確率 + (1−α)×RandomJump の遷移確率 = α×+(1−α)×v x: Stationary vector(不動ベクトル、定常ベクトル、不動点定理など) x が定常状態になった際に、x の確率分布が PageRank を表す。 x(t),x(t+1)が同一(残差が無い)だと仮定することで、次式の線形方程式を解くことで Pagerank を求める。 Mx=b,where M=(I−αP),b=(1−α)v."><meta property="og:url" content="https://shunyaueta.com/posts/2017-12-04_edgeweighted-personalized-pagerank-breaking-a-decadeold-performance-barrier-%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/"><meta property="og:site_name" content="Software Engineer as Data Scientist"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:tag" content="Machine Learning"><meta property="article:tag" content="KDD"><meta property="article:tag" content="Paper"><meta property="article:published_time" content="2017-12-04T13:06:15Z"><meta property="article:modified_time" content="2019-06-16T18:16:09+09:00"><meta name=twitter:card content="summary"><meta name=twitter:site content="@hurutoriya"><meta name=generator content="Hugo 0.67.1"><title>Edge-Weighted Personalized PageRank: Breaking A Decade-Old Performance Barrier を読んだ • Software Engineer as Data Scientist</title><link rel=canonical href=https://shunyaueta.com/posts/2017-12-04_edgeweighted-personalized-pagerank-breaking-a-decadeold-performance-barrier-%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/><link rel=icon href=/favicon.ico><link rel=stylesheet href=/assets/css/main.ab98e12b.css><link rel=stylesheet href=/css/custom.css><style>:root{--color-accent:#d3381c}</style><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-39994406-11','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script></head><body class="page type-posts"><div class=site><a class=screen-reader-text href=#content>Skip to Content</a><div class=main><div class=header-widgets><div class=container><style>.widget-breadcrumbs li:after{content:'\2f '}</style><section class="widget widget-breadcrumbs sep-after"><nav id=breadcrumbs><ol><li><a href=/>Software Engineer as Data Scientist</a></li><li><a href=/posts/>Posts</a></li><li><span>Edge-Weighted Personalized PageRank: Breaking A Decade-Old Performance Barrier を読んだ</span></li></ol></nav></section></div></div><header id=header class="header site-header"><div class="container sep-after"><div class=header-info><p class="site-title title">Software Engineer as Data Scientist</p><p class="desc site-desc">Enjoy Software Engineering & Data Science!!</p></div></div></header><main id=content><article lang=ja class=entry><header class="header entry-header"><div class="container sep-after"><div class=header-info><h1 class=title>Edge-Weighted Personalized PageRank: Breaking A Decade-Old Performance Barrier を読んだ</h1></div><div class=entry-meta><span class=posted-on><svg class="icon" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg><span class=screen-reader-text>Posted on</span>
<time class=entry-date datetime=2017-12-04T13:06:15Z>2017.12.04</time></span>
<span class=reading-time><svg class="icon" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 15 15"/></svg>2 mins read</span></div></div></header><div class="container entry-content"><p>応用数理研究者が機械学習界に進出していく研究</p><p><img src=/posts/2017-12-04_edgeweighted-personalized-pagerank-breaking-a-decadeold-performance-barrier-%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/images/1.png alt=image></p><p>youtube clip</p><p>応用数理界隈ではクラシックな解き方で PageRank が解かれているので最新の数値計算手法に置き換えることで劇的にパフォーマンスが向上して 10 年前のパフォーマンスの鎖を解き放った論文</p><ul><li>KDD2015 Best student paper award</li><li><a href=http://www.cs.cornell.edu/~bindel/present/2015-08-kdd-talk_kdd-aug15.pdf>Slide(PDF)</a></li><li><a href=http://www.cs.cornell.edu/~bindel/present/2015-08-kdd-poster_poster-kdd-pr.pdf>Poster(PDF)</a>
<a href=http://www.cs.cornell.edu/~bindel//blurbs/graphspec.html>Spectral network analysis</a></li></ul><p><a href=https://github.com/wenleix/EdgePPR>wenleix/EdgePPR</a></p><ul><li>Presentation Movie is uploaded in Youtube.</li></ul><p>Author</p><ul><li>W. Xie</li><li>Ph.D Candidate at Cornell University</li><li><a href=http://wenleix.github.io/>http://wenleix.github.io/</a></li><li>iterative computation on big graph data</li><li>D. Bindel</li><li><a href=http://www.cs.cornell.edu/~bindel/>http://www.cs.cornell.edu/~bindel/</a></li><li><a href=http://www.cs.cornell.edu/~bindel/talks.html>http://www.cs.cornell.edu/~bindel/talks.html</a></li><li>He is frequently research activ like ideal young researcher.</li><li>Nonlinear eigenvalue problem.</li><li>Alan J. Demers</li><li>Prof.</li><li>Johannes Gehrke</li><li><a href=http://www.cs.cornell.edu/johannes/>http://www.cs.cornell.edu/johannes/</a></li><li>Prof.</li><li>VLDB,SIGMOD,KDD</li></ul><h3 id=motivation>Motivation</h3><ul><li>ページランクは重要な指標。遷移確率を求めるにはランダムサーファーモデル(ランダムウォーク)が必要。</li><li>様々な高速解法が提案されている。</li></ul><h3 id=reseatch-question>Reseatch Question</h3><ul><li>しかし 10 年以上前、PageRank の黎明期から Personalization based の手法は問題がある。</li><li>一般的な PageRank の解法の説明、その後に Model Reduction をベースにした約 5 倍の性能を誇る提案手法を説明。</li><li>提案手法の性能によって、パフォーマンス上のボトムネックは消えた。</li></ul><h3 id=proposed-method>Proposed Method</h3><ul><li>PageRank</li><li>初期:WEBPage のランクに使用 → 現在:推薦、ソーシャルネットワーク</li><li>Random Suffer Model</li><li>Transition : α の確率で Random Walk(滞在ノードから無作為に遷移)</li><li>Teleporting : 1−α Random Junmp(滞在ノードに依存せずに全てのノードを対象に無作為遷移)</li><li>x(t+1)=αPxt+(1−α)v,where P=AD−1</li><li>v is represents telepotation probabilitie</li><li>xt Walker の確率分布</li><li>サーファーが来る確率 = RandomWalk の確率_RandomWalk による遷移確率 + RandomJump の確率_RandomJump の遷移確率</li><li>= α× RandomWalk による遷移確率 + (1−α)×RandomJump の遷移確率</li><li>= α×+(1−α)×v</li><li>x: Stationary vector(不動ベクトル、定常ベクトル、不動点定理など)</li><li>x が定常状態になった際に、x の確率分布が PageRank を表す。</li><li>x(t),x(t+1)が同一(残差が無い)だと仮定することで、次式の線形方程式を解くことで Pagerank を求める。</li><li>Mx=b,where M=(I−αP),b=(1−α)v.</li></ul><h4 id=standard-pagerank>Standard PageRank</h4><ul><li>グラフの構造(幾何性)を利用</li><li>多くのグラフでは、ノードやエッジに重みが存在する</li></ul><h4 id=personalized-pagerank>Personalized PageRank</h4><ul><li>PageRank を特定のユーザやクエリに合わせたランク</li><li>Node wighted graph</li><li>Mx(w)=(1−α)v(w),w∈ℝ𝕕</li><li>w: 特定の個人、クエリに合わせたパラメータ</li><li>Edge weighted graph</li><li>M(w)x(w)=(I−α)v,w∈ℝ𝕕</li><li>Node Weight, Edge Weight 共に Personalized PageRank は重要だが、２つの問題がある。</li><li>Node Weight に関する論文:多い Edge Weight:少ない</li><li>計算コストが高い</li><li>Edge weighted Personalized PageRank における x(w)を求める高速手法を提案</li><li>提案手法は計算量が準線形的。</li><li>予備知識</li><li>xt+1:べき乗法</li><li>Mx=b:ヤコビ法</li><li>x(w)=(1−α)M−1Vw.</li><li>v≈Vwwhere V∈ℝ𝕟×𝕕</li><li>M−1V:O(n) 、x(w)の再構築に O(d)、PageRank を求めるには O(nd)が要求される。</li><li>v が疎なら計算量は準線形へ。</li></ul><h3 id=model-resuction-method>MODEL RESUCTION METHOD</h3><ol><li>k 次元の次元の削減された空間を構築</li><li>k 次元を近似するために k 個の等式が必要</li><li>次元削減の問題を解く(PageRank のベクトルは一部分が重要だという仮説)</li></ol><ul><li>Reduced Space Construction</li><li>{w(j)}rj=1(ベクトルの集合)に対応する PageRank {x(j)}rj=1(ベクトルの集合)を求める。</li><li>w は乱数によって決定する</li><li>k 次元の空間 υ を探索する</li></ul></div><footer class=entry-footer><div class="container sep-before"><div class=last-updated><svg class="icon" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M20 14.66V20a2 2 0 01-2 2H4a2 2 0 01-2-2V6a2 2 0 012-2h5.34" /><polygon points="18 2 22 6 12 16 8 16 8 12 18 2" /></svg><span class=screen-reader-text>Last updated:</span>
<time class=entry-date datetime=2019-06-16T18:16:09+09:00>2019.06.16</time></div><div class=tags><svg class="icon" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M20.59 13.41l-7.17 7.17a2 2 0 01-2.83.0L2 12V2H12l8.59 8.59A2 2 0 0120.59 13.41z"/><line x1="7" y1="7" x2="7" y2="7"/></svg><span class=screen-reader-text>Tags: </span><a class=tag href=/tags/machine-learning/>Machine Learning</a>, <a class=tag href=/tags/kdd/>KDD</a>, <a class=tag href=/tags/paper/>Paper</a></div></div></footer></article><nav class=entry-nav><div class=container><div class="prev-entry sep-before"><a href=/posts/2017-12-04_nips2017-note/><span aria-hidden=true><svg class="icon" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><line x1="20" y1="12" x2="4" y2="12"/><polyline points="10 18 4 12 10 6"/></svg>Previous</span>
<span class=screen-reader-text>Previous post: </span>NIPS2017 Note</a></div><div class="next-entry sep-before"><a href=/posts/2017-12-04_visualized-approximate-eigen-vector-by-power-iteration-on-3-dimensions./><span class=screen-reader-text>Next post: </span>Visualized Approximate Eigen Vector by Power Iteration on 3 dimensions.<span aria-hidden=true>Next<svg class="icon" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><line x1="4" y1="12" x2="20" y2="12"/><polyline points="14 6 20 12 14 18"/></svg></span></a></div></div></nav><section id=comments class=comments><div class="container sep-before"><div class=comments-area><div id=disqus_thread></div><script type=application/javascript>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return;}
var d=document,s=d.createElement('script');s.async=true;s.src='//'+"hurutoriya"+'.disqus.com/embed.js';s.setAttribute('data-timestamp',+new Date());(d.head||d.body).appendChild(s);})();</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div></div></section></main><footer id=footer class=footer><div class="container sep-before"><section class="widget widget-about sep-after"><header><h2 class="title site-title"><a href=/>Shunya UETA</a></h2><div class=desc>Shunya UETA who is a working on Machine Leraning as Software Engineer at <a href=https://about.mercari.com/en/>Mercari, inc</a>. Opinions are my own. → <a href=/about>See more detail!</a></div></header></section><section class="widget widget-social_menu sep-after"><nav aria-label="Social Menu"><ul><li><a href=https://github.com/hurutoriya target=_blank rel=noopener><span class=screen-reader-text>Open Github account in new tab</span><svg class="icon" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77a5.44 5.44.0 00-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></li><li><a href=https://facebook.com/shunyaueta target=_blank rel=noopener><span class=screen-reader-text>Open Facebook account in new tab</span><svg class="icon" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M18 2h-3a5 5 0 00-5 5v3H7v4h3v8h4v-8h3l1-4h-4V7a1 1 0 011-1h3z"/></svg></a></li><li><a href=https://twitter.com/hurutoriya target=_blank rel=noopener><span class=screen-reader-text>Open Twitter account in new tab</span><svg class="icon" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg></a></li><li><a href=https://linkedin.com/in/hurutoriya target=_blank rel=noopener><span class=screen-reader-text>Open Linkedin account in new tab</span><svg class="icon" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M16 8a6 6 0 016 6v7h-4v-7a2 2 0 00-2-2 2 2 0 00-2 2v7h-4v-7a6 6 0 016-6z"/><rect x="2" y="9" width="4" height="12"/><circle cx="4" cy="4" r="2"/></svg></a></li></ul></nav></section><div class=copyright><p>&copy; 2013-2020 Shunya UETA</p></div></div></footer></div></div><script>window.__assets_js_src="/assets/js/"</script><script src=/assets/js/main.c3bcf2df.js></script><script src=/js/custom.js></script></body></html>