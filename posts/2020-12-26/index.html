<!doctype html><html lang=ja dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>PythonでApache beam 入門 | 🦅 hurutoriya</title><meta name=keywords content="apachebeam,distributedsystem,python"><meta name=description content="TensorFlowの勉強をしていたら、Apache beam を前処理に採用していたケースがあり、興味を持ったので深堀りしてみます。
興味が湧いたモチベーションとしては、
 データ量が増加しても前処理部分を難なくスケールできそう(前処理部分をスケールさせて高速に実験を回したい、並列化などはすべて良い感じにbeamに任せれそう バッチとストリーミングの両者に対応可能なので、柔軟な機械学習の推論サービスが提供できるのでは? (GCPの参考資料 Data preprocessing for machine learning: options and recommendations) Apache beam を触りつつ分散データ処理を学びたい  https://github.com/jhuangtw/xg2xg#services
を見てみるとGoogle 内部のFlume という並列データパイプライン技術がApache beam として公開されているみたいです。
 Apache beam について端的に説明すると
Apache beam は3つの考えを基礎にしています。
 Unified  ストリーミング、バッチの両者のケースに一つのプログラミングモデルで対応可能な統一性   Portable  実行パイプラインが複数の実行環境で実行可能な可搬性   Extensible  新しいSDK、IO Connectorsや変換ライブラリなどをを書いて共有することができる拡張性    Java, Python, Go やScalaを使ってBeam Model を作成して任意のruntime で実行する流れです。
自分はPythonが一眼手軽に書けるのでこの記事ではPythonで紹介していきます。
Version 2.14.0 からPython 3がサポートされたのは非常にありがたいですね。それまではPython 2のみをサポートしており、その影響で技術選定時に採用しづらかったのでは無いのでしょうか?
Spotify が作成しているApach BeamとDataflowのScala APIであるscioが開発されており、そちらも気になっています。
 https://github.com/spotify/scio https://engineering."><meta name=author content="Shunya Ueta"><link rel=canonical href=https://shunyaueta.com/posts/2020-12-26/><link crossorigin=anonymous href=/assets/css/stylesheet.min.f00f189851525f5dc525fa12dfc10fa3656c6cc16f26285e5f7347522031587e.css integrity="sha256-8A8YmFFSX13FJfoS38EPo2VsbMFvJiheX3NHUiAxWH4=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.27cd435cc9ed6abb4b496581b151804f79f366c412620272bb94e2f5f598ebcc.js integrity="sha256-J81DXMntartLSWWBsVGAT3nzZsQSYgJyu5Ti9fWY68w=" onload=hljs.initHighlightingOnLoad();></script><link rel=icon href=https://shunyaueta.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://shunyaueta.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://shunyaueta.com/favicon-32x32.png><link rel=apple-touch-icon href=https://shunyaueta.com/apple-touch-icon.png><link rel=mask-icon href=https://shunyaueta.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme: rgb(29, 30, 32);--entry: rgb(46, 46, 51);--primary: rgb(218, 218, 219);--secondary: rgb(155, 156, 157);--tertiary: rgb(65, 66, 68);--content: rgb(196, 196, 197);--hljs-bg: rgb(46, 46, 51);--code-bg: rgb(55, 56, 62);--border: rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','UA-39994406-11','auto');ga('send','pageview');}</script><meta property="og:title" content="PythonでApache beam 入門"><meta property="og:description" content="TensorFlowの勉強をしていたら、Apache beam を前処理に採用していたケースがあり、興味を持ったので深堀りしてみます。
興味が湧いたモチベーションとしては、
 データ量が増加しても前処理部分を難なくスケールできそう(前処理部分をスケールさせて高速に実験を回したい、並列化などはすべて良い感じにbeamに任せれそう バッチとストリーミングの両者に対応可能なので、柔軟な機械学習の推論サービスが提供できるのでは? (GCPの参考資料 Data preprocessing for machine learning: options and recommendations) Apache beam を触りつつ分散データ処理を学びたい  https://github.com/jhuangtw/xg2xg#services
を見てみるとGoogle 内部のFlume という並列データパイプライン技術がApache beam として公開されているみたいです。
 Apache beam について端的に説明すると
Apache beam は3つの考えを基礎にしています。
 Unified  ストリーミング、バッチの両者のケースに一つのプログラミングモデルで対応可能な統一性   Portable  実行パイプラインが複数の実行環境で実行可能な可搬性   Extensible  新しいSDK、IO Connectorsや変換ライブラリなどをを書いて共有することができる拡張性    Java, Python, Go やScalaを使ってBeam Model を作成して任意のruntime で実行する流れです。
自分はPythonが一眼手軽に書けるのでこの記事ではPythonで紹介していきます。
Version 2.14.0 からPython 3がサポートされたのは非常にありがたいですね。それまではPython 2のみをサポートしており、その影響で技術選定時に採用しづらかったのでは無いのでしょうか?
Spotify が作成しているApach BeamとDataflowのScala APIであるscioが開発されており、そちらも気になっています。
 https://github.com/spotify/scio https://engineering."><meta property="og:type" content="article"><meta property="og:url" content="https://shunyaueta.com/posts/2020-12-26/"><meta property="og:image" content="https://shunyaueta.com/ogp.jpg"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-12-26T00:41:30+09:00"><meta property="article:modified_time" content="2022-07-06T23:46:35+09:00"><meta property="og:site_name" content="Shunya Ueta"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://shunyaueta.com/ogp.jpg"><meta name=twitter:title content="PythonでApache beam 入門"><meta name=twitter:description content="TensorFlowの勉強をしていたら、Apache beam を前処理に採用していたケースがあり、興味を持ったので深堀りしてみます。
興味が湧いたモチベーションとしては、
 データ量が増加しても前処理部分を難なくスケールできそう(前処理部分をスケールさせて高速に実験を回したい、並列化などはすべて良い感じにbeamに任せれそう バッチとストリーミングの両者に対応可能なので、柔軟な機械学習の推論サービスが提供できるのでは? (GCPの参考資料 Data preprocessing for machine learning: options and recommendations) Apache beam を触りつつ分散データ処理を学びたい  https://github.com/jhuangtw/xg2xg#services
を見てみるとGoogle 内部のFlume という並列データパイプライン技術がApache beam として公開されているみたいです。
 Apache beam について端的に説明すると
Apache beam は3つの考えを基礎にしています。
 Unified  ストリーミング、バッチの両者のケースに一つのプログラミングモデルで対応可能な統一性   Portable  実行パイプラインが複数の実行環境で実行可能な可搬性   Extensible  新しいSDK、IO Connectorsや変換ライブラリなどをを書いて共有することができる拡張性    Java, Python, Go やScalaを使ってBeam Model を作成して任意のruntime で実行する流れです。
自分はPythonが一眼手軽に書けるのでこの記事ではPythonで紹介していきます。
Version 2.14.0 からPython 3がサポートされたのは非常にありがたいですね。それまではPython 2のみをサポートしており、その影響で技術選定時に採用しづらかったのでは無いのでしょうか?
Spotify が作成しているApach BeamとDataflowのScala APIであるscioが開発されており、そちらも気になっています。
 https://github.com/spotify/scio https://engineering."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"PythonでApache beam 入門","item":"https://shunyaueta.com/posts/2020-12-26/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"PythonでApache beam 入門","name":"PythonでApache beam 入門","description":"TensorFlowの勉強をしていたら、Apache beam を前処理に採用していたケースがあり、興味を持ったので深堀りしてみます。\n興味が湧いたモチベーションとしては、\n データ量が増加しても前処理部分を難なくスケールできそう(前処理部分をスケールさせて高速に実験を回したい、並列化などはすべて良い感じにbeamに任せれそう バッチとストリーミングの両者に対応可能なので、柔軟な機械学習の推論サービスが提供できるのでは? (GCPの参考資料 Data preprocessing for machine learning: options and recommendations) Apache beam を触りつつ分散データ処理を学びたい  https://github.com/jhuangtw/xg2xg#services\nを見てみるとGoogle 内部のFlume という並列データパイプライン技術がApache beam として公開されているみたいです。\n Apache beam について端的に説明すると\nApache beam は3つの考えを基礎にしています。\n Unified  ストリーミング、バッチの両者のケースに一つのプログラミングモデルで対応可能な統一性   Portable  実行パイプラインが複数の実行環境で実行可能な可搬性   Extensible  新しいSDK、IO Connectorsや変換ライブラリなどをを書いて共有することができる拡張性    Java, Python, Go やScalaを使ってBeam Model を作成して任意のruntime で実行する流れです。\n自分はPythonが一眼手軽に書けるのでこの記事ではPythonで紹介していきます。\nVersion 2.14.0 からPython 3がサポートされたのは非常にありがたいですね。それまではPython 2のみをサポートしており、その影響で技術選定時に採用しづらかったのでは無いのでしょうか?\nSpotify が作成しているApach BeamとDataflowのScala APIであるscioが開発されており、そちらも気になっています。\n https://github.com/spotify/scio https://engineering.","keywords":["apachebeam","distributedsystem","python"],"articleBody":"TensorFlowの勉強をしていたら、Apache beam を前処理に採用していたケースがあり、興味を持ったので深堀りしてみます。\n興味が湧いたモチベーションとしては、\n データ量が増加しても前処理部分を難なくスケールできそう(前処理部分をスケールさせて高速に実験を回したい、並列化などはすべて良い感じにbeamに任せれそう バッチとストリーミングの両者に対応可能なので、柔軟な機械学習の推論サービスが提供できるのでは? (GCPの参考資料 Data preprocessing for machine learning: options and recommendations) Apache beam を触りつつ分散データ処理を学びたい  https://github.com/jhuangtw/xg2xg#services\nを見てみるとGoogle 内部のFlume という並列データパイプライン技術がApache beam として公開されているみたいです。\n Apache beam について端的に説明すると\nApache beam は3つの考えを基礎にしています。\n Unified  ストリーミング、バッチの両者のケースに一つのプログラミングモデルで対応可能な統一性   Portable  実行パイプラインが複数の実行環境で実行可能な可搬性   Extensible  新しいSDK、IO Connectorsや変換ライブラリなどをを書いて共有することができる拡張性    Java, Python, Go やScalaを使ってBeam Model を作成して任意のruntime で実行する流れです。\n自分はPythonが一眼手軽に書けるのでこの記事ではPythonで紹介していきます。\nVersion 2.14.0 からPython 3がサポートされたのは非常にありがたいですね。それまではPython 2のみをサポートしており、その影響で技術選定時に採用しづらかったのでは無いのでしょうか?\nSpotify が作成しているApach BeamとDataflowのScala APIであるscioが開発されており、そちらも気になっています。\n https://github.com/spotify/scio https://engineering.atspotify.com/2017/10/16/big-data-processing-at-spotify-the-road-to-scio-part-1/  では、まずは実際に動かしながら学んでみようということで\nhttps://beam.apache.org/get-started/try-apache-beam/\nを参考にApache Beam をPython SDKで試してみます\nCOLABで実行を試せるので便利ですね\nですが、Python2で実行されるように設定されているのでPython3で実行してみました。\n実行したcolab のコードを見ていきます。\n環境準備 apache-beam のinstallとGCSからApache beamで処理を行うテキストファイルをダウンロードします。\n1 2 3 4 5 6 7 8 9 10 11 12  # shell コマンドを実行して表示する関数 def run(cmd): print(' {}'.format(cmd)) !{cmd} print('') # Install apache-beam. run('pip install --quiet apache-beam') # 対象ファイルの格納ディレクトリを作成後、gsutil を使って /data ディレクトリに格納 run('mkdir -p data') run('gsutil cp gs://dataflow-samples/shakespeare/kinglear.txt data/')   文字のカウント Hello World として単語のカウントを行うデータ処理をbeam で記述してみます。\nテキストファイルを読み込んで、各単語の頻度のカウンティングを行う単純なデータパイプラインを作成しています。\nパイプラインの結果はファイルシステム上で保存されるので分散環境下での大規模処理でも取り扱いに役立ちます。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  import apache_beam as beam import re inputs_pattern = 'data/*' outputs_prefix = 'outputs/part' with beam.Pipeline() as pipeline: ( pipeline | 'Read lines'  beam.io.ReadFromText(inputs_pattern) | 'Find words'  beam.FlatMap(lambda line: re.findall(r\"[a-zA-Z']+\", line)) | 'Pair words with 1'  beam.Map(lambda word: (word, 1)) | 'Group and sum'  beam.CombinePerKey(sum) | 'Format results'  beam.Map(lambda word_count: str(word_count)) | 'Write results'  beam.io.WriteToText(outputs_prefix) )   はい、いきなり\nwith beam.Pipeline() as pipeline: の以降から意味がわからなくなりました。\nApache beam特有の概念を理解する必要があるので\nhttps://beam.apache.org/documentation/programming-guide/\nを参考に解説してみます。\nApache Beam Programming Guide Beasm SDKで提供されるクラス郡をここでは紹介していきます。このクラス郡を使うことでデータパイプラインを作成することができます。\nOverview まずBeamを使用するためには、まず最初にBeam SDKのクラスを使って起動プログラムを作成する必要があります。driver program は、あなたのパイプライン(入力、変形と出力のすべて)と実行環境を定義する必要があります。\nBeam SDKは大規模なデータ処理のメカニズムを単純な形で抽象化している\n Pipeline  Pipeline はデータ処理タスクの実行開始から終了までをカブセル化するクラスです。これは入力データの読み込みやデータの変形、出力データの書き込みを含む。Beam driver programs は必ずPipelineを作成します。またPipelines 作成時には、実行オプション(どの実行環境下でどのように実行するか)を必ず明記する必要があ。   PCollection  Pcollection は分散データセットを表現するクラスです。ここでのデータセットは bounded (ファイルなどの固定されたソース、つまりバッチ)とunbounded (subscriptionなど連続的にアップロードされるソース、つまりストリーム)の両者を指しています。実行するパイプラインは外部データの読み込みによって初期化されたPCollectionによって構築されます。また外部データだけでなく、インメモリのデータからPCollectionを作ることも可能です。つまり、PCollectionはPipelineの出力と入力を担当する。   PTransform  PTransform パイプラインでのはデータ処理命令を表現するクラスです。すべての PTransform は一つ以上のPCollection オブジェクトを入力として受け取り、ゼロもしくはそれ以上の数のPCollectionを出力として作成する   IOS transrforms  Beamはいくらかの入力と出力のインタフェースがあり、PTransformが読み込み、もしくは書き込みを多種多様な外部のストレージシステムに対して行う    基本的なBeamの起動プログラムは以下の手順で動く\n Pipeline オブジェクトを作成し、パイプラインの実行オプションとパイプラインランナーを設定する Pipeline データのために初期のPCollection を行う。そのためにIOs を用いて外部のストレージシステムもしくはインメモリデータから PCollectionを作成する。 PTransform を各 PCollection へ適用する。Transform は新しい出力としてPCollection を作成する。PCollection を変数、PTransformは関数として考えると、Pipelineは変数と関数からなる複雑な処理グラフとして捉えることができる。 IOs を使用し、最終的に PCollection を外部ソースに書き出す パイプラインをパイプラインランナーで実行する  あなたが Beam の起動プログラムを実行した時、パイプラインランナーはPCollection を基に作成した transformが適用される workflow graph が構築される。このグラフは適切な分散処理バックエンドで、非同期ジョブとして実行される。\nここまでで Beam の基礎的な概念を理解できたと思うので最初のサンプルコードでの各行の実行内容について解説します\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  import apache_beam as beam import re inputs_pattern = 'data/*' outputs_prefix = 'outputs/part' # ローカル環境でDirectRunnerを実行 with beam.Pipeline() as pipeline: # 文字の集計データをPCollection に格納 # 各要素は (word, count) のタプルであり、(str, int)の型となっている word_counts = ( # 入力のPCollection は空のパイプラインとする pipeline # テキストファイルから行を読み込む | 'Read lines'  beam.io.ReadFromText(inputs_pattern) # Element type: str - text line # 正規表現を利用して行内のすべての単語に反復処理を行う # FlatMap will yield an element for every element in an iterable. | 'Find words'  beam.FlatMap(lambda line: re.findall(r\"[a-zA-Z']+\", line)) # Element type: str - word # 単語が存在した場合、value が１となるkey-value のペアを作成 # すべての単語を集計していき、同一単語をグループ化する | 'Pair words with 1'  beam.Map(lambda word: (word, 1)) # Element type: (str, int) - key: word, value: 1 # sum() 関数を使ってkeyごとにグループを行う | 'Group and sum'  beam.CombinePerKey(sum) # Element type: (str, int) - key: word, value: counts ) ( # 入力となるPCollection は上記で作成された word_counts # 結果は文字列に処理することで、テキストファイルとして書き込み可能にする | 'Format results'  beam.Map(lambda word_count: str(word_count)) # Element type: str - text line # 最後に結果をファイルに書き込みます。 | 'Write results'  beam.io.WriteToText(outputs_prefix) ) #20個の結果を各ファイルから出力してみる。その際に順序は保証されない run('head -n 20 {}-00000-of-*'.format(outputs_prefix))   実行結果\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.  head -n 20 outputs/part-00000-of-* ('KING', 243) ('LEAR', 236) ('DRAMATIS', 1) ('PERSONAE', 1) ('king', 65) ('of', 447) ('Britain', 2) ('OF', 15) ('FRANCE', 10) ('DUKE', 3) ('BURGUNDY', 8) ('CORNWALL', 63) ('ALBANY', 67) ('EARL', 2) ('KENT', 156) ('GLOUCESTER', 141) ('EDGAR', 126) ('son', 29) ('to', 438) ('Gloucester', 26)   どうでしたか? まだサンプルコードを動かしただけなので使いこなす自信はありませんが、Apache beam がどのような考えで設計され動かすことができるかが少しはつかめたのでは無いのでしょうか?\n次回は典型的なデータ処理をApache beamで動かしてみたいと思います。\n","wordCount":"570","inLanguage":"ja","datePublished":"2020-12-26T00:41:30+09:00","dateModified":"2022-07-06T23:46:35+09:00","author":{"@type":"Person","name":"Shunya Ueta"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://shunyaueta.com/posts/2020-12-26/"},"publisher":{"@type":"Organization","name":"🦅 hurutoriya","logo":{"@type":"ImageObject","url":"https://shunyaueta.com/favicon.ico"}}}</script></head><body id=top><script>if(localStorage.getItem("pref-theme")==="dark"){document.body.classList.add('dark');}else if(localStorage.getItem("pref-theme")==="light"){document.body.classList.remove('dark')}else if(window.matchMedia('(prefers-color-scheme: dark)').matches){document.body.classList.add('dark');}</script><header class=header><nav class=nav><div class=logo><a href=https://shunyaueta.com/ accesskey=h title="🦅 hurutoriya (Alt + H)">🦅 hurutoriya</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://shunyaueta.com/archives title=Archive><span>Archive</span></a></li><li><a href=https://shunyaueta.com/about title=About><span>About</span></a></li><li><a href=https://shunyaueta.com/tags/newsletter/ title=Newsletter><span>Newsletter</span></a></li><li><a href=https://shunyaueta.com/index.xml title=RSS><span>RSS</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>PythonでApache beam 入門</h1><div class=post-meta><span title="2020-12-26 00:41:30 +0900 +0900">December 26, 2020</span>&nbsp;·&nbsp;Shunya Ueta&nbsp;|&nbsp;<a href=https://github.com/hurutoriya/hurutoriya.github.io/tree/source/content/posts/2020-12-26/index.md rel="noopener noreferrer" target=_blank>Edit this post (この記事を編集する)</a></div></header><div class=post-content><p>TensorFlowの勉強をしていたら、Apache beam を前処理に採用していたケースがあり、興味を持ったので深堀りしてみます。</p><p>興味が湧いたモチベーションとしては、</p><ul><li>データ量が増加しても前処理部分を難なくスケールできそう(前処理部分をスケールさせて高速に実験を回したい、並列化などはすべて良い感じにbeamに任せれそう</li><li>バッチとストリーミングの両者に対応可能なので、柔軟な機械学習の推論サービスが提供できるのでは? (GCPの参考資料 <a href=https://cloud.google.com/solutions/machine-learning/data-preprocessing-for-ml-with-tf-transform-pt1>Data preprocessing for machine learning: options and recommendations</a>)</li><li>Apache beam を触りつつ分散データ処理を学びたい</li></ul><p><a href=https://github.com/jhuangtw/xg2xg#services>https://github.com/jhuangtw/xg2xg#services</a></p><p>を見てみるとGoogle 内部のFlume という並列データパイプライン技術がApache beam として公開されているみたいです。</p><hr><p>Apache beam について端的に説明すると</p><p>Apache beam は3つの考えを基礎にしています。</p><ul><li>Unified<ul><li>ストリーミング、バッチの両者のケースに一つのプログラミングモデルで対応可能な統一性</li></ul></li><li>Portable<ul><li>実行パイプラインが複数の実行環境で実行可能な可搬性</li></ul></li><li>Extensible<ul><li>新しいSDK、IO Connectorsや変換ライブラリなどをを書いて共有することができる拡張性</li></ul></li></ul><p>Java, Python, Go やScalaを使ってBeam Model を作成して任意のruntime で実行する流れです。</p><p>自分はPythonが一眼手軽に書けるのでこの記事ではPythonで紹介していきます。</p><p>Version 2.14.0 からPython 3がサポートされたのは非常にありがたいですね。それまではPython 2のみをサポートしており、その影響で技術選定時に採用しづらかったのでは無いのでしょうか?</p><p>Spotify が作成しているApach BeamとDataflowのScala APIであるscioが開発されており、そちらも気になっています。</p><ul><li><a href=https://github.com/spotify/scio>https://github.com/spotify/scio</a></li><li><a href=https://engineering.atspotify.com/2017/10/16/big-data-processing-at-spotify-the-road-to-scio-part-1/>https://engineering.atspotify.com/2017/10/16/big-data-processing-at-spotify-the-road-to-scio-part-1/</a></li></ul><p>では、まずは実際に動かしながら学んでみようということで</p><p><a href=https://beam.apache.org/get-started/try-apache-beam/>https://beam.apache.org/get-started/try-apache-beam/</a></p><p>を参考にApache Beam をPython SDKで試してみます</p><p>COLABで実行を試せるので便利ですね</p><p>ですが、Python2で実行されるように設定されているのでPython3で実行してみました。</p><p>実行したcolab のコードを見ていきます。</p><h3 id=環境準備>環境準備<a hidden class=anchor aria-hidden=true href=#環境準備>#</a></h3><p><code>apache-beam</code> のinstallとGCSからApache beamで処理を行うテキストファイルをダウンロードします。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=c1># shell コマンドを実行して表示する関数</span>
<span class=k>def</span> <span class=nf>run</span><span class=p>(</span><span class=n>cmd</span><span class=p>):</span>
  <span class=k>print</span><span class=p>(</span><span class=s1>&#39;&gt;&gt; {}&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>cmd</span><span class=p>))</span>
  <span class=err>!</span><span class=p>{</span><span class=n>cmd</span><span class=p>}</span>
  <span class=k>print</span><span class=p>(</span><span class=s1>&#39;&#39;</span><span class=p>)</span>

<span class=c1># Install apache-beam.</span>
<span class=n>run</span><span class=p>(</span><span class=s1>&#39;pip install --quiet apache-beam&#39;</span><span class=p>)</span>

<span class=c1># 対象ファイルの格納ディレクトリを作成後、gsutil を使って /data ディレクトリに格納</span>
<span class=n>run</span><span class=p>(</span><span class=s1>&#39;mkdir -p data&#39;</span><span class=p>)</span>
<span class=n>run</span><span class=p>(</span><span class=s1>&#39;gsutil cp gs://dataflow-samples/shakespeare/kinglear.txt data/&#39;</span><span class=p>)</span>
</code></pre></td></tr></table></div></div><h2 id=文字のカウント>文字のカウント<a hidden class=anchor aria-hidden=true href=#文字のカウント>#</a></h2><p>Hello World として単語のカウントを行うデータ処理をbeam で記述してみます。</p><p>テキストファイルを読み込んで、各単語の頻度のカウンティングを行う単純なデータパイプラインを作成しています。</p><p>パイプラインの結果はファイルシステム上で保存されるので分散環境下での大規模処理でも取り扱いに役立ちます。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=kn>import</span> <span class=nn>apache_beam</span> <span class=kn>as</span> <span class=nn>beam</span>
<span class=kn>import</span> <span class=nn>re</span>

<span class=n>inputs_pattern</span> <span class=o>=</span> <span class=s1>&#39;data/*&#39;</span>
<span class=n>outputs_prefix</span> <span class=o>=</span> <span class=s1>&#39;outputs/part&#39;</span>

<span class=k>with</span> <span class=n>beam</span><span class=o>.</span><span class=n>Pipeline</span><span class=p>()</span> <span class=k>as</span> <span class=n>pipeline</span><span class=p>:</span>
  <span class=p>(</span>
      <span class=n>pipeline</span>
      <span class=o>|</span> <span class=s1>&#39;Read lines&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>ReadFromText</span><span class=p>(</span><span class=n>inputs_pattern</span><span class=p>)</span>
      <span class=o>|</span> <span class=s1>&#39;Find words&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>FlatMap</span><span class=p>(</span><span class=k>lambda</span> <span class=n>line</span><span class=p>:</span> <span class=n>re</span><span class=o>.</span><span class=n>findall</span><span class=p>(</span><span class=sa>r</span><span class=s2>&#34;[a-zA-Z&#39;]+&#34;</span><span class=p>,</span> <span class=n>line</span><span class=p>))</span>
      <span class=o>|</span> <span class=s1>&#39;Pair words with 1&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>word</span><span class=p>:</span> <span class=p>(</span><span class=n>word</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
      <span class=o>|</span> <span class=s1>&#39;Group and sum&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>CombinePerKey</span><span class=p>(</span><span class=nb>sum</span><span class=p>)</span>
      <span class=o>|</span> <span class=s1>&#39;Format results&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>word_count</span><span class=p>:</span> <span class=nb>str</span><span class=p>(</span><span class=n>word_count</span><span class=p>))</span>
      <span class=o>|</span> <span class=s1>&#39;Write results&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>WriteToText</span><span class=p>(</span><span class=n>outputs_prefix</span><span class=p>)</span>
  <span class=p>)</span>
</code></pre></td></tr></table></div></div><p>はい、いきなり</p><p>with beam.Pipeline() as pipeline:
の以降から意味がわからなくなりました。</p><p>Apache beam特有の概念を理解する必要があるので</p><p><a href=https://beam.apache.org/documentation/programming-guide/>https://beam.apache.org/documentation/programming-guide/</a></p><p>を参考に解説してみます。</p><h2 id=apache-beam-programming-guide>Apache Beam Programming Guide<a hidden class=anchor aria-hidden=true href=#apache-beam-programming-guide>#</a></h2><p>Beasm SDKで提供されるクラス郡をここでは紹介していきます。このクラス郡を使うことでデータパイプラインを作成することができます。</p><h3 id=overview>Overview<a hidden class=anchor aria-hidden=true href=#overview>#</a></h3><p>まずBeamを使用するためには、まず最初にBeam SDKのクラスを使って起動プログラムを作成する必要があります。driver program は、あなたのパイプライン(入力、変形と出力のすべて)と実行環境を定義する必要があります。</p><p>Beam SDKは大規模なデータ処理のメカニズムを単純な形で抽象化している</p><ul><li>Pipeline<ul><li>Pipeline はデータ処理タスクの実行開始から終了までをカブセル化するクラスです。これは入力データの読み込みやデータの変形、出力データの書き込みを含む。Beam driver programs は必ずPipelineを作成します。またPipelines 作成時には、実行オプション(どの実行環境下でどのように実行するか)を必ず明記する必要があ。</li></ul></li><li>PCollection<ul><li>Pcollection は分散データセットを表現するクラスです。ここでのデータセットは bounded (ファイルなどの固定されたソース、つまりバッチ)とunbounded (subscriptionなど連続的にアップロードされるソース、つまりストリーム)の両者を指しています。実行するパイプラインは外部データの読み込みによって初期化されたPCollectionによって構築されます。また外部データだけでなく、インメモリのデータからPCollectionを作ることも可能です。つまり、PCollectionはPipelineの出力と入力を担当する。</li></ul></li><li>PTransform<ul><li>PTransform パイプラインでのはデータ処理命令を表現するクラスです。すべての <code>PTransform</code> は一つ以上のPCollection オブジェクトを入力として受け取り、ゼロもしくはそれ以上の数のPCollectionを出力として作成する</li></ul></li><li>IOS transrforms<ul><li>Beamはいくらかの入力と出力のインタフェースがあり、PTransformが読み込み、もしくは書き込みを多種多様な外部のストレージシステムに対して行う</li></ul></li></ul><p>基本的なBeamの起動プログラムは以下の手順で動く</p><ol><li>Pipeline オブジェクトを作成し、パイプラインの実行オプションとパイプラインランナーを設定する</li><li>Pipeline データのために初期のPCollection を行う。そのためにIOs を用いて外部のストレージシステムもしくはインメモリデータから PCollectionを作成する。</li><li>PTransform を各 PCollection へ適用する。Transform は新しい出力としてPCollection を作成する。PCollection を変数、PTransformは関数として考えると、Pipelineは変数と関数からなる複雑な処理グラフとして捉えることができる。</li><li>IOs を使用し、最終的に PCollection を外部ソースに書き出す</li><li>パイプラインをパイプラインランナーで実行する</li></ol><p>あなたが Beam の起動プログラムを実行した時、パイプラインランナーはPCollection を基に作成した transformが適用される workflow graph が構築される。このグラフは適切な分散処理バックエンドで、非同期ジョブとして実行される。</p><p>ここまでで Beam の基礎的な概念を理解できたと思うので最初のサンプルコードでの各行の実行内容について解説します</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=kn>import</span> <span class=nn>apache_beam</span> <span class=kn>as</span> <span class=nn>beam</span>
<span class=kn>import</span> <span class=nn>re</span>

<span class=n>inputs_pattern</span> <span class=o>=</span> <span class=s1>&#39;data/*&#39;</span>
<span class=n>outputs_prefix</span> <span class=o>=</span> <span class=s1>&#39;outputs/part&#39;</span>

<span class=c1># ローカル環境でDirectRunnerを実行</span>
<span class=k>with</span> <span class=n>beam</span><span class=o>.</span><span class=n>Pipeline</span><span class=p>()</span> <span class=k>as</span> <span class=n>pipeline</span><span class=p>:</span>
  <span class=c1># 文字の集計データをPCollection に格納</span>
  <span class=c1># 各要素は (word, count) のタプルであり、(str, int)の型となっている</span>
  <span class=n>word_counts</span> <span class=o>=</span> <span class=p>(</span>
      <span class=c1># 入力のPCollection は空のパイプラインとする</span>
      <span class=n>pipeline</span>

      <span class=c1># テキストファイルから行を読み込む</span>
      <span class=o>|</span> <span class=s1>&#39;Read lines&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>ReadFromText</span><span class=p>(</span><span class=n>inputs_pattern</span><span class=p>)</span>
      <span class=c1># Element type: str - text line</span>

      <span class=c1># 正規表現を利用して行内のすべての単語に反復処理を行う</span>
      <span class=c1># FlatMap will yield an element for every element in an iterable.</span>
      <span class=o>|</span> <span class=s1>&#39;Find words&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>FlatMap</span><span class=p>(</span><span class=k>lambda</span> <span class=n>line</span><span class=p>:</span> <span class=n>re</span><span class=o>.</span><span class=n>findall</span><span class=p>(</span><span class=sa>r</span><span class=s2>&#34;[a-zA-Z&#39;]+&#34;</span><span class=p>,</span> <span class=n>line</span><span class=p>))</span>
      <span class=c1># Element type: str - word</span>

      <span class=c1># 単語が存在した場合、value が１となるkey-value のペアを作成</span>
      <span class=c1># すべての単語を集計していき、同一単語をグループ化する</span>
      <span class=o>|</span> <span class=s1>&#39;Pair words with 1&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>word</span><span class=p>:</span> <span class=p>(</span><span class=n>word</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
      <span class=c1># Element type: (str, int) - key: word, value: 1</span>

      <span class=c1># sum() 関数を使ってkeyごとにグループを行う</span>
      <span class=o>|</span> <span class=s1>&#39;Group and sum&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>CombinePerKey</span><span class=p>(</span><span class=nb>sum</span><span class=p>)</span>
      <span class=c1># Element type: (str, int) - key: word, value: counts</span>
  <span class=p>)</span>
  <span class=p>(</span>
      <span class=c1># 入力となるPCollection は上記で作成された</span>
      <span class=n>word_counts</span>

      <span class=c1># 結果は文字列に処理することで、テキストファイルとして書き込み可能にする</span>
      <span class=o>|</span> <span class=s1>&#39;Format results&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>word_count</span><span class=p>:</span> <span class=nb>str</span><span class=p>(</span><span class=n>word_count</span><span class=p>))</span>
      <span class=c1># Element type: str - text line</span>

      <span class=c1># 最後に結果をファイルに書き込みます。</span>
      <span class=o>|</span> <span class=s1>&#39;Write results&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>WriteToText</span><span class=p>(</span><span class=n>outputs_prefix</span><span class=p>)</span>
  <span class=p>)</span>

<span class=c1>#20個の結果を各ファイルから出力してみる。その際に順序は保証されない</span>
<span class=n>run</span><span class=p>(</span><span class=s1>&#39;head -n 20 {}-00000-of-*&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>outputs_prefix</span><span class=p>))</span>
</code></pre></td></tr></table></div></div><p>実行結果</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-python data-lang=python><span class=n>WARNING</span><span class=p>:</span><span class=n>apache_beam</span><span class=o>.</span><span class=n>runners</span><span class=o>.</span><span class=n>interactive</span><span class=o>.</span><span class=n>interactive_environment</span><span class=p>:</span><span class=n>Dependencies</span> <span class=n>required</span> <span class=k>for</span> <span class=n>Interactive</span> <span class=n>Beam</span> <span class=n>PCollection</span> <span class=n>visualization</span> <span class=n>are</span> <span class=ow>not</span> <span class=n>available</span><span class=p>,</span> <span class=n>please</span> <span class=n>use</span><span class=p>:</span> <span class=sb>`pip install apache-beam[interactive]`</span> <span class=n>to</span> <span class=n>install</span> <span class=n>necessary</span> <span class=n>dependencies</span> <span class=n>to</span> <span class=n>enable</span> <span class=nb>all</span> <span class=n>data</span> <span class=n>visualization</span> <span class=n>features</span><span class=o>.</span>
<span class=o>&gt;&gt;</span> <span class=n>head</span> <span class=o>-</span><span class=n>n</span> <span class=mi>20</span> <span class=n>outputs</span><span class=o>/</span><span class=n>part</span><span class=o>-</span><span class=mo>00000</span><span class=o>-</span><span class=n>of</span><span class=o>-*</span>
<span class=p>(</span><span class=s1>&#39;KING&#39;</span><span class=p>,</span> <span class=mi>243</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;LEAR&#39;</span><span class=p>,</span> <span class=mi>236</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;DRAMATIS&#39;</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;PERSONAE&#39;</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;king&#39;</span><span class=p>,</span> <span class=mi>65</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;of&#39;</span><span class=p>,</span> <span class=mi>447</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;Britain&#39;</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;OF&#39;</span><span class=p>,</span> <span class=mi>15</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;FRANCE&#39;</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;DUKE&#39;</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;BURGUNDY&#39;</span><span class=p>,</span> <span class=mi>8</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;CORNWALL&#39;</span><span class=p>,</span> <span class=mi>63</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;ALBANY&#39;</span><span class=p>,</span> <span class=mi>67</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;EARL&#39;</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;KENT&#39;</span><span class=p>,</span> <span class=mi>156</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;GLOUCESTER&#39;</span><span class=p>,</span> <span class=mi>141</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;EDGAR&#39;</span><span class=p>,</span> <span class=mi>126</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;son&#39;</span><span class=p>,</span> <span class=mi>29</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;to&#39;</span><span class=p>,</span> <span class=mi>438</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;Gloucester&#39;</span><span class=p>,</span> <span class=mi>26</span><span class=p>)</span>
</code></pre></td></tr></table></div></div><p>どうでしたか?
まだサンプルコードを動かしただけなので使いこなす自信はありませんが、Apache beam がどのような考えで設計され動かすことができるかが少しはつかめたのでは無いのでしょうか?</p><p>次回は典型的なデータ処理をApache beamで動かしてみたいと思います。</p><h2>See Also</h2><ul><li><a href=/posts/2020-09-09/>pandas を使って特定のディレクトリのCSVファイルをすべて連結して一つのCSVファイルを作成</a></li><li><a href=/posts/2020-08-23/>Python の内包表記とジェネレータ式のメモリ使用量比較</a></li><li><a href=/posts/2020-08-04/>AOJの「ITP I」40問をPythonで解いた</a></li><li><a href=/posts/2020-07-25/>How to write the UnitTest with stdin at Pytest</a></li><li><a href=/posts/2020-05-10/>自走プログラマーを読み終えた</a></li></ul><h2>Support</h2>記事をお読みくださりありがとうございます。このウェブサイトの運営を支援していただける方を募集しています。
もしよろしければ、下のボタンからサポート(投げ銭)していただけると、ブログ執筆、情報発信のモチベーションに繋がります✨
<a href=https://www.buymeacoffee.com/hurutoriya><img src="https://img.buymeacoffee.com/button-api/?text=Buy me a coffee&emoji=☕&slug=hurutoriya&button_colour=FFDD00&font_colour=000000&font_family=Inter&outline_colour=000000&coffee_colour=ffffff"></a></div><footer class=post-footer><ul class=post-tags><li><a href=https://shunyaueta.com/tags/python/>python</a></li><li><a href=https://shunyaueta.com/tags/apachebeam/>apachebeam</a></li><li><a href=https://shunyaueta.com/tags/distributedsystem/>distributedsystem</a></li></ul><nav class=paginav><a class=prev href=https://shunyaueta.com/posts/2021-01-17/><span class=title>« 前のページ</span><br><span>TFXの歴史を振り返りつつ機械学習エンジニアリングを提案する論文「Towards ML Engineering: A Brief History Of TensorFlow Extended (TFX)」</span></a>
<a class=next href=https://shunyaueta.com/posts/2020-09-27/><span class=title>次のページ »</span><br><span>機械学習・ソフトウェアエンジニアリングをテーマにしたPodcast just4fun.fm を始めてみた</span></a></nav></footer><script src=https://giscus.app/client.js data-repo=hurutoriya/hurutoriya.github.io data-repo-id="MDEwOlJlcG9zaXRvcnk2MDgyNTY1Nw==" data-category=Comments data-category-id=DIC_kwDOA6AgOc4CAQTX data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=0 data-theme=dark data-lang=ja crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2022 <a href=https://shunyaueta.com/>🦅 hurutoriya</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z" /></svg></a><script>let menu=document.getElementById('menu')
if(menu){menu.scrollLeft=localStorage.getItem("menu-scroll-position");menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft);}}
document.querySelectorAll('a[href^="#"]').forEach(anchor=>{anchor.addEventListener("click",function(e){e.preventDefault();var id=this.getAttribute("href").substr(1);if(!window.matchMedia('(prefers-reduced-motion: reduce)').matches){document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({behavior:"smooth"});}else{document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();}
if(id==="top"){history.replaceState(null,null," ");}else{history.pushState(null,null,`#${id}`);}});});</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){if(document.body.scrollTop>800||document.documentElement.scrollTop>800){mybutton.style.visibility="visible";mybutton.style.opacity="1";}else{mybutton.style.visibility="hidden";mybutton.style.opacity="0";}};</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{if(document.body.className.includes("dark")){document.body.classList.remove('dark');localStorage.setItem("pref-theme",'light');}else{document.body.classList.add('dark');localStorage.setItem("pref-theme",'dark');}})</script><script>document.querySelectorAll('pre > code').forEach((codeblock)=>{const container=codeblock.parentNode.parentNode;const copybutton=document.createElement('button');copybutton.classList.add('copy-code');copybutton.innerText='copy';function copyingDone(){copybutton.innerText='copied!';setTimeout(()=>{copybutton.innerText='copy';},2000);}
copybutton.addEventListener('click',(cb)=>{if('clipboard'in navigator){navigator.clipboard.writeText(codeblock.textContent);copyingDone();return;}
const range=document.createRange();range.selectNodeContents(codeblock);const selection=window.getSelection();selection.removeAllRanges();selection.addRange(range);try{document.execCommand('copy');copyingDone();}catch(e){};selection.removeRange(range);});if(container.classList.contains("highlight")){container.appendChild(copybutton);}else if(container.parentNode.firstChild==container){}else if(codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"){codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);}else{codeblock.parentNode.appendChild(copybutton);}});</script></body></html>