<!doctype html><html lang=ja><head><meta http-equiv=x-clacks-overhead content="GNU Terry Pratchett"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>PythonでApache beam 入門 | hurutoriya</title><meta name=title content="PythonでApache beam 入門"><meta name=description content="TensorFlowの勉強をしていたら、Apache beam を前処理に採用していたケースがあり、興味を持ったので深堀りしてみます。
興味が湧いたモチベーションとしては、
データ量が増加しても前処理部分を難なくスケールできそう(前処理部分をスケールさせて高速に実験を回したい、並列化などはすべて良い感じにbeamに任せれそう バッチとストリーミングの両者に対応可能なので、柔軟な機械学習の推論サービスが提供できるのでは? (GCPの参考資料 Data preprocessing for machine learning: options and recommendations) Apache beam を触りつつ分散データ処理を学びたい https://github.com/jhuangtw/xg2xg#services
を見てみるとGoogle 内部のFlume という並列データパイプライン技術がApache beam として公開されているみたいです。
Apache beam について端的に説明すると
Apache beam は3つの考えを基礎にしています。
Unified ストリーミング、バッチの両者のケースに一つのプログラミングモデルで対応可能な統一性 Portable 実行パイプラインが複数の実行環境で実行可能な可搬性 Extensible 新しいSDK、IO Connectorsや変換ライブラリなどをを書いて共有することができる拡張性 Java, Python, Go やScalaを使ってBeam Model を作成して任意のruntime で実行する流れです。
自分はPythonが一眼手軽に書けるのでこの記事ではPythonで紹介していきます。
Version 2.14.0 からPython 3がサポートされたのは非常にありがたいですね。それまではPython 2のみをサポートしており、その影響で技術選定時に採用しづらかったのでは無いのでしょうか?
Spotify が作成しているApach BeamとDataflowのScala APIであるscioが開発されており、そちらも気になっています。
https://github.com/spotify/scio https://engineering.atspotify.com/2017/10/16/big-data-processing-at-spotify-the-road-to-scio-part-1/ では、まずは実際に動かしながら学んでみようということで
https://beam.apache.org/get-started/try-apache-beam/
を参考にApache Beam をPython SDKで試してみます
COLABで実行を試せるので便利ですね
ですが、Python2で実行されるように設定されているのでPython3で実行してみました。
実行したcolab のコードを見ていきます。
環境準備 apache-beam のinstallとGCSからApache beamで処理を行うテキストファイルをダウンロードします。"><meta name=keywords content="apachebeam,distributedsystem,python,"><meta property="og:title" content="PythonでApache beam 入門"><meta property="og:description" content="TensorFlowの勉強をしていたら、Apache beam を前処理に採用していたケースがあり、興味を持ったので深堀りしてみます。
興味が湧いたモチベーションとしては、
データ量が増加しても前処理部分を難なくスケールできそう(前処理部分をスケールさせて高速に実験を回したい、並列化などはすべて良い感じにbeamに任せれそう バッチとストリーミングの両者に対応可能なので、柔軟な機械学習の推論サービスが提供できるのでは? (GCPの参考資料 Data preprocessing for machine learning: options and recommendations) Apache beam を触りつつ分散データ処理を学びたい https://github.com/jhuangtw/xg2xg#services
を見てみるとGoogle 内部のFlume という並列データパイプライン技術がApache beam として公開されているみたいです。
Apache beam について端的に説明すると
Apache beam は3つの考えを基礎にしています。
Unified ストリーミング、バッチの両者のケースに一つのプログラミングモデルで対応可能な統一性 Portable 実行パイプラインが複数の実行環境で実行可能な可搬性 Extensible 新しいSDK、IO Connectorsや変換ライブラリなどをを書いて共有することができる拡張性 Java, Python, Go やScalaを使ってBeam Model を作成して任意のruntime で実行する流れです。
自分はPythonが一眼手軽に書けるのでこの記事ではPythonで紹介していきます。
Version 2.14.0 からPython 3がサポートされたのは非常にありがたいですね。それまではPython 2のみをサポートしており、その影響で技術選定時に採用しづらかったのでは無いのでしょうか?
Spotify が作成しているApach BeamとDataflowのScala APIであるscioが開発されており、そちらも気になっています。
https://github.com/spotify/scio https://engineering.atspotify.com/2017/10/16/big-data-processing-at-spotify-the-road-to-scio-part-1/ では、まずは実際に動かしながら学んでみようということで
https://beam.apache.org/get-started/try-apache-beam/
を参考にApache Beam をPython SDKで試してみます
COLABで実行を試せるので便利ですね
ですが、Python2で実行されるように設定されているのでPython3で実行してみました。
実行したcolab のコードを見ていきます。
環境準備 apache-beam のinstallとGCSからApache beamで処理を行うテキストファイルをダウンロードします。"><meta property="og:type" content="article"><meta property="og:url" content="https://shunyaueta.com/posts/2020-12-26/"><meta property="og:image" content="https://shunyaueta.com/ogp.jpg"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-12-26T00:41:30+09:00"><meta property="article:modified_time" content="2020-12-26T00:41:30+09:00"><meta property="og:site_name" content="Shunya Ueta"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://shunyaueta.com/ogp.jpg"><meta name=twitter:title content="PythonでApache beam 入門"><meta name=twitter:description content="TensorFlowの勉強をしていたら、Apache beam を前処理に採用していたケースがあり、興味を持ったので深堀りしてみます。
興味が湧いたモチベーションとしては、
データ量が増加しても前処理部分を難なくスケールできそう(前処理部分をスケールさせて高速に実験を回したい、並列化などはすべて良い感じにbeamに任せれそう バッチとストリーミングの両者に対応可能なので、柔軟な機械学習の推論サービスが提供できるのでは? (GCPの参考資料 Data preprocessing for machine learning: options and recommendations) Apache beam を触りつつ分散データ処理を学びたい https://github.com/jhuangtw/xg2xg#services
を見てみるとGoogle 内部のFlume という並列データパイプライン技術がApache beam として公開されているみたいです。
Apache beam について端的に説明すると
Apache beam は3つの考えを基礎にしています。
Unified ストリーミング、バッチの両者のケースに一つのプログラミングモデルで対応可能な統一性 Portable 実行パイプラインが複数の実行環境で実行可能な可搬性 Extensible 新しいSDK、IO Connectorsや変換ライブラリなどをを書いて共有することができる拡張性 Java, Python, Go やScalaを使ってBeam Model を作成して任意のruntime で実行する流れです。
自分はPythonが一眼手軽に書けるのでこの記事ではPythonで紹介していきます。
Version 2.14.0 からPython 3がサポートされたのは非常にありがたいですね。それまではPython 2のみをサポートしており、その影響で技術選定時に採用しづらかったのでは無いのでしょうか?
Spotify が作成しているApach BeamとDataflowのScala APIであるscioが開発されており、そちらも気になっています。
https://github.com/spotify/scio https://engineering.atspotify.com/2017/10/16/big-data-processing-at-spotify-the-road-to-scio-part-1/ では、まずは実際に動かしながら学んでみようということで
https://beam.apache.org/get-started/try-apache-beam/
を参考にApache Beam をPython SDKで試してみます
COLABで実行を試せるので便利ですね
ですが、Python2で実行されるように設定されているのでPython3で実行してみました。
実行したcolab のコードを見ていきます。
環境準備 apache-beam のinstallとGCSからApache beamで処理を行うテキストファイルをダウンロードします。"><meta itemprop=name content="PythonでApache beam 入門"><meta itemprop=description content="TensorFlowの勉強をしていたら、Apache beam を前処理に採用していたケースがあり、興味を持ったので深堀りしてみます。
興味が湧いたモチベーションとしては、
データ量が増加しても前処理部分を難なくスケールできそう(前処理部分をスケールさせて高速に実験を回したい、並列化などはすべて良い感じにbeamに任せれそう バッチとストリーミングの両者に対応可能なので、柔軟な機械学習の推論サービスが提供できるのでは? (GCPの参考資料 Data preprocessing for machine learning: options and recommendations) Apache beam を触りつつ分散データ処理を学びたい https://github.com/jhuangtw/xg2xg#services
を見てみるとGoogle 内部のFlume という並列データパイプライン技術がApache beam として公開されているみたいです。
Apache beam について端的に説明すると
Apache beam は3つの考えを基礎にしています。
Unified ストリーミング、バッチの両者のケースに一つのプログラミングモデルで対応可能な統一性 Portable 実行パイプラインが複数の実行環境で実行可能な可搬性 Extensible 新しいSDK、IO Connectorsや変換ライブラリなどをを書いて共有することができる拡張性 Java, Python, Go やScalaを使ってBeam Model を作成して任意のruntime で実行する流れです。
自分はPythonが一眼手軽に書けるのでこの記事ではPythonで紹介していきます。
Version 2.14.0 からPython 3がサポートされたのは非常にありがたいですね。それまではPython 2のみをサポートしており、その影響で技術選定時に採用しづらかったのでは無いのでしょうか?
Spotify が作成しているApach BeamとDataflowのScala APIであるscioが開発されており、そちらも気になっています。
https://github.com/spotify/scio https://engineering.atspotify.com/2017/10/16/big-data-processing-at-spotify-the-road-to-scio-part-1/ では、まずは実際に動かしながら学んでみようということで
https://beam.apache.org/get-started/try-apache-beam/
を参考にApache Beam をPython SDKで試してみます
COLABで実行を試せるので便利ですね
ですが、Python2で実行されるように設定されているのでPython3で実行してみました。
実行したcolab のコードを見ていきます。
環境準備 apache-beam のinstallとGCSからApache beamで処理を行うテキストファイルをダウンロードします。"><meta itemprop=datePublished content="2020-12-26T00:41:30+09:00"><meta itemprop=dateModified content="2020-12-26T00:41:30+09:00"><meta itemprop=wordCount content="474"><meta itemprop=image content="https://shunyaueta.com/ogp.jpg"><meta itemprop=keywords content="apachebeam,distributedsystem,python,"><meta name=referrer content="no-referrer-when-downgrade"><style>body{font-family:Verdana,sans-serif;margin:auto;padding:20px;max-width:720px;text-align:left;background-color:#fff;word-wrap:break-word;overflow-wrap:break-word;line-height:1.5;color:#444}h1,h2,h3,h4,h5,h6,strong,b{color:#222}a{color:#3273dc}.title{text-decoration:none;border:0}.title span{font-weight:400}nav a{margin-right:10px}textarea{width:100%;font-size:16px}input{font-size:16px}content{line-height:1.6}table{width:100%}img{max-width:100%}code{padding:2px 5px;background-color:#f2f2f2}pre code{color:#222;display:block;padding:20px;white-space:pre-wrap;font-size:14px;overflow-x:auto}div.highlight pre{background-color:initial;color:initial}div.highlight code{background-color:unset;color:unset}blockquote{border-left:1px solid #999;color:#222;padding-left:20px;font-style:italic}footer{padding:25px;text-align:center}.helptext{color:#777;font-size:small}.errorlist{color:#eba613;font-size:small}ul.blog-posts{list-style-type:none;padding:unset}ul.blog-posts li{display:flex}ul.blog-posts li span{flex:0 0 130px}ul.blog-posts li a:visited{color:#8b6fcb}@media(prefers-color-scheme:dark){body{background-color:#333;color:#ddd}h1,h2,h3,h4,h5,h6,strong,b{color:#eee}a{color:#8cc2dd}code{background-color:#777}pre code{color:#ddd}blockquote{color:#ccc}textarea,input{background-color:#252525;color:#ddd}.helptext{color:#aaa}}</style><script async src="https://www.googletagmanager.com/gtag/js?id=G-JMJRQJT0Q3"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-JMJRQJT0Q3")</script></head><body><header><a href=/ class=title><h2>hurutoriya</h2></a><nav><a href=/index.xml>RSS</a>
<a href=/about/>著者について</a></nav></header><main><h1>PythonでApache beam 入門</h1><p><i><time datetime=2020-12-26 pubdate>2020-12-26</time></i></p><content><p>TensorFlowの勉強をしていたら、Apache beam を前処理に採用していたケースがあり、興味を持ったので深堀りしてみます。</p><p>興味が湧いたモチベーションとしては、</p><ul><li>データ量が増加しても前処理部分を難なくスケールできそう(前処理部分をスケールさせて高速に実験を回したい、並列化などはすべて良い感じにbeamに任せれそう</li><li>バッチとストリーミングの両者に対応可能なので、柔軟な機械学習の推論サービスが提供できるのでは? (GCPの参考資料 <a href=https://cloud.google.com/solutions/machine-learning/data-preprocessing-for-ml-with-tf-transform-pt1>Data preprocessing for machine learning: options and recommendations</a>)</li><li>Apache beam を触りつつ分散データ処理を学びたい</li></ul><p><a href=https://github.com/jhuangtw/xg2xg#services>https://github.com/jhuangtw/xg2xg#services</a></p><p>を見てみるとGoogle 内部のFlume という並列データパイプライン技術がApache beam として公開されているみたいです。</p><hr><p>Apache beam について端的に説明すると</p><p>Apache beam は3つの考えを基礎にしています。</p><ul><li>Unified<ul><li>ストリーミング、バッチの両者のケースに一つのプログラミングモデルで対応可能な統一性</li></ul></li><li>Portable<ul><li>実行パイプラインが複数の実行環境で実行可能な可搬性</li></ul></li><li>Extensible<ul><li>新しいSDK、IO Connectorsや変換ライブラリなどをを書いて共有することができる拡張性</li></ul></li></ul><p>Java, Python, Go やScalaを使ってBeam Model を作成して任意のruntime で実行する流れです。</p><p>自分はPythonが一眼手軽に書けるのでこの記事ではPythonで紹介していきます。</p><p>Version 2.14.0 からPython 3がサポートされたのは非常にありがたいですね。それまではPython 2のみをサポートしており、その影響で技術選定時に採用しづらかったのでは無いのでしょうか?</p><p>Spotify が作成しているApach BeamとDataflowのScala APIであるscioが開発されており、そちらも気になっています。</p><ul><li><a href=https://github.com/spotify/scio>https://github.com/spotify/scio</a></li><li><a href=https://engineering.atspotify.com/2017/10/16/big-data-processing-at-spotify-the-road-to-scio-part-1/>https://engineering.atspotify.com/2017/10/16/big-data-processing-at-spotify-the-road-to-scio-part-1/</a></li></ul><p>では、まずは実際に動かしながら学んでみようということで</p><p><a href=https://beam.apache.org/get-started/try-apache-beam/>https://beam.apache.org/get-started/try-apache-beam/</a></p><p>を参考にApache Beam をPython SDKで試してみます</p><p>COLABで実行を試せるので便利ですね</p><p>ですが、Python2で実行されるように設定されているのでPython3で実行してみました。</p><p>実行したcolab のコードを見ていきます。</p><h3 id=環境準備>環境準備</h3><p><code>apache-beam</code> のinstallとGCSからApache beamで処理を行うテキストファイルをダウンロードします。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># shell コマンドを実行して表示する関数</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>run</span>(cmd):
</span></span><span style=display:flex><span>  print(<span style=color:#e6db74>&#39;&gt;&gt; </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(cmd))
</span></span><span style=display:flex><span>  <span style=color:#960050;background-color:#1e0010>!</span>{cmd}
</span></span><span style=display:flex><span>  print(<span style=color:#e6db74>&#39;&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Install apache-beam.</span>
</span></span><span style=display:flex><span>run(<span style=color:#e6db74>&#39;pip install --quiet apache-beam&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 対象ファイルの格納ディレクトリを作成後、gsutil を使って /data ディレクトリに格納</span>
</span></span><span style=display:flex><span>run(<span style=color:#e6db74>&#39;mkdir -p data&#39;</span>)
</span></span><span style=display:flex><span>run(<span style=color:#e6db74>&#39;gsutil cp gs://dataflow-samples/shakespeare/kinglear.txt data/&#39;</span>)
</span></span></code></pre></div><h2 id=文字のカウント>文字のカウント</h2><p>Hello World として単語のカウントを行うデータ処理をbeam で記述してみます。</p><p>テキストファイルを読み込んで、各単語の頻度のカウンティングを行う単純なデータパイプラインを作成しています。</p><p>パイプラインの結果はファイルシステム上で保存されるので分散環境下での大規模処理でも取り扱いに役立ちます。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> apache_beam <span style=color:#66d9ef>as</span> beam
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> re
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>inputs_pattern <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;data/*&#39;</span>
</span></span><span style=display:flex><span>outputs_prefix <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;outputs/part&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> beam<span style=color:#f92672>.</span>Pipeline() <span style=color:#66d9ef>as</span> pipeline:
</span></span><span style=display:flex><span>  (
</span></span><span style=display:flex><span>      pipeline
</span></span><span style=display:flex><span>      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Read lines&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>io<span style=color:#f92672>.</span>ReadFromText(inputs_pattern)
</span></span><span style=display:flex><span>      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Find words&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>FlatMap(<span style=color:#66d9ef>lambda</span> line: re<span style=color:#f92672>.</span>findall(<span style=color:#e6db74>r</span><span style=color:#e6db74>&#34;[a-zA-Z&#39;]+&#34;</span>, line))
</span></span><span style=display:flex><span>      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Pair words with 1&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>Map(<span style=color:#66d9ef>lambda</span> word: (word, <span style=color:#ae81ff>1</span>))
</span></span><span style=display:flex><span>      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Group and sum&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>CombinePerKey(sum)
</span></span><span style=display:flex><span>      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Format results&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>Map(<span style=color:#66d9ef>lambda</span> word_count: str(word_count))
</span></span><span style=display:flex><span>      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Write results&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>io<span style=color:#f92672>.</span>WriteToText(outputs_prefix)
</span></span><span style=display:flex><span>  )
</span></span></code></pre></div><p>はい、いきなり</p><p>with beam.Pipeline() as pipeline:
の以降から意味がわからなくなりました。</p><p>Apache beam特有の概念を理解する必要があるので</p><p><a href=https://beam.apache.org/documentation/programming-guide/>https://beam.apache.org/documentation/programming-guide/</a></p><p>を参考に解説してみます。</p><h2 id=apache-beam-programming-guide>Apache Beam Programming Guide</h2><p>Beasm SDKで提供されるクラス郡をここでは紹介していきます。このクラス郡を使うことでデータパイプラインを作成することができます。</p><h3 id=overview>Overview</h3><p>まずBeamを使用するためには、まず最初にBeam SDKのクラスを使って起動プログラムを作成する必要があります。driver program は、あなたのパイプライン(入力、変形と出力のすべて)と実行環境を定義する必要があります。</p><p>Beam SDKは大規模なデータ処理のメカニズムを単純な形で抽象化している</p><ul><li>Pipeline<ul><li>Pipeline はデータ処理タスクの実行開始から終了までをカブセル化するクラスです。これは入力データの読み込みやデータの変形、出力データの書き込みを含む。Beam driver programs は必ずPipelineを作成します。またPipelines 作成時には、実行オプション(どの実行環境下でどのように実行するか)を必ず明記する必要があ。</li></ul></li><li>PCollection<ul><li>Pcollection は分散データセットを表現するクラスです。ここでのデータセットは bounded (ファイルなどの固定されたソース、つまりバッチ)とunbounded (subscriptionなど連続的にアップロードされるソース、つまりストリーム)の両者を指しています。実行するパイプラインは外部データの読み込みによって初期化されたPCollectionによって構築されます。また外部データだけでなく、インメモリのデータからPCollectionを作ることも可能です。つまり、PCollectionはPipelineの出力と入力を担当する。</li></ul></li><li>PTransform<ul><li>PTransform パイプラインでのはデータ処理命令を表現するクラスです。すべての <code>PTransform</code> は一つ以上のPCollection オブジェクトを入力として受け取り、ゼロもしくはそれ以上の数のPCollectionを出力として作成する</li></ul></li><li>IOS transrforms<ul><li>Beamはいくらかの入力と出力のインタフェースがあり、PTransformが読み込み、もしくは書き込みを多種多様な外部のストレージシステムに対して行う</li></ul></li></ul><p>基本的なBeamの起動プログラムは以下の手順で動く</p><ol><li>Pipeline オブジェクトを作成し、パイプラインの実行オプションとパイプラインランナーを設定する</li><li>Pipeline データのために初期のPCollection を行う。そのためにIOs を用いて外部のストレージシステムもしくはインメモリデータから PCollectionを作成する。</li><li>PTransform を各 PCollection へ適用する。Transform は新しい出力としてPCollection を作成する。PCollection を変数、PTransformは関数として考えると、Pipelineは変数と関数からなる複雑な処理グラフとして捉えることができる。</li><li>IOs を使用し、最終的に PCollection を外部ソースに書き出す</li><li>パイプラインをパイプラインランナーで実行する</li></ol><p>あなたが Beam の起動プログラムを実行した時、パイプラインランナーはPCollection を基に作成した transformが適用される workflow graph が構築される。このグラフは適切な分散処理バックエンドで、非同期ジョブとして実行される。</p><p>ここまでで Beam の基礎的な概念を理解できたと思うので最初のサンプルコードでの各行の実行内容について解説します</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> apache_beam <span style=color:#66d9ef>as</span> beam
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> re
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>inputs_pattern <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;data/*&#39;</span>
</span></span><span style=display:flex><span>outputs_prefix <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;outputs/part&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># ローカル環境でDirectRunnerを実行</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> beam<span style=color:#f92672>.</span>Pipeline() <span style=color:#66d9ef>as</span> pipeline:
</span></span><span style=display:flex><span>  <span style=color:#75715e># 文字の集計データをPCollection に格納</span>
</span></span><span style=display:flex><span>  <span style=color:#75715e># 各要素は (word, count) のタプルであり、(str, int)の型となっている</span>
</span></span><span style=display:flex><span>  word_counts <span style=color:#f92672>=</span> (
</span></span><span style=display:flex><span>      <span style=color:#75715e># 入力のPCollection は空のパイプラインとする</span>
</span></span><span style=display:flex><span>      pipeline
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>      <span style=color:#75715e># テキストファイルから行を読み込む</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Read lines&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>io<span style=color:#f92672>.</span>ReadFromText(inputs_pattern)
</span></span><span style=display:flex><span>      <span style=color:#75715e># Element type: str - text line</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>      <span style=color:#75715e># 正規表現を利用して行内のすべての単語に反復処理を行う</span>
</span></span><span style=display:flex><span>      <span style=color:#75715e># FlatMap will yield an element for every element in an iterable.</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Find words&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>FlatMap(<span style=color:#66d9ef>lambda</span> line: re<span style=color:#f92672>.</span>findall(<span style=color:#e6db74>r</span><span style=color:#e6db74>&#34;[a-zA-Z&#39;]+&#34;</span>, line))
</span></span><span style=display:flex><span>      <span style=color:#75715e># Element type: str - word</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>      <span style=color:#75715e># 単語が存在した場合、value が１となるkey-value のペアを作成</span>
</span></span><span style=display:flex><span>      <span style=color:#75715e># すべての単語を集計していき、同一単語をグループ化する</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Pair words with 1&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>Map(<span style=color:#66d9ef>lambda</span> word: (word, <span style=color:#ae81ff>1</span>))
</span></span><span style=display:flex><span>      <span style=color:#75715e># Element type: (str, int) - key: word, value: 1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>      <span style=color:#75715e># sum() 関数を使ってkeyごとにグループを行う</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Group and sum&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>CombinePerKey(sum)
</span></span><span style=display:flex><span>      <span style=color:#75715e># Element type: (str, int) - key: word, value: counts</span>
</span></span><span style=display:flex><span>  )
</span></span><span style=display:flex><span>  (
</span></span><span style=display:flex><span>      <span style=color:#75715e># 入力となるPCollection は上記で作成された</span>
</span></span><span style=display:flex><span>      word_counts
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>      <span style=color:#75715e># 結果は文字列に処理することで、テキストファイルとして書き込み可能にする</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Format results&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>Map(<span style=color:#66d9ef>lambda</span> word_count: str(word_count))
</span></span><span style=display:flex><span>      <span style=color:#75715e># Element type: str - text line</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>      <span style=color:#75715e># 最後に結果をファイルに書き込みます。</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Write results&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>io<span style=color:#f92672>.</span>WriteToText(outputs_prefix)
</span></span><span style=display:flex><span>  )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>#20個の結果を各ファイルから出力してみる。その際に順序は保証されない</span>
</span></span><span style=display:flex><span>run(<span style=color:#e6db74>&#39;head -n 20 </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>-00000-of-*&#39;</span><span style=color:#f92672>.</span>format(outputs_prefix))
</span></span></code></pre></div><p>実行結果</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>WARNING:apache_beam<span style=color:#f92672>.</span>runners<span style=color:#f92672>.</span>interactive<span style=color:#f92672>.</span>interactive_environment:Dependencies required <span style=color:#66d9ef>for</span> Interactive Beam PCollection visualization are <span style=color:#f92672>not</span> available, please use: <span style=color:#960050;background-color:#1e0010>`</span>pip install apache<span style=color:#f92672>-</span>beam[interactive]<span style=color:#960050;background-color:#1e0010>`</span> to install necessary dependencies to enable all data visualization features<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;</span> head <span style=color:#f92672>-</span>n <span style=color:#ae81ff>20</span> outputs<span style=color:#f92672>/</span>part<span style=color:#f92672>-</span><span style=color:#ae81ff>00000</span><span style=color:#f92672>-</span>of<span style=color:#f92672>-*</span>
</span></span><span style=display:flex><span>(<span style=color:#e6db74>&#39;KING&#39;</span>, <span style=color:#ae81ff>243</span>)
</span></span><span style=display:flex><span>(<span style=color:#e6db74>&#39;LEAR&#39;</span>, <span style=color:#ae81ff>236</span>)
</span></span><span style=display:flex><span>(<span style=color:#e6db74>&#39;DRAMATIS&#39;</span>, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>(<span style=color:#e6db74>&#39;PERSONAE&#39;</span>, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>(<span style=color:#e6db74>&#39;king&#39;</span>, <span style=color:#ae81ff>65</span>)
</span></span><span style=display:flex><span>(<span style=color:#e6db74>&#39;of&#39;</span>, <span style=color:#ae81ff>447</span>)
</span></span><span style=display:flex><span>(<span style=color:#e6db74>&#39;Britain&#39;</span>, <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>(<span style=color:#e6db74>&#39;OF&#39;</span>, <span style=color:#ae81ff>15</span>)
</span></span><span style=display:flex><span>(<span style=color:#e6db74>&#39;FRANCE&#39;</span>, <span style=color:#ae81ff>10</span>)
</span></span><span style=display:flex><span>(<span style=color:#e6db74>&#39;DUKE&#39;</span>, <span style=color:#ae81ff>3</span>)
</span></span><span style=display:flex><span>(<span style=color:#e6db74>&#39;BURGUNDY&#39;</span>, <span style=color:#ae81ff>8</span>)
</span></span><span style=display:flex><span>(<span style=color:#e6db74>&#39;CORNWALL&#39;</span>, <span style=color:#ae81ff>63</span>)
</span></span><span style=display:flex><span>(<span style=color:#e6db74>&#39;ALBANY&#39;</span>, <span style=color:#ae81ff>67</span>)
</span></span><span style=display:flex><span>(<span style=color:#e6db74>&#39;EARL&#39;</span>, <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>(<span style=color:#e6db74>&#39;KENT&#39;</span>, <span style=color:#ae81ff>156</span>)
</span></span><span style=display:flex><span>(<span style=color:#e6db74>&#39;GLOUCESTER&#39;</span>, <span style=color:#ae81ff>141</span>)
</span></span><span style=display:flex><span>(<span style=color:#e6db74>&#39;EDGAR&#39;</span>, <span style=color:#ae81ff>126</span>)
</span></span><span style=display:flex><span>(<span style=color:#e6db74>&#39;son&#39;</span>, <span style=color:#ae81ff>29</span>)
</span></span><span style=display:flex><span>(<span style=color:#e6db74>&#39;to&#39;</span>, <span style=color:#ae81ff>438</span>)
</span></span><span style=display:flex><span>(<span style=color:#e6db74>&#39;Gloucester&#39;</span>, <span style=color:#ae81ff>26</span>)
</span></span></code></pre></div><p>どうでしたか?
まだサンプルコードを動かしただけなので使いこなす自信はありませんが、Apache beam がどのような考えで設計され動かすことができるかが少しはつかめたのでは無いのでしょうか?</p><p>次回は典型的なデータ処理をApache beamで動かしてみたいと思います。</p><h2>関連しているかもしれない記事</h2><ul><li><a href=/posts/2020-09-09/>pandas を使って特定のディレクトリのCSVファイルをすべて連結して一つのCSVファイルを作成</a></li><li><a href=/posts/2020-08-23/>Python の内包表記とジェネレータ式のメモリ使用量比較</a></li><li><a href=/posts/2020-08-04/>AOJの「ITP I」40問をPythonで解いた</a></li><li><a href=/posts/2020-07-25/>How to write the UnitTest with stdin at Pytest</a></li><li><a href=/posts/2020-05-10/>自走プログラマーを読み終えた</a></li></ul><h2>Support</h2>記事をお読みくださりありがとうございます。
このウェブサイトの運営を支援していただける方を募集しています。
もしよろしければ、<a href=https://www.buymeacoffee.com/hurutoriya>Buy Me a Coffee</a> からサポート(投げ銭)していただけると、記事の執筆、情報発信のモチベーションに繋がります✨<p>--</p>記事を楽しめましたか？
<a href=/index.xml>RSS</a>で更新情報を配信しているので、お好きなフィードリーダーで購読してみてください。</br>記事への感想などの<a href=https://forms.gle/g4rNMwPL799uHXQg7>おたより</a>をおまちしてます。
(おたより機能はGoogle フォームで実現しており、hurutoriya 個人が管理するGoogleフォームに記録されます。)
お気軽にお送りください。
お返事はメールアドレス入力があればメールでさせていただきます。
もちろんお返事を希望せずに単なる感想だけでも大歓迎です。</content><p><a href=https://shunyaueta.com/tags/apachebeam/>#apachebeam</a>
<a href=https://shunyaueta.com/tags/distributedsystem/>#distributedsystem</a>
<a href=https://shunyaueta.com/tags/python/>#python</a></p><script src=https://giscus.app/client.js data-repo=hurutoriya/hurutoriya.github.io data-repo-id="MDEwOlJlcG9zaXRvcnk2MDgyNTY1Nw==" data-category=Comments data-category-id=DIC_kwDOA6AgOc4CAQTX data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=0 data-theme=dark data-lang=ja crossorigin=anonymous async></script></main><footer>Made with <a href=https://github.com/janraasch/hugo-bearblog/>Hugo ʕ•ᴥ•ʔ Bear</a></footer></body></html>