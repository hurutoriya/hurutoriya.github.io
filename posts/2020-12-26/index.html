<!doctype html><html><head><script data-ad-client=ca-pub-8604812913439531 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>Apache beam 入門 - Shunya Ueta</title><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:image" content><meta property="og:title" content="Apache beam 入門"><meta property="og:description" content="TensorFlowの勉強をしていたら、Apache beam を前処理に採用していたケースがあり、興味を持ったので深堀りしてみます。 興味が湧いたモチベーションとしては、 データ量が増加しても前処理部分を難なくスケールできそう(前処理部分をスケールさせ"><meta property="og:type" content="article"><meta property="og:url" content="https://shunyaueta.com/posts/2020-12-26/"><meta property="article:published_time" content="2020-12-26T00:41:30+09:00"><meta property="article:modified_time" content="2020-12-26T00:41:30+09:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Apache beam 入門"><meta name=twitter:description content="TensorFlowの勉強をしていたら、Apache beam を前処理に採用していたケースがあり、興味を持ったので深堀りしてみます。 興味が湧いたモチベーションとしては、 データ量が増加しても前処理部分を難なくスケールできそう(前処理部分をスケールさせ"><script src=https://shunyaueta.com/js/feather.min.js></script><link href=https://shunyaueta.com/css/fonts.css rel=stylesheet><link rel=stylesheet type=text/css media=screen href=https://shunyaueta.com/css/main.css><link rel=stylesheet type=text/css href=https://shunyaueta.com/css/dark.css media="(prefers-color-scheme: dark)"><script async src="https://www.googletagmanager.com/gtag/js?id=UA-39994406-11"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-39994406-11');</script></head><body><div class=content><header><div class=main><a href=https://shunyaueta.com/>Shunya Ueta</a></div><nav><a href=/posts>All posts</a>
<a href=/about>About</a>
<a href=/tags>Tags</a></nav></header><main><article><div class=title><h1 class=title>Apache beam 入門</h1><div class=meta>Posted on Dec 26, 2020</div></div><section class=body><p>TensorFlowの勉強をしていたら、Apache beam を前処理に採用していたケースがあり、興味を持ったので深堀りしてみます。</p><p>興味が湧いたモチベーションとしては、</p><ul><li>データ量が増加しても前処理部分を難なくスケールできそう(前処理部分をスケールさせて高速に実験を回したい、並列化などはすべて良い感じにbeamに任せれそう</li><li>バッチとストリーミングの両者に対応可能なので、柔軟な機械学習の推論サービスが提供できるのでは? (GCPの参考資料 <a href=https://cloud.google.com/solutions/machine-learning/data-preprocessing-for-ml-with-tf-transform-pt1>Data preprocessing for machine learning: options and recommendations</a>)</li><li>Apache beam を触りつつ分散データ処理を学びたい</li></ul><p><a href=https://github.com/jhuangtw/xg2xg#services>https://github.com/jhuangtw/xg2xg#services</a></p><p>を見てみるとGoogle 内部のFlume という並列データパイプライン技術がApache beam として公開されているみたいです。</p><hr><p>Apache beam について端的に説明すると</p><p>Apache beam は3つの考えを基礎にしています。</p><ul><li>Unified<ul><li>ストリーミング、バッチの両者のケースに一つのプログラミングモデルで対応可能な統一性</li></ul></li><li>Portable<ul><li>実行パイプラインが複数の実行環境で実行可能な可搬性</li></ul></li><li>Extensible<ul><li>新しいSDK、IO Connectorsや変換ライブラリなどをを書いて共有することができる拡張性</li></ul></li></ul><p>Java, Python, Go やScalaを使ってBeam Model を作成して任意のruntime で実行する流れです。</p><p>自分はPythonが一眼手軽に書けるのでこの記事ではPythonで紹介していきます。</p><p>Version 2.14.0 からPython 3がサポートされたのは非常にありがたいですね。それまではPython 2のみをサポートしており、その影響で技術選定時に採用しづらかったのでは無いのでしょうか?</p><p>Spotify が作成しているApach BeamとDataflowのScala APIであるscioが開発されており、そちらも気になっています。</p><ul><li><a href=https://github.com/spotify/scio>https://github.com/spotify/scio</a></li><li><a href=https://engineering.atspotify.com/2017/10/16/big-data-processing-at-spotify-the-road-to-scio-part-1/>https://engineering.atspotify.com/2017/10/16/big-data-processing-at-spotify-the-road-to-scio-part-1/</a></li></ul><p>では、まずは実際に動かしながら学んでみようということで</p><p><a href=https://beam.apache.org/get-started/try-apache-beam/>https://beam.apache.org/get-started/try-apache-beam/</a></p><p>を参考にApache Beam をPython SDKで試してみます</p><p>COLABで実行を試せるので便利ですね</p><p>ですが、Python2で実行されるように設定されているのでPython3で実行してみました。</p><p>実行したcolab のコードを見ていきます。</p><h3 id=環境準備>環境準備</h3><p><code>apache-beam</code> のinstallとGCSからApache beamで処理を行うテキストファイルをダウンロードします。</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># shell コマンドを実行して表示する関数</span>
<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>run</span>(cmd):
  <span style=color:#66d9ef>print</span>(<span style=color:#e6db74>&#39;&gt;&gt; {}&#39;</span><span style=color:#f92672>.</span>format(cmd))
  <span style=color:#960050;background-color:#1e0010>!</span>{cmd}
  <span style=color:#66d9ef>print</span>(<span style=color:#e6db74>&#39;&#39;</span>)

<span style=color:#75715e># Install apache-beam.</span>
run(<span style=color:#e6db74>&#39;pip install --quiet apache-beam&#39;</span>)

<span style=color:#75715e># 対象ファイルの格納ディレクトリを作成後、gsutil を使って /data ディレクトリに格納</span>
run(<span style=color:#e6db74>&#39;mkdir -p data&#39;</span>)
run(<span style=color:#e6db74>&#39;gsutil cp gs://dataflow-samples/shakespeare/kinglear.txt data/&#39;</span>)
</code></pre></div><h2 id=文字のカウント>文字のカウント</h2><p>Hello World として単語のカウントを行うデータ処理をbeam で記述してみます。</p><p>テキストファイルを読み込んで、各単語の頻度のカウンティングを行う単純なデータパイプラインを作成しています。</p><p>パイプラインの結果はファイルシステム上で保存されるので分散環境下での大規模処理でも取り扱いに役立ちます。</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> apache_beam <span style=color:#f92672>as</span> beam
<span style=color:#f92672>import</span> re

inputs_pattern <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;data/*&#39;</span>
outputs_prefix <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;outputs/part&#39;</span>

<span style=color:#66d9ef>with</span> beam<span style=color:#f92672>.</span>Pipeline() <span style=color:#66d9ef>as</span> pipeline:
  (
      pipeline
      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Read lines&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>io<span style=color:#f92672>.</span>ReadFromText(inputs_pattern)
      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Find words&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>FlatMap(<span style=color:#66d9ef>lambda</span> line: re<span style=color:#f92672>.</span>findall(<span style=color:#e6db74>r</span><span style=color:#e6db74>&#34;[a-zA-Z&#39;]+&#34;</span>, line))
      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Pair words with 1&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>Map(<span style=color:#66d9ef>lambda</span> word: (word, <span style=color:#ae81ff>1</span>))
      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Group and sum&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>CombinePerKey(sum)
      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Format results&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>Map(<span style=color:#66d9ef>lambda</span> word_count: str(word_count))
      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Write results&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>io<span style=color:#f92672>.</span>WriteToText(outputs_prefix)
  )
</code></pre></div><p>はい、いきなり</p><p>with beam.Pipeline() as pipeline:
の以降から意味がわからなくなりました。</p><p>Apache beam特有の概念を理解する必要があるので</p><p><a href=https://beam.apache.org/documentation/programming-guide/>https://beam.apache.org/documentation/programming-guide/</a></p><p>を参考に解説してみます。</p><h2 id=apache-beam-programming-guide>Apache Beam Programming Guide</h2><p>Beasm SDKで提供されるクラス郡をここでは紹介していきます。このクラス郡を使うことでデータパイプラインを作成することができます。</p><h3 id=overview>Overview</h3><p>まずBeamを使用するためには、まず最初にBeam SDKのクラスを使って起動プログラムを作成する必要があります。driver program は、あなたのパイプライン(入力、変形と出力のすべて)と実行環境を定義する必要があります。</p><p>Beam SDKは大規模なデータ処理のメカニズムを単純な形で抽象化している</p><ul><li>Pipeline<ul><li>Pipeline はデータ処理タスクの実行開始から終了までをカブセル化するクラスです。これは入力データの読み込みやデータの変形、出力データの書き込みを含む。Beam driver programs は必ずPipelineを作成します。またPipelines 作成時には、実行オプション(どの実行環境下でどのように実行するか)を必ず明記する必要があ。</li></ul></li><li>PCollection<ul><li>Pcollection は分散データセットを表現するクラスです。ここでのデータセットは bounded (ファイルなどの固定されたソース、つまりバッチ)とunbounded (subscriptionなど連続的にアップロードされるソース、つまりストリーム)の両者を指しています。実行するパイプラインは外部データの読み込みによって初期化されたPCollectionによって構築されます。また外部データだけでなく、インメモリのデータからPCollectionを作ることも可能です。つまり、PCollectionはPipelineの出力と入力を担当する。</li></ul></li><li>PTransform<ul><li>PTransform パイプラインでのはデータ処理命令を表現するクラスです。すべての <code>PTransform</code> は一つ以上のPCollection オブジェクトを入力として受け取り、ゼロもしくはそれ以上の数のPCollectionを出力として作成する</li></ul></li><li>IOS transrforms<ul><li>Beamはいくらかの入力と出力のインタフェースがあり、PTransformが読み込み、もしくは書き込みを多種多様な外部のストレージシステムに対して行う</li></ul></li></ul><p>基本的なBeamの起動プログラムは以下の手順で動く</p><ol><li>Pipeline オブジェクトを作成し、パイプラインの実行オプションとパイプラインランナーを設定する</li><li>Pipeline データのために初期のPCollection を行う。そのためにIOs を用いて外部のストレージシステムもしくはインメモリデータから PCollectionを作成する。</li><li>PTransform を各 PCollection へ適用する。Transform は新しい出力としてPCollection を作成する。PCollection を変数、PTransformは関数として考えると、Pipelineは変数と関数からなる複雑な処理グラフとして捉えることができる。</li><li>IOs を使用し、最終的に PCollection を外部ソースに書き出す</li><li>パイプラインをパイプラインランナーで実行する</li></ol><p>あなたが Beam の起動プログラムを実行した時、パイプラインランナーはPCollection を基に作成した transformが適用される workflow graph が構築される。このグラフは適切な分散処理バックエンドで、非同期ジョブとして実行される。</p><p>ここまでで Beam の基礎的な概念を理解できたと思うので最初のサンプルコードでの各行の実行内容について解説します</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> apache_beam <span style=color:#f92672>as</span> beam
<span style=color:#f92672>import</span> re

inputs_pattern <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;data/*&#39;</span>
outputs_prefix <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;outputs/part&#39;</span>

<span style=color:#75715e># ローカル環境でDirectRunnerを実行</span>
<span style=color:#66d9ef>with</span> beam<span style=color:#f92672>.</span>Pipeline() <span style=color:#66d9ef>as</span> pipeline:
  <span style=color:#75715e># 文字の集計データをPCollection に格納</span>
  <span style=color:#75715e># 各要素は (word, count) のタプルであり、(str, int)の型となっている</span>
  word_counts <span style=color:#f92672>=</span> (
      <span style=color:#75715e># 入力のPCollection は空のパイプラインとする</span>
      pipeline

      <span style=color:#75715e># テキストファイルから行を読み込む</span>
      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Read lines&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>io<span style=color:#f92672>.</span>ReadFromText(inputs_pattern)
      <span style=color:#75715e># Element type: str - text line</span>

      <span style=color:#75715e># 正規表現を利用して行内のすべての単語に反復処理を行う</span>
      <span style=color:#75715e># FlatMap will yield an element for every element in an iterable.</span>
      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Find words&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>FlatMap(<span style=color:#66d9ef>lambda</span> line: re<span style=color:#f92672>.</span>findall(<span style=color:#e6db74>r</span><span style=color:#e6db74>&#34;[a-zA-Z&#39;]+&#34;</span>, line))
      <span style=color:#75715e># Element type: str - word</span>

      <span style=color:#75715e># 単語が存在した場合、value が１となるkey-value のペアを作成</span>
      <span style=color:#75715e># すべての単語を集計していき、同一単語をグループ化する</span>
      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Pair words with 1&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>Map(<span style=color:#66d9ef>lambda</span> word: (word, <span style=color:#ae81ff>1</span>))
      <span style=color:#75715e># Element type: (str, int) - key: word, value: 1</span>

      <span style=color:#75715e># sum() 関数を使ってkeyごとにグループを行う</span>
      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Group and sum&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>CombinePerKey(sum)
      <span style=color:#75715e># Element type: (str, int) - key: word, value: counts</span>
  )
  (
      <span style=color:#75715e># 入力となるPCollection は上記で作成された</span>
      word_counts

      <span style=color:#75715e># 結果は文字列に処理することで、テキストファイルとして書き込み可能にする</span>
      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Format results&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>Map(<span style=color:#66d9ef>lambda</span> word_count: str(word_count))
      <span style=color:#75715e># Element type: str - text line</span>

      <span style=color:#75715e># 最後に結果をファイルに書き込みます。</span>
      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Write results&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>io<span style=color:#f92672>.</span>WriteToText(outputs_prefix)
  )

<span style=color:#75715e>#20個の結果を各ファイルから出力してみる。その際に順序は保証されない</span>
run(<span style=color:#e6db74>&#39;head -n 20 {}-00000-of-*&#39;</span><span style=color:#f92672>.</span>format(outputs_prefix))
</code></pre></div><p>実行結果</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>WARNING:apache_beam<span style=color:#f92672>.</span>runners<span style=color:#f92672>.</span>interactive<span style=color:#f92672>.</span>interactive_environment:Dependencies required <span style=color:#66d9ef>for</span> Interactive Beam PCollection visualization are <span style=color:#f92672>not</span> available, please use: <span style=color:#e6db74>`pip install apache-beam[interactive]`</span> to install necessary dependencies to enable all data visualization features<span style=color:#f92672>.</span>
<span style=color:#f92672>&gt;&gt;</span> head <span style=color:#f92672>-</span>n <span style=color:#ae81ff>20</span> outputs<span style=color:#f92672>/</span>part<span style=color:#f92672>-</span><span style=color:#ae81ff>00000</span><span style=color:#f92672>-</span>of<span style=color:#f92672>-*</span>
(<span style=color:#e6db74>&#39;KING&#39;</span>, <span style=color:#ae81ff>243</span>)
(<span style=color:#e6db74>&#39;LEAR&#39;</span>, <span style=color:#ae81ff>236</span>)
(<span style=color:#e6db74>&#39;DRAMATIS&#39;</span>, <span style=color:#ae81ff>1</span>)
(<span style=color:#e6db74>&#39;PERSONAE&#39;</span>, <span style=color:#ae81ff>1</span>)
(<span style=color:#e6db74>&#39;king&#39;</span>, <span style=color:#ae81ff>65</span>)
(<span style=color:#e6db74>&#39;of&#39;</span>, <span style=color:#ae81ff>447</span>)
(<span style=color:#e6db74>&#39;Britain&#39;</span>, <span style=color:#ae81ff>2</span>)
(<span style=color:#e6db74>&#39;OF&#39;</span>, <span style=color:#ae81ff>15</span>)
(<span style=color:#e6db74>&#39;FRANCE&#39;</span>, <span style=color:#ae81ff>10</span>)
(<span style=color:#e6db74>&#39;DUKE&#39;</span>, <span style=color:#ae81ff>3</span>)
(<span style=color:#e6db74>&#39;BURGUNDY&#39;</span>, <span style=color:#ae81ff>8</span>)
(<span style=color:#e6db74>&#39;CORNWALL&#39;</span>, <span style=color:#ae81ff>63</span>)
(<span style=color:#e6db74>&#39;ALBANY&#39;</span>, <span style=color:#ae81ff>67</span>)
(<span style=color:#e6db74>&#39;EARL&#39;</span>, <span style=color:#ae81ff>2</span>)
(<span style=color:#e6db74>&#39;KENT&#39;</span>, <span style=color:#ae81ff>156</span>)
(<span style=color:#e6db74>&#39;GLOUCESTER&#39;</span>, <span style=color:#ae81ff>141</span>)
(<span style=color:#e6db74>&#39;EDGAR&#39;</span>, <span style=color:#ae81ff>126</span>)
(<span style=color:#e6db74>&#39;son&#39;</span>, <span style=color:#ae81ff>29</span>)
(<span style=color:#e6db74>&#39;to&#39;</span>, <span style=color:#ae81ff>438</span>)
(<span style=color:#e6db74>&#39;Gloucester&#39;</span>, <span style=color:#ae81ff>26</span>)
</code></pre></div><p>どうでしたか?
まだサンプルコードを動かしただけなので使いこなす自信はありませんが、Apache beam がどのような考えで設計され動かすことができるかが少しはつかめたのでは無いのでしょうか?</p><p>次回は典型的なデータ処理をApache beamで動かしてみたいと思います。</p></section><div class=post-tags><nav class="nav tags"><ul class=tags><li><a href=/tags/apache-beam>Apache beam</a></li><li><a href=/tags/distributed-data-pipeline>Distributed Data Pipeline</a></li><li><a href=/tags/python>Python</a></li></ul></nav></div></article></main><h3>See Also</h3><ul><li><a href=/posts/2020-09-09/>pandas を使って特定のディレクトリのCSVファイルをすべて連結して一つのCSVファイルを作成</a></li><li><a href=/posts/2020-08-23/>Python の内包表記とジェネレータ式のメモリ使用量比較</a></li><li><a href=/posts/2020-07-25/>How to write the UnitTest with stdin at Pytest</a></li><li><a href=/posts/2020-05-10/>自走プログラマーを読み終えた</a></li><li><a href=/posts/2020-04-26/>Pythonの関数のデフォルト引数はmutable(上書きされる)</a></li></ul><footer><hr><a class=soc href=https://github.com/hurutoriya title=GitHub><i data-feather=github></i></a>|<a class=soc href=https://twitter.com/hurutoriya/ title=Twitter><i data-feather=twitter></i></a>|⚡️
2021 © Shunya Ueta | <a href=https://github.com/athul/archie>Archie Theme</a> | Built with <a href=https://gohugo.io>Hugo</a></footer><script>feather.replace()</script></div></body></html>