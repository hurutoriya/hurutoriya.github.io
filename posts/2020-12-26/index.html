<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="TensorFlowの勉強をしていたら、Apache beam を前処理に採用していたケースがあり、興味を持ったので深堀りしてみます。
興味が湧いたモチベーションとしては、
 データ量が増加しても前処理部分を難なくスケールできそう(前処理部分をスケールさせて高速に実験を回したい、並列化などはすべて良い感じにbeamに任せれそう バッチとストリーミングの両者に対応可能なので、柔軟な機械学習の推論サービスが提供できるのでは? (GCPの参考資料 Data preprocessing for machine learning: options and recommendations) Apache beam を触りつつ分散データ処理を学びたい  https://github.com/jhuangtw/xg2xg#services
を見てみるとGoogle 内部のFlume という並列データパイプライン技術がApache beam として公開されているみたいです。
 Apache beam について端的に説明すると
Apache beam は3つの考えを基礎にしています。
 Unified  ストリーミング、バッチの両者のケースに一つのプログラミングモデルで対応可能な統一性   Portable  実行パイプラインが複数の実行環境で実行可能な可搬性   Extensible  新しいSDK、IO Connectorsや変換ライブラリなどをを書いて共有することができる拡張性    Java, Python, Go やScalaを使ってBeam Model を作成して任意のruntime で実行する流れです。
自分はPythonが一眼手軽に書けるのでこの記事ではPythonで紹介していきます。
Version 2.14.0 からPython 3がサポートされたのは非常にありがたいですね。それまではPython 2のみをサポートしており、その影響で技術選定時に採用しづらかったのでは無いのでしょうか?
Spotify が作成しているApach BeamとDataflowのScala APIであるscioが開発されており、そちらも気になっています。
 https://github.com/spotify/scio https://engineering."><meta name=theme-color content="#d3381c"><meta property="og:title" content="Apache beam 入門 • Software Engineer as Data Scientist"><meta property="og:description" content="TensorFlowの勉強をしていたら、Apache beam を前処理に採用していたケースがあり、興味を持ったので深堀りしてみます。
興味が湧いたモチベーションとしては、
 データ量が増加しても前処理部分を難なくスケールできそう(前処理部分をスケールさせて高速に実験を回したい、並列化などはすべて良い感じにbeamに任せれそう バッチとストリーミングの両者に対応可能なので、柔軟な機械学習の推論サービスが提供できるのでは? (GCPの参考資料 Data preprocessing for machine learning: options and recommendations) Apache beam を触りつつ分散データ処理を学びたい  https://github.com/jhuangtw/xg2xg#services
を見てみるとGoogle 内部のFlume という並列データパイプライン技術がApache beam として公開されているみたいです。
 Apache beam について端的に説明すると
Apache beam は3つの考えを基礎にしています。
 Unified  ストリーミング、バッチの両者のケースに一つのプログラミングモデルで対応可能な統一性   Portable  実行パイプラインが複数の実行環境で実行可能な可搬性   Extensible  新しいSDK、IO Connectorsや変換ライブラリなどをを書いて共有することができる拡張性    Java, Python, Go やScalaを使ってBeam Model を作成して任意のruntime で実行する流れです。
自分はPythonが一眼手軽に書けるのでこの記事ではPythonで紹介していきます。
Version 2.14.0 からPython 3がサポートされたのは非常にありがたいですね。それまではPython 2のみをサポートしており、その影響で技術選定時に採用しづらかったのでは無いのでしょうか?
Spotify が作成しているApach BeamとDataflowのScala APIであるscioが開発されており、そちらも気になっています。
 https://github.com/spotify/scio https://engineering."><meta property="og:url" content="https://shunyaueta.com/posts/2020-12-26/"><meta property="og:site_name" content="Software Engineer as Data Scientist"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:tag" content="Apache beam"><meta property="article:tag" content="Distributed Data Pipeline"><meta property="article:tag" content="Python"><meta property="article:published_time" content="2020-12-26T00:41:30+09:00"><meta property="article:modified_time" content="2020-12-26T00:41:30+09:00"><meta name=twitter:card content="summary"><meta name=twitter:site content="@hurutoriya"><meta name=generator content="Hugo 0.67.1"><title>Apache beam 入門 • Software Engineer as Data Scientist</title><link rel=canonical href=https://shunyaueta.com/posts/2020-12-26/><link rel=icon href=/favicon.ico><link rel=stylesheet href=/assets/css/main.ab98e12b.css><link rel=stylesheet href=/css/custom.css><style>:root{--color-accent:#d3381c}</style><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-39994406-11','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script data-ad-client=ca-pub-8604812913439531 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body class="page type-posts"><div class=site><a class=screen-reader-text href=#content>Skip to Content</a><div class=main><div class=header-widgets><div class=container><style>.widget-breadcrumbs li:after{content:'\2f '}</style><section class="widget widget-breadcrumbs sep-after"><nav id=breadcrumbs><ol><li><a href=/>Software Engineer as Data Scientist</a></li><li><a href=/posts/>Posts</a></li><li><span>Apache beam 入門</span></li></ol></nav></section></div></div><header id=header class="header site-header"><div class="container sep-after"><div class=header-info><p class="site-title title">Software Engineer as Data Scientist</p><p class="desc site-desc">Enjoy Software Engineering & Data Science!!</p></div></div></header><main id=content><article lang=ja class=entry><header class="header entry-header"><div class="container sep-after"><div class=header-info><h1 class=title>Apache beam 入門</h1></div><div class=entry-meta><span class=posted-on><svg class="icon" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg><span class=screen-reader-text>Posted on</span>
<time class=entry-date datetime=2020-12-26T00:41:30+09:00>2020.12.26</time></span>
<span class=reading-time><svg class="icon" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 15 15"/></svg>3 mins read</span></div></div></header><div class="container entry-content"><p>TensorFlowの勉強をしていたら、Apache beam を前処理に採用していたケースがあり、興味を持ったので深堀りしてみます。</p><p>興味が湧いたモチベーションとしては、</p><ul><li>データ量が増加しても前処理部分を難なくスケールできそう(前処理部分をスケールさせて高速に実験を回したい、並列化などはすべて良い感じにbeamに任せれそう</li><li>バッチとストリーミングの両者に対応可能なので、柔軟な機械学習の推論サービスが提供できるのでは? (GCPの参考資料 <a href=https://cloud.google.com/solutions/machine-learning/data-preprocessing-for-ml-with-tf-transform-pt1>Data preprocessing for machine learning: options and recommendations</a>)</li><li>Apache beam を触りつつ分散データ処理を学びたい</li></ul><p><a href=https://github.com/jhuangtw/xg2xg#services>https://github.com/jhuangtw/xg2xg#services</a></p><p>を見てみるとGoogle 内部のFlume という並列データパイプライン技術がApache beam として公開されているみたいです。</p><hr><p>Apache beam について端的に説明すると</p><p>Apache beam は3つの考えを基礎にしています。</p><ul><li>Unified<ul><li>ストリーミング、バッチの両者のケースに一つのプログラミングモデルで対応可能な統一性</li></ul></li><li>Portable<ul><li>実行パイプラインが複数の実行環境で実行可能な可搬性</li></ul></li><li>Extensible<ul><li>新しいSDK、IO Connectorsや変換ライブラリなどをを書いて共有することができる拡張性</li></ul></li></ul><p>Java, Python, Go やScalaを使ってBeam Model を作成して任意のruntime で実行する流れです。</p><p>自分はPythonが一眼手軽に書けるのでこの記事ではPythonで紹介していきます。</p><p>Version 2.14.0 からPython 3がサポートされたのは非常にありがたいですね。それまではPython 2のみをサポートしており、その影響で技術選定時に採用しづらかったのでは無いのでしょうか?</p><p>Spotify が作成しているApach BeamとDataflowのScala APIであるscioが開発されており、そちらも気になっています。</p><ul><li><a href=https://github.com/spotify/scio>https://github.com/spotify/scio</a></li><li><a href=https://engineering.atspotify.com/2017/10/16/big-data-processing-at-spotify-the-road-to-scio-part-1/>https://engineering.atspotify.com/2017/10/16/big-data-processing-at-spotify-the-road-to-scio-part-1/</a></li></ul><p>では、まずは実際に動かしながら学んでみようということで</p><p><a href=https://beam.apache.org/get-started/try-apache-beam/>https://beam.apache.org/get-started/try-apache-beam/</a></p><p>を参考にApache Beam をPython SDKで試してみます</p><p>COLABで実行を試せるので便利ですね</p><p>ですが、Python2で実行されるように設定されているのでPython3で実行してみました。</p><p>実行したcolab のコードを見ていきます。</p><h3 id=環境準備>環境準備</h3><p><code>apache-beam</code> のinstallとGCSからApache beamで処理を行うテキストファイルをダウンロードします。</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># shell コマンドを実行して表示する関数</span>
<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>run</span>(cmd):
  <span style=color:#66d9ef>print</span>(<span style=color:#e6db74>&#39;&gt;&gt; {}&#39;</span><span style=color:#f92672>.</span>format(cmd))
  <span style=color:#960050;background-color:#1e0010>!</span>{cmd}
  <span style=color:#66d9ef>print</span>(<span style=color:#e6db74>&#39;&#39;</span>)

<span style=color:#75715e># Install apache-beam.</span>
run(<span style=color:#e6db74>&#39;pip install --quiet apache-beam&#39;</span>)

<span style=color:#75715e># 対象ファイルの格納ディレクトリを作成後、gsutil を使って /data ディレクトリに格納</span>
run(<span style=color:#e6db74>&#39;mkdir -p data&#39;</span>)
run(<span style=color:#e6db74>&#39;gsutil cp gs://dataflow-samples/shakespeare/kinglear.txt data/&#39;</span>)
</code></pre></div><h2 id=文字のカウント>文字のカウント</h2><p>Hello World として単語のカウントを行うデータ処理をbeam で記述してみます。</p><p>テキストファイルを読み込んで、各単語の頻度のカウンティングを行う単純なデータパイプラインを作成しています。</p><p>パイプラインの結果はファイルシステム上で保存されるので分散環境下での大規模処理でも取り扱いに役立ちます。</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> apache_beam <span style=color:#f92672>as</span> beam
<span style=color:#f92672>import</span> re

inputs_pattern <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;data/*&#39;</span>
outputs_prefix <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;outputs/part&#39;</span>

<span style=color:#66d9ef>with</span> beam<span style=color:#f92672>.</span>Pipeline() <span style=color:#66d9ef>as</span> pipeline:
  (
      pipeline
      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Read lines&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>io<span style=color:#f92672>.</span>ReadFromText(inputs_pattern)
      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Find words&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>FlatMap(<span style=color:#66d9ef>lambda</span> line: re<span style=color:#f92672>.</span>findall(<span style=color:#e6db74>r</span><span style=color:#e6db74>&#34;[a-zA-Z&#39;]+&#34;</span>, line))
      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Pair words with 1&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>Map(<span style=color:#66d9ef>lambda</span> word: (word, <span style=color:#ae81ff>1</span>))
      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Group and sum&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>CombinePerKey(sum)
      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Format results&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>Map(<span style=color:#66d9ef>lambda</span> word_count: str(word_count))
      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Write results&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>io<span style=color:#f92672>.</span>WriteToText(outputs_prefix)
  )
</code></pre></div><p>はい、いきなり</p><p>with beam.Pipeline() as pipeline:
の以降から意味がわからなくなりました。</p><p>Apache beam特有の概念を理解する必要があるので</p><p><a href=https://beam.apache.org/documentation/programming-guide/>https://beam.apache.org/documentation/programming-guide/</a></p><p>を参考に解説してみます。</p><h2 id=apache-beam-programming-guide>Apache Beam Programming Guide</h2><p>Beasm SDKで提供されるクラス郡をここでは紹介していきます。このクラス郡を使うことでデータパイプラインを作成することができます。</p><h3 id=overview>Overview</h3><p>まずBeamを使用するためには、まず最初にBeam SDKのクラスを使って起動プログラムを作成する必要があります。driver program は、あなたのパイプライン(入力、変形と出力のすべて)と実行環境を定義する必要があります。</p><p>Beam SDKは大規模なデータ処理のメカニズムを単純な形で抽象化している</p><ul><li>Pipeline<ul><li>Pipeline はデータ処理タスクの実行開始から終了までをカブセル化するクラスです。これは入力データの読み込みやデータの変形、出力データの書き込みを含む。Beam driver programs は必ずPipelineを作成します。またPipelines 作成時には、実行オプション(どの実行環境下でどのように実行するか)を必ず明記する必要があ。</li></ul></li><li>PCollection<ul><li>Pcollection は分散データセットを表現するクラスです。ここでのデータセットは bounded (ファイルなどの固定されたソース、つまりバッチ)とunbounded (subscriptionなど連続的にアップロードされるソース、つまりストリーム)の両者を指しています。実行するパイプラインは外部データの読み込みによって初期化されたPCollectionによって構築されます。また外部データだけでなく、インメモリのデータからPCollectionを作ることも可能です。つまり、PCollectionはPipelineの出力と入力を担当する。</li></ul></li><li>PTransform<ul><li>PTransform パイプラインでのはデータ処理命令を表現するクラスです。すべての <code>PTransform</code> は一つ以上のPCollection オブジェクトを入力として受け取り、ゼロもしくはそれ以上の数のPCollectionを出力として作成する</li></ul></li><li>IOS transrforms<ul><li>Beamはいくらかの入力と出力のインタフェースがあり、PTransformが読み込み、もしくは書き込みを多種多様な外部のストレージシステムに対して行う</li></ul></li></ul><p>基本的なBeamの起動プログラムは以下の手順で動く</p><ol><li>Pipeline オブジェクトを作成し、パイプラインの実行オプションとパイプラインランナーを設定する</li><li>Pipeline データのために初期のPCollection を行う。そのためにIOs を用いて外部のストレージシステムもしくはインメモリデータから PCollectionを作成する。</li><li>PTransform を各 PCollection へ適用する。Transform は新しい出力としてPCollection を作成する。PCollection を変数、PTransformは関数として考えると、Pipelineは変数と関数からなる複雑な処理グラフとして捉えることができる。</li><li>IOs を使用し、最終的に PCollection を外部ソースに書き出す</li><li>パイプラインをパイプラインランナーで実行する</li></ol><p>あなたが Beam の起動プログラムを実行した時、パイプラインランナーはPCollection を基に作成した transformが適用される workflow graph が構築される。このグラフは適切な分散処理バックエンドで、非同期ジョブとして実行される。</p><p>ここまでで Beam の基礎的な概念を理解できたと思うので最初のサンプルコードでの各行の実行内容について解説します</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> apache_beam <span style=color:#f92672>as</span> beam
<span style=color:#f92672>import</span> re

inputs_pattern <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;data/*&#39;</span>
outputs_prefix <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;outputs/part&#39;</span>

<span style=color:#75715e># ローカル環境でDirectRunnerを実行</span>
<span style=color:#66d9ef>with</span> beam<span style=color:#f92672>.</span>Pipeline() <span style=color:#66d9ef>as</span> pipeline:
  <span style=color:#75715e># 文字の集計データをPCollection に格納</span>
  <span style=color:#75715e># 各要素は (word, count) のタプルであり、(str, int)の型となっている</span>
  word_counts <span style=color:#f92672>=</span> (
      <span style=color:#75715e># 入力のPCollection は空のパイプラインとする</span>
      pipeline

      <span style=color:#75715e># テキストファイルから行を読み込む</span>
      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Read lines&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>io<span style=color:#f92672>.</span>ReadFromText(inputs_pattern)
      <span style=color:#75715e># Element type: str - text line</span>

      <span style=color:#75715e># 正規表現を利用して行内のすべての単語に反復処理を行う</span>
      <span style=color:#75715e># FlatMap will yield an element for every element in an iterable.</span>
      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Find words&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>FlatMap(<span style=color:#66d9ef>lambda</span> line: re<span style=color:#f92672>.</span>findall(<span style=color:#e6db74>r</span><span style=color:#e6db74>&#34;[a-zA-Z&#39;]+&#34;</span>, line))
      <span style=color:#75715e># Element type: str - word</span>

      <span style=color:#75715e># 単語が存在した場合、value が１となるkey-value のペアを作成</span>
      <span style=color:#75715e># すべての単語を集計していき、同一単語をグループ化する</span>
      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Pair words with 1&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>Map(<span style=color:#66d9ef>lambda</span> word: (word, <span style=color:#ae81ff>1</span>))
      <span style=color:#75715e># Element type: (str, int) - key: word, value: 1</span>

      <span style=color:#75715e># sum() 関数を使ってkeyごとにグループを行う</span>
      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Group and sum&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>CombinePerKey(sum)
      <span style=color:#75715e># Element type: (str, int) - key: word, value: counts</span>
  )
  (
      <span style=color:#75715e># 入力となるPCollection は上記で作成された</span>
      word_counts

      <span style=color:#75715e># 結果は文字列に処理することで、テキストファイルとして書き込み可能にする</span>
      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Format results&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>Map(<span style=color:#66d9ef>lambda</span> word_count: str(word_count))
      <span style=color:#75715e># Element type: str - text line</span>

      <span style=color:#75715e># 最後に結果をファイルに書き込みます。</span>
      <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Write results&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>io<span style=color:#f92672>.</span>WriteToText(outputs_prefix)
  )

<span style=color:#75715e>#20個の結果を各ファイルから出力してみる。その際に順序は保証されない</span>
run(<span style=color:#e6db74>&#39;head -n 20 {}-00000-of-*&#39;</span><span style=color:#f92672>.</span>format(outputs_prefix))
</code></pre></div><p>実行結果</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>WARNING:apache_beam<span style=color:#f92672>.</span>runners<span style=color:#f92672>.</span>interactive<span style=color:#f92672>.</span>interactive_environment:Dependencies required <span style=color:#66d9ef>for</span> Interactive Beam PCollection visualization are <span style=color:#f92672>not</span> available, please use: <span style=color:#e6db74>`pip install apache-beam[interactive]`</span> to install necessary dependencies to enable all data visualization features<span style=color:#f92672>.</span>
<span style=color:#f92672>&gt;&gt;</span> head <span style=color:#f92672>-</span>n <span style=color:#ae81ff>20</span> outputs<span style=color:#f92672>/</span>part<span style=color:#f92672>-</span><span style=color:#ae81ff>00000</span><span style=color:#f92672>-</span>of<span style=color:#f92672>-*</span>
(<span style=color:#e6db74>&#39;KING&#39;</span>, <span style=color:#ae81ff>243</span>)
(<span style=color:#e6db74>&#39;LEAR&#39;</span>, <span style=color:#ae81ff>236</span>)
(<span style=color:#e6db74>&#39;DRAMATIS&#39;</span>, <span style=color:#ae81ff>1</span>)
(<span style=color:#e6db74>&#39;PERSONAE&#39;</span>, <span style=color:#ae81ff>1</span>)
(<span style=color:#e6db74>&#39;king&#39;</span>, <span style=color:#ae81ff>65</span>)
(<span style=color:#e6db74>&#39;of&#39;</span>, <span style=color:#ae81ff>447</span>)
(<span style=color:#e6db74>&#39;Britain&#39;</span>, <span style=color:#ae81ff>2</span>)
(<span style=color:#e6db74>&#39;OF&#39;</span>, <span style=color:#ae81ff>15</span>)
(<span style=color:#e6db74>&#39;FRANCE&#39;</span>, <span style=color:#ae81ff>10</span>)
(<span style=color:#e6db74>&#39;DUKE&#39;</span>, <span style=color:#ae81ff>3</span>)
(<span style=color:#e6db74>&#39;BURGUNDY&#39;</span>, <span style=color:#ae81ff>8</span>)
(<span style=color:#e6db74>&#39;CORNWALL&#39;</span>, <span style=color:#ae81ff>63</span>)
(<span style=color:#e6db74>&#39;ALBANY&#39;</span>, <span style=color:#ae81ff>67</span>)
(<span style=color:#e6db74>&#39;EARL&#39;</span>, <span style=color:#ae81ff>2</span>)
(<span style=color:#e6db74>&#39;KENT&#39;</span>, <span style=color:#ae81ff>156</span>)
(<span style=color:#e6db74>&#39;GLOUCESTER&#39;</span>, <span style=color:#ae81ff>141</span>)
(<span style=color:#e6db74>&#39;EDGAR&#39;</span>, <span style=color:#ae81ff>126</span>)
(<span style=color:#e6db74>&#39;son&#39;</span>, <span style=color:#ae81ff>29</span>)
(<span style=color:#e6db74>&#39;to&#39;</span>, <span style=color:#ae81ff>438</span>)
(<span style=color:#e6db74>&#39;Gloucester&#39;</span>, <span style=color:#ae81ff>26</span>)
</code></pre></div><p>どうでしたか?
まだサンプルコードを動かしただけなので使いこなす自信はありませんが、Apache beam がどのような考えで設計され動かすことができるかが少しはつかめたのでは無いのでしょうか?</p><p>次回は典型的なデータ処理をApache beamで動かしてみたいと思います。</p><h3>See Also</h3><ul><li><a href=/posts/2020-09-09/>pandas を使って特定のディレクトリのCSVファイルをすべて連結して一つのCSVファイルを作成</a></li><li><a href=/posts/2020-08-23/>Python の内包表記とジェネレータ式のメモリ使用量比較</a></li><li><a href=/posts/2020-07-25/>How to write the UnitTest with stdin at Pytest</a></li><li><a href=/posts/2020-05-10/>自走プログラマーを読み終えた</a></li><li><a href=/posts/2020-04-26/>Pythonの関数のデフォルト引数はmutable(上書きされる)</a></li></ul></div><footer class=entry-footer><div class="container sep-before"><div class=tags><svg class="icon" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M20.59 13.41l-7.17 7.17a2 2 0 01-2.83.0L2 12V2H12l8.59 8.59A2 2 0 0120.59 13.41z"/><line x1="7" y1="7" x2="7" y2="7"/></svg><span class=screen-reader-text>Tags: </span><a class=tag href=/tags/apache-beam/>Apache beam</a>, <a class=tag href=/tags/distributed-data-pipeline/>Distributed Data Pipeline</a>, <a class=tag href=/tags/python/>Python</a></div></div></footer></article><nav class=entry-nav><div class=container><div class="prev-entry sep-before"><a href=/posts/2020-09-27/><span aria-hidden=true><svg class="icon" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><line x1="20" y1="12" x2="4" y2="12"/><polyline points="10 18 4 12 10 6"/></svg>Previous</span>
<span class=screen-reader-text>Previous post: </span>機械学習・ソフトウェアエンジニアリングをテーマにしたPodcast just4fun.fm を始めてみた</a></div></div></nav><section id=comments class=comments><div class="container sep-before"><div class=comments-area><script src=https://utteranc.es/client.js repo=hurutoriya/hurutoriya.github.io issue-term=url crossorigin=anonymous async></script></div></div></section></main><footer id=footer class=footer><div class="container sep-before"><section class="widget widget-about sep-after"><header><h2 class="title site-title"><a href=/>Shunya UETA</a></h2><div class=desc>Shunya UETA who is a working on Machine Learning as Software Engineer at <a href=https://about.mercari.com/en/>Mercari, inc</a>. Opinions are my own. → <a href=/about>See more detail</a></div></header></section><section class="widget widget-social_menu sep-after"><nav aria-label="Social Menu"><ul><li><a href=https://github.com/hurutoriya target=_blank rel=noopener><span class=screen-reader-text>Open Github account in new tab</span><svg class="icon" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77a5.44 5.44.0 00-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></li><li><a href=https://facebook.com/shunyaueta target=_blank rel=noopener><span class=screen-reader-text>Open Facebook account in new tab</span><svg class="icon" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M18 2h-3a5 5 0 00-5 5v3H7v4h3v8h4v-8h3l1-4h-4V7a1 1 0 011-1h3z"/></svg></a></li><li><a href=https://twitter.com/hurutoriya target=_blank rel=noopener><span class=screen-reader-text>Open Twitter account in new tab</span><svg class="icon" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg></a></li><li><a href=https://linkedin.com/in/hurutoriya target=_blank rel=noopener><span class=screen-reader-text>Open Linkedin account in new tab</span><svg class="icon" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M16 8a6 6 0 016 6v7h-4v-7a2 2 0 00-2-2 2 2 0 00-2 2v7h-4v-7a6 6 0 016-6z"/><rect x="2" y="9" width="4" height="12"/><circle cx="4" cy="4" r="2"/></svg></a></li></ul></nav></section><div class=copyright><p>&copy; 2013-2020 Shunya UETA</p></div></div></footer></div></div><script>window.__assets_js_src="/assets/js/"</script><script src=/assets/js/main.c3bcf2df.js></script><script src=/js/custom.js></script></body></html>