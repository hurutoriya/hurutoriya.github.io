<!doctype html><html><head><script data-ad-client=ca-pub-8604812913439531 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Shunya Ueta (a.k.a hurutoriya) personal website"><link rel="shortcut icon" href=https://shunyaueta.com/favicon.ico><link rel=stylesheet href=/css/style.min.css><script data-ad-client=ca-pub-8604812913439531 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script><title>Apache beam 入門</title></head><body><header id=banner><h2><a href=https://shunyaueta.com/>Software Engineer as Data Scientist</a></h2><nav><ul><li><a href=/ title=posts>posts</a></li><li><a href=/about/ title=about>about</a></li></ul></nav></header><main id=content><article><header id=post-header><h1>Apache beam 入門</h1><time>2020-12-26</time></header><p>TensorFlowの勉強をしていたら、Apache beam を前処理に採用していたケースがあり、興味を持ったので深堀りしてみます。</p><p>興味が湧いたモチベーションとしては、</p><ul><li>データ量が増加しても前処理部分を難なくスケールできそう(前処理部分をスケールさせて高速に実験を回したい、並列化などはすべて良い感じにbeamに任せれそう</li><li>バッチとストリーミングの両者に対応可能なので、柔軟な機械学習の推論サービスが提供できるのでは? (GCPの参考資料 <a href=https://cloud.google.com/solutions/machine-learning/data-preprocessing-for-ml-with-tf-transform-pt1>Data preprocessing for machine learning: options and recommendations</a>)</li><li>Apache beam を触りつつ分散データ処理を学びたい</li></ul><p><a href=https://github.com/jhuangtw/xg2xg#services>https://github.com/jhuangtw/xg2xg#services</a></p><p>を見てみるとGoogle 内部のFlume という並列データパイプライン技術がApache beam として公開されているみたいです。</p><hr><p>Apache beam について端的に説明すると</p><p>Apache beam は3つの考えを基礎にしています。</p><ul><li>Unified<ul><li>ストリーミング、バッチの両者のケースに一つのプログラミングモデルで対応可能な統一性</li></ul></li><li>Portable<ul><li>実行パイプラインが複数の実行環境で実行可能な可搬性</li></ul></li><li>Extensible<ul><li>新しいSDK、IO Connectorsや変換ライブラリなどをを書いて共有することができる拡張性</li></ul></li></ul><p>Java, Python, Go やScalaを使ってBeam Model を作成して任意のruntime で実行する流れです。</p><p>自分はPythonが一眼手軽に書けるのでこの記事ではPythonで紹介していきます。</p><p>Version 2.14.0 からPython 3がサポートされたのは非常にありがたいですね。それまではPython 2のみをサポートしており、その影響で技術選定時に採用しづらかったのでは無いのでしょうか?</p><p>Spotify が作成しているApach BeamとDataflowのScala APIであるscioが開発されており、そちらも気になっています。</p><ul><li><a href=https://github.com/spotify/scio>https://github.com/spotify/scio</a></li><li><a href=https://engineering.atspotify.com/2017/10/16/big-data-processing-at-spotify-the-road-to-scio-part-1/>https://engineering.atspotify.com/2017/10/16/big-data-processing-at-spotify-the-road-to-scio-part-1/</a></li></ul><p>では、まずは実際に動かしながら学んでみようということで</p><p><a href=https://beam.apache.org/get-started/try-apache-beam/>https://beam.apache.org/get-started/try-apache-beam/</a></p><p>を参考にApache Beam をPython SDKで試してみます</p><p>COLABで実行を試せるので便利ですね</p><p>ですが、Python2で実行されるように設定されているのでPython3で実行してみました。</p><p>実行したcolab のコードを見ていきます。</p><h3 id=環境準備>環境準備</h3><p><code>apache-beam</code> のinstallとGCSからApache beamで処理を行うテキストファイルをダウンロードします。</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=c1># shell コマンドを実行して表示する関数</span>
<span class=k>def</span> <span class=nf>run</span><span class=p>(</span><span class=n>cmd</span><span class=p>):</span>
  <span class=k>print</span><span class=p>(</span><span class=s1>&#39;&gt;&gt; {}&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>cmd</span><span class=p>))</span>
  <span class=err>!</span><span class=p>{</span><span class=n>cmd</span><span class=p>}</span>
  <span class=k>print</span><span class=p>(</span><span class=s1>&#39;&#39;</span><span class=p>)</span>

<span class=c1># Install apache-beam.</span>
<span class=n>run</span><span class=p>(</span><span class=s1>&#39;pip install --quiet apache-beam&#39;</span><span class=p>)</span>

<span class=c1># 対象ファイルの格納ディレクトリを作成後、gsutil を使って /data ディレクトリに格納</span>
<span class=n>run</span><span class=p>(</span><span class=s1>&#39;mkdir -p data&#39;</span><span class=p>)</span>
<span class=n>run</span><span class=p>(</span><span class=s1>&#39;gsutil cp gs://dataflow-samples/shakespeare/kinglear.txt data/&#39;</span><span class=p>)</span>
</code></pre></div><h2 id=文字のカウント>文字のカウント</h2><p>Hello World として単語のカウントを行うデータ処理をbeam で記述してみます。</p><p>テキストファイルを読み込んで、各単語の頻度のカウンティングを行う単純なデータパイプラインを作成しています。</p><p>パイプラインの結果はファイルシステム上で保存されるので分散環境下での大規模処理でも取り扱いに役立ちます。</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=kn>import</span> <span class=nn>apache_beam</span> <span class=kn>as</span> <span class=nn>beam</span>
<span class=kn>import</span> <span class=nn>re</span>

<span class=n>inputs_pattern</span> <span class=o>=</span> <span class=s1>&#39;data/*&#39;</span>
<span class=n>outputs_prefix</span> <span class=o>=</span> <span class=s1>&#39;outputs/part&#39;</span>

<span class=k>with</span> <span class=n>beam</span><span class=o>.</span><span class=n>Pipeline</span><span class=p>()</span> <span class=k>as</span> <span class=n>pipeline</span><span class=p>:</span>
  <span class=p>(</span>
      <span class=n>pipeline</span>
      <span class=o>|</span> <span class=s1>&#39;Read lines&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>ReadFromText</span><span class=p>(</span><span class=n>inputs_pattern</span><span class=p>)</span>
      <span class=o>|</span> <span class=s1>&#39;Find words&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>FlatMap</span><span class=p>(</span><span class=k>lambda</span> <span class=n>line</span><span class=p>:</span> <span class=n>re</span><span class=o>.</span><span class=n>findall</span><span class=p>(</span><span class=sa>r</span><span class=s2>&#34;[a-zA-Z&#39;]+&#34;</span><span class=p>,</span> <span class=n>line</span><span class=p>))</span>
      <span class=o>|</span> <span class=s1>&#39;Pair words with 1&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>word</span><span class=p>:</span> <span class=p>(</span><span class=n>word</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
      <span class=o>|</span> <span class=s1>&#39;Group and sum&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>CombinePerKey</span><span class=p>(</span><span class=nb>sum</span><span class=p>)</span>
      <span class=o>|</span> <span class=s1>&#39;Format results&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>word_count</span><span class=p>:</span> <span class=nb>str</span><span class=p>(</span><span class=n>word_count</span><span class=p>))</span>
      <span class=o>|</span> <span class=s1>&#39;Write results&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>WriteToText</span><span class=p>(</span><span class=n>outputs_prefix</span><span class=p>)</span>
  <span class=p>)</span>
</code></pre></div><p>はい、いきなり</p><p>with beam.Pipeline() as pipeline:
の以降から意味がわからなくなりました。</p><p>Apache beam特有の概念を理解する必要があるので</p><p><a href=https://beam.apache.org/documentation/programming-guide/>https://beam.apache.org/documentation/programming-guide/</a></p><p>を参考に解説してみます。</p><h2 id=apache-beam-programming-guide>Apache Beam Programming Guide</h2><p>Beasm SDKで提供されるクラス郡をここでは紹介していきます。このクラス郡を使うことでデータパイプラインを作成することができます。</p><h3 id=overview>Overview</h3><p>まずBeamを使用するためには、まず最初にBeam SDKのクラスを使って起動プログラムを作成する必要があります。driver program は、あなたのパイプライン(入力、変形と出力のすべて)と実行環境を定義する必要があります。</p><p>Beam SDKは大規模なデータ処理のメカニズムを単純な形で抽象化している</p><ul><li>Pipeline<ul><li>Pipeline はデータ処理タスクの実行開始から終了までをカブセル化するクラスです。これは入力データの読み込みやデータの変形、出力データの書き込みを含む。Beam driver programs は必ずPipelineを作成します。またPipelines 作成時には、実行オプション(どの実行環境下でどのように実行するか)を必ず明記する必要があ。</li></ul></li><li>PCollection<ul><li>Pcollection は分散データセットを表現するクラスです。ここでのデータセットは bounded (ファイルなどの固定されたソース、つまりバッチ)とunbounded (subscriptionなど連続的にアップロードされるソース、つまりストリーム)の両者を指しています。実行するパイプラインは外部データの読み込みによって初期化されたPCollectionによって構築されます。また外部データだけでなく、インメモリのデータからPCollectionを作ることも可能です。つまり、PCollectionはPipelineの出力と入力を担当する。</li></ul></li><li>PTransform<ul><li>PTransform パイプラインでのはデータ処理命令を表現するクラスです。すべての <code>PTransform</code> は一つ以上のPCollection オブジェクトを入力として受け取り、ゼロもしくはそれ以上の数のPCollectionを出力として作成する</li></ul></li><li>IOS transrforms<ul><li>Beamはいくらかの入力と出力のインタフェースがあり、PTransformが読み込み、もしくは書き込みを多種多様な外部のストレージシステムに対して行う</li></ul></li></ul><p>基本的なBeamの起動プログラムは以下の手順で動く</p><ol><li>Pipeline オブジェクトを作成し、パイプラインの実行オプションとパイプラインランナーを設定する</li><li>Pipeline データのために初期のPCollection を行う。そのためにIOs を用いて外部のストレージシステムもしくはインメモリデータから PCollectionを作成する。</li><li>PTransform を各 PCollection へ適用する。Transform は新しい出力としてPCollection を作成する。PCollection を変数、PTransformは関数として考えると、Pipelineは変数と関数からなる複雑な処理グラフとして捉えることができる。</li><li>IOs を使用し、最終的に PCollection を外部ソースに書き出す</li><li>パイプラインをパイプラインランナーで実行する</li></ol><p>あなたが Beam の起動プログラムを実行した時、パイプラインランナーはPCollection を基に作成した transformが適用される workflow graph が構築される。このグラフは適切な分散処理バックエンドで、非同期ジョブとして実行される。</p><p>ここまでで Beam の基礎的な概念を理解できたと思うので最初のサンプルコードでの各行の実行内容について解説します</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=kn>import</span> <span class=nn>apache_beam</span> <span class=kn>as</span> <span class=nn>beam</span>
<span class=kn>import</span> <span class=nn>re</span>

<span class=n>inputs_pattern</span> <span class=o>=</span> <span class=s1>&#39;data/*&#39;</span>
<span class=n>outputs_prefix</span> <span class=o>=</span> <span class=s1>&#39;outputs/part&#39;</span>

<span class=c1># ローカル環境でDirectRunnerを実行</span>
<span class=k>with</span> <span class=n>beam</span><span class=o>.</span><span class=n>Pipeline</span><span class=p>()</span> <span class=k>as</span> <span class=n>pipeline</span><span class=p>:</span>
  <span class=c1># 文字の集計データをPCollection に格納</span>
  <span class=c1># 各要素は (word, count) のタプルであり、(str, int)の型となっている</span>
  <span class=n>word_counts</span> <span class=o>=</span> <span class=p>(</span>
      <span class=c1># 入力のPCollection は空のパイプラインとする</span>
      <span class=n>pipeline</span>

      <span class=c1># テキストファイルから行を読み込む</span>
      <span class=o>|</span> <span class=s1>&#39;Read lines&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>ReadFromText</span><span class=p>(</span><span class=n>inputs_pattern</span><span class=p>)</span>
      <span class=c1># Element type: str - text line</span>

      <span class=c1># 正規表現を利用して行内のすべての単語に反復処理を行う</span>
      <span class=c1># FlatMap will yield an element for every element in an iterable.</span>
      <span class=o>|</span> <span class=s1>&#39;Find words&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>FlatMap</span><span class=p>(</span><span class=k>lambda</span> <span class=n>line</span><span class=p>:</span> <span class=n>re</span><span class=o>.</span><span class=n>findall</span><span class=p>(</span><span class=sa>r</span><span class=s2>&#34;[a-zA-Z&#39;]+&#34;</span><span class=p>,</span> <span class=n>line</span><span class=p>))</span>
      <span class=c1># Element type: str - word</span>

      <span class=c1># 単語が存在した場合、value が１となるkey-value のペアを作成</span>
      <span class=c1># すべての単語を集計していき、同一単語をグループ化する</span>
      <span class=o>|</span> <span class=s1>&#39;Pair words with 1&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>word</span><span class=p>:</span> <span class=p>(</span><span class=n>word</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
      <span class=c1># Element type: (str, int) - key: word, value: 1</span>

      <span class=c1># sum() 関数を使ってkeyごとにグループを行う</span>
      <span class=o>|</span> <span class=s1>&#39;Group and sum&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>CombinePerKey</span><span class=p>(</span><span class=nb>sum</span><span class=p>)</span>
      <span class=c1># Element type: (str, int) - key: word, value: counts</span>
  <span class=p>)</span>
  <span class=p>(</span>
      <span class=c1># 入力となるPCollection は上記で作成された</span>
      <span class=n>word_counts</span>

      <span class=c1># 結果は文字列に処理することで、テキストファイルとして書き込み可能にする</span>
      <span class=o>|</span> <span class=s1>&#39;Format results&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>word_count</span><span class=p>:</span> <span class=nb>str</span><span class=p>(</span><span class=n>word_count</span><span class=p>))</span>
      <span class=c1># Element type: str - text line</span>

      <span class=c1># 最後に結果をファイルに書き込みます。</span>
      <span class=o>|</span> <span class=s1>&#39;Write results&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>WriteToText</span><span class=p>(</span><span class=n>outputs_prefix</span><span class=p>)</span>
  <span class=p>)</span>

<span class=c1>#20個の結果を各ファイルから出力してみる。その際に順序は保証されない</span>
<span class=n>run</span><span class=p>(</span><span class=s1>&#39;head -n 20 {}-00000-of-*&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>outputs_prefix</span><span class=p>))</span>
</code></pre></div><p>実行結果</p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=n>WARNING</span><span class=p>:</span><span class=n>apache_beam</span><span class=o>.</span><span class=n>runners</span><span class=o>.</span><span class=n>interactive</span><span class=o>.</span><span class=n>interactive_environment</span><span class=p>:</span><span class=n>Dependencies</span> <span class=n>required</span> <span class=k>for</span> <span class=n>Interactive</span> <span class=n>Beam</span> <span class=n>PCollection</span> <span class=n>visualization</span> <span class=n>are</span> <span class=ow>not</span> <span class=n>available</span><span class=p>,</span> <span class=n>please</span> <span class=n>use</span><span class=p>:</span> <span class=sb>`pip install apache-beam[interactive]`</span> <span class=n>to</span> <span class=n>install</span> <span class=n>necessary</span> <span class=n>dependencies</span> <span class=n>to</span> <span class=n>enable</span> <span class=nb>all</span> <span class=n>data</span> <span class=n>visualization</span> <span class=n>features</span><span class=o>.</span>
<span class=o>&gt;&gt;</span> <span class=n>head</span> <span class=o>-</span><span class=n>n</span> <span class=mi>20</span> <span class=n>outputs</span><span class=o>/</span><span class=n>part</span><span class=o>-</span><span class=mo>00000</span><span class=o>-</span><span class=n>of</span><span class=o>-*</span>
<span class=p>(</span><span class=s1>&#39;KING&#39;</span><span class=p>,</span> <span class=mi>243</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;LEAR&#39;</span><span class=p>,</span> <span class=mi>236</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;DRAMATIS&#39;</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;PERSONAE&#39;</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;king&#39;</span><span class=p>,</span> <span class=mi>65</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;of&#39;</span><span class=p>,</span> <span class=mi>447</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;Britain&#39;</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;OF&#39;</span><span class=p>,</span> <span class=mi>15</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;FRANCE&#39;</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;DUKE&#39;</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;BURGUNDY&#39;</span><span class=p>,</span> <span class=mi>8</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;CORNWALL&#39;</span><span class=p>,</span> <span class=mi>63</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;ALBANY&#39;</span><span class=p>,</span> <span class=mi>67</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;EARL&#39;</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;KENT&#39;</span><span class=p>,</span> <span class=mi>156</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;GLOUCESTER&#39;</span><span class=p>,</span> <span class=mi>141</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;EDGAR&#39;</span><span class=p>,</span> <span class=mi>126</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;son&#39;</span><span class=p>,</span> <span class=mi>29</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;to&#39;</span><span class=p>,</span> <span class=mi>438</span><span class=p>)</span>
<span class=p>(</span><span class=s1>&#39;Gloucester&#39;</span><span class=p>,</span> <span class=mi>26</span><span class=p>)</span>
</code></pre></div><p>どうでしたか?
まだサンプルコードを動かしただけなので使いこなす自信はありませんが、Apache beam がどのような考えで設計され動かすことができるかが少しはつかめたのでは無いのでしょうか?</p><p>次回は典型的なデータ処理をApache beamで動かしてみたいと思います。</p></article></main><h3>See Also</h3><ul><li><a href=/posts/2020-09-09/>pandas を使って特定のディレクトリのCSVファイルをすべて連結して一つのCSVファイルを作成</a></li><li><a href=/posts/2020-08-23/>Python の内包表記とジェネレータ式のメモリ使用量比較</a></li><li><a href=/posts/2020-07-25/>How to write the UnitTest with stdin at Pytest</a></li><li><a href=/posts/2020-05-10/>自走プログラマーを読み終えた</a></li><li><a href=/posts/2020-04-26/>Pythonの関数のデフォルト引数はmutable(上書きされる)</a></li></ul><footer id=footer>Copyright © 2013-2021 Shunya Ueta</footer></body></html>