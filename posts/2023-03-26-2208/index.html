<!doctype html><html lang=ja><head><meta http-equiv=x-clacks-overhead content="GNU Terry Pratchett"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>現在 Lucene の KNN ベクトルの最大次元数は1024次元 だが、それを2048次元に変更できないかという議論 | hurutoriya</title><meta name=title content="現在 Lucene の KNN ベクトルの最大次元数は1024次元 だが、それを2048次元に変更できないかという議論"><meta name=description content="初心者だけど Apache Lucene に貢献したい場合におすすめのチケットラベルのチケットを眺めていたときに面白いチケットがあった。
取り上げるのは、
Increase the number of dims for KNN vectors to 2048 [LUCENE-10471] · Issue #11507 · apache/lucene
というチケットだが、表題の通りで、現在 KNN ベクトルとして扱える最大次元数は 1024 次元だが、それを 2048 次元に変更できないかの議論がされている。
該当 PR はこちら
https://github.com/apache/lucene/pull/874/files
- public static final int MAX_DIMENSIONS = 1024; + public static final int MAX_DIMENSIONS = 2048; と一行の変更だが、大きな議論が巻き起こっている。
例えば、
MobileNet v2 は 1280 次元 OpenAPI/ GPT-3 のベクトルは 2048 次元 なので、2048 次元にすればそれらのベクトルを扱うことができるのではという課題提起。 概ねみんな反対ではないが懸念点として
ある程度は既存の値から上げてもいいが、制限は設けるべきで次元削減などで特定の次元数以下にユーザーが処理しておくべき ref Java API が Vector API を提供するようになれば、今の実装はすべて変わるので、難しいね ref CNN ベースのモデルを使っている人は、Lucene の近傍探索が使えないという状況は改善すべき。(もちろんどこまで許容すべきかは議論すべきですが) ref この決断は一方通行(制限を再び少なくしようという流れは永久に来ない)なので、急がずに慎重にベンチマークや正当性の議論などが必要 ref プラグラマブルに自由に設定することはできますか？ それは可能ですが、フォークして自分の Lucene をメンテナンスすることになるので推奨できない ref また、この決定にはデータと評価結果が無いと決定できません。争点は、1048 次元にあわせるために、ユーザー側がなぜ次元削減ができないのかという点もあると思います。 ref 歴史的にユーザーは Luene の制限と常に戦ってきているものなので、今回の制限について文句を言われても正直気にしていません。最も心配なのは、KNN Vector の機能は初期段階であり、制限をゆるくすると柔軟性が低下してしまうことです ref 2023-01-03: この issue が作成されてから、多くの変化が起きました。現在では OpenAI の ChatGPT が世の中を席巻しています。最低でも OpenAI が提供するベクトルの次元数である、1536 次元に変更することはできませんか?"><meta name=keywords content="lucene,"><meta property="og:title" content="現在 Lucene の KNN ベクトルの最大次元数は1024次元 だが、それを2048次元に変更できないかという議論"><meta property="og:description" content="初心者だけど Apache Lucene に貢献したい場合におすすめのチケットラベルのチケットを眺めていたときに面白いチケットがあった。
取り上げるのは、
Increase the number of dims for KNN vectors to 2048 [LUCENE-10471] · Issue #11507 · apache/lucene
というチケットだが、表題の通りで、現在 KNN ベクトルとして扱える最大次元数は 1024 次元だが、それを 2048 次元に変更できないかの議論がされている。
該当 PR はこちら
https://github.com/apache/lucene/pull/874/files
- public static final int MAX_DIMENSIONS = 1024; + public static final int MAX_DIMENSIONS = 2048; と一行の変更だが、大きな議論が巻き起こっている。
例えば、
MobileNet v2 は 1280 次元 OpenAPI/ GPT-3 のベクトルは 2048 次元 なので、2048 次元にすればそれらのベクトルを扱うことができるのではという課題提起。 概ねみんな反対ではないが懸念点として
ある程度は既存の値から上げてもいいが、制限は設けるべきで次元削減などで特定の次元数以下にユーザーが処理しておくべき ref Java API が Vector API を提供するようになれば、今の実装はすべて変わるので、難しいね ref CNN ベースのモデルを使っている人は、Lucene の近傍探索が使えないという状況は改善すべき。(もちろんどこまで許容すべきかは議論すべきですが) ref この決断は一方通行(制限を再び少なくしようという流れは永久に来ない)なので、急がずに慎重にベンチマークや正当性の議論などが必要 ref プラグラマブルに自由に設定することはできますか？ それは可能ですが、フォークして自分の Lucene をメンテナンスすることになるので推奨できない ref また、この決定にはデータと評価結果が無いと決定できません。争点は、1048 次元にあわせるために、ユーザー側がなぜ次元削減ができないのかという点もあると思います。 ref 歴史的にユーザーは Luene の制限と常に戦ってきているものなので、今回の制限について文句を言われても正直気にしていません。最も心配なのは、KNN Vector の機能は初期段階であり、制限をゆるくすると柔軟性が低下してしまうことです ref 2023-01-03: この issue が作成されてから、多くの変化が起きました。現在では OpenAI の ChatGPT が世の中を席巻しています。最低でも OpenAI が提供するベクトルの次元数である、1536 次元に変更することはできませんか?"><meta property="og:type" content="article"><meta property="og:url" content="https://shunyaueta.com/posts/2023-03-26-2208/"><meta property="og:image" content="https://shunyaueta.com/ogp.jpg"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-03-26T22:08:18+09:00"><meta property="article:modified_time" content="2023-03-26T22:08:18+09:00"><meta property="og:site_name" content="Shunya Ueta"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://shunyaueta.com/ogp.jpg"><meta name=twitter:title content="現在 Lucene の KNN ベクトルの最大次元数は1024次元 だが、それを2048次元に変更できないかという議論"><meta name=twitter:description content="初心者だけど Apache Lucene に貢献したい場合におすすめのチケットラベルのチケットを眺めていたときに面白いチケットがあった。
取り上げるのは、
Increase the number of dims for KNN vectors to 2048 [LUCENE-10471] · Issue #11507 · apache/lucene
というチケットだが、表題の通りで、現在 KNN ベクトルとして扱える最大次元数は 1024 次元だが、それを 2048 次元に変更できないかの議論がされている。
該当 PR はこちら
https://github.com/apache/lucene/pull/874/files
- public static final int MAX_DIMENSIONS = 1024; + public static final int MAX_DIMENSIONS = 2048; と一行の変更だが、大きな議論が巻き起こっている。
例えば、
MobileNet v2 は 1280 次元 OpenAPI/ GPT-3 のベクトルは 2048 次元 なので、2048 次元にすればそれらのベクトルを扱うことができるのではという課題提起。 概ねみんな反対ではないが懸念点として
ある程度は既存の値から上げてもいいが、制限は設けるべきで次元削減などで特定の次元数以下にユーザーが処理しておくべき ref Java API が Vector API を提供するようになれば、今の実装はすべて変わるので、難しいね ref CNN ベースのモデルを使っている人は、Lucene の近傍探索が使えないという状況は改善すべき。(もちろんどこまで許容すべきかは議論すべきですが) ref この決断は一方通行(制限を再び少なくしようという流れは永久に来ない)なので、急がずに慎重にベンチマークや正当性の議論などが必要 ref プラグラマブルに自由に設定することはできますか？ それは可能ですが、フォークして自分の Lucene をメンテナンスすることになるので推奨できない ref また、この決定にはデータと評価結果が無いと決定できません。争点は、1048 次元にあわせるために、ユーザー側がなぜ次元削減ができないのかという点もあると思います。 ref 歴史的にユーザーは Luene の制限と常に戦ってきているものなので、今回の制限について文句を言われても正直気にしていません。最も心配なのは、KNN Vector の機能は初期段階であり、制限をゆるくすると柔軟性が低下してしまうことです ref 2023-01-03: この issue が作成されてから、多くの変化が起きました。現在では OpenAI の ChatGPT が世の中を席巻しています。最低でも OpenAI が提供するベクトルの次元数である、1536 次元に変更することはできませんか?"><meta itemprop=name content="現在 Lucene の KNN ベクトルの最大次元数は1024次元 だが、それを2048次元に変更できないかという議論"><meta itemprop=description content="初心者だけど Apache Lucene に貢献したい場合におすすめのチケットラベルのチケットを眺めていたときに面白いチケットがあった。
取り上げるのは、
Increase the number of dims for KNN vectors to 2048 [LUCENE-10471] · Issue #11507 · apache/lucene
というチケットだが、表題の通りで、現在 KNN ベクトルとして扱える最大次元数は 1024 次元だが、それを 2048 次元に変更できないかの議論がされている。
該当 PR はこちら
https://github.com/apache/lucene/pull/874/files
- public static final int MAX_DIMENSIONS = 1024; + public static final int MAX_DIMENSIONS = 2048; と一行の変更だが、大きな議論が巻き起こっている。
例えば、
MobileNet v2 は 1280 次元 OpenAPI/ GPT-3 のベクトルは 2048 次元 なので、2048 次元にすればそれらのベクトルを扱うことができるのではという課題提起。 概ねみんな反対ではないが懸念点として
ある程度は既存の値から上げてもいいが、制限は設けるべきで次元削減などで特定の次元数以下にユーザーが処理しておくべき ref Java API が Vector API を提供するようになれば、今の実装はすべて変わるので、難しいね ref CNN ベースのモデルを使っている人は、Lucene の近傍探索が使えないという状況は改善すべき。(もちろんどこまで許容すべきかは議論すべきですが) ref この決断は一方通行(制限を再び少なくしようという流れは永久に来ない)なので、急がずに慎重にベンチマークや正当性の議論などが必要 ref プラグラマブルに自由に設定することはできますか？ それは可能ですが、フォークして自分の Lucene をメンテナンスすることになるので推奨できない ref また、この決定にはデータと評価結果が無いと決定できません。争点は、1048 次元にあわせるために、ユーザー側がなぜ次元削減ができないのかという点もあると思います。 ref 歴史的にユーザーは Luene の制限と常に戦ってきているものなので、今回の制限について文句を言われても正直気にしていません。最も心配なのは、KNN Vector の機能は初期段階であり、制限をゆるくすると柔軟性が低下してしまうことです ref 2023-01-03: この issue が作成されてから、多くの変化が起きました。現在では OpenAI の ChatGPT が世の中を席巻しています。最低でも OpenAI が提供するベクトルの次元数である、1536 次元に変更することはできませんか?"><meta itemprop=datePublished content="2023-03-26T22:08:18+09:00"><meta itemprop=dateModified content="2023-03-26T22:08:18+09:00"><meta itemprop=wordCount content="118"><meta itemprop=image content="https://shunyaueta.com/ogp.jpg"><meta itemprop=keywords content="lucene,"><meta name=referrer content="no-referrer-when-downgrade"><style>body{font-family:Verdana,sans-serif;margin:auto;padding:20px;max-width:720px;text-align:left;background-color:#fff;word-wrap:break-word;overflow-wrap:break-word;line-height:1.5;color:#444}h1,h2,h3,h4,h5,h6,strong,b{color:#222}a{color:#3273dc}.title{text-decoration:none;border:0}.title span{font-weight:400}nav a{margin-right:10px}textarea{width:100%;font-size:16px}input{font-size:16px}content{line-height:1.6}table{width:100%}img{max-width:100%}code{padding:2px 5px;background-color:#f2f2f2}pre code{color:#222;display:block;padding:20px;white-space:pre-wrap;font-size:14px;overflow-x:auto}div.highlight pre{background-color:initial;color:initial}div.highlight code{background-color:unset;color:unset}blockquote{border-left:1px solid #999;color:#222;padding-left:20px;font-style:italic}footer{padding:25px;text-align:center}.helptext{color:#777;font-size:small}.errorlist{color:#eba613;font-size:small}ul.blog-posts{list-style-type:none;padding:unset}ul.blog-posts li{display:flex}ul.blog-posts li span{flex:0 0 130px}ul.blog-posts li a:visited{color:#8b6fcb}@media(prefers-color-scheme:dark){body{background-color:#333;color:#ddd}h1,h2,h3,h4,h5,h6,strong,b{color:#eee}a{color:#8cc2dd}code{background-color:#777}pre code{color:#ddd}blockquote{color:#ccc}textarea,input{background-color:#252525;color:#ddd}.helptext{color:#aaa}}</style><script async src="https://www.googletagmanager.com/gtag/js?id=G-JMJRQJT0Q3"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-JMJRQJT0Q3")</script></head><body><header><a href=/ class=title><h2>hurutoriya</h2></a><nav><a href=/index.xml>RSS</a>
<a href=/about/>著者について</a></nav></header><main><h1>現在 Lucene の KNN ベクトルの最大次元数は1024次元 だが、それを2048次元に変更できないかという議論</h1><p><i><time datetime=2023-03-26 pubdate>2023-03-26</time></i></p><content><p><a href=/posts/2023-03-11-1727/>初心者だけど Apache Lucene に貢献したい場合におすすめのチケットラベル</a>のチケットを眺めていたときに面白いチケットがあった。</p><p>取り上げるのは、</p><p><a href=https://github.com/apache/lucene/issues/11507>Increase the number of dims for KNN vectors to 2048 [LUCENE-10471] · Issue #11507 · apache/lucene</a></p><p>というチケットだが、表題の通りで、現在 KNN ベクトルとして扱える最大次元数は 1024 次元だが、それを 2048 次元に変更できないかの議論がされている。</p><p>該当 PR はこちら</p><p><a href=https://github.com/apache/lucene/pull/874/files>https://github.com/apache/lucene/pull/874/files</a></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-diff data-lang=diff><span style=display:flex><span><span style=color:#f92672>-  public static final int MAX_DIMENSIONS = 1024;
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+  public static final int MAX_DIMENSIONS = 2048;
</span></span></span></code></pre></div><p>と一行の変更だが、大きな議論が巻き起こっている。</p><p>例えば、</p><ul><li>MobileNet v2 は 1280 次元</li><li>OpenAPI/ GPT-3 のベクトルは 2048 次元
なので、2048 次元にすればそれらのベクトルを扱うことができるのではという課題提起。</li></ul><p>概ねみんな反対ではないが懸念点として</p><ul><li>ある程度は既存の値から上げてもいいが、制限は設けるべきで次元削減などで特定の次元数以下にユーザーが処理しておくべき <a href=https://github.com/apache/lucene/issues/11507#issuecomment-1224402769>ref</a></li><li>Java API が Vector API を提供するようになれば、今の実装はすべて変わるので、難しいね <a href=https://github.com/apache/lucene/issues/11507#issuecomment-1224402784>ref</a></li><li>CNN ベースのモデルを使っている人は、Lucene の近傍探索が使えないという状況は改善すべき。(もちろんどこまで許容すべきかは議論すべきですが) <a href=https://github.com/apache/lucene/issues/11507#issuecomment-1224402796>ref</a></li><li>この決断は一方通行(制限を再び少なくしようという流れは永久に来ない)なので、急がずに慎重にベンチマークや正当性の議論などが必要 <a href=https://github.com/apache/lucene/issues/11507#issuecomment-1224402827>ref</a></li><li>プラグラマブルに自由に設定することはできますか？<ul><li>それは可能ですが、フォークして自分の Lucene をメンテナンスすることになるので推奨できない <a href=https://github.com/apache/lucene/issues/11507#issuecomment-1224402846>ref</a></li></ul></li><li>また、この決定にはデータと評価結果が無いと決定できません。争点は、1048 次元にあわせるために、ユーザー側がなぜ次元削減ができないのかという点もあると思います。 <a href=https://github.com/apache/lucene/issues/11507#issuecomment-1224402846>ref</a></li><li>歴史的にユーザーは Luene の制限と常に戦ってきているものなので、今回の制限について文句を言われても正直気にしていません。最も心配なのは、KNN Vector の機能は初期段階であり、制限をゆるくすると柔軟性が低下してしまうことです <a href=https://github.com/apache/lucene/issues/11507#issuecomment-1224402868>ref</a></li><li>2023-01-03: この issue が作成されてから、多くの変化が起きました。現在では OpenAI の ChatGPT が世の中を席巻しています。最低でも OpenAI が提供するベクトルの次元数である、1536 次元に変更することはできませんか? <a href=https://github.com/apache/lucene/issues/11507#issuecomment-1369369480>ref</a><ul><li>この変更は、1 行の変更で終わります。なので究極的に言えば、自分で PATCH を当ててビルドし、Elasticsearch に当てれば、すぐに利用することができます <a href=https://github.com/apache/lucene/issues/11507#issuecomment-1369724615>ref</a></li><li>なぜこのアドバイスをしたかというと、実際にその変更後にレポートを返してください。恐らく、パフォーマンスが機能しないか、メモリ使用量が劇的に高くなっていると思います。 <a href=https://github.com/apache/lucene/issues/11507#issuecomment-1369749788>ref</a></li></ul></li></ul><h2 id=総論>総論</h2><p>ベンチマークデータを取って、データを集めないとこの変更はされなさそう。
ここまで良い意味で保守的なのは、個人的に素晴らしいと思います。
それぐらい、慎重に考えていかないと今の Lucene のパフォーマンスは維持できないですよね。</p><h2>関連しているかもしれない記事</h2><ul><li><a href=/posts/2023-03-11-1727/>初心者だけど Apache Lucene に貢献したい場合におすすめのチケットラベル</a></li><li><a href=/posts/2021-11-26/>Amazonがeコマース検索を Lucene により、どうスケールさせているか at Berlin Buzzwords 2019</a></li></ul><h2>Support</h2>記事をお読みくださりありがとうございます。
このウェブサイトの運営を支援していただける方を募集しています。
もしよろしければ、<a href=https://www.buymeacoffee.com/hurutoriya>Buy Me a Coffee</a> からサポート(投げ銭)していただけると、記事の執筆、情報発信のモチベーションに繋がります✨<p>--</p>記事を楽しめましたか？
<a href=/index.xml>RSS</a>で更新情報を配信しているので、お好きなフィードリーダーで購読してみてください。</content><p><a href=https://shunyaueta.com/tags/lucene/>#lucene</a></p><script src=https://giscus.app/client.js data-repo=hurutoriya/hurutoriya.github.io data-repo-id="MDEwOlJlcG9zaXRvcnk2MDgyNTY1Nw==" data-category=Comments data-category-id=DIC_kwDOA6AgOc4CAQTX data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=0 data-theme=dark data-lang=ja crossorigin=anonymous async></script></main><footer>Made with <a href=https://github.com/janraasch/hugo-bearblog/>Hugo ʕ•ᴥ•ʔ Bear</a></footer></body></html>