<!doctype html><html lang=ja><head><meta http-equiv=x-clacks-overhead content="GNU Terry Pratchett"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>CloudComposer の Variables (環境変数)を gcloud cli で取得する | hurutoriya</title><meta name=title content="CloudComposer の Variables (環境変数)を gcloud cli で取得する"><meta name=description content="Airflow 1 系で設定されている環境変数を JSON ファイルとして GUI を使って書き出す方法の続報です。
前回、Airflow CLI からでも環境変数を JSON ファイルとして出力できる1が、手元から実行しても GCP 上のインスタンスにしか保存されなかったので諦めたと書きました。 ですが、その問題を解決できたので、解決方法を公開しておきます。
Cloud Storage に格納されるデータ | Cloud Composer | Google Cloudによると、Cloud Composer インスタンス内部のディレクトリは GCS にマッピングされているらしい。
マッピング関係は以下( GCP のドキュメントをそのまま引用)
フォルダ Storage パス マッピングされたディレクトリ 説明 DAG gs://bucket-name/dags /home/airflow/gcs/dags 環境の DAG を保存します。このフォルダ内の DAG のみが環境にスケジュールされます。 プラグイン gs://bucket-name/plugins /home/airflow/gcs/plugins カスタム プラグインを保存します。カスタムのインハウス Airflow 演算子、フック、センサー、インターフェースなどです。 データ gs://bucket-name/data /home/airflow/gcs/data タスクが生成して使用するデータを保存します。このフォルダは、すべてのワーカーノードにマウントされます。 ログ gs://bucket-name/logs タスクの Airflow ログを保存します。ログは Airflow ウェブ インターフェースでも利用できます。 それを使えば、/home/airflow/gcs/data にファイルを保存すれば、CloudComposer が保有している GCS の gs://bucket-name/data にアクセスすれば、そのファイルが参照可能になる。"><meta name=keywords content="airflow,gcp,"><meta property="og:title" content="CloudComposer の Variables (環境変数)を gcloud cli で取得する"><meta property="og:description" content="Airflow 1 系で設定されている環境変数を JSON ファイルとして GUI を使って書き出す方法の続報です。
前回、Airflow CLI からでも環境変数を JSON ファイルとして出力できる1が、手元から実行しても GCP 上のインスタンスにしか保存されなかったので諦めたと書きました。 ですが、その問題を解決できたので、解決方法を公開しておきます。
Cloud Storage に格納されるデータ | Cloud Composer | Google Cloudによると、Cloud Composer インスタンス内部のディレクトリは GCS にマッピングされているらしい。
マッピング関係は以下( GCP のドキュメントをそのまま引用)
フォルダ Storage パス マッピングされたディレクトリ 説明 DAG gs://bucket-name/dags /home/airflow/gcs/dags 環境の DAG を保存します。このフォルダ内の DAG のみが環境にスケジュールされます。 プラグイン gs://bucket-name/plugins /home/airflow/gcs/plugins カスタム プラグインを保存します。カスタムのインハウス Airflow 演算子、フック、センサー、インターフェースなどです。 データ gs://bucket-name/data /home/airflow/gcs/data タスクが生成して使用するデータを保存します。このフォルダは、すべてのワーカーノードにマウントされます。 ログ gs://bucket-name/logs タスクの Airflow ログを保存します。ログは Airflow ウェブ インターフェースでも利用できます。 それを使えば、/home/airflow/gcs/data にファイルを保存すれば、CloudComposer が保有している GCS の gs://bucket-name/data にアクセスすれば、そのファイルが参照可能になる。"><meta property="og:type" content="article"><meta property="og:url" content="https://shunyaueta.com/posts/2022-10-17-1630/"><meta property="og:image" content="https://shunyaueta.com/ogp.jpg"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-10-17T16:30:58+09:00"><meta property="article:modified_time" content="2022-10-17T16:30:58+09:00"><meta property="og:site_name" content="hurutoriya"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://shunyaueta.com/ogp.jpg"><meta name=twitter:title content="CloudComposer の Variables (環境変数)を gcloud cli で取得する"><meta name=twitter:description content="Airflow 1 系で設定されている環境変数を JSON ファイルとして GUI を使って書き出す方法の続報です。
前回、Airflow CLI からでも環境変数を JSON ファイルとして出力できる1が、手元から実行しても GCP 上のインスタンスにしか保存されなかったので諦めたと書きました。 ですが、その問題を解決できたので、解決方法を公開しておきます。
Cloud Storage に格納されるデータ | Cloud Composer | Google Cloudによると、Cloud Composer インスタンス内部のディレクトリは GCS にマッピングされているらしい。
マッピング関係は以下( GCP のドキュメントをそのまま引用)
フォルダ Storage パス マッピングされたディレクトリ 説明 DAG gs://bucket-name/dags /home/airflow/gcs/dags 環境の DAG を保存します。このフォルダ内の DAG のみが環境にスケジュールされます。 プラグイン gs://bucket-name/plugins /home/airflow/gcs/plugins カスタム プラグインを保存します。カスタムのインハウス Airflow 演算子、フック、センサー、インターフェースなどです。 データ gs://bucket-name/data /home/airflow/gcs/data タスクが生成して使用するデータを保存します。このフォルダは、すべてのワーカーノードにマウントされます。 ログ gs://bucket-name/logs タスクの Airflow ログを保存します。ログは Airflow ウェブ インターフェースでも利用できます。 それを使えば、/home/airflow/gcs/data にファイルを保存すれば、CloudComposer が保有している GCS の gs://bucket-name/data にアクセスすれば、そのファイルが参照可能になる。"><meta itemprop=name content="CloudComposer の Variables (環境変数)を gcloud cli で取得する"><meta itemprop=description content="Airflow 1 系で設定されている環境変数を JSON ファイルとして GUI を使って書き出す方法の続報です。
前回、Airflow CLI からでも環境変数を JSON ファイルとして出力できる1が、手元から実行しても GCP 上のインスタンスにしか保存されなかったので諦めたと書きました。 ですが、その問題を解決できたので、解決方法を公開しておきます。
Cloud Storage に格納されるデータ | Cloud Composer | Google Cloudによると、Cloud Composer インスタンス内部のディレクトリは GCS にマッピングされているらしい。
マッピング関係は以下( GCP のドキュメントをそのまま引用)
フォルダ Storage パス マッピングされたディレクトリ 説明 DAG gs://bucket-name/dags /home/airflow/gcs/dags 環境の DAG を保存します。このフォルダ内の DAG のみが環境にスケジュールされます。 プラグイン gs://bucket-name/plugins /home/airflow/gcs/plugins カスタム プラグインを保存します。カスタムのインハウス Airflow 演算子、フック、センサー、インターフェースなどです。 データ gs://bucket-name/data /home/airflow/gcs/data タスクが生成して使用するデータを保存します。このフォルダは、すべてのワーカーノードにマウントされます。 ログ gs://bucket-name/logs タスクの Airflow ログを保存します。ログは Airflow ウェブ インターフェースでも利用できます。 それを使えば、/home/airflow/gcs/data にファイルを保存すれば、CloudComposer が保有している GCS の gs://bucket-name/data にアクセスすれば、そのファイルが参照可能になる。"><meta itemprop=datePublished content="2022-10-17T16:30:58+09:00"><meta itemprop=dateModified content="2022-10-17T16:30:58+09:00"><meta itemprop=wordCount content="118"><meta itemprop=image content="https://shunyaueta.com/ogp.jpg"><meta itemprop=keywords content="airflow,gcp,"><meta name=referrer content="no-referrer-when-downgrade"><style>body{font-family:Verdana,sans-serif;margin:auto;padding:20px;max-width:720px;text-align:left;background-color:#fff;word-wrap:break-word;overflow-wrap:break-word;line-height:1.5;color:#444}h1,h2,h3,h4,h5,h6,strong,b{color:#222}a{color:#3273dc}.title{text-decoration:none;border:0}.title span{font-weight:400}nav a{margin-right:10px}textarea{width:100%;font-size:16px}input{font-size:16px}content{line-height:1.6}table{width:100%}img{max-width:100%}code{padding:2px 5px;background-color:#f2f2f2}pre code{color:#222;display:block;padding:20px;white-space:pre-wrap;font-size:14px;overflow-x:auto}div.highlight pre{background-color:initial;color:initial}div.highlight code{background-color:unset;color:unset}blockquote{border-left:1px solid #999;color:#222;padding-left:20px;font-style:italic}footer{padding:25px;text-align:center}.helptext{color:#777;font-size:small}.errorlist{color:#eba613;font-size:small}ul.blog-posts{list-style-type:none;padding:unset}ul.blog-posts li{display:flex}ul.blog-posts li span{flex:0 0 130px}ul.blog-posts li a:visited{color:#8b6fcb}@media(prefers-color-scheme:dark){body{background-color:#333;color:#ddd}h1,h2,h3,h4,h5,h6,strong,b{color:#eee}a{color:#8cc2dd}code{background-color:#777}pre code{color:#ddd}blockquote{color:#ccc}textarea,input{background-color:#252525;color:#ddd}.helptext{color:#aaa}}</style><script async src="https://www.googletagmanager.com/gtag/js?id=G-JMJRQJT0Q3"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-JMJRQJT0Q3")</script></head><body><header><a href=/ class=title><h2>hurutoriya</h2></a><nav><a href=/index.xml>RSS</a>
<a href=/about/>著者について</a></nav></header><main><h1>CloudComposer の Variables (環境変数)を gcloud cli で取得する</h1><p><i><time datetime=2022-10-17 pubdate>2022-10-17</time></i></p><content><p><a href=/posts/2022-10-04-1549/>Airflow 1 系で設定されている環境変数を JSON ファイルとして GUI を使って書き出す方法</a>の続報です。</p><p>前回、Airflow CLI からでも環境変数を JSON ファイルとして出力できる<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>が、手元から実行しても GCP 上のインスタンスにしか保存されなかったので諦めたと書きました。
ですが、その問題を解決できたので、解決方法を公開しておきます。</p><p><a href=https://cloud.google.com/composer/docs/concepts/cloud-storage#folders_in_the_bucket>Cloud Storage に格納されるデータ  |  Cloud Composer  |  Google Cloud</a>によると、Cloud Composer インスタンス内部のディレクトリは GCS にマッピングされているらしい。</p><p>マッピング関係は以下( GCP のドキュメントをそのまま引用)</p><table><thead><tr><th>フォルダ</th><th>Storage パス</th><th>マッピングされたディレクトリ</th><th>説明</th></tr></thead><tbody><tr><td>DAG</td><td><code>gs://bucket-name/dags</code></td><td><code>/home/airflow/gcs/dags</code></td><td>環境の DAG を保存します。このフォルダ内の DAG のみが環境にスケジュールされます。</td></tr><tr><td>プラグイン</td><td><code>gs://bucket-name/plugins</code></td><td><code>/home/airflow/gcs/plugins</code></td><td>カスタム プラグインを保存します。カスタムのインハウス Airflow 演算子、フック、センサー、インターフェースなどです。</td></tr><tr><td>データ</td><td><code>gs://bucket-name/data</code></td><td><code>/home/airflow/gcs/data</code></td><td>タスクが生成して使用するデータを保存します。このフォルダは、すべてのワーカーノードにマウントされます。</td></tr><tr><td>ログ</td><td><code>gs://bucket-name/logs</code></td><td>タスクの Airflow ログを保存します。ログは <a href=https://cloud.google.com/composer/docs/how-to/accessing/airflow-web-interface>Airflow ウェブ インターフェース</a>でも利用できます。</td><td></td></tr></tbody></table><p>それを使えば、<code>/home/airflow/gcs/data</code> にファイルを保存すれば、CloudComposer が保有している GCS の <code>gs://bucket-name/data</code> にアクセスすれば、そのファイルが参照可能になる。</p><p>実際に以下のようなコマンドを実行したところ、<code>gs://bucket-name/data</code> からファイルを参照できました。
めでたい 🎉</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># GCSにファイルを保存</span>
</span></span><span style=display:flex><span>$ gcloud composer environments run COMPOSER_NAME --location LOCATION variables -- --export /home/airflow/gcs/data/airflow_env.json
</span></span><span style=display:flex><span><span style=color:#75715e># 生成されたファイルをGCS上で確認</span>
</span></span><span style=display:flex><span>$ gsutil cat <span style=color:#e6db74>`</span>gs://bucket-name/data/airflow_env.json
</span></span></code></pre></div><p>これで前回紹介したアプローチの欠点である GUI での操作に依存せず、CLI で完結してファイルを作成できるようになったのでミスも減りますね。
このディレクトリと GCS のマッピング機能を考えた人は、頭いいなと思いました。</p><p>まず CloudComposer を GCP 上で提供する上で DAG の同期のためにマッピング機能は不可欠なので、最初からこの機能があるんじゃないかと考えるべきでしたね&mldr; 反省</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href=https://stackoverflow.com/questions/53206003/export-all-airflow-variables>python - Export all Airflow variables - Stack Overflow</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div><h2>関連しているかもしれない記事</h2><ul><li><a href=/posts/2022-10-04-1549/>Airflow 1系で設定されている環境変数を JSON ファイルとしてGUIを使って書き出す方法</a></li><li><a href=/posts/2021-10-04/>CloudComposer のDAGをCircleCIで更新する</a></li><li><a href=/posts/2021-09-29/>GCPのCloud Composer のDAGを素早く・簡単にデバッグする</a></li><li><a href=/posts/2022-01-20/>OSS の Google BigQuery UDF `bqutil.fn` を使えば UDF の独自実装を置き換えられるかもしれない</a></li><li><a href=/posts/2021-11-05/>Dataflow template を使って Google Cloud Pub/Sub の中身を簡単に確認する</a></li></ul><p>---</p>記事を楽しめましたか？ <a href=/index.xml>RSS</a>で更新情報を配信しているので、お好きなフィードリーダーで購読してみてください。</br><b>Support:</b> このウェブサイトの運営を支援していただける方を募集しています。もしよろしければ、<a href=https://www.buymeacoffee.com/hurutoriya>Buy Me a Coffee</a> からサポート(投げ銭)していただけると、記事の執筆、情報発信のモチベーションに繋がります✨</br>記事への感想などの<a href="https://docs.google.com/forms/d/e/1FAIpQLScgZVDrjQiKLbQRovfs88oweCITzjtvt1PlgwL14JfWPOrpPQ/viewform?usp=pp_url&entry.838298670=https%3a%2f%2fshunyaueta.com%2fposts%2f2022-10-17-1630%2f">おたより</a>をおまちしてます。
お気軽にお送りください。
お返事はメールアドレス入力があればメールでさせていただきます。
もちろんお返事を希望せずに単なる感想だけでも大歓迎です。</content><p><a href=https://shunyaueta.com/tags/airflow/>#airflow</a>
<a href=https://shunyaueta.com/tags/gcp/>#gcp</a></p></main><footer>Made with <a href=https://github.com/janraasch/hugo-bearblog/>Hugo ʕ•ᴥ•ʔ Bear</a></footer></body></html>