<!doctype html><html lang=ja><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=theme-color content="dark"><title>Slicing Convolutional Neural Network for Crowd Video Understanding (CVPR2016)を読んだ | Shunya Ueta</title><link rel=stylesheet href=/sass/main.min.1a3290acca8b3fc92df85ea9200859476d6c80d59009c89a749300f3ce7a7a67.css><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','UA-39994406-11','auto');ga('send','pageview');}</script><meta property="og:title" content="Slicing Convolutional Neural Network for Crowd Video Understanding (CVPR2016)を読んだ"><meta property="og:description" content="群衆解析の手法に興味があるので、サーベイの結果を放流しておきます。
Jing Shao, Chen Change Loy, Kai Kang, and Xiaogang Wang, “Slicing Convolutional Neural Network for Crowd Video Understanding”, in CVPR, 2016.
Project Page
Summary
一言説明 時系列・空間的特徴から CNN で特徴を学習、群衆の動画に対してstate-of-the-artを達成
3 個の CNN を用いて下記の３つの特徴を表現学習
 xy- : 空間的特徴 xt- : x 軸の時系列特徴 yt- : y 軸の時系列特徴  Comments Dataset としてWWW Crowd Dataset
が公開されている。10,000 本の群衆の動画を収集公開しているとのこと。
Demo Movie
 紹介動画を見てみたら分かるが、群衆の動画というよりも数が増大した結果一般的な画像認識のデモ動画になっている Jing Shaoさんは CVPR2014 から群衆解析のための descriptor を提案したりしてたんだけど、2016 年から Deep な手法での群衆解析の研究をやっているのは手が早いなと 所属グループは ISLVRC2015 の物体認識タスクで優勝した香港大学のグループ Multimedia Laboratory The Chinese University of Hong Kong データセット、実装コードを必ず公開しているのは尊敬、またそれくらいやらないとトップには通過しないんだろうな CNN のアーキテクチャ毎の比較実験と考察をかなり入念に行っていた。数年後には各データのフォーマットに合わせたベストな DNN のアーキテクチャが決まってくるんじゃないだろうか"><meta property="og:type" content="article"><meta property="og:url" content="https://shunyaueta.com/posts/2018-01-16/"><meta property="og:image" content="https://shunyaueta.com/ogp.jpg"><meta property="article:published_time" content="2018-01-16T06:04:37+00:00"><meta property="article:modified_time" content="2021-12-03T23:02:09+09:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://shunyaueta.com/ogp.jpg"><meta name=twitter:title content="Slicing Convolutional Neural Network for Crowd Video Understanding (CVPR2016)を読んだ"><meta name=twitter:description content="群衆解析の手法に興味があるので、サーベイの結果を放流しておきます。
Jing Shao, Chen Change Loy, Kai Kang, and Xiaogang Wang, “Slicing Convolutional Neural Network for Crowd Video Understanding”, in CVPR, 2016.
Project Page
Summary
一言説明 時系列・空間的特徴から CNN で特徴を学習、群衆の動画に対してstate-of-the-artを達成
3 個の CNN を用いて下記の３つの特徴を表現学習
 xy- : 空間的特徴 xt- : x 軸の時系列特徴 yt- : y 軸の時系列特徴  Comments Dataset としてWWW Crowd Dataset
が公開されている。10,000 本の群衆の動画を収集公開しているとのこと。
Demo Movie
 紹介動画を見てみたら分かるが、群衆の動画というよりも数が増大した結果一般的な画像認識のデモ動画になっている Jing Shaoさんは CVPR2014 から群衆解析のための descriptor を提案したりしてたんだけど、2016 年から Deep な手法での群衆解析の研究をやっているのは手が早いなと 所属グループは ISLVRC2015 の物体認識タスクで優勝した香港大学のグループ Multimedia Laboratory The Chinese University of Hong Kong データセット、実装コードを必ず公開しているのは尊敬、またそれくらいやらないとトップには通過しないんだろうな CNN のアーキテクチャ毎の比較実験と考察をかなり入念に行っていた。数年後には各データのフォーマットに合わせたベストな DNN のアーキテクチャが決まってくるんじゃないだろうか"></head><body class=dark><nav class=navbar><div class=container><div class=flex><div><a class=brand href=/><span class=emoji>🦅</span>
Shunya Ueta</a></div><div class=flex><a href=/articles/>All posts</a>
<button id=dark-mode-button></button></div></div></div></nav><main><div class=container><article><header class=article-header><div class=thumb><div><h1>Slicing Convolutional Neural Network for Crowd Video Understanding (CVPR2016)を読んだ</h1><div class=post-meta><div>By on <time>2018.01.16</time> (Last updated:<time>2021.12.03</time>)</div><div class=tags><a href=/tags/paper/>paper</a>
<a href=/tags/computervision/>computervision</a></div></div></div></div></header></article><div class=article-post><p>群衆解析の手法に興味があるので、サーベイの結果を放流しておきます。</p><p>Jing Shao, Chen Change Loy, Kai Kang, and Xiaogang Wang, “Slicing Convolutional Neural Network for Crowd Video Understanding”, in CVPR, 2016.</p><p><a href=http://www.ee.cuhk.edu.hk/~jshao/SCNN.html>Project Page</a></p><p><img src=/posts/2018-01-17/images/1.png alt=image></p><p>Summary</p><h3 id=一言説明>一言説明</h3><p>時系列・空間的特徴から CNN で特徴を学習、群衆の動画に対して<code>state-of-the-art</code>を達成</p><p>3 個の CNN を用いて下記の３つの特徴を表現学習</p><ul><li>xy- : 空間的特徴</li><li>xt- : x 軸の時系列特徴</li><li>yt- : y 軸の時系列特徴</li></ul><h3 id=comments>Comments</h3><p>Dataset として<a href=http://www.ee.cuhk.edu.hk/~jshao/WWWCrowdDataset.html>WWW Crowd Dataset</a><br>が公開されている。10,000 本の群衆の動画を収集公開しているとのこと。</p><p>Demo Movie</p><ul><li>紹介動画を見てみたら分かるが、群衆の動画というよりも数が増大した結果一般的な画像認識のデモ動画になっている</li><li><a href=http://www.ee.cuhk.edu.hk/~jshao/>Jing Shao</a>さんは CVPR2014 から群衆解析のための descriptor を提案したりしてたんだけど、2016 年から Deep な手法での群衆解析の研究をやっているのは手が早いなと</li><li>所属グループは ISLVRC2015 の物体認識タスクで優勝した香港大学のグループ</li><li><a href=http://mmlab.ie.cuhk.edu.hk/index.html>Multimedia Laboratory The Chinese University of Hong Kong</a></li><li>データセット、実装コードを必ず公開しているのは尊敬、またそれくらいやらないとトップには通過しないんだろうな</li><li>CNN のアーキテクチャ毎の比較実験と考察をかなり入念に行っていた。数年後には各データのフォーマットに合わせたベストな DNN のアーキテクチャが決まってくるんじゃないだろうか</li></ul></div><h2>Support</h2><div class=container><div class=posts><div class=post><div class=post-row><a href=https://www.buymeacoffee.com/hurutoriya target=_blank>☕️ Buy me a cofee: お読みくださりありがとうございます。
こちらから ☕ を一杯支援していただけると、ブログ執筆のモチベーションに繋がります ✨</a></div></div></div></div><h2>See Also</h2><ul><li><a href=/posts/2018-01-14/>Analyzing Free-standing Conversational Groups: A Multimodal Approach (ACMMM15) を読んだ</a></li><li><a href=/posts/2018-01-12/>Call center stress recognition with person-specific models を読んだ</a></li><li><a href=/posts/2018-01-11/>FUSE: Full Spectral Clustering(KDD2016) を読んだ</a></li><li><a href=/posts/2017-12-23/>“Learning Deep Representations for Graph Clustering (AAAI2014)” を読んだ</a></li><li><a href=/posts/2017-12-04/>Edge-Weighted Personalized PageRank: Breaking A Decade-Old Performance Barrier を読んだ</a></li></ul></div><div class=container><nav class="flex container suggested"><a rel=prev href=/posts/2018-01-15/ title="Previous post (older)"><span>Previous</span>
Jupyter Notebookの差分を明瞭に確認する事ができるpackage : nbdime</a>
<a rel=next href=/posts/2018-01-17/ title="Next post (newer)"><span>Next</span>
Data-driven Crowd Analysis in Videos (ICCV2011)を読んだ</a></nav></div></main></main><footer class="footer flex"><section class=container><nav class=footer-links><a href=/index.xml>RSS</a></nav></section><script async src=/js/features.min.a94f58a30ad2560de728e080d87f75c60cf806fd1b3d5f4815f1a1a02c0d1859.js></script></footer></body></html>