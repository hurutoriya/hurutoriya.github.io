<!doctype html><html><head><script data-ad-client=ca-pub-8604812913439531 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>Slicing Convolutional Neural Network for Crowd Video Understanding (CVPR2016)を読んだ - hurutoriya</title><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:image" content><meta property="og:title" content="Slicing Convolutional Neural Network for Crowd Video Understanding (CVPR2016)を読んだ"><meta property="og:description" content="群衆解析の手法に興味があるので、サーベイの結果を放流しておきます。
Jing Shao, Chen Change Loy, Kai Kang, and Xiaogang Wang, “Slicing Convolutional Neural Network for Crowd Video Understanding”, in CVPR, 2016.
Project Page
Summary
一言説明 時系列・空間的特徴から CNN で特徴を学習、群衆の動画に対してstate-of-the-artを達成
3 個の CNN を用いて下記の３つの特徴を表現学習
 xy- : 空間的特徴 xt- : x 軸の時系列特徴 yt- : y 軸の時系列特徴  Comments Dataset としてWWW Crowd Dataset
が公開されている。10,000 本の群衆の動画を収集公開しているとのこと。
Demo Movie
 紹介動画を見てみたら分かるが、群衆の動画というよりも数が増大した結果一般的な画像認識のデモ動画になっている Jing Shaoさんは CVPR2014 から群衆解析のための descriptor を提案したりしてたんだけど、2016 年から Deep な手法での群衆解析の研究をやっているのは手が早いなと 所属グループは ISLVRC2015 の物体認識タスクで優勝した香港大学のグループ Multimedia Laboratory The Chinese University of Hong Kong データセット、実装コードを必ず公開しているのは尊敬、またそれくらいやらないとトップには通過しないんだろうな CNN のアーキテクチャ毎の比較実験と考察をかなり入念に行っていた。数年後には各データのフォーマットに合わせたベストな DNN のアーキテクチャが決まってくるんじゃないだろうか"><meta property="og:type" content="article"><meta property="og:url" content="https://shunyaueta.com/posts/2018-01-16/"><meta property="article:published_time" content="2018-01-16T06:04:37+00:00"><meta property="article:modified_time" content="2018-01-16T06:04:37+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Slicing Convolutional Neural Network for Crowd Video Understanding (CVPR2016)を読んだ"><meta name=twitter:description content="群衆解析の手法に興味があるので、サーベイの結果を放流しておきます。
Jing Shao, Chen Change Loy, Kai Kang, and Xiaogang Wang, “Slicing Convolutional Neural Network for Crowd Video Understanding”, in CVPR, 2016.
Project Page
Summary
一言説明 時系列・空間的特徴から CNN で特徴を学習、群衆の動画に対してstate-of-the-artを達成
3 個の CNN を用いて下記の３つの特徴を表現学習
 xy- : 空間的特徴 xt- : x 軸の時系列特徴 yt- : y 軸の時系列特徴  Comments Dataset としてWWW Crowd Dataset
が公開されている。10,000 本の群衆の動画を収集公開しているとのこと。
Demo Movie
 紹介動画を見てみたら分かるが、群衆の動画というよりも数が増大した結果一般的な画像認識のデモ動画になっている Jing Shaoさんは CVPR2014 から群衆解析のための descriptor を提案したりしてたんだけど、2016 年から Deep な手法での群衆解析の研究をやっているのは手が早いなと 所属グループは ISLVRC2015 の物体認識タスクで優勝した香港大学のグループ Multimedia Laboratory The Chinese University of Hong Kong データセット、実装コードを必ず公開しているのは尊敬、またそれくらいやらないとトップには通過しないんだろうな CNN のアーキテクチャ毎の比較実験と考察をかなり入念に行っていた。数年後には各データのフォーマットに合わせたベストな DNN のアーキテクチャが決まってくるんじゃないだろうか"><script src=https://shunyaueta.com/js/feather.min.js></script><link href=https://shunyaueta.com/css/fonts.css rel=stylesheet><link rel=stylesheet type=text/css media=screen href=https://shunyaueta.com/css/main.css><link rel=stylesheet type=text/css href=https://shunyaueta.com/css/dark.css media="(prefers-color-scheme: dark)"><script async src="https://www.googletagmanager.com/gtag/js?id=UA-39994406-11"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-39994406-11');</script></head><body><div class=content><header><div class=main><a href=https://shunyaueta.com/>hurutoriya</a></div><nav><a href=/>Home</a>
<a href=/posts>All posts</a>
<a href=/about>About</a>
<a href=/tags>Tags</a></nav></header><main><article><div class=title><h1 class=title>Slicing Convolutional Neural Network for Crowd Video Understanding (CVPR2016)を読んだ</h1><div class=meta>Posted on Jan 16, 2018</div></div><section class=body><p>群衆解析の手法に興味があるので、サーベイの結果を放流しておきます。</p><p>Jing Shao, Chen Change Loy, Kai Kang, and Xiaogang Wang, “Slicing Convolutional Neural Network for Crowd Video Understanding”, in CVPR, 2016.</p><p><a href=http://www.ee.cuhk.edu.hk/~jshao/SCNN.html>Project Page</a></p><p><img src=/posts/2018-01-17/images/1.png alt=image></p><p>Summary</p><h3 id=一言説明>一言説明</h3><p>時系列・空間的特徴から CNN で特徴を学習、群衆の動画に対して<code>state-of-the-art</code>を達成</p><p>3 個の CNN を用いて下記の３つの特徴を表現学習</p><ul><li>xy- : 空間的特徴</li><li>xt- : x 軸の時系列特徴</li><li>yt- : y 軸の時系列特徴</li></ul><h3 id=comments>Comments</h3><p>Dataset として<a href=http://www.ee.cuhk.edu.hk/~jshao/WWWCrowdDataset.html>WWW Crowd Dataset</a><br>が公開されている。10,000 本の群衆の動画を収集公開しているとのこと。</p><p>Demo Movie</p><ul><li>紹介動画を見てみたら分かるが、群衆の動画というよりも数が増大した結果一般的な画像認識のデモ動画になっている</li><li><a href=http://www.ee.cuhk.edu.hk/~jshao/>Jing Shao</a>さんは CVPR2014 から群衆解析のための descriptor を提案したりしてたんだけど、2016 年から Deep な手法での群衆解析の研究をやっているのは手が早いなと</li><li>所属グループは ISLVRC2015 の物体認識タスクで優勝した香港大学のグループ</li><li><a href=http://mmlab.ie.cuhk.edu.hk/index.html>Multimedia Laboratory The Chinese University of Hong Kong</a></li><li>データセット、実装コードを必ず公開しているのは尊敬、またそれくらいやらないとトップには通過しないんだろうな</li><li>CNN のアーキテクチャ毎の比較実験と考察をかなり入念に行っていた。数年後には各データのフォーマットに合わせたベストな DNN のアーキテクチャが決まってくるんじゃないだろうか</li></ul></section><div class=post-tags><nav class="nav tags"><ul class=tags><li><a href=/tags/computer-vision>Computer Vision</a></li><li><a href=/tags/cvpr>CVPR</a></li><li><a href=/tags/paper>Paper</a></li></ul></nav></div></article></main><h3>See Also</h3><ul><li><a href=/posts/2018-01-14/>Analyzing Free-standing Conversational Groups: A Multimodal Approach (ACMMM15) を読んだ</a></li><li><a href=/posts/2018-01-12/>Call center stress recognition with person-specific models を読んだ</a></li><li><a href=/posts/2018-01-11/>FUSE: Full Spectral Clustering(KDD2016) を読んだ</a></li><li><a href=/posts/2017-12-23/>“Learning Deep Representations for Graph Clustering (AAAI2014)” を読んだ</a></li><li><a href=/posts/2017-12-04/>Edge-Weighted Personalized PageRank: Breaking A Decade-Old Performance Barrier を読んだ</a></li></ul><footer><hr><a class=soc href=https://github.com/hurutoriya title=GitHub><i data-feather=github></i></a>|<a class=soc href=https://twitter.com/hurutoriya/ title=Twitter><i data-feather=twitter></i></a>|⚡️
2021 © Shunya Ueta | <a href=https://github.com/athul/archie>Archie Theme</a> | Built with <a href=https://gohugo.io>Hugo</a></footer><script>feather.replace()</script></div></body></html>