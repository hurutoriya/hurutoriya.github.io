<!doctype html><html lang=ja><head><meta http-equiv=x-clacks-overhead content="GNU Terry Pratchett"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Slicing Convolutional Neural Network for Crowd Video Understanding (CVPR2016)ã‚’èª­ã‚“ã  | Shunya Ueta</title><meta name=title content="Slicing Convolutional Neural Network for Crowd Video Understanding (CVPR2016)ã‚’èª­ã‚“ã "><meta name=description content="ç¾¤è¡†è§£æã®æ‰‹æ³•ã«èˆˆå‘³ãŒã‚ã‚‹ã®ã§ã€ã‚µãƒ¼ãƒ™ã‚¤ã®çµæœã‚’æ”¾æµã—ã¦ãŠãã¾ã™ã€‚
Jing Shao, Chen Change Loy, Kai Kang, and Xiaogang Wang, â€œSlicing Convolutional Neural Network for Crowd Video Understandingâ€, in CVPR, 2016.
Project Page
Summary
ä¸€è¨€èª¬æ˜ æ™‚ç³»åˆ—ãƒ»ç©ºé–“çš„ç‰¹å¾´ã‹ã‚‰ CNN ã§ç‰¹å¾´ã‚’å­¦ç¿’ã€ç¾¤è¡†ã®å‹•ç”»ã«å¯¾ã—ã¦state-of-the-artã‚’é”æˆ
3 å€‹ã® CNN ã‚’ç”¨ã„ã¦ä¸‹è¨˜ã®ï¼“ã¤ã®ç‰¹å¾´ã‚’è¡¨ç¾å­¦ç¿’
xy- : ç©ºé–“çš„ç‰¹å¾´ xt- : x è»¸ã®æ™‚ç³»åˆ—ç‰¹å¾´ yt- : y è»¸ã®æ™‚ç³»åˆ—ç‰¹å¾´ Comments Dataset ã¨ã—ã¦WWW Crowd Dataset
ãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚10,000 æœ¬ã®ç¾¤è¡†ã®å‹•ç”»ã‚’åé›†å…¬é–‹ã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚
Demo Movie
ç´¹ä»‹å‹•ç”»ã‚’è¦‹ã¦ã¿ãŸã‚‰åˆ†ã‹ã‚‹ãŒã€ç¾¤è¡†ã®å‹•ç”»ã¨ã„ã†ã‚ˆã‚Šã‚‚æ•°ãŒå¢—å¤§ã—ãŸçµæœä¸€èˆ¬çš„ãªç”»åƒèªè­˜ã®ãƒ‡ãƒ¢å‹•ç”»ã«ãªã£ã¦ã„ã‚‹ Jing Shaoã•ã‚“ã¯ CVPR2014 ã‹ã‚‰ç¾¤è¡†è§£æã®ãŸã‚ã® descriptor ã‚’ææ¡ˆã—ãŸã‚Šã—ã¦ãŸã‚“ã ã‘ã©ã€2016 å¹´ã‹ã‚‰ Deep ãªæ‰‹æ³•ã§ã®ç¾¤è¡†è§£æã®ç ”ç©¶ã‚’ã‚„ã£ã¦ã„ã‚‹ã®ã¯æ‰‹ãŒæ—©ã„ãªã¨ æ‰€å±ã‚°ãƒ«ãƒ¼ãƒ—ã¯ ISLVRC2015 ã®ç‰©ä½“èªè­˜ã‚¿ã‚¹ã‚¯ã§å„ªå‹ã—ãŸé¦™æ¸¯å¤§å­¦ã®ã‚°ãƒ«ãƒ¼ãƒ— Multimedia Laboratory The Chinese University of Hong Kong ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€å®Ÿè£…ã‚³ãƒ¼ãƒ‰ã‚’å¿…ãšå…¬é–‹ã—ã¦ã„ã‚‹ã®ã¯å°Šæ•¬ã€ã¾ãŸãã‚Œãã‚‰ã„ã‚„ã‚‰ãªã„ã¨ãƒˆãƒƒãƒ—ã«ã¯é€šéã—ãªã„ã‚“ã ã‚ã†ãª CNN ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¯ã®æ¯”è¼ƒå®Ÿé¨“ã¨è€ƒå¯Ÿã‚’ã‹ãªã‚Šå…¥å¿µã«è¡Œã£ã¦ã„ãŸã€‚æ•°å¹´å¾Œã«ã¯å„ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«åˆã‚ã›ãŸãƒ™ã‚¹ãƒˆãª DNN ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãŒæ±ºã¾ã£ã¦ãã‚‹ã‚“ã˜ã‚ƒãªã„ã ã‚ã†ã‹ "><meta name=keywords content="computervision,paper,"><meta property="og:title" content="Slicing Convolutional Neural Network for Crowd Video Understanding (CVPR2016)ã‚’èª­ã‚“ã "><meta property="og:description" content="ç¾¤è¡†è§£æã®æ‰‹æ³•ã«èˆˆå‘³ãŒã‚ã‚‹ã®ã§ã€ã‚µãƒ¼ãƒ™ã‚¤ã®çµæœã‚’æ”¾æµã—ã¦ãŠãã¾ã™ã€‚
Jing Shao, Chen Change Loy, Kai Kang, and Xiaogang Wang, â€œSlicing Convolutional Neural Network for Crowd Video Understandingâ€, in CVPR, 2016.
Project Page
Summary
ä¸€è¨€èª¬æ˜ æ™‚ç³»åˆ—ãƒ»ç©ºé–“çš„ç‰¹å¾´ã‹ã‚‰ CNN ã§ç‰¹å¾´ã‚’å­¦ç¿’ã€ç¾¤è¡†ã®å‹•ç”»ã«å¯¾ã—ã¦state-of-the-artã‚’é”æˆ
3 å€‹ã® CNN ã‚’ç”¨ã„ã¦ä¸‹è¨˜ã®ï¼“ã¤ã®ç‰¹å¾´ã‚’è¡¨ç¾å­¦ç¿’
xy- : ç©ºé–“çš„ç‰¹å¾´ xt- : x è»¸ã®æ™‚ç³»åˆ—ç‰¹å¾´ yt- : y è»¸ã®æ™‚ç³»åˆ—ç‰¹å¾´ Comments Dataset ã¨ã—ã¦WWW Crowd Dataset
ãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚10,000 æœ¬ã®ç¾¤è¡†ã®å‹•ç”»ã‚’åé›†å…¬é–‹ã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚
Demo Movie
ç´¹ä»‹å‹•ç”»ã‚’è¦‹ã¦ã¿ãŸã‚‰åˆ†ã‹ã‚‹ãŒã€ç¾¤è¡†ã®å‹•ç”»ã¨ã„ã†ã‚ˆã‚Šã‚‚æ•°ãŒå¢—å¤§ã—ãŸçµæœä¸€èˆ¬çš„ãªç”»åƒèªè­˜ã®ãƒ‡ãƒ¢å‹•ç”»ã«ãªã£ã¦ã„ã‚‹ Jing Shaoã•ã‚“ã¯ CVPR2014 ã‹ã‚‰ç¾¤è¡†è§£æã®ãŸã‚ã® descriptor ã‚’ææ¡ˆã—ãŸã‚Šã—ã¦ãŸã‚“ã ã‘ã©ã€2016 å¹´ã‹ã‚‰ Deep ãªæ‰‹æ³•ã§ã®ç¾¤è¡†è§£æã®ç ”ç©¶ã‚’ã‚„ã£ã¦ã„ã‚‹ã®ã¯æ‰‹ãŒæ—©ã„ãªã¨ æ‰€å±ã‚°ãƒ«ãƒ¼ãƒ—ã¯ ISLVRC2015 ã®ç‰©ä½“èªè­˜ã‚¿ã‚¹ã‚¯ã§å„ªå‹ã—ãŸé¦™æ¸¯å¤§å­¦ã®ã‚°ãƒ«ãƒ¼ãƒ— Multimedia Laboratory The Chinese University of Hong Kong ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€å®Ÿè£…ã‚³ãƒ¼ãƒ‰ã‚’å¿…ãšå…¬é–‹ã—ã¦ã„ã‚‹ã®ã¯å°Šæ•¬ã€ã¾ãŸãã‚Œãã‚‰ã„ã‚„ã‚‰ãªã„ã¨ãƒˆãƒƒãƒ—ã«ã¯é€šéã—ãªã„ã‚“ã ã‚ã†ãª CNN ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¯ã®æ¯”è¼ƒå®Ÿé¨“ã¨è€ƒå¯Ÿã‚’ã‹ãªã‚Šå…¥å¿µã«è¡Œã£ã¦ã„ãŸã€‚æ•°å¹´å¾Œã«ã¯å„ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«åˆã‚ã›ãŸãƒ™ã‚¹ãƒˆãª DNN ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãŒæ±ºã¾ã£ã¦ãã‚‹ã‚“ã˜ã‚ƒãªã„ã ã‚ã†ã‹ "><meta property="og:type" content="article"><meta property="og:url" content="https://shunyaueta.com/posts/2018-01-16/"><meta property="og:image" content="https://shunyaueta.com/ogp.jpg"><meta property="article:section" content="posts"><meta property="article:published_time" content="2018-01-16T06:04:37+00:00"><meta property="article:modified_time" content="2018-01-16T06:04:37+00:00"><meta property="og:site_name" content="Shunya Ueta"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://shunyaueta.com/ogp.jpg"><meta name=twitter:title content="Slicing Convolutional Neural Network for Crowd Video Understanding (CVPR2016)ã‚’èª­ã‚“ã "><meta name=twitter:description content="ç¾¤è¡†è§£æã®æ‰‹æ³•ã«èˆˆå‘³ãŒã‚ã‚‹ã®ã§ã€ã‚µãƒ¼ãƒ™ã‚¤ã®çµæœã‚’æ”¾æµã—ã¦ãŠãã¾ã™ã€‚
Jing Shao, Chen Change Loy, Kai Kang, and Xiaogang Wang, â€œSlicing Convolutional Neural Network for Crowd Video Understandingâ€, in CVPR, 2016.
Project Page
Summary
ä¸€è¨€èª¬æ˜ æ™‚ç³»åˆ—ãƒ»ç©ºé–“çš„ç‰¹å¾´ã‹ã‚‰ CNN ã§ç‰¹å¾´ã‚’å­¦ç¿’ã€ç¾¤è¡†ã®å‹•ç”»ã«å¯¾ã—ã¦state-of-the-artã‚’é”æˆ
3 å€‹ã® CNN ã‚’ç”¨ã„ã¦ä¸‹è¨˜ã®ï¼“ã¤ã®ç‰¹å¾´ã‚’è¡¨ç¾å­¦ç¿’
xy- : ç©ºé–“çš„ç‰¹å¾´ xt- : x è»¸ã®æ™‚ç³»åˆ—ç‰¹å¾´ yt- : y è»¸ã®æ™‚ç³»åˆ—ç‰¹å¾´ Comments Dataset ã¨ã—ã¦WWW Crowd Dataset
ãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚10,000 æœ¬ã®ç¾¤è¡†ã®å‹•ç”»ã‚’åé›†å…¬é–‹ã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚
Demo Movie
ç´¹ä»‹å‹•ç”»ã‚’è¦‹ã¦ã¿ãŸã‚‰åˆ†ã‹ã‚‹ãŒã€ç¾¤è¡†ã®å‹•ç”»ã¨ã„ã†ã‚ˆã‚Šã‚‚æ•°ãŒå¢—å¤§ã—ãŸçµæœä¸€èˆ¬çš„ãªç”»åƒèªè­˜ã®ãƒ‡ãƒ¢å‹•ç”»ã«ãªã£ã¦ã„ã‚‹ Jing Shaoã•ã‚“ã¯ CVPR2014 ã‹ã‚‰ç¾¤è¡†è§£æã®ãŸã‚ã® descriptor ã‚’ææ¡ˆã—ãŸã‚Šã—ã¦ãŸã‚“ã ã‘ã©ã€2016 å¹´ã‹ã‚‰ Deep ãªæ‰‹æ³•ã§ã®ç¾¤è¡†è§£æã®ç ”ç©¶ã‚’ã‚„ã£ã¦ã„ã‚‹ã®ã¯æ‰‹ãŒæ—©ã„ãªã¨ æ‰€å±ã‚°ãƒ«ãƒ¼ãƒ—ã¯ ISLVRC2015 ã®ç‰©ä½“èªè­˜ã‚¿ã‚¹ã‚¯ã§å„ªå‹ã—ãŸé¦™æ¸¯å¤§å­¦ã®ã‚°ãƒ«ãƒ¼ãƒ— Multimedia Laboratory The Chinese University of Hong Kong ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€å®Ÿè£…ã‚³ãƒ¼ãƒ‰ã‚’å¿…ãšå…¬é–‹ã—ã¦ã„ã‚‹ã®ã¯å°Šæ•¬ã€ã¾ãŸãã‚Œãã‚‰ã„ã‚„ã‚‰ãªã„ã¨ãƒˆãƒƒãƒ—ã«ã¯é€šéã—ãªã„ã‚“ã ã‚ã†ãª CNN ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¯ã®æ¯”è¼ƒå®Ÿé¨“ã¨è€ƒå¯Ÿã‚’ã‹ãªã‚Šå…¥å¿µã«è¡Œã£ã¦ã„ãŸã€‚æ•°å¹´å¾Œã«ã¯å„ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«åˆã‚ã›ãŸãƒ™ã‚¹ãƒˆãª DNN ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãŒæ±ºã¾ã£ã¦ãã‚‹ã‚“ã˜ã‚ƒãªã„ã ã‚ã†ã‹ "><meta itemprop=name content="Slicing Convolutional Neural Network for Crowd Video Understanding (CVPR2016)ã‚’èª­ã‚“ã "><meta itemprop=description content="ç¾¤è¡†è§£æã®æ‰‹æ³•ã«èˆˆå‘³ãŒã‚ã‚‹ã®ã§ã€ã‚µãƒ¼ãƒ™ã‚¤ã®çµæœã‚’æ”¾æµã—ã¦ãŠãã¾ã™ã€‚
Jing Shao, Chen Change Loy, Kai Kang, and Xiaogang Wang, â€œSlicing Convolutional Neural Network for Crowd Video Understandingâ€, in CVPR, 2016.
Project Page
Summary
ä¸€è¨€èª¬æ˜ æ™‚ç³»åˆ—ãƒ»ç©ºé–“çš„ç‰¹å¾´ã‹ã‚‰ CNN ã§ç‰¹å¾´ã‚’å­¦ç¿’ã€ç¾¤è¡†ã®å‹•ç”»ã«å¯¾ã—ã¦state-of-the-artã‚’é”æˆ
3 å€‹ã® CNN ã‚’ç”¨ã„ã¦ä¸‹è¨˜ã®ï¼“ã¤ã®ç‰¹å¾´ã‚’è¡¨ç¾å­¦ç¿’
xy- : ç©ºé–“çš„ç‰¹å¾´ xt- : x è»¸ã®æ™‚ç³»åˆ—ç‰¹å¾´ yt- : y è»¸ã®æ™‚ç³»åˆ—ç‰¹å¾´ Comments Dataset ã¨ã—ã¦WWW Crowd Dataset
ãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚10,000 æœ¬ã®ç¾¤è¡†ã®å‹•ç”»ã‚’åé›†å…¬é–‹ã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚
Demo Movie
ç´¹ä»‹å‹•ç”»ã‚’è¦‹ã¦ã¿ãŸã‚‰åˆ†ã‹ã‚‹ãŒã€ç¾¤è¡†ã®å‹•ç”»ã¨ã„ã†ã‚ˆã‚Šã‚‚æ•°ãŒå¢—å¤§ã—ãŸçµæœä¸€èˆ¬çš„ãªç”»åƒèªè­˜ã®ãƒ‡ãƒ¢å‹•ç”»ã«ãªã£ã¦ã„ã‚‹ Jing Shaoã•ã‚“ã¯ CVPR2014 ã‹ã‚‰ç¾¤è¡†è§£æã®ãŸã‚ã® descriptor ã‚’ææ¡ˆã—ãŸã‚Šã—ã¦ãŸã‚“ã ã‘ã©ã€2016 å¹´ã‹ã‚‰ Deep ãªæ‰‹æ³•ã§ã®ç¾¤è¡†è§£æã®ç ”ç©¶ã‚’ã‚„ã£ã¦ã„ã‚‹ã®ã¯æ‰‹ãŒæ—©ã„ãªã¨ æ‰€å±ã‚°ãƒ«ãƒ¼ãƒ—ã¯ ISLVRC2015 ã®ç‰©ä½“èªè­˜ã‚¿ã‚¹ã‚¯ã§å„ªå‹ã—ãŸé¦™æ¸¯å¤§å­¦ã®ã‚°ãƒ«ãƒ¼ãƒ— Multimedia Laboratory The Chinese University of Hong Kong ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€å®Ÿè£…ã‚³ãƒ¼ãƒ‰ã‚’å¿…ãšå…¬é–‹ã—ã¦ã„ã‚‹ã®ã¯å°Šæ•¬ã€ã¾ãŸãã‚Œãã‚‰ã„ã‚„ã‚‰ãªã„ã¨ãƒˆãƒƒãƒ—ã«ã¯é€šéã—ãªã„ã‚“ã ã‚ã†ãª CNN ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¯ã®æ¯”è¼ƒå®Ÿé¨“ã¨è€ƒå¯Ÿã‚’ã‹ãªã‚Šå…¥å¿µã«è¡Œã£ã¦ã„ãŸã€‚æ•°å¹´å¾Œã«ã¯å„ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«åˆã‚ã›ãŸãƒ™ã‚¹ãƒˆãª DNN ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãŒæ±ºã¾ã£ã¦ãã‚‹ã‚“ã˜ã‚ƒãªã„ã ã‚ã†ã‹ "><meta itemprop=datePublished content="2018-01-16T06:04:37+00:00"><meta itemprop=dateModified content="2018-01-16T06:04:37+00:00"><meta itemprop=wordCount content="79"><meta itemprop=image content="https://shunyaueta.com/ogp.jpg"><meta itemprop=keywords content="computervision,paper,"><meta name=referrer content="no-referrer-when-downgrade"><style>body{font-family:Verdana,sans-serif;margin:auto;padding:20px;max-width:720px;text-align:left;background-color:#fff;word-wrap:break-word;overflow-wrap:break-word;line-height:1.5;color:#444}h1,h2,h3,h4,h5,h6,strong,b{color:#222}a{color:#3273dc}.title{text-decoration:none;border:0}.title span{font-weight:400}nav a{margin-right:10px}textarea{width:100%;font-size:16px}input{font-size:16px}content{line-height:1.6}table{width:100%}img{max-width:100%}code{padding:2px 5px;background-color:#f2f2f2}pre code{color:#222;display:block;padding:20px;white-space:pre-wrap;font-size:14px;overflow-x:auto}div.highlight pre{background-color:initial;color:initial}div.highlight code{background-color:unset;color:unset}blockquote{border-left:1px solid #999;color:#222;padding-left:20px;font-style:italic}footer{padding:25px;text-align:center}.helptext{color:#777;font-size:small}.errorlist{color:#eba613;font-size:small}ul.blog-posts{list-style-type:none;padding:unset}ul.blog-posts li{display:flex}ul.blog-posts li span{flex:0 0 130px}ul.blog-posts li a:visited{color:#8b6fcb}@media(prefers-color-scheme:dark){body{background-color:#333;color:#ddd}h1,h2,h3,h4,h5,h6,strong,b{color:#eee}a{color:#8cc2dd}code{background-color:#777}pre code{color:#ddd}blockquote{color:#ccc}textarea,input{background-color:#252525;color:#ddd}.helptext{color:#aaa}}</style><script async src="https://www.googletagmanager.com/gtag/js?id=G-JMJRQJT0Q3"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-JMJRQJT0Q3")</script></head><body><header><a href=/ class=title><h2>Shunya Ueta</h2></a><nav><a href=/about/>è‘—è€…ã«ã¤ã„ã¦</a>
<a href=/index.xml>RSS</a></nav></header><main><h1>Slicing Convolutional Neural Network for Crowd Video Understanding (CVPR2016)ã‚’èª­ã‚“ã </h1><p><i><time datetime=2018-01-16 pubdate>2018-01-16</time></i></p><content><p>ç¾¤è¡†è§£æã®æ‰‹æ³•ã«èˆˆå‘³ãŒã‚ã‚‹ã®ã§ã€ã‚µãƒ¼ãƒ™ã‚¤ã®çµæœã‚’æ”¾æµã—ã¦ãŠãã¾ã™ã€‚</p><p>Jing Shao, Chen Change Loy, Kai Kang, and Xiaogang Wang, â€œSlicing Convolutional Neural Network for Crowd Video Understandingâ€, in CVPR, 2016.</p><p><a href=http://www.ee.cuhk.edu.hk/~jshao/SCNN.html>Project Page</a></p><p><img src=/posts/2018-01-17/images/1.png alt=image></p><p>Summary</p><h3 id=ä¸€è¨€èª¬æ˜>ä¸€è¨€èª¬æ˜</h3><p>æ™‚ç³»åˆ—ãƒ»ç©ºé–“çš„ç‰¹å¾´ã‹ã‚‰ CNN ã§ç‰¹å¾´ã‚’å­¦ç¿’ã€ç¾¤è¡†ã®å‹•ç”»ã«å¯¾ã—ã¦<code>state-of-the-art</code>ã‚’é”æˆ</p><p>3 å€‹ã® CNN ã‚’ç”¨ã„ã¦ä¸‹è¨˜ã®ï¼“ã¤ã®ç‰¹å¾´ã‚’è¡¨ç¾å­¦ç¿’</p><ul><li>xy- : ç©ºé–“çš„ç‰¹å¾´</li><li>xt- : x è»¸ã®æ™‚ç³»åˆ—ç‰¹å¾´</li><li>yt- : y è»¸ã®æ™‚ç³»åˆ—ç‰¹å¾´</li></ul><h2 id=comments>Comments</h2><p>Dataset ã¨ã—ã¦<a href=http://www.ee.cuhk.edu.hk/~jshao/WWWCrowdDataset.html>WWW Crowd Dataset</a><br>ãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚10,000 æœ¬ã®ç¾¤è¡†ã®å‹•ç”»ã‚’åé›†å…¬é–‹ã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚</p><p>Demo Movie</p><ul><li>ç´¹ä»‹å‹•ç”»ã‚’è¦‹ã¦ã¿ãŸã‚‰åˆ†ã‹ã‚‹ãŒã€ç¾¤è¡†ã®å‹•ç”»ã¨ã„ã†ã‚ˆã‚Šã‚‚æ•°ãŒå¢—å¤§ã—ãŸçµæœä¸€èˆ¬çš„ãªç”»åƒèªè­˜ã®ãƒ‡ãƒ¢å‹•ç”»ã«ãªã£ã¦ã„ã‚‹</li><li><a href=http://www.ee.cuhk.edu.hk/~jshao/>Jing Shao</a>ã•ã‚“ã¯ CVPR2014 ã‹ã‚‰ç¾¤è¡†è§£æã®ãŸã‚ã® descriptor ã‚’ææ¡ˆã—ãŸã‚Šã—ã¦ãŸã‚“ã ã‘ã©ã€2016 å¹´ã‹ã‚‰ Deep ãªæ‰‹æ³•ã§ã®ç¾¤è¡†è§£æã®ç ”ç©¶ã‚’ã‚„ã£ã¦ã„ã‚‹ã®ã¯æ‰‹ãŒæ—©ã„ãªã¨</li><li>æ‰€å±ã‚°ãƒ«ãƒ¼ãƒ—ã¯ ISLVRC2015 ã®ç‰©ä½“èªè­˜ã‚¿ã‚¹ã‚¯ã§å„ªå‹ã—ãŸé¦™æ¸¯å¤§å­¦ã®ã‚°ãƒ«ãƒ¼ãƒ—</li><li><a href=http://mmlab.ie.cuhk.edu.hk/index.html>Multimedia Laboratory The Chinese University of Hong Kong</a></li><li>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€å®Ÿè£…ã‚³ãƒ¼ãƒ‰ã‚’å¿…ãšå…¬é–‹ã—ã¦ã„ã‚‹ã®ã¯å°Šæ•¬ã€ã¾ãŸãã‚Œãã‚‰ã„ã‚„ã‚‰ãªã„ã¨ãƒˆãƒƒãƒ—ã«ã¯é€šéã—ãªã„ã‚“ã ã‚ã†ãª</li><li>CNN ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¯ã®æ¯”è¼ƒå®Ÿé¨“ã¨è€ƒå¯Ÿã‚’ã‹ãªã‚Šå…¥å¿µã«è¡Œã£ã¦ã„ãŸã€‚æ•°å¹´å¾Œã«ã¯å„ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«åˆã‚ã›ãŸãƒ™ã‚¹ãƒˆãª DNN ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãŒæ±ºã¾ã£ã¦ãã‚‹ã‚“ã˜ã‚ƒãªã„ã ã‚ã†ã‹</li></ul></content><p><a href=https://shunyaueta.com/tags/computervision/>#computervision</a>
<a href=https://shunyaueta.com/tags/paper/>#paper</a></p>---<br>ğŸ“® ğŸ“§ ğŸ: è¨˜äº‹ã¸ã®<a href="https://docs.google.com/forms/d/e/1FAIpQLScgZVDrjQiKLbQRovfs88oweCITzjtvt1PlgwL14JfWPOrpPQ/viewform?usp=pp_url&entry.838298670=https%3a%2f%2fshunyaueta.com%2fposts%2f2018-01-16%2f">æ„Ÿæƒ³</a>ã®ãŠãŸã‚ˆã‚Šã‚’ãŠã¾ã¡ã—ã¦ã¾ã™ã€‚
ãŠæ°—è»½ã«ãŠé€ã‚Šãã ã•ã„ã€‚
ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹å…¥åŠ›ãŒã‚ã‚Œã°ãƒ¡ãƒ¼ãƒ«ã§è¿”ä¿¡ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚
ã‚‚ã¡ã‚ã‚“ãŠè¿”äº‹ã‚’å¸Œæœ›ã›ãšã«å˜ãªã‚‹æ„Ÿæƒ³ã ã‘ã§ã‚‚å¤§æ­“è¿ã§ã™ã€‚<br><br>ã“ã®ã‚µã‚¤ãƒˆã®æ›´æ–°æƒ…å ±ã‚’<a href=/index.xml>RSS</a>ã§é…ä¿¡ã—ã¦ã„ã¾ã™ã€‚
ãŠå¥½ããªãƒ•ã‚£ãƒ¼ãƒ‰ãƒªãƒ¼ãƒ€ãƒ¼ã§è³¼èª­ã—ã¦ã¿ã¦ãã ã•ã„ã€‚<br><br>ã“ã®ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã®é‹å–¶ã‚„è‘—è€…ã®æ´»å‹•ã‚’æ”¯æ´ã—ã¦ã„ãŸã ã‘ã‚‹æ–¹ã‚’å‹Ÿé›†ã—ã¦ã„ã¾ã™ã€‚<br>ã‚‚ã—ã‚ˆã‚ã—ã‘ã‚Œã°ã€<a href=https://www.buymeacoffee.com/hurutoriya>Buy Me a Coffee</a> ã‹ã‚‰ã‚µãƒãƒ¼ãƒˆ(æŠ•ã’éŠ­)ã—ã¦ã„ãŸã ã‘ã‚‹ã¨ã€è‘—è€…ã®æ´»å‹•ã®ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã«ç¹‹ãŒã‚Šã¾ã™âœ¨<br>---<br><p>é–¢é€£ã—ã¦ã„ã‚‹ã‹ã‚‚ã—ã‚Œãªã„è¨˜äº‹</p><ul><li><a href=/posts/2018-01-14/>Analyzing Free-standing Conversational Groups: A Multimodal Approach (ACMMM15) ã‚’èª­ã‚“ã </a></li><li><a href=/posts/2018-01-12/>Call center stress recognition with person-specific models ã‚’èª­ã‚“ã </a></li><li><a href=/posts/2018-01-11/>FUSE: Full Spectral Clustering(KDD2016) ã‚’èª­ã‚“ã </a></li><li><a href=/posts/2017-12-23/>â€œLearning Deep Representations for Graph Clustering (AAAI2014)â€ ã‚’èª­ã‚“ã </a></li><li><a href=/posts/2017-12-04/>Edge-Weighted Personalized PageRank: Breaking A Decade-Old Performance Barrier ã‚’èª­ã‚“ã </a></li></ul></main><footer>Made with <a href=https://github.com/janraasch/hugo-bearblog/>Hugo Ê•â€¢á´¥â€¢Ê” Bear</a></footer></body></html>