<!doctype html><html><head><script data-ad-client=ca-pub-8604812913439531 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Shunya Ueta (a.k.a hurutoriya) personal website"><link rel="shortcut icon" href=https://shunyaueta.com/favicon.ico><link rel=stylesheet href=/css/style.min.css><script async src="https://www.googletagmanager.com/gtag/js?id=UA-39994406-11"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-39994406-11');</script><title>Analyzing Free-standing Conversational Groups: A Multimodal Approach (ACMMM15) を読んだ</title></head><body><header id=banner><h2><a href=https://shunyaueta.com/>Software Engineer as Data Scientist</a></h2><nav><ul><li><a href=/ title=posts>posts</a></li><li><a href=/about/ title=about>about</a></li></ul></nav></header><main id=content><article><header id=post-header><h1>Analyzing Free-standing Conversational Groups: A Multimodal Approach (ACMMM15) を読んだ</h1><time>2018-01-14</time></header><p>スタンディングディスカッション形式での会話を評価した研究</p><p><img src=/posts/2018-01-14/images/1.png alt=image></p><p>Summary Slide</p><p>X Alameda-Pineda, Y Yan, E Ricci, O Lanz, N Sebe<br>“Analyzing Free-standing Conversational Groups: A Multimodal Approach”, in 2015 ACM Multimedia Conference</p><p><a href=http://xavirema.eu/wp-content/papercite-data/pdf/Alameda-ACMMM-2015.pdf>link</a></p><p>を読んだので、軽くメモ。</p><p>マルチモーダル系の論文初めて読んだんですが、まとめるとコントリビューションが 5 つあると主張。</p><h3 id=contribution>Contribution</h3><ul><li>音声・近接情報、そして監視カメラからの身体と頭の姿勢推定からマルチモーダルに解析</li><li>フリースタンディングディスカッションを身体・頭の姿勢推定から解析</li><li>カメラと音声・近接センサーからなるマルチモーダルな解析するためのフレームワークを提案</li><li>ラベリングされてないデータに対する行列補間問題の考案</li><li>SALSA(データ・セット)を公開・評価</li></ul><p>SALSA というポスターセッションの動画と音声のデータも公開されている</p><blockquote><p><a href=http://tev.fbk.eu/salsa><em>SALSA: Synergetic sociAL Scene Analysis</em></a></p></blockquote><p>動画は Google Drive で公開されていて時代の波を感じる。</p><ul><li>データセットを公開</li><li>論文も読みやすい</li><li>新しい行列補完計画法(アルゴリズム)を提案</li><li>実問題に取り組む</li></ul><p>と盛り沢山な内容で面白かった。</p><p>スライド内のリンクは Google Slide で共有しているのでこちらを参照すると便利です。</p><p><a href="https://docs.google.com/presentation/d/1G6zfzV4jIm7qj4LkHkm3Gk_qHEml0SWZExkNuqw0ef8/embed?start=true&loop=true&delayms=1000&slide=id.g1502801dfc_2_6">X Alameda-Pineda, Y Yan, E Ricci, O Lanz, N Sebe "Analyzing Free-standing Conversational Groups: A…</a></p></article></main><h3>See Also</h3><ul><li><a href=/posts/2018-01-12/>Call center stress recognition with person-specific models を読んだ</a></li><li><a href=/posts/2018-01-11/>FUSE: Full Spectral Clustering(KDD2016) を読んだ</a></li><li><a href=/posts/2017-12-23/>“Learning Deep Representations for Graph Clustering (AAAI2014)” を読んだ</a></li><li><a href=/posts/2017-12-04/>Edge-Weighted Personalized PageRank: Breaking A Decade-Old Performance Barrier を読んだ</a></li><li><a href=/posts/2017-12-01/>Machine Learning that Matters (ICML2012) を読んだ</a></li></ul><footer id=footer>Copyright © 2013-2021 Shunya Ueta</footer></body></html>