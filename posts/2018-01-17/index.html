<!doctype html><html lang=ja><head><meta http-equiv=x-clacks-overhead content="GNU Terry Pratchett"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Data-driven Crowd Analysis in Videos (ICCV2011)を読んだ | hurutoriya</title><meta name=title content="Data-driven Crowd Analysis in Videos (ICCV2011)を読んだ"><meta name=description content="Data-driven Crowd Analysis in Videos (ICCV2011)を読んだ
Mikel Rodriguez, Josef Sivic, Ivan Laptev, Jean-Yves Audibert, “Data-driven Crowd Analysis in Videos”, in ICCV2011.
Project Page
を読んだので、メモです。
Summary
tl;dr 高密度な群集内の個人を追跡を転移学習によって精度を向上させる手法 Contribution 追跡の精度を転移学習によって向上させた 転移学習を行うためのデータセットとそのフレームワークを考案 論文内では、転移学習の例としてマラソンAの群集を対象に追跡する際に、以下の流れで転移学習を行う。
大域的な群衆状況のマッチング : 同じようなシーンを探索(この場合 DB 内にあるマラソン動画) 局所的な群衆状況のマッチング : 1でマッチした動画においてオプティカルフローが類似するパッチを探索して転移学習 また、Rare Events(デモの最中に群集を横断するカメラマンなど、群衆の流れに対して同調しない動きを行う人物)に対しても実験を行い評価。
Comments 転移学習は自分のイメージだと、自然言語処理のイメージ(一般的な文書を学習したモデルを法律文書に対して適用するなど)しかなかったので新鮮な気持ちで読めた。
動画なら転移学習を行ったとしても、直感的に良い特徴を学べそうなので、良い仮説を立てている論文でした。
最後に示されてる個人追跡における平均誤検出の単位がpixelだが、Ground-Truth と提案手法の追跡軌跡の重複度具合を見てると誤検出が更に高そうに見えるけどどうなんでしょうか？
(テストデータのみ学習が 58.82、転移学習を行った提案手法だと 46.88になっていてもっと相対的な差が出てくるはず?)"><meta name=keywords content="computervision,paper,"><meta property="og:title" content="Data-driven Crowd Analysis in Videos (ICCV2011)を読んだ"><meta property="og:description" content="Data-driven Crowd Analysis in Videos (ICCV2011)を読んだ
Mikel Rodriguez, Josef Sivic, Ivan Laptev, Jean-Yves Audibert, “Data-driven Crowd Analysis in Videos”, in ICCV2011.
Project Page
を読んだので、メモです。
Summary
tl;dr 高密度な群集内の個人を追跡を転移学習によって精度を向上させる手法 Contribution 追跡の精度を転移学習によって向上させた 転移学習を行うためのデータセットとそのフレームワークを考案 論文内では、転移学習の例としてマラソンAの群集を対象に追跡する際に、以下の流れで転移学習を行う。
大域的な群衆状況のマッチング : 同じようなシーンを探索(この場合 DB 内にあるマラソン動画) 局所的な群衆状況のマッチング : 1でマッチした動画においてオプティカルフローが類似するパッチを探索して転移学習 また、Rare Events(デモの最中に群集を横断するカメラマンなど、群衆の流れに対して同調しない動きを行う人物)に対しても実験を行い評価。
Comments 転移学習は自分のイメージだと、自然言語処理のイメージ(一般的な文書を学習したモデルを法律文書に対して適用するなど)しかなかったので新鮮な気持ちで読めた。
動画なら転移学習を行ったとしても、直感的に良い特徴を学べそうなので、良い仮説を立てている論文でした。
最後に示されてる個人追跡における平均誤検出の単位がpixelだが、Ground-Truth と提案手法の追跡軌跡の重複度具合を見てると誤検出が更に高そうに見えるけどどうなんでしょうか？
(テストデータのみ学習が 58.82、転移学習を行った提案手法だと 46.88になっていてもっと相対的な差が出てくるはず?)"><meta property="og:type" content="article"><meta property="og:url" content="https://shunyaueta.com/posts/2018-01-17/"><meta property="og:image" content="https://shunyaueta.com/ogp.jpg"><meta property="article:section" content="posts"><meta property="article:published_time" content="2018-01-17T05:55:41+00:00"><meta property="article:modified_time" content="2019-06-16T18:17:47+09:00"><meta property="og:site_name" content="Shunya Ueta"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://shunyaueta.com/ogp.jpg"><meta name=twitter:title content="Data-driven Crowd Analysis in Videos (ICCV2011)を読んだ"><meta name=twitter:description content="Data-driven Crowd Analysis in Videos (ICCV2011)を読んだ
Mikel Rodriguez, Josef Sivic, Ivan Laptev, Jean-Yves Audibert, “Data-driven Crowd Analysis in Videos”, in ICCV2011.
Project Page
を読んだので、メモです。
Summary
tl;dr 高密度な群集内の個人を追跡を転移学習によって精度を向上させる手法 Contribution 追跡の精度を転移学習によって向上させた 転移学習を行うためのデータセットとそのフレームワークを考案 論文内では、転移学習の例としてマラソンAの群集を対象に追跡する際に、以下の流れで転移学習を行う。
大域的な群衆状況のマッチング : 同じようなシーンを探索(この場合 DB 内にあるマラソン動画) 局所的な群衆状況のマッチング : 1でマッチした動画においてオプティカルフローが類似するパッチを探索して転移学習 また、Rare Events(デモの最中に群集を横断するカメラマンなど、群衆の流れに対して同調しない動きを行う人物)に対しても実験を行い評価。
Comments 転移学習は自分のイメージだと、自然言語処理のイメージ(一般的な文書を学習したモデルを法律文書に対して適用するなど)しかなかったので新鮮な気持ちで読めた。
動画なら転移学習を行ったとしても、直感的に良い特徴を学べそうなので、良い仮説を立てている論文でした。
最後に示されてる個人追跡における平均誤検出の単位がpixelだが、Ground-Truth と提案手法の追跡軌跡の重複度具合を見てると誤検出が更に高そうに見えるけどどうなんでしょうか？
(テストデータのみ学習が 58.82、転移学習を行った提案手法だと 46.88になっていてもっと相対的な差が出てくるはず?)"><meta itemprop=name content="Data-driven Crowd Analysis in Videos (ICCV2011)を読んだ"><meta itemprop=description content="Data-driven Crowd Analysis in Videos (ICCV2011)を読んだ
Mikel Rodriguez, Josef Sivic, Ivan Laptev, Jean-Yves Audibert, “Data-driven Crowd Analysis in Videos”, in ICCV2011.
Project Page
を読んだので、メモです。
Summary
tl;dr 高密度な群集内の個人を追跡を転移学習によって精度を向上させる手法 Contribution 追跡の精度を転移学習によって向上させた 転移学習を行うためのデータセットとそのフレームワークを考案 論文内では、転移学習の例としてマラソンAの群集を対象に追跡する際に、以下の流れで転移学習を行う。
大域的な群衆状況のマッチング : 同じようなシーンを探索(この場合 DB 内にあるマラソン動画) 局所的な群衆状況のマッチング : 1でマッチした動画においてオプティカルフローが類似するパッチを探索して転移学習 また、Rare Events(デモの最中に群集を横断するカメラマンなど、群衆の流れに対して同調しない動きを行う人物)に対しても実験を行い評価。
Comments 転移学習は自分のイメージだと、自然言語処理のイメージ(一般的な文書を学習したモデルを法律文書に対して適用するなど)しかなかったので新鮮な気持ちで読めた。
動画なら転移学習を行ったとしても、直感的に良い特徴を学べそうなので、良い仮説を立てている論文でした。
最後に示されてる個人追跡における平均誤検出の単位がpixelだが、Ground-Truth と提案手法の追跡軌跡の重複度具合を見てると誤検出が更に高そうに見えるけどどうなんでしょうか？
(テストデータのみ学習が 58.82、転移学習を行った提案手法だと 46.88になっていてもっと相対的な差が出てくるはず?)"><meta itemprop=datePublished content="2018-01-17T05:55:41+00:00"><meta itemprop=dateModified content="2019-06-16T18:17:47+09:00"><meta itemprop=wordCount content="49"><meta itemprop=image content="https://shunyaueta.com/ogp.jpg"><meta itemprop=keywords content="computervision,paper,"><meta name=referrer content="no-referrer-when-downgrade"><style>body{font-family:Verdana,sans-serif;margin:auto;padding:20px;max-width:720px;text-align:left;background-color:#fff;word-wrap:break-word;overflow-wrap:break-word;line-height:1.5;color:#444}h1,h2,h3,h4,h5,h6,strong,b{color:#222}a{color:#3273dc}.title{text-decoration:none;border:0}.title span{font-weight:400}nav a{margin-right:10px}textarea{width:100%;font-size:16px}input{font-size:16px}content{line-height:1.6}table{width:100%}img{max-width:100%}code{padding:2px 5px;background-color:#f2f2f2}pre code{color:#222;display:block;padding:20px;white-space:pre-wrap;font-size:14px;overflow-x:auto}div.highlight pre{background-color:initial;color:initial}div.highlight code{background-color:unset;color:unset}blockquote{border-left:1px solid #999;color:#222;padding-left:20px;font-style:italic}footer{padding:25px;text-align:center}.helptext{color:#777;font-size:small}.errorlist{color:#eba613;font-size:small}ul.blog-posts{list-style-type:none;padding:unset}ul.blog-posts li{display:flex}ul.blog-posts li span{flex:0 0 130px}ul.blog-posts li a:visited{color:#8b6fcb}@media(prefers-color-scheme:dark){body{background-color:#333;color:#ddd}h1,h2,h3,h4,h5,h6,strong,b{color:#eee}a{color:#8cc2dd}code{background-color:#777}pre code{color:#ddd}blockquote{color:#ccc}textarea,input{background-color:#252525;color:#ddd}.helptext{color:#aaa}}</style><script async src="https://www.googletagmanager.com/gtag/js?id=G-JMJRQJT0Q3"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-JMJRQJT0Q3")</script></head><body><header><a href=/ class=title><h2>hurutoriya</h2></a><nav><a href=/about/>著者について</a>
<a href=/posts>Blog</a>
<a href=/index.xml>RSS</a></nav></header><main><content><p>Data-driven Crowd Analysis in Videos (ICCV2011)を読んだ</p><p>Mikel Rodriguez, Josef Sivic, Ivan Laptev, Jean-Yves Audibert, “Data-driven Crowd Analysis in Videos”, in ICCV2011.<br><a href=http://www.di.ens.fr/willow/research/datadriven/>Project Page</a></p><p>を読んだので、メモです。</p><p><img src=/posts/2018-01-17/images/1.png alt=image></p><p>Summary</p><h2 id=tldr>tl;dr</h2><ul><li>高密度な群集内の個人を追跡を転移学習によって精度を向上させる手法</li></ul><h2 id=contribution>Contribution</h2><ul><li>追跡の精度を転移学習によって向上させた</li><li>転移学習を行うためのデータセットとそのフレームワークを考案</li></ul><p>論文内では、転移学習の例として<code>マラソンA</code>の群集を対象に追跡する際に、以下の流れで転移学習を行う。</p><ol><li>大域的な群衆状況のマッチング : 同じようなシーンを探索(この場合 DB 内にあるマラソン動画)</li><li>局所的な群衆状況のマッチング : <code>1</code>でマッチした動画においてオプティカルフローが類似するパッチを探索して転移学習</li></ol><p>また、Rare Events(デモの最中に群集を横断するカメラマンなど、群衆の流れに対して同調しない動きを行う人物)に対しても実験を行い評価。</p><h2 id=comments>Comments</h2><p>転移学習は自分のイメージだと、自然言語処理のイメージ(一般的な文書を学習したモデルを法律文書に対して適用するなど)しかなかったので新鮮な気持ちで読めた。<br>動画なら転移学習を行ったとしても、直感的に良い特徴を学べそうなので、良い仮説を立てている論文でした。</p><p>最後に示されてる個人追跡における平均誤検出の単位が<code>pixel</code>だが、Ground-Truth と提案手法の追跡軌跡の重複度具合を見てると誤検出が更に高そうに見えるけどどうなんでしょうか？<br>(テストデータのみ学習が <code>58.82</code>、転移学習を行った提案手法だと <code>46.88</code>になっていてもっと相対的な差が出てくるはず?)</p><h2>関連しているかもしれない記事</h2><ul><li><a href=/posts/2018-01-16/>Slicing Convolutional Neural Network for Crowd Video Understanding (CVPR2016)を読んだ</a></li><li><a href=/posts/2018-01-14/>Analyzing Free-standing Conversational Groups: A Multimodal Approach (ACMMM15) を読んだ</a></li><li><a href=/posts/2018-01-12/>Call center stress recognition with person-specific models を読んだ</a></li><li><a href=/posts/2018-01-11/>FUSE: Full Spectral Clustering(KDD2016) を読んだ</a></li><li><a href=/posts/2017-12-23/>“Learning Deep Representations for Graph Clustering (AAAI2014)” を読んだ</a></li></ul><h2>Support</h2>記事をお読みくださりありがとうございます。このウェブサイトの運営を支援していただける方を募集しています。
もしよろしければ、<a href=https://www.buymeacoffee.com/hurutoriya>Buy Me a Coffee</a> からサポート(投げ銭)していただけると、ブログ執筆、情報発信のモチベーションに繋がります✨<p>--</p>記事を楽しめましたか？
月に1-2本程度書いています。
<a href=/index.xml>RSS</a>フィードで更新通知を受け取ることができます。</content><p><a href=https://shunyaueta.com/tags/computervision/>#computervision</a>
<a href=https://shunyaueta.com/tags/paper/>#paper</a></p><script src=https://giscus.app/client.js data-repo=hurutoriya/hurutoriya.github.io data-repo-id="MDEwOlJlcG9zaXRvcnk2MDgyNTY1Nw==" data-category=Comments data-category-id=DIC_kwDOA6AgOc4CAQTX data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=0 data-theme=dark data-lang=ja crossorigin=anonymous async></script></main><footer>Made with <a href=https://github.com/janraasch/hugo-bearblog/>Hugo ʕ•ᴥ•ʔ Bear</a></footer></body></html>