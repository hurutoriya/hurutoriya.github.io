<!doctype html><html lang=ja><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=theme-color content="dark"><title>Data-driven Crowd Analysis in Videos (ICCV2011)ã‚’èª­ã‚“ã  | Shunya Ueta</title><link rel=stylesheet href=/sass/main.min.1a3290acca8b3fc92df85ea9200859476d6c80d59009c89a749300f3ce7a7a67.css><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','UA-39994406-11','auto');ga('send','pageview');}</script><meta property="og:title" content="Data-driven Crowd Analysis in Videos (ICCV2011)ã‚’èª­ã‚“ã "><meta property="og:description" content="Data-driven Crowd Analysis in Videos (ICCV2011)ã‚’èª­ã‚“ã 
Mikel Rodriguez, Josef Sivic, Ivan Laptev, Jean-Yves Audibert, â€œData-driven Crowd Analysis in Videosâ€, in ICCV2011.
Project Page
ã‚’èª­ã‚“ã ã®ã§ã€ãƒ¡ãƒ¢ã§ã™ã€‚
Summary
tl;dr  é«˜å¯†åº¦ãªç¾¤é›†å†…ã®å€‹äººã‚’è¿½è·¡ã‚’è»¢ç§»å­¦ç¿’ã«ã‚ˆã£ã¦ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•  Contribution  è¿½è·¡ã®ç²¾åº¦ã‚’è»¢ç§»å­¦ç¿’ã«ã‚ˆã£ã¦å‘ä¸Šã•ã›ãŸ è»¢ç§»å­¦ç¿’ã‚’è¡Œã†ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’è€ƒæ¡ˆ  è«–æ–‡å†…ã§ã¯ã€è»¢ç§»å­¦ç¿’ã®ä¾‹ã¨ã—ã¦ãƒãƒ©ã‚½ãƒ³Aã®ç¾¤é›†ã‚’å¯¾è±¡ã«è¿½è·¡ã™ã‚‹éš›ã«ã€ä»¥ä¸‹ã®æµã‚Œã§è»¢ç§»å­¦ç¿’ã‚’è¡Œã†ã€‚
 å¤§åŸŸçš„ãªç¾¤è¡†çŠ¶æ³ã®ãƒãƒƒãƒãƒ³ã‚° : åŒã˜ã‚ˆã†ãªã‚·ãƒ¼ãƒ³ã‚’æ¢ç´¢(ã“ã®å ´åˆ DB å†…ã«ã‚ã‚‹ãƒãƒ©ã‚½ãƒ³å‹•ç”») å±€æ‰€çš„ãªç¾¤è¡†çŠ¶æ³ã®ãƒãƒƒãƒãƒ³ã‚° : 1ã§ãƒãƒƒãƒã—ãŸå‹•ç”»ã«ãŠã„ã¦ã‚ªãƒ—ãƒ†ã‚£ã‚«ãƒ«ãƒ•ãƒ­ãƒ¼ãŒé¡ä¼¼ã™ã‚‹ãƒ‘ãƒƒãƒã‚’æ¢ç´¢ã—ã¦è»¢ç§»å­¦ç¿’  ã¾ãŸã€Rare Events(ãƒ‡ãƒ¢ã®æœ€ä¸­ã«ç¾¤é›†ã‚’æ¨ªæ–­ã™ã‚‹ã‚«ãƒ¡ãƒ©ãƒãƒ³ãªã©ã€ç¾¤è¡†ã®æµã‚Œã«å¯¾ã—ã¦åŒèª¿ã—ãªã„å‹•ãã‚’è¡Œã†äººç‰©)ã«å¯¾ã—ã¦ã‚‚å®Ÿé¨“ã‚’è¡Œã„è©•ä¾¡ã€‚
Comments è»¢ç§»å­¦ç¿’ã¯è‡ªåˆ†ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã ã¨ã€è‡ªç„¶è¨€èªå‡¦ç†ã®ã‚¤ãƒ¡ãƒ¼ã‚¸(ä¸€èˆ¬çš„ãªæ–‡æ›¸ã‚’å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’æ³•å¾‹æ–‡æ›¸ã«å¯¾ã—ã¦é©ç”¨ã™ã‚‹ãªã©)ã—ã‹ãªã‹ã£ãŸã®ã§æ–°é®®ãªæ°—æŒã¡ã§èª­ã‚ãŸã€‚
å‹•ç”»ãªã‚‰è»¢ç§»å­¦ç¿’ã‚’è¡Œã£ãŸã¨ã—ã¦ã‚‚ã€ç›´æ„Ÿçš„ã«è‰¯ã„ç‰¹å¾´ã‚’å­¦ã¹ãã†ãªã®ã§ã€è‰¯ã„ä»®èª¬ã‚’ç«‹ã¦ã¦ã„ã‚‹è«–æ–‡ã§ã—ãŸã€‚
æœ€å¾Œã«ç¤ºã•ã‚Œã¦ã‚‹å€‹äººè¿½è·¡ã«ãŠã‘ã‚‹å¹³å‡èª¤æ¤œå‡ºã®å˜ä½ãŒpixelã ãŒã€Ground-Truth ã¨ææ¡ˆæ‰‹æ³•ã®è¿½è·¡è»Œè·¡ã®é‡è¤‡åº¦å…·åˆã‚’è¦‹ã¦ã‚‹ã¨èª¤æ¤œå‡ºãŒæ›´ã«é«˜ãã†ã«è¦‹ãˆã‚‹ã‘ã©ã©ã†ãªã‚“ã§ã—ã‚‡ã†ã‹ï¼Ÿ
(ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã¿å­¦ç¿’ãŒ 58.82ã€è»¢ç§»å­¦ç¿’ã‚’è¡Œã£ãŸææ¡ˆæ‰‹æ³•ã ã¨ 46.88[pixel]ã«ãªã£ã¦ã„ã¦ã‚‚ã£ã¨ç›¸å¯¾çš„ãªå·®ãŒå‡ºã¦ãã‚‹ã¯ãš?)"><meta property="og:type" content="article"><meta property="og:url" content="https://shunyaueta.com/posts/2018-01-17/"><meta property="og:image" content="https://shunyaueta.com/ogp.jpg"><meta property="article:published_time" content="2018-01-17T05:55:41+00:00"><meta property="article:modified_time" content="2021-10-06T21:14:44+09:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://shunyaueta.com/ogp.jpg"><meta name=twitter:title content="Data-driven Crowd Analysis in Videos (ICCV2011)ã‚’èª­ã‚“ã "><meta name=twitter:description content="Data-driven Crowd Analysis in Videos (ICCV2011)ã‚’èª­ã‚“ã 
Mikel Rodriguez, Josef Sivic, Ivan Laptev, Jean-Yves Audibert, â€œData-driven Crowd Analysis in Videosâ€, in ICCV2011.
Project Page
ã‚’èª­ã‚“ã ã®ã§ã€ãƒ¡ãƒ¢ã§ã™ã€‚
Summary
tl;dr  é«˜å¯†åº¦ãªç¾¤é›†å†…ã®å€‹äººã‚’è¿½è·¡ã‚’è»¢ç§»å­¦ç¿’ã«ã‚ˆã£ã¦ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•  Contribution  è¿½è·¡ã®ç²¾åº¦ã‚’è»¢ç§»å­¦ç¿’ã«ã‚ˆã£ã¦å‘ä¸Šã•ã›ãŸ è»¢ç§»å­¦ç¿’ã‚’è¡Œã†ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’è€ƒæ¡ˆ  è«–æ–‡å†…ã§ã¯ã€è»¢ç§»å­¦ç¿’ã®ä¾‹ã¨ã—ã¦ãƒãƒ©ã‚½ãƒ³Aã®ç¾¤é›†ã‚’å¯¾è±¡ã«è¿½è·¡ã™ã‚‹éš›ã«ã€ä»¥ä¸‹ã®æµã‚Œã§è»¢ç§»å­¦ç¿’ã‚’è¡Œã†ã€‚
 å¤§åŸŸçš„ãªç¾¤è¡†çŠ¶æ³ã®ãƒãƒƒãƒãƒ³ã‚° : åŒã˜ã‚ˆã†ãªã‚·ãƒ¼ãƒ³ã‚’æ¢ç´¢(ã“ã®å ´åˆ DB å†…ã«ã‚ã‚‹ãƒãƒ©ã‚½ãƒ³å‹•ç”») å±€æ‰€çš„ãªç¾¤è¡†çŠ¶æ³ã®ãƒãƒƒãƒãƒ³ã‚° : 1ã§ãƒãƒƒãƒã—ãŸå‹•ç”»ã«ãŠã„ã¦ã‚ªãƒ—ãƒ†ã‚£ã‚«ãƒ«ãƒ•ãƒ­ãƒ¼ãŒé¡ä¼¼ã™ã‚‹ãƒ‘ãƒƒãƒã‚’æ¢ç´¢ã—ã¦è»¢ç§»å­¦ç¿’  ã¾ãŸã€Rare Events(ãƒ‡ãƒ¢ã®æœ€ä¸­ã«ç¾¤é›†ã‚’æ¨ªæ–­ã™ã‚‹ã‚«ãƒ¡ãƒ©ãƒãƒ³ãªã©ã€ç¾¤è¡†ã®æµã‚Œã«å¯¾ã—ã¦åŒèª¿ã—ãªã„å‹•ãã‚’è¡Œã†äººç‰©)ã«å¯¾ã—ã¦ã‚‚å®Ÿé¨“ã‚’è¡Œã„è©•ä¾¡ã€‚
Comments è»¢ç§»å­¦ç¿’ã¯è‡ªåˆ†ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã ã¨ã€è‡ªç„¶è¨€èªå‡¦ç†ã®ã‚¤ãƒ¡ãƒ¼ã‚¸(ä¸€èˆ¬çš„ãªæ–‡æ›¸ã‚’å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’æ³•å¾‹æ–‡æ›¸ã«å¯¾ã—ã¦é©ç”¨ã™ã‚‹ãªã©)ã—ã‹ãªã‹ã£ãŸã®ã§æ–°é®®ãªæ°—æŒã¡ã§èª­ã‚ãŸã€‚
å‹•ç”»ãªã‚‰è»¢ç§»å­¦ç¿’ã‚’è¡Œã£ãŸã¨ã—ã¦ã‚‚ã€ç›´æ„Ÿçš„ã«è‰¯ã„ç‰¹å¾´ã‚’å­¦ã¹ãã†ãªã®ã§ã€è‰¯ã„ä»®èª¬ã‚’ç«‹ã¦ã¦ã„ã‚‹è«–æ–‡ã§ã—ãŸã€‚
æœ€å¾Œã«ç¤ºã•ã‚Œã¦ã‚‹å€‹äººè¿½è·¡ã«ãŠã‘ã‚‹å¹³å‡èª¤æ¤œå‡ºã®å˜ä½ãŒpixelã ãŒã€Ground-Truth ã¨ææ¡ˆæ‰‹æ³•ã®è¿½è·¡è»Œè·¡ã®é‡è¤‡åº¦å…·åˆã‚’è¦‹ã¦ã‚‹ã¨èª¤æ¤œå‡ºãŒæ›´ã«é«˜ãã†ã«è¦‹ãˆã‚‹ã‘ã©ã©ã†ãªã‚“ã§ã—ã‚‡ã†ã‹ï¼Ÿ
(ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã¿å­¦ç¿’ãŒ 58.82ã€è»¢ç§»å­¦ç¿’ã‚’è¡Œã£ãŸææ¡ˆæ‰‹æ³•ã ã¨ 46.88[pixel]ã«ãªã£ã¦ã„ã¦ã‚‚ã£ã¨ç›¸å¯¾çš„ãªå·®ãŒå‡ºã¦ãã‚‹ã¯ãš?)"></head><body class=dark><nav class=navbar><div class=container><div class=flex><div><a class=brand href=/><span class=emoji>ğŸ¦…</span>
Shunya Ueta</a></div><div class=flex><a href=/articles/>All posts</a>
<button id=dark-mode-button></button></div></div></div></nav><main><div class=container><article><header class=article-header><div class=thumb><div><h1>Data-driven Crowd Analysis in Videos (ICCV2011)ã‚’èª­ã‚“ã </h1><div class=post-meta><div>By on <time>2018.01.17</time> (Last updated:<time>2021.10.06</time>)</div><div class=tags><a href=/tags/paper/>paper</a>
<a href=/tags/computervision/>computervision</a></div></div></div></div></header></article><div class=article-post><p>Data-driven Crowd Analysis in Videos (ICCV2011)ã‚’èª­ã‚“ã </p><p>Mikel Rodriguez, Josef Sivic, Ivan Laptev, Jean-Yves Audibert, â€œData-driven Crowd Analysis in Videosâ€, in ICCV2011.<br><a href=http://www.di.ens.fr/willow/research/datadriven/>Project Page</a></p><p>ã‚’èª­ã‚“ã ã®ã§ã€ãƒ¡ãƒ¢ã§ã™ã€‚</p><p><img src=/posts/2018-01-17/images/1.png alt=image></p><p>Summary</p><h3 id=tldr>tl;dr</h3><ul><li>é«˜å¯†åº¦ãªç¾¤é›†å†…ã®å€‹äººã‚’è¿½è·¡ã‚’è»¢ç§»å­¦ç¿’ã«ã‚ˆã£ã¦ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•</li></ul><h3 id=contribution>Contribution</h3><ul><li>è¿½è·¡ã®ç²¾åº¦ã‚’è»¢ç§»å­¦ç¿’ã«ã‚ˆã£ã¦å‘ä¸Šã•ã›ãŸ</li><li>è»¢ç§»å­¦ç¿’ã‚’è¡Œã†ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’è€ƒæ¡ˆ</li></ul><p>è«–æ–‡å†…ã§ã¯ã€è»¢ç§»å­¦ç¿’ã®ä¾‹ã¨ã—ã¦<code>ãƒãƒ©ã‚½ãƒ³A</code>ã®ç¾¤é›†ã‚’å¯¾è±¡ã«è¿½è·¡ã™ã‚‹éš›ã«ã€ä»¥ä¸‹ã®æµã‚Œã§è»¢ç§»å­¦ç¿’ã‚’è¡Œã†ã€‚</p><ol><li>å¤§åŸŸçš„ãªç¾¤è¡†çŠ¶æ³ã®ãƒãƒƒãƒãƒ³ã‚° : åŒã˜ã‚ˆã†ãªã‚·ãƒ¼ãƒ³ã‚’æ¢ç´¢(ã“ã®å ´åˆ DB å†…ã«ã‚ã‚‹ãƒãƒ©ã‚½ãƒ³å‹•ç”»)</li><li>å±€æ‰€çš„ãªç¾¤è¡†çŠ¶æ³ã®ãƒãƒƒãƒãƒ³ã‚° : <code>1</code>ã§ãƒãƒƒãƒã—ãŸå‹•ç”»ã«ãŠã„ã¦ã‚ªãƒ—ãƒ†ã‚£ã‚«ãƒ«ãƒ•ãƒ­ãƒ¼ãŒé¡ä¼¼ã™ã‚‹ãƒ‘ãƒƒãƒã‚’æ¢ç´¢ã—ã¦è»¢ç§»å­¦ç¿’</li></ol><p>ã¾ãŸã€Rare Events(ãƒ‡ãƒ¢ã®æœ€ä¸­ã«ç¾¤é›†ã‚’æ¨ªæ–­ã™ã‚‹ã‚«ãƒ¡ãƒ©ãƒãƒ³ãªã©ã€ç¾¤è¡†ã®æµã‚Œã«å¯¾ã—ã¦åŒèª¿ã—ãªã„å‹•ãã‚’è¡Œã†äººç‰©)ã«å¯¾ã—ã¦ã‚‚å®Ÿé¨“ã‚’è¡Œã„è©•ä¾¡ã€‚</p><h3 id=comments>Comments</h3><p>è»¢ç§»å­¦ç¿’ã¯è‡ªåˆ†ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã ã¨ã€è‡ªç„¶è¨€èªå‡¦ç†ã®ã‚¤ãƒ¡ãƒ¼ã‚¸(ä¸€èˆ¬çš„ãªæ–‡æ›¸ã‚’å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’æ³•å¾‹æ–‡æ›¸ã«å¯¾ã—ã¦é©ç”¨ã™ã‚‹ãªã©)ã—ã‹ãªã‹ã£ãŸã®ã§æ–°é®®ãªæ°—æŒã¡ã§èª­ã‚ãŸã€‚<br>å‹•ç”»ãªã‚‰è»¢ç§»å­¦ç¿’ã‚’è¡Œã£ãŸã¨ã—ã¦ã‚‚ã€ç›´æ„Ÿçš„ã«è‰¯ã„ç‰¹å¾´ã‚’å­¦ã¹ãã†ãªã®ã§ã€è‰¯ã„ä»®èª¬ã‚’ç«‹ã¦ã¦ã„ã‚‹è«–æ–‡ã§ã—ãŸã€‚</p><p>æœ€å¾Œã«ç¤ºã•ã‚Œã¦ã‚‹å€‹äººè¿½è·¡ã«ãŠã‘ã‚‹å¹³å‡èª¤æ¤œå‡ºã®å˜ä½ãŒ<code>pixel</code>ã ãŒã€Ground-Truth ã¨ææ¡ˆæ‰‹æ³•ã®è¿½è·¡è»Œè·¡ã®é‡è¤‡åº¦å…·åˆã‚’è¦‹ã¦ã‚‹ã¨èª¤æ¤œå‡ºãŒæ›´ã«é«˜ãã†ã«è¦‹ãˆã‚‹ã‘ã©ã©ã†ãªã‚“ã§ã—ã‚‡ã†ã‹ï¼Ÿ<br>(ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã¿å­¦ç¿’ãŒ 58.82ã€è»¢ç§»å­¦ç¿’ã‚’è¡Œã£ãŸææ¡ˆæ‰‹æ³•ã ã¨ 46.88[pixel]ã«ãªã£ã¦ã„ã¦ã‚‚ã£ã¨ç›¸å¯¾çš„ãªå·®ãŒå‡ºã¦ãã‚‹ã¯ãš?)</p></div><h2>See Also</h2><ul><li><a href=/posts/2018-01-16/>Slicing Convolutional Neural Network for Crowd Video Understanding (CVPR2016)ã‚’èª­ã‚“ã </a></li><li><a href=/posts/2018-01-14/>Analyzing Free-standing Conversational Groups: A Multimodal Approach (ACMMM15) ã‚’èª­ã‚“ã </a></li><li><a href=/posts/2018-01-12/>Call center stress recognition with person-specific models ã‚’èª­ã‚“ã </a></li><li><a href=/posts/2018-01-11/>FUSE: Full Spectral Clustering(KDD2016) ã‚’èª­ã‚“ã </a></li><li><a href=/posts/2017-12-23/>â€œLearning Deep Representations for Graph Clustering (AAAI2014)â€ ã‚’èª­ã‚“ã </a></li></ul></div><div class=container><nav class="flex container suggested"><a rel=prev href=/posts/2018-01-16/ title="Previous post (older)"><span>Previous</span>
Slicing Convolutional Neural Network for Crowd Video Understanding (CVPR2016)ã‚’èª­ã‚“ã </a>
<a rel=next href=/posts/2018-01-18/ title="Next post (newer)"><span>Next</span>
Where To Look: Focus Regions for Visual Question Answering (CVPR2016)ã‚’èª­ã‚“ã </a></nav></div></main></main><footer class="footer flex"><section class=container><nav class=footer-links><a href=/index.xml>RSS</a></nav></section><script async src=/js/features.min.a94f58a30ad2560de728e080d87f75c60cf806fd1b3d5f4815f1a1a02c0d1859.js></script></footer></body></html>