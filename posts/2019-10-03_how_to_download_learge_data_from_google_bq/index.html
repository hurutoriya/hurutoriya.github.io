<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>遅すぎる pandas.read_gbq を使わずに、Google BigQueryから巨大なデータをダウンロードする - Shunya UETA</title><meta name="viewport" content="width=device-width, initial-scale=1">
	<meta property="og:title" content="遅すぎる pandas.read_gbq を使わずに、Google BigQueryから巨大なデータをダウンロードする" />
<meta property="og:description" content="pandas.read_gbq 便利ですよね。 クレデンシャルファイルを認証画面からコピペすればJupyter上でさっと動き、Google Big Queryが実行されてその結果が" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://shunyaueta.com/posts/2019-10-03_how_to_download_learge_data_from_google_bq/" />
<meta property="article:published_time" content="2019-10-03T23:52:54+09:00" />
<meta property="article:modified_time" content="2019-10-03T23:52:54+09:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="遅すぎる pandas.read_gbq を使わずに、Google BigQueryから巨大なデータをダウンロードする"/>
<meta name="twitter:description" content="pandas.read_gbq 便利ですよね。 クレデンシャルファイルを認証画面からコピペすればJupyter上でさっと動き、Google Big Queryが実行されてその結果が"/>
<link href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,300italic,400italic|Raleway:500,100,300" rel="stylesheet">

	<link rel="stylesheet" type="text/css" media="screen" href="/css/normalize.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="/css/main.css" /><script src="/js/feather.min.js"></script><script src="/js/main.js"></script>
</head>

<body>
	<div class="container wrapper post">
		<div class="header">
	<h1 class="site-title">Shunya UETA</h1>
	<div class="site-description"><h2>Software Engineer As Data Scientist</h2><nav class="nav social">
			<ul class="flat"><a href="https://www.linkedin.com/in/hurutoriya/" title="Linkedin"><i data-feather="linkedin"></i></a><a href="https://github.com/hurutoriya" title="Github"><i data-feather="github"></i></a><a href="https://twitter.com/hurutoriya" title="Twitter"><i data-feather="twitter"></i></a><a href="/index.xml" title="RSS"><i data-feather="rss"></i></a></ul>
		</nav>
	</div>

	<nav class="nav">
		<ul class="flat">
			
			<li>
				<a href="/">Home</a>
			</li>
			
			<li>
				<a href="/posts">All posts</a>
			</li>
			
			<li>
				<a href="/about">About</a>
			</li>
			
			<li>
				<a href="/tags">Tags</a>
			</li>
			
		</ul>
	</nav>
</div>


		<div class="post-header">
			<h1 class="title">遅すぎる pandas.read_gbq を使わずに、Google BigQueryから巨大なデータをダウンロードする</h1>
			<div class="meta">Posted at &mdash; Oct 3, 2019</div>
		</div>

		<div class="markdown">
			

<p><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_gbq.html">pandas.read_gbq</a> 便利ですよね。
クレデンシャルファイルを認証画面からコピペすればJupyter上でさっと動き、Google Big Queryが実行されてその結果がそのままデータフレームとして扱えます。
JupyterとGoogle BQを連携させたいときはいつも使っています</p>

<h2 id="問題点">問題点</h2>

<ul>
<li>そこそこ大きなデータを持ってこようとするとめちゃくちゃ遅くてストレスが半端ない</li>
</ul>

<p>解決方法として、Google Big Query で巨大なデータをダウンロードする方法について書く</p>

<p>実はGoogle の公式ドキュメントでも記載されている。</p>

<ul>
<li><a href="https://cloud.google.com/bigquery/docs/pandas-gbq-migration">https://cloud.google.com/bigquery/docs/pandas-gbq-migration</a></li>
<li><a href="https://cloud.google.com/bigquery/docs/bigquery-storage-python-pandas">https://cloud.google.com/bigquery/docs/bigquery-storage-python-pandas</a></li>
</ul>

<p>方法は以下の２つ。</p>

<ol>
<li><code>google-cloud-bigquery</code> をインストールして、マジックコマンドでGoogle BQを実行</li>
<li>BQ実行→BigQuery table として保存→GCSへ保存→ <code>gsutil</code> でマシンへコピー</li>
</ol>

<p>1番目は、Jupyter上でマジックコマンドでGoogle BQが実行できて、速度も <code>pandas.rad_gbq</code> よりも高速です
2番目はそもそも実行結果が巨大な場合で、目安としては<code>1GB以上</code>なら2番目の方法を使えば楽です。</p>

<h3 id="1-google-cloud-bigquery-をインストールして-マジックコマンドでgoogle-bqを実行">1, <code>google-cloud-bigquery</code> をインストールして、マジックコマンドでGoogle BQを実行</h3>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">pip install --upgrade google-cloud-bigquery[bqstorage,pandas]</code></pre></div>
<p>magic commandを実行</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">%load_ext google.cloud.bigquery</code></pre></div>
<p>後はJupyter Notebookのセルで以下のコマンドぞを実行すれば、</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">%%bigquery df --use_bqstorage_api
SELECT
  CONCAT(
    &#39;https://stackoverflow.com/questions/&#39;,
    CAST(id as STRING)) as url,
  view_count
FROM `bigquery-public-data.stackoverflow.posts_questions`
WHERE tags like &#39;%google-bigquery%&#39;
ORDER BY view_count DESC
LIMIT 10</pre></div>
<p><code>df</code> にマジックコマンドで実行したSQLの実行結果が格納されます!
便利ですね!</p>

<h3 id="2-bq実行-bigquery-table-として保存-gcsへ保存-gsutil-でマシンへコピー">2, BQ実行→BigQuery table として保存→GCSへ保存→ <code>gsutil</code> でマシンへコピー</h3>

<ol>
<li>BigQuery でクエリを実行、実行結果を BigQuery Tableへ保存</li>
</ol>

<ul>
<li><p>注)実行結果の容量が巨大なので、保存先は基本的にBig Query Tableへ保存するしか選択肢が無い</p></li>

<li><p><img src="/posts/2019-10-03_how_to_download_learge_data_from_google_bq/export-to-bqtable.png" alt="can't export large file as one file" /></p></li>
</ul>

<ol>
<li>BigQuery table からGCSへテーブルをCSVとして保存</li>
</ol>

<p>Big Query tableからエクスポート時に、ファイルサイズが大きいとエクスポートできないので、分割が必要です。</p>

<ul>
<li><img src="/posts/2019-10-03_how_to_download_learge_data_from_google_bq/cant-export-onefile.png" alt="can't export large file as one file" /></li>
</ul>

<p><a href="https://cloud.google.com/bigquery/docs/exporting-data">https://cloud.google.com/bigquery/docs/exporting-data</a></p>

<p>保存ファイル名を</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">file-*</pre></div>
<p>のようにワイルドカードを指定すると、自動的にひとつのテーブルを複数ファイルに分割して保存してくれる</p>

<ol>
<li><code>gsutil</code> commands で任意のマシンへダウンロードする。</li>
</ol>

<p><code>-m</code> オプションを付け足すと並列ダウンロードが始まるので、複数ファイルダウンロードする場合はおすすめ</p>

<p>ストレスレスなデータ分析ライフを!</p>

		</div><div id="disqus_thread"></div>
<script type="text/javascript">
	(function () {
		
		
		if (window.location.hostname == "localhost")
			return;

		var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
		var disqus_shortname = 'hurutoriya';
		dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
		(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	})();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by
		Disqus.</a></noscript>
<a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>
	<div class="footer wrapper">
	<nav class="nav">
		<div><a href="https://github.com/vividvilla/ezhil">Ezhil theme</a> | Built with <a href="gohugo.io">Hugo</a></div>
	</nav>
</div>

</body>
</html>
