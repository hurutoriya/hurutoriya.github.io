<!doctype html><html lang=ja dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | hurutoriya</title><meta name=keywords content><meta name=description content="Posts - hurutoriya"><meta name=author content="Shunya Ueta"><link rel=canonical href=https://shunyaueta.com/posts/><link crossorigin=anonymous href=/assets/css/stylesheet.6a98292fb8fa8cf0f3ba4042d4b75515c04267550f3ad49ff6271b5af9562443.css integrity="sha256-apgpL7j6jPDzukBC1LdVFcBCZ1UPOtSf9icbWvlWJEM=" rel="preload stylesheet" as=style><link rel=icon href=https://shunyaueta.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://shunyaueta.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://shunyaueta.com/favicon-32x32.png><link rel=apple-touch-icon href=https://shunyaueta.com/apple-touch-icon.png><link rel=mask-icon href=https://shunyaueta.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://shunyaueta.com/posts/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-JMJRQJT0Q3"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-JMJRQJT0Q3")</script><meta property="og:title" content="Posts"><meta property="og:description" content="Shunya Ueta's blog"><meta property="og:type" content="website"><meta property="og:url" content="https://shunyaueta.com/posts/"><meta property="og:image" content="https://shunyaueta.com/ogp.jpg"><meta property="og:site_name" content="Shunya Ueta"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://shunyaueta.com/ogp.jpg"><meta name=twitter:title content="Posts"><meta name=twitter:description content="Shunya Ueta's blog"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://shunyaueta.com/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://shunyaueta.com/ accesskey=h title="hurutoriya (Alt + H)">hurutoriya</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://shunyaueta.com/archives title=Archive><span>Archive</span></a></li><li><a href=https://shunyaueta.com/about title=About><span>About</span></a></li><li><a href=https://searchengineeringnewsletter.substack.com/ title=Newsletter><span>Newsletter</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://shunyaueta.com/index.xml title=RSS><span>RSS</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>Posts</h1></header><article class=post-entry><header class=entry-header><h2>Analyzing Free-standing Conversational Groups: A Multimodal Approach (ACMMM15) を読んだ</h2></header><div class=entry-content><p>スタンディングディスカッション形式での会話を評価した研究
Summary Slide
X Alameda-Pineda, Y Yan, E Ricci, O Lanz, N Sebe
“Analyzing Free-standing Conversational Groups: A Multimodal Approach”, in 2015 ACM Multimedia Conference
link
を読んだので、軽くメモ。
マルチモーダル系の論文初めて読んだんですが、まとめるとコントリビューションが 5 つあると主張。
Contribution 音声・近接情報、そして監視カメラからの身体と頭の姿勢推定からマルチモーダルに解析 フリースタンディングディスカッションを身体・頭の姿勢推定から解析 カメラと音声・近接センサーからなるマルチモーダルな解析するためのフレームワークを提案 ラベリングされてないデータに対する行列補間問題の考案 SALSA(データ・セット)を公開・評価 SALSA というポスターセッションの動画と音声のデータも公開されている
SALSA: Synergetic sociAL Scene Analysis
動画は Google Drive で公開されていて時代の波を感じる。
データセットを公開 論文も読みやすい 新しい行列補完計画法(アルゴリズム)を提案 実問題に取り組む と盛り沢山な内容で面白かった。
スライド内のリンクは Google Slide で共有しているのでこちらを参照すると便利です。
X Alameda-Pineda, Y Yan, E Ricci, O Lanz, N Sebe "Analyzing Free-standing Conversational Groups: A…</p></div><footer class=entry-footer><span title='2018-01-14 10:41:12.009 +0000 UTC'>1月 14, 2018</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to Analyzing Free-standing Conversational Groups: A Multimodal Approach (ACMMM15) を読んだ" href=https://shunyaueta.com/posts/2018-01-14/></a></article><article class=post-entry><header class=entry-header><h2>PythonでGaussian Kernelのアニメーションを作成</h2></header><div class=entry-content><p>Python でアニメーションを作成したかったのでメモ
Gaussian Kernel GIF Animation
当然ながら、HTML5 の Video は再生されないので GIF に変換した結果が以下。
これで HTML5 で再生される。
**GIF**で表示する方法として %matplotlib nbagg
というオプションが存在しているが、Kernel が busy 状態を何度も繰り返すので、自分は mp4 で出力するようにした。
実験結果も以前は GIF で保存してたが、最近は全てmp4で管理するようにした。
あと、**np.linspace()**が iterable ではないので、イマイチな書き方になった。。
**np.arange()**を使うべきなのか…
References Embedding Matplotlib Animations in Jupyter Notebooks Jupyter 上で matplotlib のアニメーションを再生する - Qiita</p></div><footer class=entry-footer><span title='2018-01-13 17:03:43.429 +0000 UTC'>1月 13, 2018</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to PythonでGaussian Kernelのアニメーションを作成" href=https://shunyaueta.com/posts/2018-01-13/></a></article><article class=post-entry><header class=entry-header><h2>Call center stress recognition with person-specific models を読んだ</h2></header><div class=entry-content><p>Affective Computing: 計算機と人間の感情や情緒の関係性を考える領域
MIT Media Lab Affective Computing Group のプロジェクト。
2 年前に MIT Media Lab へ訪問した際に、色々と見せてもらったけどかなり野心的な事に取り組んでいて感動してた。(デバイスも自分たちでプロトタイプを作りまくっていて、Deploy or Dieの意思を感じ取れる)
論文のまとめスライドは以下
One Slide Summary
HCI 系の論文は初めてまともに読んだんですが、
実験デザインが一番難しそう。人と計算機の関係を研究するので、必然的に人間の感性をどう評価する話にもつながってきてる? 手法に重きを置くというよりも、問題に重きを置いている印象 普段自分は、数値線形代数や機械学習、コンピュータビジョンを主にやっていて、精度をどれだけ出せるか、正解率をどれだけ向上や、速度をどれだけ上げれるかを理論的に保証、提案したりしていますが、面白い問題や興味深いデータを集めることも大事だなと思った。
実験計画法¹もかなり重要で、メンターの人から実験計画法の成り立ちを教えてもらってとてもおもしろかった。</p></div><footer class=entry-footer><span title='2018-01-12 17:19:48.278 +0000 UTC'>1月 12, 2018</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to Call center stress recognition with person-specific models を読んだ" href=https://shunyaueta.com/posts/2018-01-12/></a></article><article class=post-entry><header class=entry-header><h2>FUSE: Full Spectral Clustering(KDD2016) を読んだ</h2></header><div class=entry-content><p>べき乗法と独立成分分析を用いたマルチスケールに頑強なクラスタリング手法の提案
べき乗法では近似固有ベクトル(Pseudo-eigenvectors)は複数の真の固有ベクトルの線形結合からなる。有益でない固有ベクトルも含まれるのでいかにそれを除去するか Fig.1 で言ってることがいまいちわからない。ｃ,ｄも変化がないように見える。論文で言及してる stripe が何を指してるかが不明 分かった。赤・青・黒の３つのクラスタで分かれている。最初は黒色がクラスタ境界面に見えた。論文内での multi scale というのは、データの幾何的な分布を指している？ 固有値計算は O(n³）かかるから計算量が~~って毎回言われるが、行列の状態に依存するので毎回最悪の場合を主張されてるも困る ZP self-turining spectral clustering をなぜ対抗馬にして比較してるのかは謎。 ICA¹を行ったあとにその行列に対して回転処理を行い情報量の最小化を狙う クラスタ数が多い場合、PIC では良い結果が出づらい multi scale なデータの場合標準の spectral clustering では失敗することが多々ある fig.2 (a) 見ればわかるがk-means では分離が困難 fig.2(b) ４－５本目の固有ベクトルを基底ベクトルにもつ空間ではクラスタのオーバーラップが少ない つまり１－５本目の固有ベクトル全て含めてクラスタリングすれば結果が良好になるのではないか？（仮説） fig.2 © ４回べき乗法を行った。結果が似てる。（縦軸が何を表してるかは不明）。四回が上から四本求めたのか、一番上の固有ベクトルを４回求めたのか分からない fig. (d) 提案手法を適用。k-means で分離可能 行列Vをp回べき乗法を行って構築 E=MVの最小化を行う ICA を最小化するために Jacobi Rotation を用いる。探索には貪欲法を採用 Contribution マルチスケール（多種多様な）データ分布に対してクラスタリングが可能 計算時間は従来（ncut)と同等 感想 PIC(Power Itetaion Clusterg)をまさか拡張してくるとは思わなかったなので、興味深い論文。(実装して再現実験したけど、Early stopping の段階で高確率でクラスタリングが失敗していて使い物にならなかった印象があるので…) データの分布が多様な場合、上位数本のベクトルではなく、そこから更に下の固有ベクトルに着目したほうが結果が良好になるのは面白い KDD の論文、相変わらず読みやすかった。</p></div><footer class=entry-footer><span title='2018-01-11 17:30:28.693 +0000 UTC'>1月 11, 2018</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to FUSE: Full Spectral Clustering(KDD2016) を読んだ" href=https://shunyaueta.com/posts/2018-01-11/></a></article><article class=post-entry><header class=entry-header><h2>サイトのPWA化、ホスティングをGithub PagesからFirebaseへ移行</h2></header><div class=entry-content><p>PWA と FireBase を試してみたかった
firebase init で現れる画面、テンション上がる
Github Pages + CloudFlare で独自ドメインの shunyaueta.com をホスティングしてたんですが、Firebase でホスティングできると聞いて Firebase に移行しました。
PWA にしたのは完全に趣味です。
TL;DR; Web App を作ってる人は manifest.json を設置するだけでも Android の使用感が改善されそう 独自ドメインでお手軽に SSL ホスティングしたいなら Firebase hosting めっちゃおすすめです(1GB のホスティングは無料) FireBase Hosting だけだと Firebase 本来の旨味は味わえません PWA 1 年前ですが、簡潔に PWA の事が書かれています
プログレッシブウェブアプリ詳解 ─ 過去・現在・未来
左: PWA 化以前 右: PWA 化以降
ServiceWorker と manifest.json,あとは&lt;meta name=”theme-color”>を指定すると PWA のスコアが 100 点になる 🎉
manihest.json によるホームアイコン作成誘導
Favicon の各画像の生成は下記のサイトが便利でした。要求される解像度毎の画像(Favicon,Home icon, Apple home icon)が生成されて mahifest....</p></div><footer class=entry-footer><span title='2018-01-09 18:59:59.969 +0000 UTC'>1月 9, 2018</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to サイトのPWA化、ホスティングをGithub PagesからFirebaseへ移行" href=https://shunyaueta.com/posts/2018-01-09/></a></article><article class=post-entry><header class=entry-header><h2>HerokuのDBにpgadmin4で接続してローカルにデータをダウンロードする</h2></header><div class=entry-content><p>pyadmin4 で Heroku 上の DB に接続する記事が日本語になかったので、メモ
接続前の準備 Heroku にログインして、対象の App の DB のページへ
Heroku App DB page
そこから DB のセッティングページにある credential ボタンをクリック
click credential button
そこに記載されている各種情報を pgadmin4 に入力して Heroku 上の DB に接続する
Copy information
pgadmin4 で Heroku の DB に接続 以下のページから pgAdmin4 をダウンロード
Download
そこからアプリを開くと下記の画面になるので、Add new Serverをクリック
Click Add New Server
Heroku 上の DB の情報を入力していく。Server の名前は適当で大丈夫です。
接続されるとこんな感じになります。
Query Tool Query Toolを使うことで Heroku 上の DB に対して SQL クエリを投げる事ができます。
Query Toolは上部のツールバーからアクセス可能です。 注意) 左カラムのテーブルをクリックした後でないとアクティブになりません。...</p></div><footer class=entry-footer><span title='2017-12-27 08:12:17.298 +0000 UTC'>12月 27, 2017</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to HerokuのDBにpgadmin4で接続してローカルにデータをダウンロードする" href=https://shunyaueta.com/posts/2017-12-27/></a></article><article class=post-entry><header class=entry-header><h2>“Learning Deep Representations for Graph Clustering (AAAI2014)” を読んだ</h2></header><div class=entry-content><p>自己符号化器と Spectral Clusteing の関連性を示した論文
Paper link Author Fei Tian : http://home.ustc.edu.cn/~tianfei/ 中国科学技術大学 Ph.D １年生 MSRA と共同研究、2014 年に AAAI2 本,COLING1 本を 1st で通してる。 この資料も面白い。ILSVRC2015 で 152 層の Deep Residual Learning を提案し優勝(Error Rate : 3.57%) MSRA @ ILSVRC2015 資料 Motivation (研究背景・動機) Deep Learning が数多くの応用でめざましい成果をあげている。 音声認識 画像認識 自然言語処理 DL において Clustering に関する適切な調査が行われてない。 論文の目的として、DL における Clustering の調査を行う 概要 Graph Clustering はクラスタリングでも重要な手法の一つ Graph Clustering の応用 Image segmentation Community Detection VLSI Design 嬉しい点 : ベクトル空間におけるクラスタリングの問題 → データの類似度グラフ問題への変換が可能 自己符号化器と Spectral Clustering の類似性 Spectral Clustering : グラフラプラシアンに対して EVD を行い k 本の非零固有ベクトルを用いた空間に対して k-means を行ったもの。 自己符号化器 : 入力データを低次元化、情報が最大限になるようにデータの次元を再構築する 計算量 : 対象とするグラフは n 個のノードを持つ EVD : ナイーブに実装すると O(n3)の計算量、最速の実装は O(n2)の計算量 自己符号化器 : ノードがスパースな際は計算量は O(kn) スパース表現 : データが大きくなるならスパース性を有効活用したい EVD : 固有ベクトルが高い確率で密になるため、スパース性が保証されない 自己符号化器 : スパース性を用いるのは容易 既存研究で未検証な事柄、何を解決・解明したいのか？ Graph Clustering のための Deep Learning の活用方法と調査 自己符号化器と Spectral Clustering の類似性とその比較・検証 Method (提案手法) GraphEncoder(for graph clustering....</p></div><footer class=entry-footer><span title='2017-12-23 17:38:19.179 +0000 UTC'>12月 23, 2017</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to “Learning Deep Representations for Graph Clustering (AAAI2014)” を読んだ" href=https://shunyaueta.com/posts/2017-12-23/></a></article><article class=post-entry><header class=entry-header><h2>JupyterNotebookをリモートサーバー上で公開して、どこでも研究開発 & 講義でJupyterhubを利用する</h2></header><div class=entry-content><p>JupyterNotebook をリモートサーバー上で公開して、どこでも研究開発。
講義で Jupyterhub を利用するお話です。
GIF 画像は下記の記事で知ったtqdmというパッケージを使いたくなったので載せてみた。
私が選ぶ 2015 年の”新しい”Python モジュール トップ 5 IPython データサイエンスクックブック ―対話型コンピューティングと可視化のためのレシピ集 IPython データサイエンスクックブックをキッカケに研究室でも JupyterNotebook の凄さを皆が知り、MATLAB の kernel を通して利用を始めたりしています。自分は Python2→MATLAB→MATLAB & Python3 という流れで移り変わっています。
JupyterNotebook をリモートサーバー上で公開 コードは以下の通りです。特に問題なく公開することができました。
環境 CentOS 7 系 下記の記事を参考にセットアップする。
pyenv と virtualenv で環境構築 今回は pyenv を使って Python3.5.1 でホストしています。
昨日この記事を読んで、Anaconda がオススメされているので今度セットアップするときに使ってみよう。
Running a public notebook server | JupyterNotebook Docment こまかい設定等は以下の記事で説明されています。IPython Notebook を対象にした記事ですが、ほとんど一緒なので問題ありません。(config.py 自体がコメントで丁寧に各設定が記述されています。)
IPython notebook サーバーを立ち上げる ipython notebook をリモートサーバ上で動かす。 参考記事 iPython notebook で研究開発生活 Juptyerhub : 講義で Jupyter を利用する。 JupyterNotebook を講義でも活用できるようにならないかなと先生と探していたのですが、Jupyternotebook を公開するだけだとユーザー管理が不可能です。例えば ~tarou/というディレクトリで jupyternotebook を公開すると~tarou/に notebook が沢山できだれがどのノートを作ったのかが把握できないという問題点があります。...</p></div><footer class=entry-footer><span title='2017-12-22 17:48:12.894 +0000 UTC'>12月 22, 2017</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to JupyterNotebookをリモートサーバー上で公開して、どこでも研究開発 & 講義でJupyterhubを利用する" href=https://shunyaueta.com/posts/2017-12-22/></a></article><article class=post-entry><header class=entry-header><h2>CoreMLがTensorFlow Liteをサポート</h2></header><div class=entry-content><p>TensorFlow 無双
TensorFlow Lite meets CoreML!!
個人的にいま興味ある分野のうちの一つがスマホで動く機械学習なんですが、昨日 TensorFlow Lite が CoreML でサポートされるというアナウンスがありました!
Announcing Core ML support in TensorFlow Lite
CoreML の最大の利点は iPhone のアーキテクチャを最大限に利用した推論の高速化なので、Google も何かしらの手を打ってくると思っていましたがまさかそのまま CoreML にサポートされたのは驚きです。
個人的に keras2, Caffe¹だけがサポートされてる今の状態は選択肢が少なくて微妙だなと思っていたので良いことだと思います。
少し横道にそれますが、ONNX と呼ばれる Machine Leaning のモデルを相互変換できるプロジェクトも立ち上がっているので、近いうちにフレームワーク間の差異は消えていき、書きたいフレームワークで書き、動かしたい環境にモデルを変換して運用するという流れになる未来がくるかもしれません。
ONNX: Open Neural Network Exchange Format
Pixel²も iPhone8³以降に搭載されている A11 チップに機械学習の計算を高速化させるチップが採用されているのでこれから Machine Learning on Mobile はドンドン加速していくとおもいます。iOS11 の吉田さんが担当している CoreML の章を見てましたが、利点と欠点が明快に知れるのでオススメです。
iOS 11 Programming - PEAKS
TensorFlow Lite もデフォルトで Android をサポートしているので、こりゃほんとにプロダクション環境だと TensorFlow 一択になりつつありますね
にしても TensorFlow の勢いはほんとに凄い…</p></div><footer class=entry-footer><span title='2017-12-06 13:36:38.235 +0000 UTC'>12月 6, 2017</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to CoreMLがTensorFlow Liteをサポート" href=https://shunyaueta.com/posts/2017-12-06/></a></article><article class=post-entry><header class=entry-header><h2>Visualized Approximate Eigen Vector by Power Iteration on 3 dimensions.</h2></header><div class=entry-content><p>You can intuitively lean Power Iteration by Visualization Power.
Animation of Power Iteration by MATLAB
Power iteration - Wikipedia
Finally you put a command line
1 > convert -layers optimize -loop 0 -delay 40 eigenvector*.png anim.gif</p></div><footer class=entry-footer><span title='2017-12-05 13:20:41.792 +0000 UTC'>12月 5, 2017</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to Visualized Approximate Eigen Vector by Power Iteration on 3 dimensions." href=https://shunyaueta.com/posts/2017-12-05/></a></article><article class=post-entry><header class=entry-header><h2>Edge-Weighted Personalized PageRank: Breaking A Decade-Old Performance Barrier を読んだ</h2></header><div class=entry-content><p>応用数理研究者が機械学習界に進出していく研究
youtube clip
応用数理界隈ではクラシックな解き方で PageRank が解かれているので最新の数値計算手法に置き換えることで劇的にパフォーマンスが向上して 10 年前のパフォーマンスの鎖を解き放った論文
KDD2015 Best student paper award Slide(PDF) Poster(PDF) Spectral network analysis wenleix/EdgePPR
Presentation Movie is uploaded in Youtube. Author
W. Xie Ph.D Candidate at Cornell University http://wenleix.github.io/ iterative computation on big graph data D. Bindel http://www.cs.cornell.edu/~bindel/ http://www.cs.cornell.edu/~bindel/talks.html He is frequently research activ like ideal young researcher. Nonlinear eigenvalue problem. Alan J. Demers Prof. Johannes Gehrke http://www.cs.cornell.edu/johannes/ Prof. VLDB,SIGMOD,KDD Motivation ページランクは重要な指標。遷移確率を求めるにはランダムサーファーモデル(ランダムウォーク)が必要。 様々な高速解法が提案されている。 Reseatch Question しかし 10 年以上前、PageRank の黎明期から Personalization based の手法は問題がある。 一般的な PageRank の解法の説明、その後に Model Reduction をベースにした約 5 倍の性能を誇る提案手法を説明。 提案手法の性能によって、パフォーマンス上のボトムネックは消えた。 Proposed Method PageRank 初期:WEBPage のランクに使用 → 現在:推薦、ソーシャルネットワーク Random Suffer Model Transition : α の確率で Random Walk(滞在ノードから無作為に遷移) Teleporting : 1−α Random Junmp(滞在ノードに依存せずに全てのノードを対象に無作為遷移) x(t+1)=αPxt+(1−α)v,where P=AD−1 v is represents telepotation probabilitie xt Walker の確率分布 サーファーが来る確率 = RandomWalk の確率_RandomWalk による遷移確率 + RandomJump の確率_RandomJump の遷移確率 = α× RandomWalk による遷移確率 + (1−α)×RandomJump の遷移確率 = α×+(1−α)×v x: Stationary vector(不動ベクトル、定常ベクトル、不動点定理など) x が定常状態になった際に、x の確率分布が PageRank を表す。 x(t),x(t+1)が同一(残差が無い)だと仮定することで、次式の線形方程式を解くことで Pagerank を求める。 Mx=b,where M=(I−αP),b=(1−α)v....</p></div><footer class=entry-footer><span title='2017-12-04 13:06:15.767 +0000 UTC'>12月 4, 2017</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to Edge-Weighted Personalized PageRank: Breaking A Decade-Old Performance Barrier を読んだ" href=https://shunyaueta.com/posts/2017-12-04/></a></article><article class=post-entry><header class=entry-header><h2>Machine Learning that Matters (ICML2012) を読んだ</h2></header><div class=entry-content><p>機械学習の研究してる人は全員読んだ方がいい。そう断言できるぐらい良い内容が書かれています。 ICML2012 で発表された最近の機械学習に関する研究の問題点を論じた論文。
Summaly
「あなたは現実世界で役立つデータに対して機械学習の研究を行っていますか?」
著者は NASA の JPL(ジェット推進研究所)、カリフォルニア工科大学に所属する Kiri L.
Kiri L. Wagstaff
発表動画を探してみたんですが、ICML2012 で発表した際のビデオはサーバのクラッシュにより喪失したとのこと。
The video for my controversial ICML 2012 talk is no longer available (lost in a server crash). However, you can read the original paper: Machine Learning that Matters (pdf, 6 pages, 234K) and see the slides from a subsequent invited AAAI talk: Challenges for Machine Learning Impact on the Real World (1.6M). PowerPoint は下記リンク先に配布されています。http://www.wkiri.com/research/papers/wagstaff-MLmatters-slides-AAAI.pptx...</p></div><footer class=entry-footer><span title='2017-12-01 07:55:12.617 +0000 UTC'>12月 1, 2017</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to Machine Learning that Matters (ICML2012) を読んだ" href=https://shunyaueta.com/posts/2017-12-01/></a></article><article class=post-entry><header class=entry-header><h2>Jupyter上でSVGのイラストやアニメーションが作成できるプラグイン egel</h2></header><div class=entry-content><p>アイデアは面白い… けど easy drawing ではない
Jupyter 使ってると作図も Jupyter 上で完結させたいなぁ~って思うときがあるんですが、スクリプトで作図はけっこう辛いものがあります
そのため Jupyter 上でフリースタイルに作図できる機能ないかなと探してたら egal という面白そうな拡張機能があったので使ってみました
uclmr/egal
egal GIF animation
以下のリポジトリから $pip3 install git+https://github.com/uclmr/egal.gi
でクローンしてきて $jupyter nbextension install --py egal $jupyter nbextension enable --py egal
で拡張機能を有効にして使えるようになります。
ブラシアイコンをクリックすると新たなセルが生成される
ボタンをクリックすると各オブジェクトの詳細なプロパティが調整できる
フレーム毎にオブジェクトを設定してアニメーションっぽくもできる
5–6 分使ってみて感じましたが、めちゃくちゃ操作がしづらい…
やはりブラウザ上での図形作成はめちゃくちゃストレスたまるので、ローカルで keynote 使って図形作成したほうがマシな感じです。
遊んだ結果を notebook で github にアップしておきました。
残念ながら SVG が Github 上ではレンダリングされないので残念な感じになっております… ローカルにクローンしてきて egal を有効にしておくと見れます。
hurutoriya/notebook
結論 Jupyter で全てを完結させるのは難しい</p></div><footer class=entry-footer><span title='2017-11-22 12:04:30.104 +0000 UTC'>11月 22, 2017</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to Jupyter上でSVGのイラストやアニメーションが作成できるプラグイン egel" href=https://shunyaueta.com/posts/2017-11-22/></a></article><article class=post-entry><header class=entry-header><h2>OpenCV 3.3から使えるDNNモジュールを使って物体検出</h2></header><div class=entry-content><p>OpenCV と MobileNet を使って物体検出を行った
Object Detection with OpenCV dnn modules and MobileNetSSD on Jupyter Notebook
Introduction 物体検出を Deep Leaning と OpenCV を用いて行う
OpenCV 3.3 からdnnモジュールが正式にリリースされた
The main news is that we promoted DNN module from opencv_contrib to the main repository, improved and accelerated it a lot. An external BLAS implementation is not needed anymore. For GPU there is experimental DNN acceleration using Halide (http://halide-lang.org_). The detailed information about the module can be found in our wiki: Deep Learning in OpenCV....</p></div><footer class=entry-footer><span title='2017-11-14 11:36:43.926 +0000 UTC'>11月 14, 2017</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to OpenCV 3.3から使えるDNNモジュールを使って物体検出" href=https://shunyaueta.com/posts/2017-11-14/></a></article><article class=post-entry><header class=entry-header><h2>Djangoで顔認識の結果をJSONで返す最小構成のAPIサーバーを作った</h2></header><div class=entry-content><p>DEMO GitHub でコードを公開してます。
hurutoriya/face_detector_api
Django の勉強は、基本的なイントロダクションとしてオフィシャルサイトのドキュメントが充実しているのでオススメです。
pyimagesearch の Blog 記事で最小限の構成で顔検出を行う API サーバーを作る記事があり、今回はそれを基本に作成した。
以下所感
Django は Rails と比べるとそんなにレールが敷かれていない 日本語の記事がほぼ存在しないので、英語の記事を読む良い練習になった OpenCV や Scikit-lean がそのまま動くのは相当魅力的で、サーバからのレスポンスが帰ってきた時には地味に感動 API 設計や非同期処理なんかの知識が全く足りない 次の課題 今回の発展形として django-rest-framework を使って、モデルを組み込んで作り上げて Google Apps Engine 上で公開してみよう。 REST Framework はこの記事2を参考に画像をアップロードできる雛形は作り上げた。 後は OpenCV で処理を施す部分を書き上げたらいけそう。
django-rest-framework で使える管理画面
References hurutoriya/face_detector_api Django REST Framework を使って爆速で API を実装する,ChristianKreuzberger/django-rest-imageupload-example Creating a face detection API with Python and OpenCV (in just 5 minutes) Django 1.11 Documentation Django REST framework is a powerful and flexible toolkit for building Web APIs....</p></div><footer class=entry-footer><span title='2017-11-13 17:22:38.891 +0000 UTC'>11月 13, 2017</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to Djangoで顔認識の結果をJSONで返す最小構成のAPIサーバーを作った" href=https://shunyaueta.com/posts/2017-11-13/></a></article><article class=post-entry><header class=entry-header><h2>TexPadのおかげでLatex人生が変わりました</h2></header><div class=entry-content><p>Latex の煩わしい点が全て解決される Mac のソフトウェアです。
自動補完 synctex 対応(コマンド+クリックで PDF、tex ファイル同期) 自動タイプセット Texpad · Smoothest way to write LaTeX 以前は atom+latexmk で Latex を扱ってましたが、texpad の方が断トツに使い心地が最高です。
購入方法 Appstore か、クレジットカードで Appstore を経由せずに買うかの２つの方法があります。
Appstore はだいぶ前に更新を停止しているみたいなので、クレジットカードを持っている人はクレジットカードを使って MacAppstore を経由せずに購入することをオススメします。
$24.99 しましたが、それ以上の価値があるソフトウェアです。
2 週間の無料体験期間があるので是非お試し下さい。
下記のスクリーンショットのように、beamer も texpad で動くのは感動モノ。
beamer on texpad
日本語で TexPad を扱いたいときは下記のスクリプトを読み込んだら、bibtex のバグが治ります。</p></div><footer class=entry-footer><span title='2017-10-08 02:22:24.069 +0000 UTC'>10月 8, 2017</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to TexPadのおかげでLatex人生が変わりました" href=https://shunyaueta.com/posts/2017-10-08/></a></article><article class=post-entry><header class=entry-header><h2>機械学習・コンピュータビジョンを活かしたビジネスを手掛ける株式会社ABEJAでインターンしてきた</h2></header><div class=entry-content><p>株式会社 ABEJA という会社に 2013/8/25~2013/9/26 間に 2 週間弱インターンシップに参加してきました。
2013 年当時のサイトのスクショ
What’S ABEJA? ABEJA について詳しく知りたい方は下記のリンクを見るとわかりやすいです。
マーケティングから決済まで、人認証技術 × ビジネスプロデュースで未来を変える ABEJA の挑戦【連載:NEO ジェネ！】 いまそこにある、リアルタイムデータ解析。ぼくらの暮らしを変える、日本のスタートアップ 3 社 この会社をはじめて知ったのは、ミクシィでのインターンシップに参加してた時に別グループでインターンしていた知り合いの人に教えてもらったのがキッカケです。 機械学習や画像解析を用いて、現実世界の問題を解決して更にビジネスにまで昇華させている点に痺れました。
本来なら一ヶ月近く参加予定だったんですが、もう一つ挑戦していたリクルートのインターンに運良く合格したので結果的には 2 週間弱という短めのインターンになりました。
What do you doing in ABEJA intern? インターンの内容は Python を使って社内用のツールをゴニョゴニョしてました。
郷に従います。(StyleGuide 見てなかった…) / 他 2 コメント http://t.co/5I0nThs4rU “PEP 8 — Style Guide for Python Code” http://t.co/in7q9lD6cy> — UEDA (@hurutoriya) 2014, 9 月 25
普段は matlab か Ruby 書いてるんですが、普段書いてない言語を書くとあまりよろしくないコードになったので StyleGuide 導入しました。
_“vim で python 開発するとき pyflakes + PEP8 = flake8 が便利 _http://t....</p></div><footer class=entry-footer><span title='2014-08-23 17:18:02.763 +0000 UTC'>8月 23, 2014</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to 機械学習・コンピュータビジョンを活かしたビジネスを手掛ける株式会社ABEJAでインターンしてきた" href=https://shunyaueta.com/posts/2014-08-23/></a></article><article class=post-entry><header class=entry-header><h2>ミクシィにインターンしてきた</h2></header><div class=entry-content><p>株式会社ミクシイに 2013/8/9~2013/9/20 までインターンしてきました。 2013 年当時のスクリーンショットを探してたが、無かったので 2017/12/24 のを撮ってきた。良い意味であまり変わってない(ライさんの謎のくるまアプリとか)
Dive into mixi
なぜインターンに行こうと思ったのか 僕は高専から筑波大学の情報系に今年度から編入したんですが、
編入してから同期の編入生や先輩、内部生の人達に会って 「このままじゃダメだ、もっと面白く!もっと楽しく生きる!!」 と感じたので参加しました。
…つまり、面白そうな事をしたかったので参加しました。 選考過程 エントリーリーシートを提出、希望する配属先はここで提出します。 2 回の面接があるのですが、つくばから渋谷への道のりは遠いので一回にしてくれました。ありがとうございます！！
面接の服装は、スーツじゃなくて良いので楽です！(むしろスーツはやめてねと言われました)
自己紹介と自分のこれまでの成果物を面接官に説明した後に、質疑応答を 30 分、時間が 20 分ほど余ったので面接官の方から「気になってることをなんでも聞いて下さい」と言われて質問をしていると面接がいつの間にか終わりました。
合否発表は翌日に連絡がきて無事合格することができました、嬉しい!!
配属先 僕は第一希望のDeployGateに配属されました。
DeployGate チームは社員二人、インターン三人という謎構成でした。
「DepoyGate」とは、ミクシィ社の新規事業第 1 弾として登場した Android アプリ提供者向けのテスト版アプリ配信サービスです。 アプリをワイヤレスで配布することができ、アップデータ配信や動作ログがリアルタイムに取得できるので、プロジェクトメンバー全員が常に最新版アプリに触れることができます。 2012 年 9 月のサービス開始から、世界 93 ヵ国 3600 以上のアプリ開発に利用され、そのユーザーの 76％は英語圏というグローバルなサービスでもあります。 「DepoyGate」エンジニアからの発案で生まれたサービスです。 最新の技術に触れ、一緒に開発を進めていきたいという、あなたのチャレンジをお待ちしております。### メリット
今回のミクシィインターンは 6 週間を超える長期のインターンで実際に提供されているサービスの開発に参加すること t ができます。
デメリット 基本的に無いです。
強いて言うなら夏休みが 4/5 ほど持ってかれたことですね。
何をやった？ 基本的に Github に issue に上がってるチケットを消化していく感じでした。 自分でこれがあったら便利だなと思う機能を追加したり、不便な箇所を改修したりして、GO サインが出たら Depoloy していきます。
今年度のインターン生は何人? 内定生のインターンを除くと両手で数えられるほどでした。...</p></div><footer class=entry-footer><span title='2013-08-23 17:04:38.281 +0000 UTC'>8月 23, 2013</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to ミクシィにインターンしてきた" href=https://shunyaueta.com/posts/2013-08-21/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://shunyaueta.com/posts/page/7/>«&nbsp;前へ&nbsp;</a></nav></footer></main><footer class=footer><span>&copy; 2023 <a href=https://shunyaueta.com/>hurutoriya</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>