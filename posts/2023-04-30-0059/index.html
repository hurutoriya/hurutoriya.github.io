<!doctype html><html lang=ja><head><meta http-equiv=x-clacks-overhead content="GNU Terry Pratchett"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>技術書の翻訳作業の最終段階で、 Latex 形式に変換する際に英語だけコメントアウトして、日本語はそのまま残す Python スクリプト | Shunya Ueta</title><meta name=title content="技術書の翻訳作業の最終段階で、 Latex 形式に変換する際に英語だけコメントアウトして、日本語はそのまま残す Python スクリプト"><meta name=description content="直近 2 年くらいプライベートの時間を費やして、機械学習関係の技術書の翻訳作業を友人を交えて 3 人のグループで行っているのですが、ついに最終段階を迎え、ほぼほぼ翻訳作業は終えました。
翻訳作業中は、共同作業がしやすいように Google Docs を使っているのですが以下のような形で
Today is good weather. 今日はいい天気です。 英語(原著)を残して、その下に翻訳結果の日本語を追記していくスタイルで翻訳しています。
現在は書籍の校正作業のために、Google Docs で記載された文章を Latex に変換していく作業があるのですが、その際に原著の英語はコメントアウトする必要があります。 試しに、手作業でコメントアウトしていってみるとこれは辛いという時間がかかりそうなので、自動化することにしました。
最初は、シュッと機械学習ベースで Fasttext 1や https://github.com/google/cld3 で言語判定してみようかと思ったら、Fasttext もうまくインストールできないし、cld3 もインストールさえできないしで、30 分くらい時間を溶かした後に不毛だなと思って正規表現ベースで言語判定を行うスクリプトを書きました。 precision 99%2くらいで動いており、非常に快適です。
import re new_txt = [] file_name = &#34;original.txt&#34; with open('./data/' + file_name, 'r') as file: for line in file: # 行ごとに処理を行う if len(line)==1: # 開業のみの場合はコメントアウトせず、そのまま new_txt.append(line) elif re.search(r'[ぁ-ん]+|[ァ-ヴー]+|[一-龠]+', line): # 日本語のひらがな、かたかな、漢字が含まれていたら日本語とみなして、コメントアウトをしない new_txt.append(line) else: # 英語はLatex形式ででコメントアウトする new_txt.append(&#34;% &#34;+line) # 新規のファイルとして保存 with open('."><meta name=keywords content="python,"><meta property="og:title" content="技術書の翻訳作業の最終段階で、 Latex 形式に変換する際に英語だけコメントアウトして、日本語はそのまま残す Python スクリプト"><meta property="og:description" content="直近 2 年くらいプライベートの時間を費やして、機械学習関係の技術書の翻訳作業を友人を交えて 3 人のグループで行っているのですが、ついに最終段階を迎え、ほぼほぼ翻訳作業は終えました。
翻訳作業中は、共同作業がしやすいように Google Docs を使っているのですが以下のような形で
Today is good weather. 今日はいい天気です。 英語(原著)を残して、その下に翻訳結果の日本語を追記していくスタイルで翻訳しています。
現在は書籍の校正作業のために、Google Docs で記載された文章を Latex に変換していく作業があるのですが、その際に原著の英語はコメントアウトする必要があります。 試しに、手作業でコメントアウトしていってみるとこれは辛いという時間がかかりそうなので、自動化することにしました。
最初は、シュッと機械学習ベースで Fasttext 1や https://github.com/google/cld3 で言語判定してみようかと思ったら、Fasttext もうまくインストールできないし、cld3 もインストールさえできないしで、30 分くらい時間を溶かした後に不毛だなと思って正規表現ベースで言語判定を行うスクリプトを書きました。 precision 99%2くらいで動いており、非常に快適です。
import re new_txt = [] file_name = &#34;original.txt&#34; with open('./data/' + file_name, 'r') as file: for line in file: # 行ごとに処理を行う if len(line)==1: # 開業のみの場合はコメントアウトせず、そのまま new_txt.append(line) elif re.search(r'[ぁ-ん]+|[ァ-ヴー]+|[一-龠]+', line): # 日本語のひらがな、かたかな、漢字が含まれていたら日本語とみなして、コメントアウトをしない new_txt.append(line) else: # 英語はLatex形式ででコメントアウトする new_txt.append(&#34;% &#34;+line) # 新規のファイルとして保存 with open('."><meta property="og:type" content="article"><meta property="og:url" content="https://shunyaueta.com/posts/2023-04-30-0059/"><meta property="og:image" content="https://shunyaueta.com/ogp.jpg"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-04-30T00:59:44+09:00"><meta property="article:modified_time" content="2023-04-30T00:59:44+09:00"><meta property="og:site_name" content="Shunya Ueta"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://shunyaueta.com/ogp.jpg"><meta name=twitter:title content="技術書の翻訳作業の最終段階で、 Latex 形式に変換する際に英語だけコメントアウトして、日本語はそのまま残す Python スクリプト"><meta name=twitter:description content="直近 2 年くらいプライベートの時間を費やして、機械学習関係の技術書の翻訳作業を友人を交えて 3 人のグループで行っているのですが、ついに最終段階を迎え、ほぼほぼ翻訳作業は終えました。
翻訳作業中は、共同作業がしやすいように Google Docs を使っているのですが以下のような形で
Today is good weather. 今日はいい天気です。 英語(原著)を残して、その下に翻訳結果の日本語を追記していくスタイルで翻訳しています。
現在は書籍の校正作業のために、Google Docs で記載された文章を Latex に変換していく作業があるのですが、その際に原著の英語はコメントアウトする必要があります。 試しに、手作業でコメントアウトしていってみるとこれは辛いという時間がかかりそうなので、自動化することにしました。
最初は、シュッと機械学習ベースで Fasttext 1や https://github.com/google/cld3 で言語判定してみようかと思ったら、Fasttext もうまくインストールできないし、cld3 もインストールさえできないしで、30 分くらい時間を溶かした後に不毛だなと思って正規表現ベースで言語判定を行うスクリプトを書きました。 precision 99%2くらいで動いており、非常に快適です。
import re new_txt = [] file_name = &#34;original.txt&#34; with open('./data/' + file_name, 'r') as file: for line in file: # 行ごとに処理を行う if len(line)==1: # 開業のみの場合はコメントアウトせず、そのまま new_txt.append(line) elif re.search(r'[ぁ-ん]+|[ァ-ヴー]+|[一-龠]+', line): # 日本語のひらがな、かたかな、漢字が含まれていたら日本語とみなして、コメントアウトをしない new_txt.append(line) else: # 英語はLatex形式ででコメントアウトする new_txt.append(&#34;% &#34;+line) # 新規のファイルとして保存 with open('."><meta itemprop=name content="技術書の翻訳作業の最終段階で、 Latex 形式に変換する際に英語だけコメントアウトして、日本語はそのまま残す Python スクリプト"><meta itemprop=description content="直近 2 年くらいプライベートの時間を費やして、機械学習関係の技術書の翻訳作業を友人を交えて 3 人のグループで行っているのですが、ついに最終段階を迎え、ほぼほぼ翻訳作業は終えました。
翻訳作業中は、共同作業がしやすいように Google Docs を使っているのですが以下のような形で
Today is good weather. 今日はいい天気です。 英語(原著)を残して、その下に翻訳結果の日本語を追記していくスタイルで翻訳しています。
現在は書籍の校正作業のために、Google Docs で記載された文章を Latex に変換していく作業があるのですが、その際に原著の英語はコメントアウトする必要があります。 試しに、手作業でコメントアウトしていってみるとこれは辛いという時間がかかりそうなので、自動化することにしました。
最初は、シュッと機械学習ベースで Fasttext 1や https://github.com/google/cld3 で言語判定してみようかと思ったら、Fasttext もうまくインストールできないし、cld3 もインストールさえできないしで、30 分くらい時間を溶かした後に不毛だなと思って正規表現ベースで言語判定を行うスクリプトを書きました。 precision 99%2くらいで動いており、非常に快適です。
import re new_txt = [] file_name = &#34;original.txt&#34; with open('./data/' + file_name, 'r') as file: for line in file: # 行ごとに処理を行う if len(line)==1: # 開業のみの場合はコメントアウトせず、そのまま new_txt.append(line) elif re.search(r'[ぁ-ん]+|[ァ-ヴー]+|[一-龠]+', line): # 日本語のひらがな、かたかな、漢字が含まれていたら日本語とみなして、コメントアウトをしない new_txt.append(line) else: # 英語はLatex形式ででコメントアウトする new_txt.append(&#34;% &#34;+line) # 新規のファイルとして保存 with open('."><meta itemprop=datePublished content="2023-04-30T00:59:44+09:00"><meta itemprop=dateModified content="2023-04-30T00:59:44+09:00"><meta itemprop=wordCount content="83"><meta itemprop=image content="https://shunyaueta.com/ogp.jpg"><meta itemprop=keywords content="python,"><meta name=referrer content="no-referrer-when-downgrade"><style>body{font-family:Verdana,sans-serif;margin:auto;padding:20px;max-width:720px;text-align:left;background-color:#fff;word-wrap:break-word;overflow-wrap:break-word;line-height:1.5;color:#444}h1,h2,h3,h4,h5,h6,strong,b{color:#222}a{color:#3273dc}.title{text-decoration:none;border:0}.title span{font-weight:400}nav a{margin-right:10px}textarea{width:100%;font-size:16px}input{font-size:16px}content{line-height:1.6}table{width:100%}img{max-width:100%}code{padding:2px 5px;background-color:#f2f2f2}pre code{color:#222;display:block;padding:20px;white-space:pre-wrap;font-size:14px;overflow-x:auto}div.highlight pre{background-color:initial;color:initial}div.highlight code{background-color:unset;color:unset}blockquote{border-left:1px solid #999;color:#222;padding-left:20px;font-style:italic}footer{padding:25px;text-align:center}.helptext{color:#777;font-size:small}.errorlist{color:#eba613;font-size:small}ul.blog-posts{list-style-type:none;padding:unset}ul.blog-posts li{display:flex}ul.blog-posts li span{flex:0 0 130px}ul.blog-posts li a:visited{color:#8b6fcb}@media(prefers-color-scheme:dark){body{background-color:#333;color:#ddd}h1,h2,h3,h4,h5,h6,strong,b{color:#eee}a{color:#8cc2dd}code{background-color:#777}pre code{color:#ddd}blockquote{color:#ccc}textarea,input{background-color:#252525;color:#ddd}.helptext{color:#aaa}}</style><script async src="https://www.googletagmanager.com/gtag/js?id=G-JMJRQJT0Q3"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-JMJRQJT0Q3")</script></head><body><header><a href=/ class=title><h2>Shunya Ueta</h2></a><nav><a href=/about/>著者について</a>
<a href=/index.xml>RSS</a></nav></header><main><h1>技術書の翻訳作業の最終段階で、 Latex 形式に変換する際に英語だけコメントアウトして、日本語はそのまま残す Python スクリプト</h1><p><i><time datetime=2023-04-30 pubdate>2023-04-30</time></i></p><content><p>直近 2 年くらいプライベートの時間を費やして、機械学習関係の技術書の翻訳作業を友人を交えて 3 人のグループで行っているのですが、ついに最終段階を迎え、ほぼほぼ翻訳作業は終えました。</p><p>翻訳作業中は、共同作業がしやすいように Google Docs を使っているのですが以下のような形で</p><pre tabindex=0><code>Today is good weather.

今日はいい天気です。
</code></pre><p>英語(原著)を残して、その下に翻訳結果の日本語を追記していくスタイルで翻訳しています。</p><p>現在は書籍の校正作業のために、Google Docs で記載された文章を Latex に変換していく作業があるのですが、その際に原著の英語はコメントアウトする必要があります。
試しに、手作業でコメントアウトしていってみるとこれは辛いという時間がかかりそうなので、自動化することにしました。</p><p>最初は、シュッと機械学習ベースで Fasttext <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>や <a href=https://github.com/google/cld3>https://github.com/google/cld3</a> で言語判定してみようかと思ったら、Fasttext もうまくインストールできないし、cld3 もインストールさえできないしで、30 分くらい時間を溶かした後に不毛だなと思って正規表現ベースで言語判定を行うスクリプトを書きました。
precision 99%<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>くらいで動いており、非常に快適です。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> re
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>new_txt <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>file_name <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;original.txt&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> open(<span style=color:#e6db74>&#39;./data/&#39;</span> <span style=color:#f92672>+</span> file_name, <span style=color:#e6db74>&#39;r&#39;</span>) <span style=color:#66d9ef>as</span> file:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> line <span style=color:#f92672>in</span> file:
</span></span><span style=display:flex><span>        <span style=color:#75715e># 行ごとに処理を行う</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> len(line)<span style=color:#f92672>==</span><span style=color:#ae81ff>1</span>:
</span></span><span style=display:flex><span>            <span style=color:#75715e># 開業のみの場合はコメントアウトせず、そのまま</span>
</span></span><span style=display:flex><span>            new_txt<span style=color:#f92672>.</span>append(line)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>elif</span> re<span style=color:#f92672>.</span>search(<span style=color:#e6db74>r</span><span style=color:#e6db74>&#39;[ぁ-ん]+|[ァ-ヴー]+|[一-龠]+&#39;</span>, line):
</span></span><span style=display:flex><span>            <span style=color:#75715e># 日本語のひらがな、かたかな、漢字が含まれていたら日本語とみなして、コメントアウトをしない</span>
</span></span><span style=display:flex><span>            new_txt<span style=color:#f92672>.</span>append(line)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>            <span style=color:#75715e># 英語はLatex形式ででコメントアウトする</span>
</span></span><span style=display:flex><span>            new_txt<span style=color:#f92672>.</span>append(<span style=color:#e6db74>&#34;% &#34;</span><span style=color:#f92672>+</span>line)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 新規のファイルとして保存</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> open(<span style=color:#e6db74>&#39;./data/en-comment-out-&#39;</span> <span style=color:#f92672>+</span> file_name, <span style=color:#e6db74>&#39;w&#39;</span>) <span style=color:#66d9ef>as</span> file:
</span></span><span style=display:flex><span>    file<span style=color:#f92672>.</span>write(<span style=color:#e6db74>&#39;&#39;</span><span style=color:#f92672>.</span>join(new_txt))
</span></span></code></pre></div><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href=https://yag-ays.github.io/project/fasttext_language_identification/>fasttext を用いた言語判定 - Out-of-the-box</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>時たま巻き込みが発生しているときがある。数式とかで日本語が使われていない行など&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></content>---<p>関連しているかもしれない記事</p><ul><li><a href=/posts/2022-10-23-2344/>Elasticsearchの近似近傍探索を使って、ドラえもんのひみつ道具検索エンジンを作ってみた</a></li><li><a href=/posts/2022-10-17-1156/>Python で zip関数を使う際に、２つの配列が同じ大きさを想定する場合は 3.10 から導入された strict=True を使おう</a></li><li><a href=/posts/2022-08-18-1938/>Apache Beam 2.40 で導入された scikit-lean, Pytorch の効率的な推論が可能になる RunInference API を試してみる</a></li><li><a href=/posts/2022-08-10-1717/>poetry show でパッケージ名に (!) が付与されている意味</a></li><li><a href=/posts/2022-05-10-2200/>社内でデータ分析結果を可視化・共有する際に Google Colab が便利</a></li></ul><br>📮 📧 🐏: 記事への<a href="https://docs.google.com/forms/d/e/1FAIpQLScgZVDrjQiKLbQRovfs88oweCITzjtvt1PlgwL14JfWPOrpPQ/viewform?usp=pp_url&entry.838298670=https%3a%2f%2fshunyaueta.com%2fposts%2f2023-04-30-0059%2f">感想</a>のおたよりをおまちしてます。
お気軽にお送りください。
メールアドレス入力があればメールで返信させていただきます。
もちろんお返事を希望せずに単なる感想だけでも大歓迎です。<br><br>このサイトの更新情報を<a href=/index.xml>RSS</a>で配信しています。
お好きなフィードリーダーで購読してみてください。<br><br>このウェブサイトの運営や著者の活動を支援していただける方を募集しています。
もしよろしければ、<a href=https://www.buymeacoffee.com/hurutoriya>Buy Me a Coffee</a> からサポート(投げ銭)していただけると、著者の活動のモチベーションに繋がります✨<br><br><p><a href=https://shunyaueta.com/tags/python/>#python</a></p></main><footer>Made with <a href=https://github.com/janraasch/hugo-bearblog/>Hugo ʕ•ᴥ•ʔ Bear</a></footer></body></html>