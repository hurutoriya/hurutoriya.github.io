<!doctype html><html lang=ja prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb#"><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><meta name=description content><meta name=HandheldFriendly content="True"><meta name=MobileOptimized content="320"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=keywords content="Paper,
ACMMM,
Computer Vision,
Machine Learning,"><meta property="og:type" content="article"><meta property="og:description" content><meta property="og:title" content="Analyzing Free-standing Conversational Groups: A Multimodal Approach (ACMMM15) を読んだ"><meta property="og:site_name" content><meta property="og:image" content><meta property="og:image:type" content="image/jpeg"><meta property="og:image:width" content><meta property="og:image:height" content><meta property="og:url" content="https://shunyaueta.com/posts/2018-01-14_analyzing-freestanding-conversational-groups-a-multimodal-approach-acmmm15-%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/"><meta property="og:locale" content="ja"><meta property="article:published_time" content="2018-01-14"><meta property="article:modified_time" content="2018-01-14"><meta property="article:tag" content="Paper"><meta property="article:tag" content="ACMMM"><meta property="article:tag" content="Computer Vision"><meta property="article:tag" content="Machine Learning"><meta name=twitter:card content="summary"><meta name=twitter:site content="@hurutoriya"><meta name=twitter:creator content="@hurutoriya"><meta name=twitter:title content="Analyzing Free-standing Conversational Groups: A Multimodal Approach (ACMMM15) を読んだ |"><meta name=twitter:description content="スタンディングディスカッション形式での会話を評価した研究
Summary Slide
X Alameda-Pineda, Y Yan, E Ricci, O Lanz, N Sebe
“Analyzing Free-standing Conversational Groups: A Multimodal Approach”, in 2015 ACM Multimedia Conference
link
を読んだので、軽くメモ。
マルチモーダル系の論文初めて読んだんですが、まとめるとコントリビューションが 5 つあると主張。
Contribution  音声・近接情報、そして監視カメラからの身体と頭の姿勢推定からマルチモーダルに解析 フリースタンディングディスカッションを身体・頭の姿勢推定から解析 カメラと音声・近接センサーからなるマルチモーダルな解析するためのフレームワークを提案 ラベリングされてないデータに対する行列補間問題の考案 SALSA(データ・セット)を公開・評価  SALSA というポスターセッションの動画と音声のデータも公開されている
 SALSA: Synergetic sociAL Scene Analysis
 動画は Google Drive で公開されていて時代の波を感じる。
 データセットを公開 論文も読みやすい 新しい行列補完計画法(アルゴリズム)を提案 実問題に取り組む  と盛り沢山な内容で面白かった。
スライド内のリンクは Google Slide で共有しているのでこちらを参照すると便利です。
X Alameda-Pineda, Y Yan, E Ricci, O Lanz, N Sebe &#34;Analyzing Free-standing Conversational Groups: A…|"><meta name=twitter:image:src content><meta name=twitter:domain content="https://shunyaueta.com/posts/2018-01-14_analyzing-freestanding-conversational-groups-a-multimodal-approach-acmmm15-%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/"><title>Analyzing Free-standing Conversational Groups: A Multimodal Approach (ACMMM15) を読んだ</title><link rel=canonical href=https://shunyaueta.com/posts/2018-01-14_analyzing-freestanding-conversational-groups-a-multimodal-approach-acmmm15-%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/><link rel=stylesheet href=https://unpkg.com/tachyons@4.11.1/css/tachyons.min.css><link rel=stylesheet href=https://shunyaueta.com/css/style.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/highlightjs@9.12.0/styles/github-gist.css><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-39994406-11','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><link rel="shortcut icon" href=/favicon.ico type=image/x-icon><link rel=apple-touch-icon href=/apple-touch-icon.png></head><body lang=ja class="sans-serif w-90 w-60-ns center center-ns mv2 mv5-ns" itemscope itemtype=http://schema.org/Article><span class=b>/</span>
<a href=https://shunyaueta.com/ class="b bb bw1 pb1 no-underline black"></a><section id=main class=mt5><h1 itemprop=name id=title>Analyzing Free-standing Conversational Groups: A Multimodal Approach (ACMMM15) を読んだ</h1><article itemprop=articleBody id=content class="w-90 lh-copy"><p>スタンディングディスカッション形式での会話を評価した研究</p><p><img src=/posts/2018-01-14_analyzing-freestanding-conversational-groups-a-multimodal-approach-acmmm15-%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/images/1.png alt=image></p><p>Summary Slide</p><p>X Alameda-Pineda, Y Yan, E Ricci, O Lanz, N Sebe<br>“Analyzing Free-standing Conversational Groups: A Multimodal Approach”, in 2015 ACM Multimedia Conference</p><p><a href=http://xavirema.eu/wp-content/papercite-data/pdf/Alameda-ACMMM-2015.pdf>link</a></p><p>を読んだので、軽くメモ。</p><p>マルチモーダル系の論文初めて読んだんですが、まとめるとコントリビューションが 5 つあると主張。</p><h3 id=contribution>Contribution</h3><ul><li>音声・近接情報、そして監視カメラからの身体と頭の姿勢推定からマルチモーダルに解析</li><li>フリースタンディングディスカッションを身体・頭の姿勢推定から解析</li><li>カメラと音声・近接センサーからなるマルチモーダルな解析するためのフレームワークを提案</li><li>ラベリングされてないデータに対する行列補間問題の考案</li><li>SALSA(データ・セット)を公開・評価</li></ul><p>SALSA というポスターセッションの動画と音声のデータも公開されている</p><blockquote><p><a href=http://tev.fbk.eu/salsa><em>SALSA: Synergetic sociAL Scene Analysis</em></a></p></blockquote><p>動画は Google Drive で公開されていて時代の波を感じる。</p><ul><li>データセットを公開</li><li>論文も読みやすい</li><li>新しい行列補完計画法(アルゴリズム)を提案</li><li>実問題に取り組む</li></ul><p>と盛り沢山な内容で面白かった。</p><p>スライド内のリンクは Google Slide で共有しているのでこちらを参照すると便利です。</p><p><a href="https://docs.google.com/presentation/d/1G6zfzV4jIm7qj4LkHkm3Gk_qHEml0SWZExkNuqw0ef8/embed?start=true&loop=true&delayms=1000&slide=id.g1502801dfc_2_6">X Alameda-Pineda, Y Yan, E Ricci, O Lanz, N Sebe "Analyzing Free-standing Conversational Groups: A…</a></p></article></section><footer><div><p class="f6 gray mt6 lh-copy">© 2016-20 <a href=https://twitter.com/hurutoriya>@hurutoriya</a>.</p></div></footer><script src=//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.14.2/highlight.min.js></script><script>hljs.initHighlightingOnLoad();</script></body></html>