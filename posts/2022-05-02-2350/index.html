<!doctype html><html lang=ja dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Search Engineering Newsletter vol.05 | 🦅 hurutoriya</title><meta name=keywords content="newsletter,search"><meta name=description content="5 回目のニュースレター配信です。更新頻度を保つために、1 時間で読めるだけ記事を読んで配信していくスタイルに次回からしようと思いました。 本格的に精読したい面白い記事が来ると一時間なんて一瞬で潰れてしまう&mldr;
Search Introducing Natural Language Search for Podcast Episodes
Spotify が Podcast 検索において text matching の従来の検索エンジンではなく、ニューラル検索を導入した解説記事。 ニューラル検索の実運用例として面白かったので、以下に抄訳として内容をまとめた。
 Beyond term-based Search 「electric cars climate impact」と自然言語のクエリを Elasticsearch に投げても何も検索結果が表示されなかった&mldr;だが検索されなかったのは、Spotify 上の Podcast に関連する内容がなかったからなのだろうか?
NOTE:個人的に本当に結果が出なかったのかは気になるところではある。ワードの完全一致ならともかく、BoW や BM25 で検索すれば結果は出るのでは&mldr;?
Natural Language Search 自然言語検索(Natural Language Search、またの名を意味検索(Semantic Search) と呼ばれる技術について調査を始めた。すごくざっくり言えば、従来ではクエリとドキュメントの単語の一致によって検索を行っていたが、意味検索ではクエリとドキュメントの意味的な相関によって検索を行う。
実際の検索結果の例を見ても、クエリのすべての単語が Podcast のタイトルには含まれていない(Elasticsearch が検索結果を出さない理由でもある)が検索結果として妥当なことがわかる。
Technical solution これらの結果を実現するために深層学習の技術である、自己教師学習と Transformer を利用、そしてそれらの結果を高速に提供するために近似近傍探索(Approximate Nearest Neighbor (ANN))を利用する。
共通の埋め込み空間上で、クエリのベクトルに近い Podcast を検索結果として計算する。また、Podcast の題目、説明文、そして親ポッドキャストのテキスト情報などを連結して特徴量とする。
Picking the right pre-trained Transformer model for our task BERT のような Transformer モデルは、自然言語処理タスクでは現在最高峰の性能を誇っている。 BERT は 2 つの観点から高性能になっている"><meta name=author content="Shunya Ueta"><link rel=canonical href=https://shunyaueta.com/posts/2022-05-02-2350/><link crossorigin=anonymous href=/assets/css/stylesheet.min.f00f189851525f5dc525fa12dfc10fa3656c6cc16f26285e5f7347522031587e.css integrity="sha256-8A8YmFFSX13FJfoS38EPo2VsbMFvJiheX3NHUiAxWH4=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.27cd435cc9ed6abb4b496581b151804f79f366c412620272bb94e2f5f598ebcc.js integrity="sha256-J81DXMntartLSWWBsVGAT3nzZsQSYgJyu5Ti9fWY68w=" onload=hljs.initHighlightingOnLoad();></script><link rel=icon href=https://shunyaueta.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://shunyaueta.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://shunyaueta.com/favicon-32x32.png><link rel=apple-touch-icon href=https://shunyaueta.com/apple-touch-icon.png><link rel=mask-icon href=https://shunyaueta.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme: rgb(29, 30, 32);--entry: rgb(46, 46, 51);--primary: rgb(218, 218, 219);--secondary: rgb(155, 156, 157);--tertiary: rgb(65, 66, 68);--content: rgb(196, 196, 197);--hljs-bg: rgb(46, 46, 51);--code-bg: rgb(55, 56, 62);--border: rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','UA-39994406-11','auto');ga('send','pageview');}</script><meta property="og:title" content="Search Engineering Newsletter vol.05"><meta property="og:description" content="5 回目のニュースレター配信です。更新頻度を保つために、1 時間で読めるだけ記事を読んで配信していくスタイルに次回からしようと思いました。 本格的に精読したい面白い記事が来ると一時間なんて一瞬で潰れてしまう&mldr;
Search Introducing Natural Language Search for Podcast Episodes
Spotify が Podcast 検索において text matching の従来の検索エンジンではなく、ニューラル検索を導入した解説記事。 ニューラル検索の実運用例として面白かったので、以下に抄訳として内容をまとめた。
 Beyond term-based Search 「electric cars climate impact」と自然言語のクエリを Elasticsearch に投げても何も検索結果が表示されなかった&mldr;だが検索されなかったのは、Spotify 上の Podcast に関連する内容がなかったからなのだろうか?
NOTE:個人的に本当に結果が出なかったのかは気になるところではある。ワードの完全一致ならともかく、BoW や BM25 で検索すれば結果は出るのでは&mldr;?
Natural Language Search 自然言語検索(Natural Language Search、またの名を意味検索(Semantic Search) と呼ばれる技術について調査を始めた。すごくざっくり言えば、従来ではクエリとドキュメントの単語の一致によって検索を行っていたが、意味検索ではクエリとドキュメントの意味的な相関によって検索を行う。
実際の検索結果の例を見ても、クエリのすべての単語が Podcast のタイトルには含まれていない(Elasticsearch が検索結果を出さない理由でもある)が検索結果として妥当なことがわかる。
Technical solution これらの結果を実現するために深層学習の技術である、自己教師学習と Transformer を利用、そしてそれらの結果を高速に提供するために近似近傍探索(Approximate Nearest Neighbor (ANN))を利用する。
共通の埋め込み空間上で、クエリのベクトルに近い Podcast を検索結果として計算する。また、Podcast の題目、説明文、そして親ポッドキャストのテキスト情報などを連結して特徴量とする。
Picking the right pre-trained Transformer model for our task BERT のような Transformer モデルは、自然言語処理タスクでは現在最高峰の性能を誇っている。 BERT は 2 つの観点から高性能になっている"><meta property="og:type" content="article"><meta property="og:url" content="https://shunyaueta.com/posts/2022-05-02-2350/"><meta property="og:image" content="https://shunyaueta.com/posts/2022-01-16/images/1.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-05-02T23:50:35+09:00"><meta property="article:modified_time" content="2022-07-15T10:57:54+09:00"><meta property="og:site_name" content="Shunya Ueta"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://shunyaueta.com/posts/2022-01-16/images/1.png"><meta name=twitter:title content="Search Engineering Newsletter vol.05"><meta name=twitter:description content="5 回目のニュースレター配信です。更新頻度を保つために、1 時間で読めるだけ記事を読んで配信していくスタイルに次回からしようと思いました。 本格的に精読したい面白い記事が来ると一時間なんて一瞬で潰れてしまう&mldr;
Search Introducing Natural Language Search for Podcast Episodes
Spotify が Podcast 検索において text matching の従来の検索エンジンではなく、ニューラル検索を導入した解説記事。 ニューラル検索の実運用例として面白かったので、以下に抄訳として内容をまとめた。
 Beyond term-based Search 「electric cars climate impact」と自然言語のクエリを Elasticsearch に投げても何も検索結果が表示されなかった&mldr;だが検索されなかったのは、Spotify 上の Podcast に関連する内容がなかったからなのだろうか?
NOTE:個人的に本当に結果が出なかったのかは気になるところではある。ワードの完全一致ならともかく、BoW や BM25 で検索すれば結果は出るのでは&mldr;?
Natural Language Search 自然言語検索(Natural Language Search、またの名を意味検索(Semantic Search) と呼ばれる技術について調査を始めた。すごくざっくり言えば、従来ではクエリとドキュメントの単語の一致によって検索を行っていたが、意味検索ではクエリとドキュメントの意味的な相関によって検索を行う。
実際の検索結果の例を見ても、クエリのすべての単語が Podcast のタイトルには含まれていない(Elasticsearch が検索結果を出さない理由でもある)が検索結果として妥当なことがわかる。
Technical solution これらの結果を実現するために深層学習の技術である、自己教師学習と Transformer を利用、そしてそれらの結果を高速に提供するために近似近傍探索(Approximate Nearest Neighbor (ANN))を利用する。
共通の埋め込み空間上で、クエリのベクトルに近い Podcast を検索結果として計算する。また、Podcast の題目、説明文、そして親ポッドキャストのテキスト情報などを連結して特徴量とする。
Picking the right pre-trained Transformer model for our task BERT のような Transformer モデルは、自然言語処理タスクでは現在最高峰の性能を誇っている。 BERT は 2 つの観点から高性能になっている"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Search Engineering Newsletter vol.05","item":"https://shunyaueta.com/posts/2022-05-02-2350/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Search Engineering Newsletter vol.05","name":"Search Engineering Newsletter vol.05","description":"5 回目のニュースレター配信です。更新頻度を保つために、1 時間で読めるだけ記事を読んで配信していくスタイルに次回からしようと思いました。 本格的に精読したい面白い記事が来ると一時間なんて一瞬で潰れてしまう\u0026hellip;\nSearch Introducing Natural Language Search for Podcast Episodes\nSpotify が Podcast 検索において text matching の従来の検索エンジンではなく、ニューラル検索を導入した解説記事。 ニューラル検索の実運用例として面白かったので、以下に抄訳として内容をまとめた。\n Beyond term-based Search 「electric cars climate impact」と自然言語のクエリを Elasticsearch に投げても何も検索結果が表示されなかった\u0026hellip;だが検索されなかったのは、Spotify 上の Podcast に関連する内容がなかったからなのだろうか?\nNOTE:個人的に本当に結果が出なかったのかは気になるところではある。ワードの完全一致ならともかく、BoW や BM25 で検索すれば結果は出るのでは\u0026hellip;?\nNatural Language Search 自然言語検索(Natural Language Search、またの名を意味検索(Semantic Search) と呼ばれる技術について調査を始めた。すごくざっくり言えば、従来ではクエリとドキュメントの単語の一致によって検索を行っていたが、意味検索ではクエリとドキュメントの意味的な相関によって検索を行う。\n実際の検索結果の例を見ても、クエリのすべての単語が Podcast のタイトルには含まれていない(Elasticsearch が検索結果を出さない理由でもある)が検索結果として妥当なことがわかる。\nTechnical solution これらの結果を実現するために深層学習の技術である、自己教師学習と Transformer を利用、そしてそれらの結果を高速に提供するために近似近傍探索(Approximate Nearest Neighbor (ANN))を利用する。\n共通の埋め込み空間上で、クエリのベクトルに近い Podcast を検索結果として計算する。また、Podcast の題目、説明文、そして親ポッドキャストのテキスト情報などを連結して特徴量とする。\nPicking the right pre-trained Transformer model for our task BERT のような Transformer モデルは、自然言語処理タスクでは現在最高峰の性能を誇っている。 BERT は 2 つの観点から高性能になっている","keywords":["newsletter","search"],"articleBody":"5 回目のニュースレター配信です。更新頻度を保つために、1 時間で読めるだけ記事を読んで配信していくスタイルに次回からしようと思いました。 本格的に精読したい面白い記事が来ると一時間なんて一瞬で潰れてしまう…\nSearch Introducing Natural Language Search for Podcast Episodes\nSpotify が Podcast 検索において text matching の従来の検索エンジンではなく、ニューラル検索を導入した解説記事。 ニューラル検索の実運用例として面白かったので、以下に抄訳として内容をまとめた。\n Beyond term-based Search 「electric cars climate impact」と自然言語のクエリを Elasticsearch に投げても何も検索結果が表示されなかった…だが検索されなかったのは、Spotify 上の Podcast に関連する内容がなかったからなのだろうか?\nNOTE:個人的に本当に結果が出なかったのかは気になるところではある。ワードの完全一致ならともかく、BoW や BM25 で検索すれば結果は出るのでは…?\nNatural Language Search 自然言語検索(Natural Language Search、またの名を意味検索(Semantic Search) と呼ばれる技術について調査を始めた。すごくざっくり言えば、従来ではクエリとドキュメントの単語の一致によって検索を行っていたが、意味検索ではクエリとドキュメントの意味的な相関によって検索を行う。\n実際の検索結果の例を見ても、クエリのすべての単語が Podcast のタイトルには含まれていない(Elasticsearch が検索結果を出さない理由でもある)が検索結果として妥当なことがわかる。\nTechnical solution これらの結果を実現するために深層学習の技術である、自己教師学習と Transformer を利用、そしてそれらの結果を高速に提供するために近似近傍探索(Approximate Nearest Neighbor (ANN))を利用する。\n共通の埋め込み空間上で、クエリのベクトルに近い Podcast を検索結果として計算する。また、Podcast の題目、説明文、そして親ポッドキャストのテキスト情報などを連結して特徴量とする。\nPicking the right pre-trained Transformer model for our task BERT のような Transformer モデルは、自然言語処理タスクでは現在最高峰の性能を誇っている。 BERT は 2 つの観点から高性能になっている\n 自己教師学習による文章からの巨大なコーパスを作成。文章からランダムにマスクした単語を予想するタスクを主なタスクとしてモデルを構築 Bidirectional self-attention により、高品質な単語埋め込み空間を獲得可能  だが、基礎の BERT モデルは今回の事例に以下の理由で適していないことが分かった\n SBERT, “Sentence-BERT: Sentence Embeddings Using Siamese BERT-Networks”の論文で示されたが、文脈に沿った埋め込み空間を得られるが BERT では文の表現に対しては良い結果が出ない。 英語の文章のみで事前学習されているが、我々は多言語の検索をサポートしたい。  それらの課題を解決するための手法として、Universal Sentence Representation Learning with Conditional Masked Language Model で提案された CMLM モデルが実験を通して良好な結果を得ることができた。 CMLM モデルは以下の利点がある。\n CMLM モデルは高品質な文章の埋め込み空間を生成可能 巨大な 100 以上の言語コーパスから学習された事前学習モデルが TFHub で利用可能  Preparing the data 強力な事前学習モデルを使えるようになったので、次のステップとして Spotify の Podcast データに合わせたモデルの fine-tune が必要である。\n Elasticsearch の検索から得られた過去の検索ログから、成功した検索セッションを元に (クエリ, エピソード)のペアを作成する。 また過去の検索ログから、セッションを通じて最初の検索が失敗後にクエリを調整して検索が成功したデータを用いて、(調整が成功したクエリ, エピソード)のペアを作成する。これによって学習データにより(クエリ, エピソード)のペアで、単語の一致がクエリとエピソードのメタデータで発生していないより意味的な近さを捉えることができる。 学習データの多様性と規模を工場させるために人工的なクエリを人気のエピソードの題目と説明文から作成する。この作成方法はEmbedding-based Zero-shot Retrieval through Query Generationからアイデアを得た。 最後に、人気のあるエピソードに対して、小規模だが激選された「意味的なクエリ」を手動で作成した。  すべてのデータは学習時と評価時の両方に利用されている。(手動で作成した激選されたくいクエリのみ、評価データセットとして飲み使われた。) また学習データと評価データの分割時には、評価データに含まれるエピソードが学習データに含まれないように確認した。(leakage 予防)\nTraining 学習済みの Universal Sentence Encoder CMLM モデルを使って、クエリとエピソードのエンコーダを作成する。また効果的にモデルを学習するためにポジティブな(クエリ, エピソード)のペアだけでなく、ネガティブなペアも必要になった。\n「Dense Passage Retrieval for Open-Domain Question Answering (DPR)」や「Que2Search: Fast and Accurate Query and Document Understanding for Search at Facebook」の論文を参考にバッチ内の他のペアからエピソードを抜き出してそれらをネガティブなペアとしてデータを生成する。\nOffline evaluation In-batch metrics, Full-retrieval setting metrics の２つの指標で評価。\nIntegration with production Offline indexing of episode vectors Vespaを利用して検索インデックスを作成。また、episode の人気情報などに基づいた re-rank なども可能になる。\nOnline query encoding and retrieval Google Cloud Vertex AI で、Query encoder がデプロイされておりクエリがベクトルに変換される。採用理由としては GPU インスタンスがサポートされおり過去の実験から GPU よりも T4 GPU のほうが 6 倍のコスト削減(この際のコストは費用?)を確認できたらしい。 クエリのベクトル生成後は Vespa により Top30 の意味的に相関が高いエピソードベクトルを検索する。またもちろんクエリのベクトル生成時にキャッシャは作成して同じクエリの encode は避けている。\nThere is no silver bullet in retrieval 自然言語検索は面白い性質を持つが、単語の一致をベースにした伝統的な検索手法に頻繁に検索精度としては劣る場合が発生する。また、計算コストとしても、とても高くなりがちである。 これらの事実から Vespa による自然言語検索で既存の検索システムを置き換えるよりむしろ、追加のデータソースとして扱うようにした。\nSpotify の検索では最終段階の re-ranking モデルを運用しており、Elasticsearch, Vespa, 他のデータソースを元に re-ranking を行い最終的なランキング結果を顧客に提示している。\nConclusion and future works 結果として、vespa による自然言語検索をデータソースとして導入することで A/B テストでは有意に Podcast のエンゲージメント指標が向上した。そして初期の自然言語検索システムはほぼすべての顧客に提供されておりモデルの改善も進んでいる。\n Amazon KDD Cup 2022\nAmazon が製品検索改善の競技コンペを KDD2022 で開催。データセットは英語・日本語・スペイン語で公開。\nタスクは 3 種類\n Query-Product Ranking: クエリと製品のマッチングのランキングを行う。評価指標はnDCG Multiclass Product Classification: クエリと製品のペアが Exact(E)・Substitute(S)・Complement(C)・Irrelevant(I) のなかでどの関係性になっているかを予測する。  Exact(一致): その商品はクエリと関連(relevant)しており、そのクエリは商品の使用を満たすクエリになっている。例)「プラスチックウォーターボトル 24L」 にクエリに記された仕様を満たすウォーターボトルの製品が出ている。 Substitute(代替): その商品とクエリはやや関連している。完全に関連はしていないが、マッチした商品は機能的に同じものである。例)「セーター」というクエリに「フリース」の製品 Complement(補完): クエリの対して商品は関連していないが、関連した商品と組み合わせて使用できる商品。例)「ランニングシューズ」のクエリに対して、「トラックパンツ」の製品 Irrelevant(非関連): クエリに対して関連性がない。例) 「パンツ」のクエリに対して、「ソックス」の製品   Product Substitute Identification: クエリと製品が Substitute の関係かどうかを予測する 2 値の予測問題。2 番目のタスクの Multiclass Product Classification と入力形式は同一で、Substitute かどうかを当てるのみになっている。  How Amazon Search achieves low-latency, high-throughput T5 inference with NVIDIA Triton on AWS | AWS Machine Learning Blog\nNvidia の Trion server(旧名は TensorRT Inference Server という名前だった)の実証実験をしてみたよという記事。プロダクション環境下での AB テストはしていないので、単なる性能実験でしかないが、将来的に機械学習の推論を Trion server でサービングしたいとのこと。\nEnable Amazon Kendra search for a scanned or image-based text document | AWS Machine Learning Blog\n今回始めて知ったんですが、Amazon Kendra という、自然言語的なクエリでも検索可能な AWS の検索サービスがあるらしいです。 この記事は、手元のスキャンした書類や画像、PDF や画像などを AWS Lambda を介して、Amazon Textract という API で文書化。 その後 S3 起点で Amazon Kandera にその情報を同期させて検索可能にできるよという紹介記事。 社内の紙の書類なども検索可能になるという発想は面白い。\nElasticsearch 運用ノウハウ - メルカリ\nメルカリでの Elasticsearch の運用方法をまとめた記事。 最近メルカリの検索の内側を紹介する記事が増えているので良いことですね。 インデックスの管理方法や、Elasticsearch の各種設定を調整方法などが説明されています。\nBuilding a Deep Learning Based Retrieval System for Personalized Recommendations\n1.5 億の顧客と 15 億を超えるアクティブな出品商品がある eBay で、深層学習ベースの推薦システムをどう作り上げたかの解説。\n オフラインでのバッチ オフラインとニアリアルタイム(NRT)のハイブリッド ニアリアルタイム  のレベルで段階的にどのように作り上げていったかの説明をしており、愚直に地道に作り上げた話から学びが多く良記事。\nモデルの詳細は KDD2021 の推薦システムに関するワークショップ IRS workshop 2021 で発表されている1。 2-tower でモデルは構成されており、1 つめのタワーで商品、もう一つのタワーでユーザーの埋め込み空間を獲得。 与えられた user_id の k 個の ANN による近似近傍探索の商品を返す。\n段階を経て、バッチ処理からストリーミング処理に変遷するのはお疲れさまでした感が凄い。 非常に気になる話としては、バッチ処理からニアリアルタイムでのストリーミング処理に置き換えて、それに見合う成果がどれほどでているのかは表に出して欲しい~。\n論文1では、モデルの投入によってコールドスタートや在庫なしの課題を有意に改善できたとのこと。 読んだ感じだとこの論文執筆時では 1 段階目のバッチ処理のアーキテクチャっぽい。\nSearchSage: Learning Search Query Representations at Pinterest\n画像検索に強みを持つ Pinretest が、検索システムにテキスト検索と埋め込みでの検索を混ぜることで Top35 の検索結果で 11% CTR を向上させたとのころ。 モデル構成は two-tower らしく、どこもかしこも two-tower を使っている気がする。 モデルの Serving には、TensorFlowServing 上で構築された内製の C++の推論サーバーで運用しているらしくすごくテッキーというか Pinterest らしい構成。 学習は Python、推論は C++で計算コスト効率を目指すことを念頭に置いて、 前処理のために PyTorch の C++オペレータを使用している。(凄い、小並感) 技術的な面の追求だけでなく、ビジネス的な数値もしっかりとリフトさせているのが Pinterest の凄いところですね。\nNear real-time features for near real-time personalization\nLinkedin でのニアリアルタイムでの推薦システム構築の記事。 Table 1.の表のデータが面白く、仕事の推薦モデルに対して応募状況のデータの遅延影響が、どれくらいモデルの精度に影響するかのシミュレーション結果を公開してくれている。 1 分の遅延をベースラインにして、1 時間で 3.51%の ROC-AUC の低下、24 時間で 4.45%まで低下するらしい。 こういう遅延が定量的にどれくらい損益を与えているかを測定しているのは科学をちゃんとしていて、非常に尊敬。 リアルタイムにデータを提供できることで、各種推薦システムも軒並み数値をリフトしており、まさに速さこそ正義2状態になっている。\nまた記事の締めくくりに\n Short development cycle helps. Successful completion of this initiative required several iterations. Our short development cycle allowed fast iterations. This was in a big part due to prior investments in scaling machine learning productivity, our experimentation platform, and continuous deployment.\n 基盤への投資によって開発サイクルが短縮され、高速な反復が実現できたんだよ とものすごく良い話を聞けた。 Linkedin のこの事例は、モデル構築然り、データエンジニアリング、その後の測定などなど、複雑な要素が絡みあうプロジェクトなので基盤への投資による生産性の底上げってのはものすごく効きそうですね。\nElasticsearch LTR プラグインと特徴量キャッシュ機能の基本\nElasticsearch で Learning to Rank(LTR)を行うことができるプラグインの詳細。 特徴量キャッシュの PR を作成して本体にマージされているのカッコよすぎますね。 Yahoo さんのこの底力は毎回凄い。人材の層が厚いですね。\nメルカリ Shops の検索改善とそれを支える AB テストの仕組み\nメルカリ Shops での検索を、メルカリ上での検索とどうインテグレーションしているかの紹介記事。\nDMM の検索改善専門チームが教える！ 検索改善に向けた考え方から効果検証まで - DMM inside\n検索改善の考え方や向き合い方についての記事。 検索改善で、システム面ではなく仮説検証から AB テストまでのメタ的な枠組みを文章化して説明してくれている記事は良い意味で珍しい気がします。 DMM さんは最近、検索や推薦領域でおもしろい記事をたくさん書いてくれていてありがたいですね。\n大規模サービスで効率よくレコメンドを提供するために Tensorflow Recommenders を活用する - DMM inside\nDMM さんによる、tensorflow/recommenders を活用した推薦事例紹介記事。 既にサービスに導入しているらしく、プロダクションで運用されているのは率直に素晴らしいなと思いました。\nData Science \u0026 Machine Learning DeepETA: How Uber Predicts Arrival Times Using Deep Learning\nUber で到着予想時刻(estimated time of arrival: ETA)をどうやって予測しているかの紹介記事。Uber の事業領域としてこの ETA 予測はすべての顧客体験に根本的な影響を及ぼすほど重要なモデルである。\nUber は数年前から GBDT のモデルを ETA 予測に採用しており、モデルの更新のたびに学習データは着実に巨大化しており、それらをさばくために XGBoost に分散学習の PRを作成したりと XGBoost へのかなりのコントリビューションを行っている。\nだが、リアルタイムの交通指標や地図情報などを特徴量として使った深層学習ベースの DeepETA とよばれるモデルの開発を開始した。 考慮すべき点として、Uber のリクエスト規模をさばくことが可能な高速なモデルが求められる。 モデルの軽量化も工夫が凝らされており、これだけ頑張らないとプロダクションに載せられないんだろうなとハラハラした気持ちで読んでいた。\nDeepETA のモデルは内製基盤の Michelangelo で運用されており、実際に XGBoost と比較しても良好な結果が得られたのこと。\nXGBoost から DeepETA へ移行した経緯を読み取ってみると、深層学習を使うに値する規模のデータが収集してそれらを活かせる環境も整ったから移行したのかなと個人的には思った。 結論でも書かれているが、モデル自体はこれからもいろんなアプローチで改善していくぜと書いてあるので、将来的な改善幅に投資したのでしょう。 現状維持よりもさらなる改善を見据えた投資を行っているのが素晴らしい。\n…と思っていたら、 DeepETA の Product Manager3 の方の Linkedin を見ていると、DeepETA により\n In 2021, I helped my team land +$100M of incremental revenue through shipping Deep Learning ETA models, XX% improvements to delivery time estimate accuracy, etc.\n と書かれており、100 億円以上の利益向上と書かれており、ギエピーとなりました。 やはり規模の経済…。レバレッジが効くところに機械学習をブッこむべきですね。\nHow LinkedIn Personalized Performance for Millions of Members using Tensorflow.js — The TensorFlow Blog\nLinkedin はLinkedin Liteというプロジェクトの一環で、クライアントの状況を Performance Quality Model (PQM)4と呼ばれる機械学習モデルで予測を行い\n ハイエンドかつネットワーク状況が良好なクライアント: 画像をそのまま提供 ローエンドかつネットワーク状況が良好でないクライアント: 低解像度の画像を提供  を識別することで状況に応じた最適な web ページをクライアントに返す実験を行った。 その結果、フィードでの数値が大幅に向上させることができた。 動的な配信するアセットを変更するというアイデア、痺れますね。 これもまた速さこそ正義2案件。\nそして、そのモデルをどのようにデプロイしたかがこの記事で書かれているのだが、TensorFlow Serving などを使わずに TensorFlow.js でサービング環境を運用しているらしくとてもユニークな記事になっている。\nTensorFlow.js の選定理由としては、まず当時の Linkedin では、TensorFlow の運用状況が成熟しているとは言い難く、 TensorFlow Serving を運用する選択肢は無かった。 Linkedin 内では JVM スタックがメインだったが、Node.js をフロントエンドとして運用していたので、Node.js で動く TensorFlow.js が採用された。 だが、実際には Python も TensorFlow の運用環境として採用可能だったが、Node.js を選んだ理由として語られているのが、\n 既に Node.js の環境を構築済だった Python よりも Node.js での TensorFlow の 50 percentile が 8%ほど高速だった。  という２つの理由かららしい。この結果は面白く、TensorFlow のレスポンス速度は Node.js のほうが Python よりも早かったのかと驚いた。 もちろんモデルのアーキテクチャや他の条件などにも夜がそれらを踏まえても面白い結果だ。\n日本語における評価用データセットの構築と利用性の向上（JED2022） | NLP2022 Workshop on Japanese Evaluation Dataset\n 日本語における評価用データセットの構築手法そのものに加えて，データセットの公開方式・利用性の高い著作権設定・タスクの複合化といった応用を容易にするための研究を集めて議論することで，日本語データセット公開の流れを加速し，日本語 NLP 業界全体のさらなる発展および生産性向上につなげていきたい．\n 素晴らしいワークショップが NLP2022 で開催されていました。 知らない日本語のデータセットも知れたり、法的な取り組みも知れたりと学びの多い資料が多い。 日本語データセットの拡充は、まさに日本語自然言語の発展を促進させるので、自分も貢献したいなぁと思っている。 2023 年にも JED2023 が開催されるらしいので楽しみにしています。\n感想など Twitter で #searchengineeringnewsletter のハッシュタグでつぶやいていただくか、 Google フォーム での感想投稿をお待ちしております。\n投稿の励みにさせていただきます。\nSearch Engineering Newsletter の購読方法 配信記事が蓄積される RSS5 を作成しています。\nまた、今までの配信記事一覧もこちら6から閲覧できます。\n  Personalized Embedding-based e-Commerce Recommendations at eBay, YouTube ↩︎\n 速さ事正義を示す実験事例 システムの応答速度は本質的な価値提供であることを示す A/B テストの実例 ↩︎\n https://www.linkedin.com/in/wataru-ueno/ ↩︎\n OSS で公開されていた https://github.com/linkedin/performance-quality-models ↩︎\n newsletter RSS: https://shunyaueta.com/tags/newsletter/index.xml ↩︎\n https://shunyaueta.com/tags/newsletter/ ↩︎\n   ","wordCount":"788","inLanguage":"ja","image":"https://shunyaueta.com/posts/2022-01-16/images/1.png","datePublished":"2022-05-02T23:50:35+09:00","dateModified":"2022-07-15T10:57:54+09:00","author":{"@type":"Person","name":"Shunya Ueta"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://shunyaueta.com/posts/2022-05-02-2350/"},"publisher":{"@type":"Organization","name":"🦅 hurutoriya","logo":{"@type":"ImageObject","url":"https://shunyaueta.com/favicon.ico"}}}</script></head><body id=top><script>if(localStorage.getItem("pref-theme")==="dark"){document.body.classList.add('dark');}else if(localStorage.getItem("pref-theme")==="light"){document.body.classList.remove('dark')}else if(window.matchMedia('(prefers-color-scheme: dark)').matches){document.body.classList.add('dark');}</script><header class=header><nav class=nav><div class=logo><a href=https://shunyaueta.com/ accesskey=h title="🦅 hurutoriya (Alt + H)">🦅 hurutoriya</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://shunyaueta.com/archives title=Archive><span>Archive</span></a></li><li><a href=https://shunyaueta.com/about title=About><span>About</span></a></li><li><a href=https://shunyaueta.com/tags/newsletter/ title=Newsletter><span>Newsletter</span></a></li><li><a href=https://shunyaueta.com/index.xml title=RSS><span>RSS</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Search Engineering Newsletter vol.05</h1><div class=post-meta><span title="2022-05-02 23:50:35 +0900 +0900">May 2, 2022</span>&nbsp;·&nbsp;Shunya Ueta&nbsp;|&nbsp;<a href=https://github.com/hurutoriya/hurutoriya.github.io/tree/source/content/posts/2022-05-02-2350/index.md rel="noopener noreferrer" target=_blank>Edit this post (この記事を編集する)</a></div></header><figure class=entry-cover><img loading=lazy src=https://shunyaueta.com/posts/2022-01-16/images/1.png alt></figure><div class=post-content><p>5 回目のニュースレター配信です。更新頻度を保つために、1 時間で読めるだけ記事を読んで配信していくスタイルに次回からしようと思いました。
本格的に精読したい面白い記事が来ると一時間なんて一瞬で潰れてしまう&mldr;</p><h2 id=search>Search<a hidden class=anchor aria-hidden=true href=#search>#</a></h2><p><a href=https://engineering.atspotify.com/2022/03/introducing-natural-language-search-for-podcast-episodes>Introducing Natural Language Search for Podcast Episodes</a></p><p>Spotify が Podcast 検索において text matching の従来の検索エンジンではなく、ニューラル検索を導入した解説記事。
ニューラル検索の実運用例として面白かったので、以下に抄訳として内容をまとめた。</p><hr><h3 id=beyond-term-based-search>Beyond term-based Search<a hidden class=anchor aria-hidden=true href=#beyond-term-based-search>#</a></h3><p>「electric cars climate impact」と自然言語のクエリを Elasticsearch に投げても何も検索結果が表示されなかった&mldr;だが検索されなかったのは、Spotify 上の Podcast に関連する内容がなかったからなのだろうか?</p><p><code>NOTE:</code>個人的に本当に結果が出なかったのかは気になるところではある。ワードの完全一致ならともかく、BoW や BM25 で検索すれば結果は出るのでは&mldr;?</p><h3 id=natural-language-search>Natural Language Search<a hidden class=anchor aria-hidden=true href=#natural-language-search>#</a></h3><p>自然言語検索(Natural Language Search、またの名を意味検索(Semantic Search) と呼ばれる技術について調査を始めた。すごくざっくり言えば、従来ではクエリとドキュメントの単語の一致によって検索を行っていたが、意味検索ではクエリとドキュメントの意味的な相関によって検索を行う。</p><p>実際の検索結果の例を見ても、クエリのすべての単語が Podcast のタイトルには含まれていない(Elasticsearch が検索結果を出さない理由でもある)が検索結果として妥当なことがわかる。</p><h3 id=technical-solution>Technical solution<a hidden class=anchor aria-hidden=true href=#technical-solution>#</a></h3><p>これらの結果を実現するために深層学習の技術である、自己教師学習と Transformer を利用、そしてそれらの結果を高速に提供するために近似近傍探索(Approximate Nearest Neighbor (ANN))を利用する。</p><p>共通の埋め込み空間上で、クエリのベクトルに近い Podcast を検索結果として計算する。また、Podcast の題目、説明文、そして親ポッドキャストのテキスト情報などを連結して特徴量とする。</p><h3 id=picking-the-right-pre-trained-transformer-model-for-our-task>Picking the right pre-trained Transformer model for our task<a hidden class=anchor aria-hidden=true href=#picking-the-right-pre-trained-transformer-model-for-our-task>#</a></h3><p>BERT のような Transformer モデルは、自然言語処理タスクでは現在最高峰の性能を誇っている。
BERT は 2 つの観点から高性能になっている</p><ul><li>自己教師学習による文章からの巨大なコーパスを作成。文章からランダムにマスクした単語を予想するタスクを主なタスクとしてモデルを構築</li><li>Bidirectional self-attention により、高品質な単語埋め込み空間を獲得可能</li></ul><p>だが、基礎の BERT モデルは今回の事例に以下の理由で適していないことが分かった</p><ul><li><a href=https://arxiv.org/abs/1908.10084>SBERT, “Sentence-BERT: Sentence Embeddings Using Siamese BERT-Networks”</a>の論文で示されたが、文脈に沿った埋め込み空間を得られるが BERT では文の表現に対しては良い結果が出ない。</li><li>英語の文章のみで事前学習されているが、我々は多言語の検索をサポートしたい。</li></ul><p>それらの課題を解決するための手法として、<a href=https://arxiv.org/abs/2012.14388>Universal Sentence Representation Learning with Conditional Masked Language Model</a> で提案された CMLM モデルが実験を通して良好な結果を得ることができた。
CMLM モデルは以下の利点がある。</p><ul><li>CMLM モデルは高品質な文章の埋め込み空間を生成可能</li><li>巨大な 100 以上の言語コーパスから学習された事前学習モデルが <a href=https://tfhub.dev/google/universal-sentence-encoder-cmlm/multilingual-base-br/1>TFHub</a> で利用可能</li></ul><h3 id=preparing-the-data>Preparing the data<a hidden class=anchor aria-hidden=true href=#preparing-the-data>#</a></h3><p>強力な事前学習モデルを使えるようになったので、次のステップとして Spotify の Podcast データに合わせたモデルの fine-tune が必要である。</p><ul><li>Elasticsearch の検索から得られた過去の検索ログから、成功した検索セッションを元に (クエリ, エピソード)のペアを作成する。</li><li>また過去の検索ログから、セッションを通じて最初の検索が失敗後にクエリを調整して検索が成功したデータを用いて、(調整が成功したクエリ, エピソード)のペアを作成する。これによって学習データにより(クエリ, エピソード)のペアで、単語の一致がクエリとエピソードのメタデータで発生していないより意味的な近さを捉えることができる。</li><li>学習データの多様性と規模を工場させるために人工的なクエリを人気のエピソードの題目と説明文から作成する。この作成方法は<a href=https://arxiv.org/abs/2009.10270>Embedding-based Zero-shot Retrieval through Query Generation</a>からアイデアを得た。</li><li>最後に、人気のあるエピソードに対して、小規模だが激選された「意味的なクエリ」を手動で作成した。</li></ul><p>すべてのデータは学習時と評価時の両方に利用されている。(手動で作成した激選されたくいクエリのみ、評価データセットとして飲み使われた。)
また学習データと評価データの分割時には、評価データに含まれるエピソードが学習データに含まれないように確認した。(leakage 予防)</p><h3 id=training>Training<a hidden class=anchor aria-hidden=true href=#training>#</a></h3><p>学習済みの Universal Sentence Encoder CMLM モデルを使って、クエリとエピソードのエンコーダを作成する。また効果的にモデルを学習するためにポジティブな(クエリ, エピソード)のペアだけでなく、ネガティブなペアも必要になった。</p><p>「Dense Passage Retrieval for Open-Domain Question Answering (DPR)」や「Que2Search: Fast and Accurate Query and Document Understanding for Search at Facebook」の論文を参考にバッチ内の他のペアからエピソードを抜き出してそれらをネガティブなペアとしてデータを生成する。</p><h3 id=offline-evaluation>Offline evaluation<a hidden class=anchor aria-hidden=true href=#offline-evaluation>#</a></h3><p>In-batch metrics, Full-retrieval setting metrics の２つの指標で評価。</p><h3 id=integration-with-production>Integration with production<a hidden class=anchor aria-hidden=true href=#integration-with-production>#</a></h3><h4 id=offline-indexing-of-episode-vectors>Offline indexing of episode vectors<a hidden class=anchor aria-hidden=true href=#offline-indexing-of-episode-vectors>#</a></h4><p><a href=https://vespa.ai/>Vespa</a>を利用して検索インデックスを作成。また、episode の人気情報などに基づいた re-rank なども可能になる。</p><h4 id=online-query-encoding-and-retrieval>Online query encoding and retrieval<a hidden class=anchor aria-hidden=true href=#online-query-encoding-and-retrieval>#</a></h4><p>Google Cloud Vertex AI で、Query encoder がデプロイされておりクエリがベクトルに変換される。採用理由としては GPU インスタンスがサポートされおり過去の実験から GPU よりも T4 GPU のほうが 6 倍のコスト削減(この際のコストは費用?)を確認できたらしい。
クエリのベクトル生成後は Vespa により Top30 の意味的に相関が高いエピソードベクトルを検索する。またもちろんクエリのベクトル生成時にキャッシャは作成して同じクエリの encode は避けている。</p><h4 id=there-is-no-silver-bullet-in-retrieval>There is no silver bullet in retrieval<a hidden class=anchor aria-hidden=true href=#there-is-no-silver-bullet-in-retrieval>#</a></h4><p>自然言語検索は面白い性質を持つが、単語の一致をベースにした伝統的な検索手法に頻繁に検索精度としては劣る場合が発生する。また、計算コストとしても、とても高くなりがちである。
これらの事実から Vespa による自然言語検索で既存の検索システムを置き換えるよりむしろ、追加のデータソースとして扱うようにした。</p><p>Spotify の検索では最終段階の re-ranking モデルを運用しており、Elasticsearch, Vespa, 他のデータソースを元に re-ranking を行い最終的なランキング結果を顧客に提示している。</p><h3 id=conclusion-and-future-works>Conclusion and future works<a hidden class=anchor aria-hidden=true href=#conclusion-and-future-works>#</a></h3><p>結果として、vespa による自然言語検索をデータソースとして導入することで A/B テストでは有意に Podcast のエンゲージメント指標が向上した。そして初期の自然言語検索システムはほぼすべての顧客に提供されておりモデルの改善も進んでいる。</p><hr><p><a href=https://www.aicrowd.com/challenges/esci-challenge-for-improving-product-search>Amazon KDD Cup 2022</a></p><p>Amazon が製品検索改善の競技コンペを KDD2022 で開催。データセットは英語・日本語・スペイン語で公開。</p><p>タスクは 3 種類</p><ul><li>Query-Product Ranking: クエリと製品のマッチングのランキングを行う。評価指標は<code>nDCG</code></li><li>Multiclass Product Classification: クエリと製品のペアが Exact(E)・Substitute(S)・Complement(C)・Irrelevant(I) のなかでどの関係性になっているかを予測する。<ul><li>Exact(一致): その商品はクエリと関連(relevant)しており、そのクエリは商品の使用を満たすクエリになっている。例)「プラスチックウォーターボトル 24L」 にクエリに記された仕様を満たすウォーターボトルの製品が出ている。</li><li>Substitute(代替): その商品とクエリはやや関連している。完全に関連はしていないが、マッチした商品は機能的に同じものである。例)「セーター」というクエリに「フリース」の製品</li><li>Complement(補完): クエリの対して商品は関連していないが、関連した商品と組み合わせて使用できる商品。例)「ランニングシューズ」のクエリに対して、「トラックパンツ」の製品</li><li>Irrelevant(非関連): クエリに対して関連性がない。例) 「パンツ」のクエリに対して、「ソックス」の製品</li></ul></li><li>Product Substitute Identification: クエリと製品が Substitute の関係かどうかを予測する 2 値の予測問題。2 番目のタスクの Multiclass Product Classification と入力形式は同一で、Substitute かどうかを当てるのみになっている。</li></ul><p><a href=https://aws.amazon.com/jp/blogs/machine-learning/how-amazon-search-achieves-low-latency-high-throughput-t5-inference-with-nvidia-triton-on-aws/>How Amazon Search achieves low-latency, high-throughput T5 inference with NVIDIA Triton on AWS | AWS Machine Learning Blog</a></p><p>Nvidia の Trion server(旧名は TensorRT Inference Server という名前だった)の実証実験をしてみたよという記事。プロダクション環境下での AB テストはしていないので、単なる性能実験でしかないが、将来的に機械学習の推論を Trion server でサービングしたいとのこと。</p><p><a href=https://aws.amazon.com/jp/blogs/machine-learning/enable-amazon-kendra-search-for-a-scanned-or-image-based-text-document/>Enable Amazon Kendra search for a scanned or image-based text document | AWS Machine Learning Blog</a></p><p>今回始めて知ったんですが、Amazon Kendra という、自然言語的なクエリでも検索可能な AWS の検索サービスがあるらしいです。
この記事は、手元のスキャンした書類や画像、PDF や画像などを AWS Lambda を介して、Amazon Textract という API で文書化。
その後 S3 起点で Amazon Kandera にその情報を同期させて検索可能にできるよという紹介記事。
社内の紙の書類なども検索可能になるという発想は面白い。</p><p><a href=https://engineering.mercari.com/blog/entry/20220311-97aec2a2f8/>Elasticsearch 運用ノウハウ - メルカリ</a></p><p>メルカリでの Elasticsearch の運用方法をまとめた記事。
最近メルカリの検索の内側を紹介する記事が増えているので良いことですね。
インデックスの管理方法や、Elasticsearch の各種設定を調整方法などが説明されています。</p><p><a href=https://tech.ebayinc.com/engineering/building-a-deep-learning-based-retrieval-system-for-personalized-recommendations>Building a Deep Learning Based Retrieval System for Personalized Recommendations</a></p><p>1.5 億の顧客と 15 億を超えるアクティブな出品商品がある eBay で、深層学習ベースの推薦システムをどう作り上げたかの解説。</p><ol><li>オフラインでのバッチ</li><li>オフラインとニアリアルタイム(NRT)のハイブリッド</li><li>ニアリアルタイム</li></ol><p>のレベルで段階的にどのように作り上げていったかの説明をしており、愚直に地道に作り上げた話から学びが多く良記事。</p><p>モデルの詳細は KDD2021 の推薦システムに関するワークショップ <a href=https://irsworkshop.github.io/2021/>IRS workshop 2021</a> で発表されている<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>。
2-tower でモデルは構成されており、1 つめのタワーで商品、もう一つのタワーでユーザーの埋め込み空間を獲得。
与えられた <code>user_id</code> の k 個の ANN による近似近傍探索の商品を返す。</p><p>段階を経て、バッチ処理からストリーミング処理に変遷するのはお疲れさまでした感が凄い。
非常に気になる話としては、バッチ処理からニアリアルタイムでのストリーミング処理に置き換えて、それに見合う成果がどれほどでているのかは表に出して欲しい~。</p><p>論文<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>では、モデルの投入によってコールドスタートや在庫なしの課題を有意に改善できたとのこと。
読んだ感じだとこの論文執筆時では 1 段階目のバッチ処理のアーキテクチャっぽい。</p><p><a href=https://medium.com/pinterest-engineering/searchsage-learning-search-query-representations-at-pinterest-654f2bb887fc>SearchSage: Learning Search Query Representations at Pinterest</a></p><p>画像検索に強みを持つ Pinretest が、検索システムにテキスト検索と埋め込みでの検索を混ぜることで Top35 の検索結果で 11% CTR を向上させたとのころ。
モデル構成は two-tower らしく、どこもかしこも two-tower を使っている気がする。
モデルの Serving には、TensorFlowServing 上で構築された内製の C++の推論サーバーで運用しているらしくすごくテッキーというか Pinterest らしい構成。
学習は Python、推論は C++で計算コスト効率を目指すことを念頭に置いて、 前処理のために PyTorch の C++オペレータを使用している。(凄い、小並感)
技術的な面の追求だけでなく、ビジネス的な数値もしっかりとリフトさせているのが Pinterest の凄いところですね。</p><p><a href=https://engineering.linkedin.com/blog/2022/near-real-time-features-for-near-real-time-personalization>Near real-time features for near real-time personalization</a></p><p>Linkedin でのニアリアルタイムでの推薦システム構築の記事。
Table 1.の表のデータが面白く、仕事の推薦モデルに対して応募状況のデータの遅延影響が、どれくらいモデルの精度に影響するかのシミュレーション結果を公開してくれている。
1 分の遅延をベースラインにして、1 時間で 3.51%の ROC-AUC の低下、24 時間で 4.45%まで低下するらしい。
こういう遅延が定量的にどれくらい損益を与えているかを測定しているのは科学をちゃんとしていて、非常に尊敬。
リアルタイムにデータを提供できることで、各種推薦システムも軒並み数値をリフトしており、まさに速さこそ正義<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>状態になっている。</p><p>また記事の締めくくりに</p><blockquote><p>Short development cycle helps. Successful completion of this initiative required several iterations. Our short development cycle allowed fast iterations. This was in a big part due to prior investments in scaling machine learning productivity, our experimentation platform, and continuous deployment.</p></blockquote><p>基盤への投資によって開発サイクルが短縮され、高速な反復が実現できたんだよ
とものすごく良い話を聞けた。
Linkedin のこの事例は、モデル構築然り、データエンジニアリング、その後の測定などなど、複雑な要素が絡みあうプロジェクトなので基盤への投資による生産性の底上げってのはものすごく効きそうですね。</p><p><a href=https://techblog.zozo.com/entry/basics-of-elasticsearch-ltr-plugin-and-feature-score-cache>Elasticsearch LTR プラグインと特徴量キャッシュ機能の基本</a></p><p>Elasticsearch で Learning to Rank(LTR)を行うことができるプラグインの詳細。
特徴量キャッシュの PR を作成して本体にマージされているのカッコよすぎますね。
Yahoo さんのこの底力は毎回凄い。人材の層が厚いですね。</p><p><a href=https://engineering.mercari.com/blog/entry/20220311-9a1103aed1/>メルカリ Shops の検索改善とそれを支える AB テストの仕組み</a></p><p>メルカリ Shops での検索を、メルカリ上での検索とどうインテグレーションしているかの紹介記事。</p><p><a href=https://inside.dmm.com/entry/2022/4/7/engineer-search>DMM の検索改善専門チームが教える！ 検索改善に向けた考え方から効果検証まで - DMM inside</a></p><p>検索改善の考え方や向き合い方についての記事。
検索改善で、システム面ではなく仮説検証から AB テストまでのメタ的な枠組みを文章化して説明してくれている記事は良い意味で珍しい気がします。
DMM さんは最近、検索や推薦領域でおもしろい記事をたくさん書いてくれていてありがたいですね。</p><p><a href=https://inside.dmm.com/entry/2022/3/22/engineer-recommend>大規模サービスで効率よくレコメンドを提供するために Tensorflow Recommenders を活用する - DMM inside</a></p><p>DMM さんによる、<a href=https://github.com/tensorflow/recommenders>tensorflow/recommenders</a> を活用した推薦事例紹介記事。
既にサービスに導入しているらしく、プロダクションで運用されているのは率直に素晴らしいなと思いました。</p><h2 id=data-science--machine-learning>Data Science & Machine Learning<a hidden class=anchor aria-hidden=true href=#data-science--machine-learning>#</a></h2><p><a href=https://eng.uber.com/deepeta-how-uber-predicts-arrival-times/>DeepETA: How Uber Predicts Arrival Times Using Deep Learning</a></p><p>Uber で到着予想時刻(estimated time of arrival: ETA)をどうやって予測しているかの紹介記事。Uber の事業領域としてこの ETA 予測はすべての顧客体験に根本的な影響を及ぼすほど重要なモデルである。</p><p>Uber は数年前から GBDT のモデルを ETA 予測に採用しており、モデルの更新のたびに学習データは着実に巨大化しており、それらをさばくために XGBoost に<a href=https://github.com/dmlc/xgboost/issues/4250>分散学習の PR</a>を作成したりと XGBoost へのかなりのコントリビューションを行っている。</p><p>だが、リアルタイムの交通指標や地図情報などを特徴量として使った深層学習ベースの DeepETA とよばれるモデルの開発を開始した。
考慮すべき点として、Uber のリクエスト規模をさばくことが可能な高速なモデルが求められる。
モデルの軽量化も工夫が凝らされており、これだけ頑張らないとプロダクションに載せられないんだろうなとハラハラした気持ちで読んでいた。</p><p>DeepETA のモデルは内製基盤の Michelangelo で運用されており、実際に XGBoost と比較しても良好な結果が得られたのこと。</p><p>XGBoost から DeepETA へ移行した経緯を読み取ってみると、深層学習を使うに値する規模のデータが収集してそれらを活かせる環境も整ったから移行したのかなと個人的には思った。
結論でも書かれているが、モデル自体はこれからもいろんなアプローチで改善していくぜと書いてあるので、将来的な改善幅に投資したのでしょう。
現状維持よりもさらなる改善を見据えた投資を行っているのが素晴らしい。</p><p>&mldr;と思っていたら、 DeepETA の Product Manager<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup> の方の Linkedin を見ていると、DeepETA により</p><blockquote><p>In 2021, I helped my team land +$100M of incremental revenue through shipping Deep Learning ETA models, XX% improvements to delivery time estimate accuracy, etc.</p></blockquote><p>と書かれており、100 億円以上の利益向上と書かれており、ギエピーとなりました。
やはり規模の経済&mldr;。レバレッジが効くところに機械学習をブッこむべきですね。</p><p><a href=https://blog.tensorflow.org/2022/03/how-linkedin-personalized-performance.html>How LinkedIn Personalized Performance for Millions of Members using Tensorflow.js — The TensorFlow Blog</a></p><p>Linkedin は<a href=https://engineering.linkedin.com/blog/2018/03/linkedin-lite--a-lightweight-mobile-web-experience>Linkedin Lite</a>というプロジェクトの一環で、クライアントの状況を Performance Quality Model (PQM)<sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup>と呼ばれる機械学習モデルで予測を行い</p><ul><li>ハイエンドかつネットワーク状況が良好なクライアント: 画像をそのまま提供</li><li>ローエンドかつネットワーク状況が良好でないクライアント: 低解像度の画像を提供</li></ul><p>を識別することで状況に応じた最適な web ページをクライアントに返す実験を行った。
その結果、フィードでの数値が大幅に向上させることができた。
動的な配信するアセットを変更するというアイデア、痺れますね。
これもまた速さこそ正義<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>案件。</p><p>そして、そのモデルをどのようにデプロイしたかがこの記事で書かれているのだが、TensorFlow Serving などを使わずに TensorFlow.js でサービング環境を運用しているらしくとてもユニークな記事になっている。</p><p>TensorFlow.js の選定理由としては、まず当時の Linkedin では、TensorFlow の運用状況が成熟しているとは言い難く、 TensorFlow Serving を運用する選択肢は無かった。
Linkedin 内では JVM スタックがメインだったが、Node.js をフロントエンドとして運用していたので、Node.js で動く TensorFlow.js が採用された。
だが、実際には Python も TensorFlow の運用環境として採用可能だったが、Node.js を選んだ理由として語られているのが、</p><ul><li>既に Node.js の環境を構築済だった</li><li>Python よりも Node.js での TensorFlow の 50 percentile が 8%ほど高速だった。</li></ul><p>という２つの理由かららしい。この結果は面白く、TensorFlow のレスポンス速度は Node.js のほうが Python よりも早かったのかと驚いた。
もちろんモデルのアーキテクチャや他の条件などにも夜がそれらを踏まえても面白い結果だ。</p><p><a href=https://jedworkshop.github.io/jed2022/>日本語における評価用データセットの構築と利用性の向上（JED2022） | NLP2022 Workshop on Japanese Evaluation Dataset</a></p><blockquote><p>日本語における評価用データセットの構築手法そのものに加えて，データセットの公開方式・利用性の高い著作権設定・タスクの複合化といった応用を容易にするための研究を集めて議論することで，日本語データセット公開の流れを加速し，日本語 NLP 業界全体のさらなる発展および生産性向上につなげていきたい．</p></blockquote><p>素晴らしいワークショップが NLP2022 で開催されていました。
知らない日本語のデータセットも知れたり、法的な取り組みも知れたりと学びの多い資料が多い。
日本語データセットの拡充は、まさに日本語自然言語の発展を促進させるので、自分も貢献したいなぁと思っている。 2023 年にも JED2023 が開催されるらしいので楽しみにしています。</p><h2 id=感想など>感想など<a hidden class=anchor aria-hidden=true href=#感想など>#</a></h2><p>Twitter で <a href="https://twitter.com/hashtag/searchengineeringnewsletter?f=live">#searchengineeringnewsletter</a> のハッシュタグでつぶやいていただくか、
<a href=https://forms.gle/xFgMwRJbeqJxNtfe9>Google フォーム</a> での感想投稿をお待ちしております。</p><p>投稿の励みにさせていただきます。</p><h2 id=search-engineering-newsletter-の購読方法>Search Engineering Newsletter の購読方法<a hidden class=anchor aria-hidden=true href=#search-engineering-newsletter-の購読方法>#</a></h2><p>配信記事が蓄積される RSS<sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup> を作成しています。</p><p>また、今までの配信記事一覧もこちら<sup id=fnref:6><a href=#fn:6 class=footnote-ref role=doc-noteref>6</a></sup>から閲覧できます。</p><section class=footnotes role=doc-endnotes><hr><ol><li id=fn:1 role=doc-endnote><p><a href=https://irsworkshop.github.io/2021/publications/IRS2021_paper_14.pdf>Personalized Embedding-based e-Commerce Recommendations at eBay</a>, <a href=https://youtu.be/THwyB1gQrxs>YouTube</a> <a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2 role=doc-endnote><p>速さ事正義を示す実験事例 <a href=/posts/2021-08-13/>システムの応答速度は本質的な価値提供であることを示す A/B テストの実例</a> <a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3 role=doc-endnote><p><a href=https://www.linkedin.com/in/wataru-ueno/>https://www.linkedin.com/in/wataru-ueno/</a> <a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4 role=doc-endnote><p>OSS で公開されていた <a href=https://github.com/linkedin/performance-quality-models>https://github.com/linkedin/performance-quality-models</a> <a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5 role=doc-endnote><p>newsletter RSS: <a href=https://shunyaueta.com/tags/newsletter/index.xml>https://shunyaueta.com/tags/newsletter/index.xml</a> <a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:6 role=doc-endnote><p><a href=https://shunyaueta.com/tags/newsletter/>https://shunyaueta.com/tags/newsletter/</a> <a href=#fnref:6 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></section><h2>See Also</h2><ul><li><a href=/posts/2022-04-07/>Search Engineering Newsletter vol.04</a></li><li><a href=/posts/2022-03-28/>Search Engineering Newsletter vol.03</a></li><li><a href=/posts/2022-02-09/>Search Engineering Newsletter vol.02</a></li><li><a href=/posts/2022-01-21/>Search Engineering Newsletter vol.01</a></li><li><a href=/posts/2022-01-16/>Search Engineering Newsletter vol.00</a></li></ul><h2>Support</h2>記事をお読みくださりありがとうございます。このウェブサイトの運営を支援していただける方を募集しています。
もしよろしければ、下のボタンからサポート(投げ銭)していただけると、ブログ執筆、情報発信のモチベーションに繋がります✨
<a href=https://www.buymeacoffee.com/hurutoriya><img src="https://img.buymeacoffee.com/button-api/?text=Buy me a coffee&emoji=☕&slug=hurutoriya&button_colour=FFDD00&font_colour=000000&font_family=Inter&outline_colour=000000&coffee_colour=ffffff"></a></div><footer class=post-footer><ul class=post-tags><li><a href=https://shunyaueta.com/tags/newsletter/>newsletter</a></li><li><a href=https://shunyaueta.com/tags/search/>search</a></li></ul><nav class=paginav><a class=prev href=https://shunyaueta.com/posts/2022-05-04-2243/><span class=title>« 前のページ</span><br><span>2022年、はじめてのまともな確定申告</span></a>
<a class=next href=https://shunyaueta.com/posts/2022-04-28-2114/><span class=title>次のページ »</span><br><span>gRPCurl で `Failed to process proto source files.: could not parse given files:` エラーが出たときの対処方法</span></a></nav></footer><script src=https://giscus.app/client.js data-repo=hurutoriya/hurutoriya.github.io data-repo-id="MDEwOlJlcG9zaXRvcnk2MDgyNTY1Nw==" data-category=Comments data-category-id=DIC_kwDOA6AgOc4CAQTX data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=0 data-theme=dark data-lang=ja crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2022 <a href=https://shunyaueta.com/>🦅 hurutoriya</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z" /></svg></a><script>let menu=document.getElementById('menu')
if(menu){menu.scrollLeft=localStorage.getItem("menu-scroll-position");menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft);}}
document.querySelectorAll('a[href^="#"]').forEach(anchor=>{anchor.addEventListener("click",function(e){e.preventDefault();var id=this.getAttribute("href").substr(1);if(!window.matchMedia('(prefers-reduced-motion: reduce)').matches){document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({behavior:"smooth"});}else{document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();}
if(id==="top"){history.replaceState(null,null," ");}else{history.pushState(null,null,`#${id}`);}});});</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){if(document.body.scrollTop>800||document.documentElement.scrollTop>800){mybutton.style.visibility="visible";mybutton.style.opacity="1";}else{mybutton.style.visibility="hidden";mybutton.style.opacity="0";}};</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{if(document.body.className.includes("dark")){document.body.classList.remove('dark');localStorage.setItem("pref-theme",'light');}else{document.body.classList.add('dark');localStorage.setItem("pref-theme",'dark');}})</script><script>document.querySelectorAll('pre > code').forEach((codeblock)=>{const container=codeblock.parentNode.parentNode;const copybutton=document.createElement('button');copybutton.classList.add('copy-code');copybutton.innerText='copy';function copyingDone(){copybutton.innerText='copied!';setTimeout(()=>{copybutton.innerText='copy';},2000);}
copybutton.addEventListener('click',(cb)=>{if('clipboard'in navigator){navigator.clipboard.writeText(codeblock.textContent);copyingDone();return;}
const range=document.createRange();range.selectNodeContents(codeblock);const selection=window.getSelection();selection.removeAllRanges();selection.addRange(range);try{document.execCommand('copy');copyingDone();}catch(e){};selection.removeRange(range);});if(container.classList.contains("highlight")){container.appendChild(copybutton);}else if(container.parentNode.firstChild==container){}else if(codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"){codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);}else{codeblock.parentNode.appendChild(copybutton);}});</script></body></html>