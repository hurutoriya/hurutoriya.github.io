<!doctype html><html lang=ja><head><meta http-equiv=x-clacks-overhead content="GNU Terry Pratchett"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Apache Beam 2.40 ã§å°å…¥ã•ã‚ŒãŸ scikit-lean, Pytorch ã®åŠ¹ç‡çš„ãªæ¨è«–ãŒå¯èƒ½ã«ãªã‚‹ RunInference API ã‚’è©¦ã—ã¦ã¿ã‚‹ | hurutoriya</title><meta name=title content="Apache Beam 2.40 ã§å°å…¥ã•ã‚ŒãŸ scikit-lean, Pytorch ã®åŠ¹ç‡çš„ãªæ¨è«–ãŒå¯èƒ½ã«ãªã‚‹ RunInference API ã‚’è©¦ã—ã¦ã¿ã‚‹"><meta name=description content="2022-07-21 ã« Google Cloud ãŒ Cloud DataFlow ã®æ–°æ©Ÿèƒ½ã¨ã—ã¦ã€DataFlow ML ã¨ã„ã†æ–°æ©Ÿèƒ½ã‚’ç™ºè¡¨ã—ãŸã€‚1
Dataflow MLÂ - Speaking of ML transforms, Dataflow now has added out of the box support for running PyTorch and scikit-learn models directly within the pipeline. The new RunInference transform enables simplicity by allowing models to be used in production pipelines with very little code. These features are in addition to Dataflow&rsquo;s existing ML capabilities such asÂ GPU supportÂ and the pre and post processing system for ML training, either directly or via frameworks such asÂ Tensorflow Extended (TFX)."><meta name=keywords content="apachebeam,machinelearning,python,"><meta property="og:title" content="Apache Beam 2.40 ã§å°å…¥ã•ã‚ŒãŸ scikit-lean, Pytorch ã®åŠ¹ç‡çš„ãªæ¨è«–ãŒå¯èƒ½ã«ãªã‚‹ RunInference API ã‚’è©¦ã—ã¦ã¿ã‚‹"><meta property="og:description" content="2022-07-21 ã« Google Cloud ãŒ Cloud DataFlow ã®æ–°æ©Ÿèƒ½ã¨ã—ã¦ã€DataFlow ML ã¨ã„ã†æ–°æ©Ÿèƒ½ã‚’ç™ºè¡¨ã—ãŸã€‚1
Dataflow MLÂ - Speaking of ML transforms, Dataflow now has added out of the box support for running PyTorch and scikit-learn models directly within the pipeline. The new RunInference transform enables simplicity by allowing models to be used in production pipelines with very little code. These features are in addition to Dataflow&rsquo;s existing ML capabilities such asÂ GPU supportÂ and the pre and post processing system for ML training, either directly or via frameworks such asÂ Tensorflow Extended (TFX)."><meta property="og:type" content="article"><meta property="og:url" content="https://shunyaueta.com/posts/2022-08-18-1938/"><meta property="og:image" content="https://shunyaueta.com/ogp.jpg"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-08-18T19:38:29+09:00"><meta property="article:modified_time" content="2022-08-18T19:38:29+09:00"><meta property="og:site_name" content="hurutoriya"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://shunyaueta.com/ogp.jpg"><meta name=twitter:title content="Apache Beam 2.40 ã§å°å…¥ã•ã‚ŒãŸ scikit-lean, Pytorch ã®åŠ¹ç‡çš„ãªæ¨è«–ãŒå¯èƒ½ã«ãªã‚‹ RunInference API ã‚’è©¦ã—ã¦ã¿ã‚‹"><meta name=twitter:description content="2022-07-21 ã« Google Cloud ãŒ Cloud DataFlow ã®æ–°æ©Ÿèƒ½ã¨ã—ã¦ã€DataFlow ML ã¨ã„ã†æ–°æ©Ÿèƒ½ã‚’ç™ºè¡¨ã—ãŸã€‚1
Dataflow MLÂ - Speaking of ML transforms, Dataflow now has added out of the box support for running PyTorch and scikit-learn models directly within the pipeline. The new RunInference transform enables simplicity by allowing models to be used in production pipelines with very little code. These features are in addition to Dataflow&rsquo;s existing ML capabilities such asÂ GPU supportÂ and the pre and post processing system for ML training, either directly or via frameworks such asÂ Tensorflow Extended (TFX)."><meta itemprop=name content="Apache Beam 2.40 ã§å°å…¥ã•ã‚ŒãŸ scikit-lean, Pytorch ã®åŠ¹ç‡çš„ãªæ¨è«–ãŒå¯èƒ½ã«ãªã‚‹ RunInference API ã‚’è©¦ã—ã¦ã¿ã‚‹"><meta itemprop=description content="2022-07-21 ã« Google Cloud ãŒ Cloud DataFlow ã®æ–°æ©Ÿèƒ½ã¨ã—ã¦ã€DataFlow ML ã¨ã„ã†æ–°æ©Ÿèƒ½ã‚’ç™ºè¡¨ã—ãŸã€‚1
Dataflow MLÂ - Speaking of ML transforms, Dataflow now has added out of the box support for running PyTorch and scikit-learn models directly within the pipeline. The new RunInference transform enables simplicity by allowing models to be used in production pipelines with very little code. These features are in addition to Dataflow&rsquo;s existing ML capabilities such asÂ GPU supportÂ and the pre and post processing system for ML training, either directly or via frameworks such asÂ Tensorflow Extended (TFX)."><meta itemprop=datePublished content="2022-08-18T19:38:29+09:00"><meta itemprop=dateModified content="2022-08-18T19:38:29+09:00"><meta itemprop=wordCount content="645"><meta itemprop=image content="https://shunyaueta.com/ogp.jpg"><meta itemprop=keywords content="apachebeam,machinelearning,python,"><meta name=referrer content="no-referrer-when-downgrade"><style>body{font-family:Verdana,sans-serif;margin:auto;padding:20px;max-width:720px;text-align:left;background-color:#fff;word-wrap:break-word;overflow-wrap:break-word;line-height:1.5;color:#444}h1,h2,h3,h4,h5,h6,strong,b{color:#222}a{color:#3273dc}.title{text-decoration:none;border:0}.title span{font-weight:400}nav a{margin-right:10px}textarea{width:100%;font-size:16px}input{font-size:16px}content{line-height:1.6}table{width:100%}img{max-width:100%}code{padding:2px 5px;background-color:#f2f2f2}pre code{color:#222;display:block;padding:20px;white-space:pre-wrap;font-size:14px;overflow-x:auto}div.highlight pre{background-color:initial;color:initial}div.highlight code{background-color:unset;color:unset}blockquote{border-left:1px solid #999;color:#222;padding-left:20px;font-style:italic}footer{padding:25px;text-align:center}.helptext{color:#777;font-size:small}.errorlist{color:#eba613;font-size:small}ul.blog-posts{list-style-type:none;padding:unset}ul.blog-posts li{display:flex}ul.blog-posts li span{flex:0 0 130px}ul.blog-posts li a:visited{color:#8b6fcb}@media(prefers-color-scheme:dark){body{background-color:#333;color:#ddd}h1,h2,h3,h4,h5,h6,strong,b{color:#eee}a{color:#8cc2dd}code{background-color:#777}pre code{color:#ddd}blockquote{color:#ccc}textarea,input{background-color:#252525;color:#ddd}.helptext{color:#aaa}}</style><script async src="https://www.googletagmanager.com/gtag/js?id=G-JMJRQJT0Q3"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-JMJRQJT0Q3")</script></head><body><header><a href=/ class=title><h2>hurutoriya</h2></a><nav><a href=/index.xml>RSS</a>
<a href=/about/>è‘—è€…ã«ã¤ã„ã¦</a></nav></header><main><h1>Apache Beam 2.40 ã§å°å…¥ã•ã‚ŒãŸ scikit-lean, Pytorch ã®åŠ¹ç‡çš„ãªæ¨è«–ãŒå¯èƒ½ã«ãªã‚‹ RunInference API ã‚’è©¦ã—ã¦ã¿ã‚‹</h1><p><i><time datetime=2022-08-18 pubdate>2022-08-18</time></i></p><content><p><code>2022-07-21</code> ã« Google Cloud ãŒ Cloud DataFlow ã®æ–°æ©Ÿèƒ½ã¨ã—ã¦ã€DataFlow ML ã¨ã„ã†æ–°æ©Ÿèƒ½ã‚’ç™ºè¡¨ã—ãŸã€‚<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></p><blockquote><p><strong>Dataflow ML</strong>Â - Speaking of ML transforms, Dataflow now has added out of the box support for running PyTorch and scikit-learn models directly within the pipeline. The new RunInference transform enables simplicity by allowing models to be used in production pipelines with very little code. These features are in addition to Dataflow&rsquo;s existing ML capabilities such asÂ <a href=https://cloud.google.com/dataflow/docs/guides/using-gpus>GPU support</a>Â and the pre and post processing system for ML training, either directly or via frameworks such asÂ <a href=https://www.tensorflow.org/tfx>Tensorflow Extended (TFX)</a>.</p></blockquote><p>DataFlow ã¯ Apache Beam ã§è¨˜è¿°ã—ãŸãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®å®Ÿè¡Œç’°å¢ƒã ã€‚
ä¸»ã«ã€ãƒãƒƒãƒå‡¦ç†ãƒ»ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã§ä½¿ã‚ã‚Œã¦ãŠã‚Šã€æ©Ÿæ¢°å­¦ç¿’ã«æ¬ ã‹ã›ãªã„ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®è¦³ç‚¹ã‹ã‚‰ã—ã¦éå¸¸ã«é¢ç™½ã„ã¨æ€ã£ã¦ã„ã‚‹ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ãªã®ã§ã€ç©æ¥µçš„ã«å‹•å‘ã‚’è¿½ã£ã¦ã„ã‚‹ã€‚</p><p>DataFlow ML ã¯ç°¡å˜ã«èª¬æ˜ã™ã‚‹ã¨ã€PyTorch ã¨ scikit-learn ãŒ Dataflow ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å†…éƒ¨ã§ç›´æ¥æ¨è«–å¯èƒ½ã«ãªã£ãŸã€‚
ç›´è¿‘ã§ã¯ Python SDK ã«é™ã‚‹ãŒ DataFlow ã§ GPU ã®åˆ©ç”¨ãŒå¯èƒ½ã«ãªã£ãŸã‚Šã¨ã€å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚„æ©Ÿæ¢°å­¦ç¿’ã‚’è¡Œã†éš›ã«é­…åŠ›çš„ãªæ©Ÿèƒ½ãŒç¶šã€…ã¨ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¯ã˜ã‚ãŸã€‚
DataFlow ML ã®å®Ÿæ…‹ã¯ <a href=https://beam.apache.org/blog/beam-2.40.0>Apache Beam 2.40.0</a>ã§è¿½åŠ ã•ã‚ŒãŸ RunInference API ã ã€‚
RunInference API ã® DesignDocs <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>ãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€ãã‚Œã‚’è¦‹ã¦ã¿ã‚‹ã€‚
æ©Ÿæ¢°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã® DesignDocs ã¨ã—ã¦éå¸¸ã«é¢ç™½ã„ã®ã§èˆˆå‘³ãŒã‚ã‚‹äººã¯ã€è¦‹ã¦ã¿ã‚‹ã¨é¢ç™½ã„ã¨ãŠã‚‚ã†ã€‚</p><h2 id=designdocs-runinference-ml-inference-in-beam>DesignDocs: RunInference: ML Inference in Beam</h2><p>RunInference API ãŒä½œã‚‰ã‚ŒãŸèƒŒæ™¯ã¨ã—ã¦ã€TensorFlow ã ã‘ãŒ Beam å†…éƒ¨ã§ã€å‡¦ç†ã™ã‚‹ãƒ‡ãƒ¼ã‚¿( Apache beam ã§ã¯<code>PCollection</code> ã¨å‘¼ã°ã‚Œã‚‹) ã«å¯¾ã—ã¦ã€æ¨è«–ã‚’è¡Œã†ãŸã‚ã® <a href=https://github.com/tensorflow/tfx-bsl/blob/master/tfx_bsl/beam/run_inference.py>RunInference transformer</a> (Apache Beam ã§ã¯ <code>PTransform</code>ã¨å‘¼ã°ã‚Œã€<code>PCollection</code> ã‚’å…¥åŠ›ã¨ã—ã¦å‡¦ç†ã‚’è¡Œã†) ãŒå­˜åœ¨ã—ã¦ãŠã‚Šã€å®Ÿè£…ä¸è¦ã ã£ãŸã€‚</p><ul><li>å•é¡Œç‚¹ã¨ã—ã¦ã¯<ul><li>Beam ã®ãƒ¬ãƒã‚¸ãƒˆãƒªã«å­˜åœ¨ã›ãšã€<a href=https://github.com/tensorflow/tfx-bsl>tensorflow/tfx-bsl</a>ã®ãƒªãƒã‚¸ãƒˆãƒªã«å­˜åœ¨ã—ã¦ã„ã‚‹ã€‚</li><li>TFX ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«ç‰¹åŒ–ã—ãŸ API ã«ãªã£ã¦ã„ã‚‹</li><li>ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ãŒå……å®Ÿã—ã¦ãŠã‚‰ãšã€å­¦ç¿’ã‚³ã‚¹ãƒˆãŒé«˜ã„</li></ul></li></ul><p>ã“ã® DesignDocs ã®ç›®çš„ã¯ã€RunInference API ã‚’ä»¥ä¸‹ã® 2 ã¤ã®äººæ°—ã®ã‚ã‚‹æ©Ÿæ¢°å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ä½¿ãˆã‚‹ã‚ˆã†ã«å®Ÿè£…ã™ã‚‹ã“ã¨</p><ul><li>scikit-learn</li><li>PyTorch</li></ul><p>å®Ÿè£…æ–¹æ³•ã¨ã—ã¦ã¯ã€</p><ul><li>å†…éƒ¨ã®æœ€é©åŒ–ãŒè¡Œã‚ã‚Œã¦ã„ã‚‹ã¹ã</li><li>å˜ç´”ã‹ã¤çµ±åˆã•ã‚ŒãŸã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ã‚¤ã‚¹ã§æä¾›ã•ã‚Œã‚‹ã¹ã</li><li>å…¥åŠ›ã¨å‡ºåŠ›ãŒã€æ©Ÿæ¢°å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã«å¯¾ã—ã¦ã€ç›´æ„Ÿçš„ãªå‹ã«ãªã£ã¦ã„ã‚‹ã¹ã<ul><li>scikit-learn ãªã‚‰ numpy</li><li>PyTorch ãªã‚‰ Tensors</li></ul></li></ul><p>æœ€çµ‚çš„ãªã‚´ãƒ¼ãƒ«ã¨ã—ã¦ã¯ã€XGBoost ã‚„ JAX ãªã©ä»–ã®æ©Ÿæ¢°å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ã‚‚é©åˆã—ãŸã‚Šã€Vertex AI ãªã©å¤–éƒ¨ã®ã‚µãƒ¼ãƒ“ã‚¹ã‚‚ä½¿ãˆã‚‹ã‚ˆã†ã«ã—ãŸã„ã€‚</p><p>å†…éƒ¨ã®å®Ÿè£…æ–¹é‡ã¯ DesignDocs ã§è©³ç´°ã«è­°è«–ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€ãã“ã¯å‰²æ„›ã—ã¦ã€ã¾ãšã¯ RunInference API ã®ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã‚’å‹•ã‹ã—ã¦ã¿ã‚‹ã€‚</p><h2 id=ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã‚’é€šã˜ã¦å­¦ã¶>ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã‚’é€šã˜ã¦å­¦ã¶</h2><p><a href=https://github.com/apache/beam/tree/master/sdks/python/apache_beam/examples/inference>Example RunInference API pipelines</a>ã«ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ãŒå…¬é–‹ã•ã‚Œã¦ã„ãŸã®ã§ã€å‹•ã‹ã—ã¦ã¿ã‚‹ã€‚
ã¾ãšã¯ä¸€ç•ªç°¡å˜ãã†ãªã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã§ã‚ã‚‹ scikit-learn ã«ã‚ˆã‚‹ MNIST åˆ†é¡ã‚’å‹•ã‹ã—ã¦ã¿ã‚‹ã€‚
æœ€åˆã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã˜ã£ãã‚Šèª­ã‚€ã‚ˆã‚Šã‚‚å®Ÿéš›ã«ã‚³ãƒ¼ãƒ‰ã‚’è¦‹ãŸã»ã†ãŒç†è§£ãŒæ·±ã¾ã‚‹ã®ã§å®Ÿéš›ã«å‹•ã‹ã—ã¦ã¿ã‚‹ã®ãŒè¿‘é“ã€‚
ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã¯ã“ã¡ã‚‰<a href=https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/inference/sklearn_mnist_classification.py>beam/sdks/python/apache_beam/examples/inference/sklearn_mnist_classification.py</a>
å…¬å¼ã®ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã ã¨ã€æ¨è«–å¯¾è±¡ã®å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã¨å­¦ç¿’æ¸ˆã¿ã® scikit-learn ã®ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‰ã§ç”¨æ„ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã®ã§ã‚³ãƒãƒ³ãƒ‰ä¸€ç™ºã§ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã‚’å‹•ã‹ã›ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’ä»¥ä¸‹ã®ãƒ¬ãƒã‚¸ãƒˆãƒªã«å…¬é–‹ã—ã¾ã—ãŸã€‚
å°†æ¥çš„ã«ã¯ scikit-learn ã ã‘ã§ãªãã€PyTorch ã«ã‚‚å¯¾å¿œã—ãŸã„ã€‚</p><p><a href=https://github.com/hurutoriya/beam-runinferenceapi-sample>https://github.com/hurutoriya/beam-runinferenceapi-sample</a></p><p>å®Ÿéš›ã«ä½•ã‚’ã‚„ã£ã¦ã„ã‚‹ã‹ã®è§£èª¬ã¯ã€æ—¥æœ¬èªã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’æ·»ãˆã¦è§£èª¬ã—ã¦ã¿ã¾ã™ã€‚</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#e6db74>&#34;&#34;&#34;ã“ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯ã€RunInference APIã‚’ä½¿ã£ã¦ã€MNISTãƒ‡ãƒ¼ã‚¿ã®åˆ†é¡ã‚’è¡Œã†ã€‚
</span></span></span><span style=display:flex><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>ã“ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯ã€int å½¢å¼ã§CSVå½¢å¼ã§ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã€‚CSVã®ï¼‘ã¤ç›®ã®åˆ—ã¯ãƒ©ãƒ™ãƒ«ã€ãã®ã»ã‹ã®åˆ—ã¯MNISTã®ãƒ”ã‚¯ã‚»ãƒ«ã®å€¤ã‚’æ ¼ç´ã—ã¦ã„ã‚‹ã€‚ãƒ‡ãƒ¼ã‚¿ã¯å­¦ç¿’æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã§æ¨è«–ã•ã‚Œã‚‹ã€‚ã“ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯ output ãƒ•ã‚¡ã‚¤ãƒ«ã«æ¨è«–çµæœã®æ›¸ãè¾¼ã¿ã‚’è¡Œã„ã€ãƒ©ãƒ™ãƒ«ã¨æ¨è«–çµæœã®æ¯”è¼ƒã‚’è¡Œã†ã“ã¨ãŒã§ãã‚‹ã€‚
</span></span></span><span style=display:flex><span><span style=color:#e6db74>&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> argparse
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> typing <span style=color:#f92672>import</span> Iterable
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> typing <span style=color:#f92672>import</span> List
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> typing <span style=color:#f92672>import</span> Tuple
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> apache_beam <span style=color:#66d9ef>as</span> beam
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> apache_beam.ml.inference.base <span style=color:#f92672>import</span> KeyedModelHandler
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> apache_beam.ml.inference.base <span style=color:#f92672>import</span> PredictionResult
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> apache_beam.ml.inference.base <span style=color:#f92672>import</span> RunInference
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> apache_beam.ml.inference.sklearn_inference <span style=color:#f92672>import</span> ModelFileType
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> apache_beam.ml.inference.sklearn_inference <span style=color:#f92672>import</span> SklearnModelHandlerNumpy
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> apache_beam.options.pipeline_options <span style=color:#f92672>import</span> PipelineOptions
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> apache_beam.options.pipeline_options <span style=color:#f92672>import</span> SetupOptions
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>process_input</span>(row: str) <span style=color:#f92672>-&gt;</span> Tuple[int, List[int:
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;&#34;&#34;å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ©ãƒ™ãƒ«ã¨ãƒ”ã‚¯ã‚»ãƒ«ã«åˆ†ã‘ã¦ã€è¿”ã™
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>  data <span style=color:#f92672>=</span> row<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#39;,&#39;</span>)
</span></span><span style=display:flex><span>  label, pixels <span style=color:#f92672>=</span> int(data[<span style=color:#ae81ff>0</span>]), data[<span style=color:#ae81ff>1</span>:]
</span></span><span style=display:flex><span>  pixels <span style=color:#f92672>=</span> [int(pixel) <span style=color:#66d9ef>for</span> pixel <span style=color:#f92672>in</span> pixels]
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> label, pixels
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>PostProcessor</span>(beam<span style=color:#f92672>.</span>DoFn):
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;&#34;&#34;äºˆæ¸¬ãƒ©ãƒ™ãƒ«ã‚’å¾—ã‚‹ãŸã‚ã«äºˆæ¸¬çµæœã‚’å‡¦ç†ã™ã‚‹ã€‚CSVå½¢å¼ã§ã€çœŸå€¤ã¨äºˆæ¸¬ãƒ©ãƒ™ãƒ«ã‚’è¿”ã™ã€‚
</span></span></span><span style=display:flex><span><span style=color:#e6db74>  &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>process</span>(self, element: Tuple[int, PredictionResult]) <span style=color:#f92672>-&gt;</span> Iterable[str]:
</span></span><span style=display:flex><span>    label, prediction_result <span style=color:#f92672>=</span> element
</span></span><span style=display:flex><span>    prediction <span style=color:#f92672>=</span> prediction_result<span style=color:#f92672>.</span>inference
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>yield</span> <span style=color:#e6db74>&#39;</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>,</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(label, prediction)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>parse_known_args</span>(argv):
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;&#34;&#34;å¼•æ•°ã‚’å®šç¾©&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>  parser <span style=color:#f92672>=</span> argparse<span style=color:#f92672>.</span>ArgumentParser()
</span></span><span style=display:flex><span>  parser<span style=color:#f92672>.</span>add_argument(
</span></span><span style=display:flex><span>      <span style=color:#e6db74>&#39;--input_file&#39;</span>,
</span></span><span style=display:flex><span>      dest<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;input&#39;</span>,
</span></span><span style=display:flex><span>      required<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>      help<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;text file with comma separated int values.&#39;</span>)
</span></span><span style=display:flex><span>  parser<span style=color:#f92672>.</span>add_argument(
</span></span><span style=display:flex><span>      <span style=color:#e6db74>&#39;--output&#39;</span>,
</span></span><span style=display:flex><span>      dest<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;output&#39;</span>,
</span></span><span style=display:flex><span>      required<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>      help<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Path to save output predictions.&#39;</span>)
</span></span><span style=display:flex><span>  parser<span style=color:#f92672>.</span>add_argument(
</span></span><span style=display:flex><span>      <span style=color:#e6db74>&#39;--model_path&#39;</span>,
</span></span><span style=display:flex><span>      dest<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;model_path&#39;</span>,
</span></span><span style=display:flex><span>      required<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,
</span></span><span style=display:flex><span>      help<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Path to load the Sklearn model for Inference.&#39;</span>)
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>return</span> parser<span style=color:#f92672>.</span>parse_known_args(argv)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>run</span>(argv<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>, save_main_session<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>):
</span></span><span style=display:flex><span>  <span style=color:#e6db74>&#34;&#34;&#34;ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®šç¾©&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>  known_args, pipeline_args <span style=color:#f92672>=</span> parse_known_args(argv)
</span></span><span style=display:flex><span>  pipeline_options <span style=color:#f92672>=</span> PipelineOptions(pipeline_args)
</span></span><span style=display:flex><span>  pipeline_options<span style=color:#f92672>.</span>view_as(SetupOptions)<span style=color:#f92672>.</span>save_main_session <span style=color:#f92672>=</span> save_main_session
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#75715e># ã“ã®ä¾‹ã§ã¯ã€RunInference ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ ã«ã‚­ãƒ¼ã¨ãªã‚‹å…¥åŠ›ã‚’æ¸¡ã—ã¦ã„ã‚‹ã€‚ãã‚Œã«ã‚ˆã£ã¦ã€SklearnModelHandlerNumpy ã®ãƒ©ãƒƒãƒ‘ãƒ¼ã§ã‚ã‚‹ KeyedModelHandler ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã€‚</span>
</span></span><span style=display:flex><span>  model_loader <span style=color:#f92672>=</span> KeyedModelHandler(
</span></span><span style=display:flex><span>      SklearnModelHandlerNumpy(
</span></span><span style=display:flex><span>          model_file_type<span style=color:#f92672>=</span>ModelFileType<span style=color:#f92672>.</span>PICKLE,
</span></span><span style=display:flex><span>          model_uri<span style=color:#f92672>=</span>known_args<span style=color:#f92672>.</span>model_path))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>with</span> beam<span style=color:#f92672>.</span>Pipeline(options<span style=color:#f92672>=</span>pipeline_options) <span style=color:#66d9ef>as</span> p:
</span></span><span style=display:flex><span>	<span style=color:#75715e># å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€</span>
</span></span><span style=display:flex><span>    label_pixel_tuple <span style=color:#f92672>=</span> (
</span></span><span style=display:flex><span>        p
</span></span><span style=display:flex><span>        <span style=color:#f92672>|</span> <span style=color:#e6db74>&#34;ReadFromInput&#34;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>io<span style=color:#f92672>.</span>ReadFromText(
</span></span><span style=display:flex><span>            known_args<span style=color:#f92672>.</span>input, skip_header_lines<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        <span style=color:#f92672>|</span> <span style=color:#e6db74>&#34;PreProcessInputs&#34;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>Map(process_input))
</span></span><span style=display:flex><span>	<span style=color:#75715e># æ¨è«–ã—ã¦å¾Œå‡¦ç†ã‚’è¡Œã†</span>
</span></span><span style=display:flex><span>    predictions <span style=color:#f92672>=</span> (
</span></span><span style=display:flex><span>        label_pixel_tuple
</span></span><span style=display:flex><span>        <span style=color:#f92672>|</span> <span style=color:#e6db74>&#34;RunInference&#34;</span> <span style=color:#f92672>&gt;&gt;</span> RunInference(model_loader)
</span></span><span style=display:flex><span>        <span style=color:#f92672>|</span> <span style=color:#e6db74>&#34;PostProcessOutputs&#34;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>ParDo(PostProcessor()))
</span></span><span style=display:flex><span>	<span style=color:#75715e># å¾Œå‡¦ç†ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’å‡ºåŠ›ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã™ã‚‹</span>
</span></span><span style=display:flex><span>    _ <span style=color:#f92672>=</span> predictions <span style=color:#f92672>|</span> <span style=color:#e6db74>&#34;WriteOutput&#34;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>io<span style=color:#f92672>.</span>WriteToText(
</span></span><span style=display:flex><span>        known_args<span style=color:#f92672>.</span>output,
</span></span><span style=display:flex><span>        shard_name_template<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;&#39;</span>,
</span></span><span style=display:flex><span>        append_trailing_newlines<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#39;__main__&#39;</span>:
</span></span><span style=display:flex><span>  run()
</span></span></code></pre></div><h2 id=runinference-api-ã«ã¤ã„ã¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰å­¦ã¶>RunInference API ã«ã¤ã„ã¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰å­¦ã¶</h2><p>RunInference API ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>ãŒæ—¢ã«å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€èª­ã¿è¾¼ã‚€ã“ã¨ã§å®Ÿéš›ã«ã©ã‚“ãªæ¦‚å¿µã§ä½œæˆã•ã‚Œã¦ã„ã‚‹ã®ã‹ç†è§£ã§ãã‚‹ã€‚
Apache Beam ã®åŸºç¤çš„ãªæ¦‚å¿µã‚„ç”¨èªã«ã¤ã„ã¦ã¯ã€ã“ã®è¨˜äº‹ã‚’èª­ã‚€å‰ã«éå»ã«æ›¸ã„ãŸ Apache beam Python å…¥é–€ã‚’èª­ã‚“ã§ã„ãŸã ã‘ã‚‹ã¨ã€ã“ã®è¨˜äº‹ãŒåˆ†ã‹ã‚Šã‚„ã™ãèª­ã‚ã‚‹ã¨æ€ã„ã¾ã™ã€‚</p><h3 id=ãªãœ-runinferenceapi-ã‚’ä½¿ã†ã®ã‹>ãªãœ RunInferenceAPI ã‚’ä½¿ã†ã®ã‹?</h3><p>ãã‚‚ãã‚‚åƒ•ã®ç–‘å•ã¯ã€Œä»Šã¾ã§ã€Beam ã§ PyTorch ã‚„ scikit-learn ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦æ¨è«–ã¯å¯èƒ½ã ã£ãŸãŒã€ RunInferenceAPI ã¯ä½•ãŒå¬‰ã—ã„ã®ã‹?ã€ã¸ã®ç­”ãˆãŒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«æ›¸ã„ã¦ã‚ã‚Šã¾ã—ãŸã€‚</p><ul><li><code>BatchElements</code>ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ ã‚„<code>Shared</code>ã‚¯ãƒ©ã‚¹ãªã©æ—¢å­˜ã® Apache Beam ã®æ¦‚å¿µã«æ²¿ã£ã¦ã€æ©Ÿæ¢°å­¦ç¿’ã®æ¨è«–å‡¦ç†ã‚’æœ€é©åŒ–ãŒå¯èƒ½ã«ãªã‚‹ã€‚ã¾ãŸãƒãƒ«ãƒãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãªã©ã€è¤‡é›‘ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ§‹ç¯‰ã‚‚æ¯”è¼ƒçš„ç°¡å˜ã«æ§‹ç¯‰ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚</li></ul><h3 id=batchelements-ptransform-ã¨ã¯>BatchElements PTransform ã¨ã¯</h3><p>å¤šãã®ãƒ¢ãƒ‡ãƒ«ãŒå®Ÿè£…ã—ã¦ã„ã‚‹ãƒ™ã‚¯ãƒˆãƒ«åŒ–æ¨è«–ã®æœ€é©åŒ–ã‚’åˆ©ç”¨ã™ã‚‹ãŸã‚ã«ã€ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’è¡Œã†å‰ã®ä¸­é–“æ®µéšã¨ã—ã¦ã€BatchElements ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ ã®è¿½åŠ ã—ãŸã€‚ã“ã®ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ ã¯ã€è¦ç´ ã‚’ãƒãƒƒãƒå‡¦ç†ã™ã‚‹ã€‚ãã—ã¦ã€ãƒãƒƒãƒã•ã‚ŒãŸè¦ç´ ã¯ã€RunInference ã®ç‰¹å®šã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®ãŸã‚ã®å¤‰æ›ã§é©ç”¨ã•ã‚Œã‚‹ã€‚ä¾‹ãˆã°ã€numpy ã® ndarrays ã®å ´åˆã¯ numpy.stack()ã‚’ã€torch ã® Tensor è¦ç´ ã®å ´åˆã¯ torch.stack()ã‚’å‘¼ã³å‡ºã™ã€‚</p><p>beam.BatchElements ã®è¨­å®šã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã™ã‚‹ã«ã¯ã€ModelHandler ã®ä¸­ã§ã€batch_elements_kwargs é–¢æ•°ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚ä¾‹ãˆã°ã€<code>min_batch_size</code> ã§ãƒãƒƒãƒã‚ãŸã‚Šã®è¦ç´ æ•°ã®æœ€å°å€¤ã‚’è¨­å®šã—ã€<code>max_batch_size</code> ã§ãƒãƒƒãƒã‚ãŸã‚Šã®è¦ç´ æ•°ã®æœ€å¤§å€¤ã‚’è¨­å®šã™ã‚‹ã€‚
è©³ã—ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯<a href=https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.util.html#apache_beam.transforms.util.BatchElements>ã“ã¡ã‚‰</a></p><h3 id=shared-helper-class>Shared helper class</h3><p>RunInference API ã§<code>Shared</code> ã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã«ã‚ˆã‚Šã€ãƒ—ãƒ­ã‚»ã‚¹ã”ã¨ã«ä¸€åº¦ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã å¾Œã«å„ãƒ—ãƒ­ã‚»ã‚¹å†…éƒ¨ã§ãã®èª­ã¿è¾¼ã‚“ã ãƒ¢ãƒ‡ãƒ«ã‚’<code>DoFn</code>(å…¨ã¦ã®<code>PCollection</code>ã«é©ç”¨ã•ã‚Œã‚‹å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä¿æŒã™ã‚‹)å†…ã§å…±æœ‰ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ã“ã®ã‚¯ãƒ©ã‚¹ã‚’ä½¿ãˆã°ã€ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿æ™‚é–“ã¨ãƒ¡ãƒ¢ãƒªæ¶ˆè²»ã‚’å‰Šæ¸›ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚</p><p>è©³ã—ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ(ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰)ã¯<a href=https://github.com/apache/beam/blob/master/sdks/python/apache_beam/utils/shared.py#L20>ã“ã¡ã‚‰</a>ã€‚å†…éƒ¨ã®å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯è‡ªä½“ 100 è¡Œæœªæº€ã§æ›¸ã‹ã‚Œã¦ã„ã‚‹ã®ã§ã€èª­ã‚“ã§è¦‹ã‚‹ã®ã‚‚ã‚ã‚Šã€‚</p><h3 id=æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã†ãŸã‚ã«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹>æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã†ãŸã‚ã«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹</h3><p>ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’ Apache Beam ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«è¿½åŠ ã™ã‚Œã°ã€RunInference ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ ã‚’ä½¿ç”¨ã§ãã‚‹ã€‚</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> apache_beam.ml.inference.base <span style=color:#f92672>import</span> RunInference
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> pipeline <span style=color:#66d9ef>as</span> p:
</span></span><span style=display:flex><span>   predictions <span style=color:#f92672>=</span> ( p <span style=color:#f92672>|</span>  <span style=color:#e6db74>&#39;Read&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>ReadFromSource(<span style=color:#e6db74>&#39;a_source&#39;</span>)
</span></span><span style=display:flex><span>                     <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;RunInference&#39;</span> <span style=color:#f92672>&gt;&gt;</span> RunInference(<span style=color:#f92672>&lt;</span>model_handler<span style=color:#f92672>&gt;</span>)
</span></span></code></pre></div><p><code>model_handler</code> ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã®ãŸã‚ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚³ãƒ¼ãƒ‰ã§ã€ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒã§ãã‚‹ã€‚
ä»¥ä¸‹ã®ã‚ˆã†ãª<code>ModelHandler</code>ã®ä¾‹ãŒã‚ã‚‹</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> apache_beam.ml.inference.sklearn_inference <span style=color:#f92672>import</span> SklearnModelHandlerNumpy
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> apache_beam.ml.inference.sklearn_inference <span style=color:#f92672>import</span> SklearnModelHandlerPandas
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> apache_beam.ml.inference.pytorch_inference <span style=color:#f92672>import</span> PytorchModelHandlerTensor
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> apache_beam.ml.inference.pytorch_inference <span style=color:#f92672>import</span> PytorchModelHandlerKeyedTensor
</span></span></code></pre></div><p>ãƒ¢ãƒ‡ãƒ« A ã¨ ãƒ¢ãƒ‡ãƒ« B ã®æ¨è«–çµæœã‚’ä¸¦åˆ—ã—ã¦è¡Œã£ãŸã‚Šã€</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>with</span> pipeline <span style=color:#66d9ef>as</span> p:
</span></span><span style=display:flex><span>   data <span style=color:#f92672>=</span> p <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Read&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>ReadFromSource(<span style=color:#e6db74>&#39;a_source&#39;</span>)
</span></span><span style=display:flex><span>   model_a_predictions <span style=color:#f92672>=</span> data <span style=color:#f92672>|</span> RunInference(<span style=color:#f92672>&lt;</span>model_handler_A<span style=color:#f92672>&gt;</span>)
</span></span><span style=display:flex><span>   model_b_predictions <span style=color:#f92672>=</span> data <span style=color:#f92672>|</span> RunInference(<span style=color:#f92672>&lt;</span>model_handler_B<span style=color:#f92672>&gt;</span>)
</span></span></code></pre></div><p>ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚‚æŸ”è»Ÿã«è¨˜è¿°ã§ãã‚‹ã€‚</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>with</span> pipeline <span style=color:#66d9ef>as</span> p:
</span></span><span style=display:flex><span>   data <span style=color:#f92672>=</span> p <span style=color:#f92672>|</span> <span style=color:#e6db74>&#39;Read&#39;</span> <span style=color:#f92672>&gt;&gt;</span> beam<span style=color:#f92672>.</span>ReadFromSource(<span style=color:#e6db74>&#39;a_source&#39;</span>)
</span></span><span style=display:flex><span>   model_a_predictions <span style=color:#f92672>=</span> data <span style=color:#f92672>|</span> RunInference(<span style=color:#f92672>&lt;</span>model_handler_A<span style=color:#f92672>&gt;</span>)
</span></span><span style=display:flex><span>   model_b_predictions <span style=color:#f92672>=</span> model_a_predictions <span style=color:#f92672>|</span> beam<span style=color:#f92672>.</span>Map(some_post_processing) <span style=color:#f92672>|</span> RunInference(<span style=color:#f92672>&lt;</span>model_handler_B<span style=color:#f92672>&gt;</span>)
</span></span></code></pre></div><p>ã¾ãŸé©šããªã®ãŒã€Apache Beam 2.41.0 ç§»è¡Œã¯ <a href=https://beam.apache.org/documentation/programming-guide/#multi-language-pipelines>Multi Language SDK</a>ã«ã‚ˆã£ã¦ã€ Java ã‹ã‚‰ã‚‚ RunInference API ã‚’ä½¿ã†ã“ã¨ãŒã§ãã‚‹ã‚‰ã—ã„ã€‚
ã“ã‚Œã£ã¦ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã¯ Python ã§è¡Œã£ã¦ã€é‹ç”¨ã¯å®‰å®šã—ãŸ Java ã§å®Ÿè¡Œå¯èƒ½ã¨ã„ã†ã“ã¨ãªã®ã§å‡„ã„æ©Ÿèƒ½ã§ã™ã­ã€‚</p><p><a href=https://github.com/apache/beam/blob/master/sdks/java/extensions/python/src/main/java/org/apache/beam/sdk/extensions/python/transforms/RunInference.java>https://github.com/apache/beam/blob/master/sdks/java/extensions/python/src/main/java/org/apache/beam/sdk/extensions/python/transforms/RunInference.java</a></p><p>Multi Language SDK ã‚‚éå¸¸ã«é¢ç™½ãã†ã ãŒã€ã¾ã ä½¿ã£ãŸã“ã¨ã¯ãªã„ã®ã§ã€å®Ÿéš›ã«ã‚³ãƒ¼ãƒ‰ã‚’ã‹ãã¤ã¤ç†è§£ã‚’æ·±ã‚ãŸã„ã€‚</p><h2 id=ã¾ã¨ã‚>ã¾ã¨ã‚</h2><p>Apache Beam 2.40.0 ã‹ã‚‰åˆ©ç”¨å¯èƒ½ã«ãªã£ãŸ RunInference API ã«ã¤ã„ã¦ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã¨å…±ã«ä½•ã‚’ã‚„ã£ã¦ã„ã‚‹ã‹ã‚’ã¾ã¨ã‚ã¾ã—ãŸã€‚</p><p>Apache Beam ã¯ã¨ã¦ã‚‚æœªæ¥ã‚’æ„Ÿã˜ã‚‹ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ãªã®ã§ã€ã“ã® OSS ã«ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ãƒˆã§ãã‚‹ä½™åœ°ãŒã‚ã‚Œã°ç©æ¥µçš„ã«ã‚„ã£ã¦ã„ããŸã„ã€‚
ãã®ãŸã‚ã€ã“ã‚Œã‹ã‚‰ã¯ã¡ã‚‡ã£ã¨ã—ãŸ Beam ã®å‹‰å¼·ãƒ¡ãƒ¢ãªã©ã‚‚ç©æ¥µçš„ã«å…¬é–‹ã•ã‚Œã¦ã„ãã¨æ€ã„ã¾ã™ã€‚</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href=https://cloud.google.com/blog/products/data-analytics/latest-dataflow-innovations-for-real-time-streaming-and-aiml>Latest Dataflow innovations for real-time streaming and AI/ML | Google Cloud Blog</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p><a href="https://docs.google.com/document/d/1bVMU7Uo9Nzuu6aXR702j74nhQK4j6J1lkRVVBRySI0g/edit#heading=h.cqivojrr7lme">RunInference: ML Inference in Beam</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p><a href=https://beam.apache.org/documentation/sdks/python-machine-learning/>Apache Beam Python Machine Learning</a>&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div><h2>é–¢é€£ã—ã¦ã„ã‚‹ã‹ã‚‚ã—ã‚Œãªã„è¨˜äº‹</h2><ul><li><a href=/posts/2020-12-26/>Pythonã§Apache beam å…¥é–€</a></li><li><a href=/posts/2017-11-14/>OpenCV 3.3ã‹ã‚‰ä½¿ãˆã‚‹DNNãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦ç‰©ä½“æ¤œå‡º</a></li><li><a href=/posts/2022-08-15-2335/>KDD2022 ã§æ°—ã«ãªã£ãŸç ”ç©¶</a></li><li><a href=/posts/2022-08-10-1717/>poetry show ã§ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åã« (!) ãŒä»˜ä¸ã•ã‚Œã¦ã„ã‚‹æ„å‘³</a></li><li><a href=/posts/2022-05-10-2200/>ç¤¾å†…ã§ãƒ‡ãƒ¼ã‚¿åˆ†æçµæœã‚’å¯è¦–åŒ–ãƒ»å…±æœ‰ã™ã‚‹éš›ã« Google Colab ãŒä¾¿åˆ©</a></li></ul><pre>
---

ã“ã®ã‚µã‚¤ãƒˆã®æ›´æ–°æƒ…å ±ã‚’<a href=/index.xml>RSS</a>ã§é…ä¿¡ã—ã¦ã„ã¾ã™ã€‚ãŠå¥½ããªãƒ•ã‚£ãƒ¼ãƒ‰ãƒªãƒ¼ãƒ€ãƒ¼ã§è³¼èª­ã—ã¦ã¿ã¦ãã ã•ã„ã€‚

ğŸ‘ã“ã®ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã®é‹å–¶ã‚’æ”¯æ´ã—ã¦ã„ãŸã ã‘ã‚‹æ–¹ã‚’å‹Ÿé›†ã—ã¦ã„ã¾ã™ã€‚
ã‚‚ã—ã‚ˆã‚ã—ã‘ã‚Œã°ã€<a href=https://www.buymeacoffee.com/hurutoriya>Buy Me a Coffee</a> ã‹ã‚‰ã‚µãƒãƒ¼ãƒˆ(æŠ•ã’éŠ­)ã—ã¦ã„ãŸã ã‘ã‚‹ã¨ã€è‘—è€…ã®æ´»å‹•ã®ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã«ç¹‹ãŒã‚Šã¾ã™âœ¨

ğŸ“®ãŠãŸã‚ˆã‚Š
è¨˜äº‹ã¸ã®æ„Ÿæƒ³ã®<a href="https://docs.google.com/forms/d/e/1FAIpQLScgZVDrjQiKLbQRovfs88oweCITzjtvt1PlgwL14JfWPOrpPQ/viewform?usp=pp_url&entry.838298670=https%3a%2f%2fshunyaueta.com%2fposts%2f2022-08-18-1938%2f">ãŠãŸã‚ˆã‚Š</a>ã‚’ãŠã¾ã¡ã—ã¦ã¾ã™ã€‚
ãŠæ°—è»½ã«ãŠé€ã‚Šãã ã•ã„ã€‚
ãŠè¿”äº‹ã¯ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹å…¥åŠ›ãŒã‚ã‚Œã°ãƒ¡ãƒ¼ãƒ«ã§ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚
ã‚‚ã¡ã‚ã‚“ãŠè¿”äº‹ã‚’å¸Œæœ›ã›ãšã«å˜ãªã‚‹æ„Ÿæƒ³ã ã‘ã§ã‚‚å¤§æ­“è¿ã§ã™ã€‚
</pre></content><p><a href=https://shunyaueta.com/tags/apachebeam/>#apachebeam</a>
<a href=https://shunyaueta.com/tags/machinelearning/>#machinelearning</a>
<a href=https://shunyaueta.com/tags/python/>#python</a></p></main><footer>Made with <a href=https://github.com/janraasch/hugo-bearblog/>Hugo Ê•â€¢á´¥â€¢Ê” Bear</a></footer></body></html>