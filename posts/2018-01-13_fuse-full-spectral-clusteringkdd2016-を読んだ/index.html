<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>FUSE: Full Spectral Clustering(KDD2016) を読んだ - Shunya UETA</title><meta name="viewport" content="width=device-width, initial-scale=1">
	<meta property="og:title" content="FUSE: Full Spectral Clustering(KDD2016) を読んだ" />
<meta property="og:description" content="べき乗法と独立成分分析を用いたマルチスケールに頑強なクラスタリング手法の提案 べき乗法では近似固有ベクトル(Pseudo-eigenvecto" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://shunyaueta.com/posts/2018-01-13_fuse-full-spectral-clusteringkdd2016-%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/" />

<meta property="og:image" content="https://shunyaueta.com/posts/2018-01-13_fuse-full-spectral-clusteringkdd2016-%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/images/1.png" />
<meta property="article:published_time" content="2018-01-13T17:30:28+00:00" />
<meta property="article:modified_time" content="2019-06-16T18:17:39+09:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://shunyaueta.com/posts/2018-01-13_fuse-full-spectral-clusteringkdd2016-%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/images/1.png"/>

<meta name="twitter:title" content="FUSE: Full Spectral Clustering(KDD2016) を読んだ"/>
<meta name="twitter:description" content="べき乗法と独立成分分析を用いたマルチスケールに頑強なクラスタリング手法の提案 べき乗法では近似固有ベクトル(Pseudo-eigenvecto"/>
<link href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,300italic,400italic|Raleway:500,100,300" rel="stylesheet">

	<link rel="stylesheet" type="text/css" media="screen" href="/css/normalize.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="/css/main.css" /><script src="/js/feather.min.js"></script><script src="/js/main.js"></script>
</head>

<body>
	<div class="container wrapper post">
		<div class="header">
	<h1 class="site-title">Shunya UETA</h1>
	<div class="site-description"><h2>Software Engineer As Data Scientist</h2><nav class="nav social">
			<ul class="flat"><a href="https://www.linkedin.com/in/hurutoriya/" title="Linkedin"><i data-feather="linkedin"></i></a><a href="https://github.com/hurutoriya" title="Github"><i data-feather="github"></i></a><a href="https://twitter.com/hurutoriya" title="Twitter"><i data-feather="twitter"></i></a><a href="/index.xml" title="RSS"><i data-feather="rss"></i></a></ul>
		</nav>
	</div>

	<nav class="nav">
		<ul class="flat">
			
			<li>
				<a href="/">Home</a>
			</li>
			
			<li>
				<a href="/posts">All posts</a>
			</li>
			
			<li>
				<a href="/about">About</a>
			</li>
			
			<li>
				<a href="/tags">Tags</a>
			</li>
			
		</ul>
	</nav>
</div>


		<div class="post-header">
			<h1 class="title">FUSE: Full Spectral Clustering(KDD2016) を読んだ</h1>
			<div class="meta">Posted at &mdash; Jan 13, 2018</div>
		</div>

		<div class="markdown">
			

<p>べき乗法と独立成分分析を用いたマルチスケールに頑強なクラスタリング手法の提案</p>

<p><img src="/posts/2018-01-13_fuse-full-spectral-clusteringkdd2016-を読んだ/images/1.png" alt="image" /></p>

<ul>
<li>べき乗法では近似固有ベクトル(Pseudo-eigenvectors)は複数の真の固有ベクトルの線形結合からなる。有益でない固有ベクトルも含まれるのでいかにそれを除去するか</li>
<li>Fig.1 で言ってることがいまいちわからない。ｃ,ｄも変化がないように見える。論文で言及してるstripeが何を指してるかが不明
分かった。赤・青・黒の３つのクラスタで分かれている。最初は黒色がクラスタ境界面に見えた。論文内でのmulti scaleというのは、データの幾何的な分布を指している？</li>
<li>固有値計算はO(n³）かかるから計算量が~~って毎回言われるが、行列の状態に依存するので毎回最悪の場合を主張されてるも困る</li>
<li>ZP self-turining spectral clusteringをなぜ対抗馬にして比較してるのかは謎。</li>
<li>ICA<a href="http://www.kecl.ntt.co.jp/icl/signal/sawada/mypaper/subspace2010rev.pdf">¹</a>を行ったあとにその行列に対して回転処理を行い情報量の最小化を狙う</li>
<li>クラスタ数が多い場合、PICでは良い結果が出づらい
multi scale なデータの場合標準のspectral clusteringでは失敗することが多々ある</li>
<li>fig.2 (a) 見ればわかるが<em>k</em>-meansでは分離が困難</li>
<li>fig.2(b) ４－５本目の固有ベクトルを基底ベクトルにもつ空間ではクラスタのオーバーラップが少ない</li>
<li>つまり１－５本目の固有ベクトル全て含めてクラスタリングすれば結果が良好になるのではないか？（仮説）</li>
<li>fig.2 © ４回べき乗法を行った。結果が似てる。（縦軸が何を表してるかは不明）。四回が上から四本求めたのか、一番上の固有ベクトルを４回求めたのか分からない</li>
<li>fig. (d) 提案手法を適用。k-meansで分離可能 行列<strong>V</strong>を_p_回べき乗法を行って構築 <strong>E=MV</strong>の最小化を行う</li>
<li>ICAを最小化するためにJacobi Rotationを用いる。探索には貪欲法を採用</li>
</ul>

<h3 id="contribution">Contribution</h3>

<ul>
<li>マルチスケール（多種多様な）データ分布に対してクラスタリングが可能</li>
<li>計算時間は従来（ncut)と同等</li>
</ul>

<h3 id="感想">感想</h3>

<ul>
<li>PIC(Power Itetaion Clusterg)をまさか拡張してくるとは思わなかったなので、興味深い論文。(実装して再現実験したけど、Early stoppingの段階で高確率でクラスタリングが失敗していて使い物にならなかった印象があるので…)</li>
<li>データの分布が多様な場合、上位数本のベクトルではなく、そこから更に下の固有ベクトルに着目したほうが結果が良好になるのは面白い</li>
<li>KDDの論文、相変わらず読みやすかった。</li>
</ul>

		</div><div id="disqus_thread"></div>
<script type="text/javascript">
	(function () {
		
		
		if (window.location.hostname == "localhost")
			return;

		var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
		var disqus_shortname = 'hurutoriya';
		dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
		(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	})();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by
		Disqus.</a></noscript>
<a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>
	<div class="footer wrapper">
	<nav class="nav">
		<div><a href="https://github.com/vividvilla/ezhil">Ezhil theme</a> | Built with <a href="gohugo.io">Hugo</a></div>
	</nav>
</div>

</body>
</html>
