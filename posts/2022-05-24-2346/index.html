<!doctype html><html lang=ja dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Search Engineering Newsletter vol.06 | 🦅 hurutoriya</title><meta name=keywords content="newsletter,search"><meta name=description content="6 回目の配信です。 今回のイチオシは、DoorDash の検索システム刷新の記事です。
Search Apache Solr Release Notes
Solr 9.0.0 がリリースされました。 Elasticsearch と同じく、 Lucene 9 の ANN をサポートしたことにより、近傍探索機能が追加された。
Apache Solr 9.0.0 がリリースされました！ - KandaSearch
リリース文の日本語訳も公開されていました。
 Also in 9.0 is a brand new Solr Ref Guide, completely re-organized and built on @antoraproject which gives us a dozen features we&rsquo;ve wanted like search. Which is probably the one you really wanted too: https://solr.apache.org/guide/solr/latest/ > https://twitter.com/childerelda/status/1524854759022379017
 Solr 9 のリリースに伴い、Apache Solr Reference Guide も再編成されました。検索機能がサイトに搭載されたと言及されているので便利になったのでは?"><meta name=author content="Shunya Ueta"><link rel=canonical href=https://shunyaueta.com/posts/2022-05-24-2346/><link crossorigin=anonymous href=/assets/css/stylesheet.abc7c82c3d415a6df50430738d1cbcc4c76fea558bc5a0c830d3babf78167a35.css integrity="sha256-q8fILD1BWm31BDBzjRy8xMdv6lWLxaDIMNO6v3gWejU=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad();></script><link rel=icon href=https://shunyaueta.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://shunyaueta.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://shunyaueta.com/favicon-32x32.png><link rel=apple-touch-icon href=https://shunyaueta.com/apple-touch-icon.png><link rel=mask-icon href=https://shunyaueta.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme: rgb(29, 30, 32);--entry: rgb(46, 46, 51);--primary: rgb(218, 218, 219);--secondary: rgb(155, 156, 157);--tertiary: rgb(65, 66, 68);--content: rgb(196, 196, 197);--hljs-bg: rgb(46, 46, 51);--code-bg: rgb(55, 56, 62);--border: rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-JMJRQJT0Q3"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','G-JMJRQJT0Q3');</script><meta property="og:title" content="Search Engineering Newsletter vol.06"><meta property="og:description" content="6 回目の配信です。 今回のイチオシは、DoorDash の検索システム刷新の記事です。
Search Apache Solr Release Notes
Solr 9.0.0 がリリースされました。 Elasticsearch と同じく、 Lucene 9 の ANN をサポートしたことにより、近傍探索機能が追加された。
Apache Solr 9.0.0 がリリースされました！ - KandaSearch
リリース文の日本語訳も公開されていました。
 Also in 9.0 is a brand new Solr Ref Guide, completely re-organized and built on @antoraproject which gives us a dozen features we&rsquo;ve wanted like search. Which is probably the one you really wanted too: https://solr.apache.org/guide/solr/latest/ > https://twitter.com/childerelda/status/1524854759022379017
 Solr 9 のリリースに伴い、Apache Solr Reference Guide も再編成されました。検索機能がサイトに搭載されたと言及されているので便利になったのでは?"><meta property="og:type" content="article"><meta property="og:url" content="https://shunyaueta.com/posts/2022-05-24-2346/"><meta property="og:image" content="https://shunyaueta.com/posts/2022-01-16/images/1.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-05-24T23:46:38+09:00"><meta property="article:modified_time" content="2022-10-17T12:00:06+09:00"><meta property="og:site_name" content="Shunya Ueta"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://shunyaueta.com/posts/2022-01-16/images/1.png"><meta name=twitter:title content="Search Engineering Newsletter vol.06"><meta name=twitter:description content="6 回目の配信です。 今回のイチオシは、DoorDash の検索システム刷新の記事です。
Search Apache Solr Release Notes
Solr 9.0.0 がリリースされました。 Elasticsearch と同じく、 Lucene 9 の ANN をサポートしたことにより、近傍探索機能が追加された。
Apache Solr 9.0.0 がリリースされました！ - KandaSearch
リリース文の日本語訳も公開されていました。
 Also in 9.0 is a brand new Solr Ref Guide, completely re-organized and built on @antoraproject which gives us a dozen features we&rsquo;ve wanted like search. Which is probably the one you really wanted too: https://solr.apache.org/guide/solr/latest/ > https://twitter.com/childerelda/status/1524854759022379017
 Solr 9 のリリースに伴い、Apache Solr Reference Guide も再編成されました。検索機能がサイトに搭載されたと言及されているので便利になったのでは?"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Search Engineering Newsletter vol.06","item":"https://shunyaueta.com/posts/2022-05-24-2346/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Search Engineering Newsletter vol.06","name":"Search Engineering Newsletter vol.06","description":"6 回目の配信です。 今回のイチオシは、DoorDash の検索システム刷新の記事です。\nSearch Apache Solr Release Notes\nSolr 9.0.0 がリリースされました。 Elasticsearch と同じく、 Lucene 9 の ANN をサポートしたことにより、近傍探索機能が追加された。\nApache Solr 9.0.0 がリリースされました！ - KandaSearch\nリリース文の日本語訳も公開されていました。\n Also in 9.0 is a brand new Solr Ref Guide, completely re-organized and built on @antoraproject which gives us a dozen features we\u0026rsquo;ve wanted like search. Which is probably the one you really wanted too: https://solr.apache.org/guide/solr/latest/ \u0026gt; https://twitter.com/childerelda/status/1524854759022379017\n Solr 9 のリリースに伴い、Apache Solr Reference Guide も再編成されました。検索機能がサイトに搭載されたと言及されているので便利になったのでは?","keywords":["newsletter","search"],"articleBody":"6 回目の配信です。 今回のイチオシは、DoorDash の検索システム刷新の記事です。\nSearch Apache Solr Release Notes\nSolr 9.0.0 がリリースされました。 Elasticsearch と同じく、 Lucene 9 の ANN をサポートしたことにより、近傍探索機能が追加された。\nApache Solr 9.0.0 がリリースされました！ - KandaSearch\nリリース文の日本語訳も公開されていました。\n Also in 9.0 is a brand new Solr Ref Guide, completely re-organized and built on @antoraproject which gives us a dozen features we’ve wanted like search. Which is probably the one you really wanted too: https://solr.apache.org/guide/solr/latest/  https://twitter.com/childerelda/status/1524854759022379017\n Solr 9 のリリースに伴い、Apache Solr Reference Guide も再編成されました。検索機能がサイトに搭載されたと言及されているので便利になったのでは?\nOn-device Text-to-Image Search with TensorFlow Lite Searcher Library — The TensorFlow Blog\nTensorFlow Lite を使ってデバイス上での言語クエリから画像検索を行った解説記事。 デバイス上で、検索クエリに対応する画像の埋め込みベクトルを ScaNN(Google が開発した近似近傍探索のアルゴリズム)で近似近傍を行い、Top N 枚の画像のメタデータを検索する。つまり、デバイス上には画像のメタデータのみ保有しており、画像自体は例えばネット経由で表示させることも可能。 記事内では、画像をデバイスに保存しているような記述はなかったので、画像の埋め込み空間のみ保持している模様。 Pixel 6 での実機テストでは、各検索クエリは 6m sec で完結しているらしくすべてデバイス上で完結するだけはある鬼の速さ。\n初めて知ったが、TensorFlow Lite Model Maker というライブラリを使うことで、TensorFlow Lite の学習を簡素化できるらしい。\nユーザの地域考慮＋機械学習モデルによる CTR 改善 〜 ヤフー検索の入力補助機能での事例 - Yahoo! JAPAN Tech Blog\n関連検索ワードの精度を地理情報によりパーソナライズしてみたお話。 地理に依存したクエリにおいて曖昧性回避のために有効だが、地理情報ごとに QAC のインデックスを作成するの大変そう。 大まかに分けても地方ごと(関西・関東とか?)にインデックスを作成するのだろうか…?\n実験結果で、CTR がスマートフォンと PC だと結果が顕著に分かれており、検索結果の上部と下部で PC だと下部が CTR が下がっていて面白かった。 考察しようとしたけどここまで差異がでるのはなぜか思いつかなかった.. これも Web 検索ならではの取り組みがいがある課題ですね。\nOpenSearchCon 2022 · OpenSearch\n2022.09.21 に OpenSearch(Elasticsearch をベースに AWS 主体で開発している検索エンジン)のカンファレンスが開催予定。 OpenSearch は近似近傍探索1で、 nmslib や faiss を利用しており本元の Elasticsearch と違う方向性に変化していきそうなので、今後に期待している。\n3 Changes to Expand DoorDash’s Product Search Beyond Delivery\nフードデリバリーユニコーンの DoorDash が検索システムで機能を刷新した 3 つの点を解説した記事。 DoorDash の技術ブログは、機械学習2や検索システム3など、自分の興味ある分野で良質な記事が目白押しなので毎回更新を楽しみにしています。\nかなり面白かったので深堀りして抄訳しました。\n 3 Changes to Expand DoorDash’s Product Search Beyond Delivery 要点まとめ 当初はフードデリバリーのみだったが DoorDash の検索機能は、料理のメニュー検索のために作成された。 ビジネス拡大に伴い、料理のメニュー以外にも、スーパーの食材や雑貨、アルコールやペットフードなど様々な種類の製品を検索可能にする必要があった。\n まず、データレイヤーの視点では、商品のメニュー以外に検索機能を拡大する際に、スーパーの食材などは SKU の単位として非常に粒度が細かく、領域が拡大するたびにその領域に合わせたデータをインデックスする必要がある。 また、新しい領域にビジネスを拡大する際には、膨大な数の SKU にラベル付をする必要があるが、スケールさせるために機械学習ベースの手法でラベリングをスケールさせた。  それら２つの課題を解決するために新しく検索システムのインフラを刷新し、 Query undestanding, Document Understanding によって検索結果のランキングを改善する。\n具体的に何をやったのか?\n Rebuilding search infrastructure for new challenges  active/nextgen indexing: まず DoorDash の事業形態として、高速にインデックスを更新する必要がある。(NOTE:オンライン何かをオーダーする際に、検索インデックスが更新されていなかったので、検索結果には表示されていたけど売り切れてるような体験は避けたいですよね) federated search: 食料品、料理、アルコールなど複数領域の検索結果を混ぜる new search storage: 上記を可能にする検索インフラ   Improving query and document understanding  new taxonomies: Query \u0026 Document understanding のために、機械学習を用いた製品のラベリングシステムを開発   Learning-to-rank  learning-to-rank \u0026 evaluation system: Rerank の仕組みと、検索結果の評価を可能にするフレームワークを開発。(モデルの詳細は後日データサイエンスチームがブログ記事を書いてくれるとのこと)    Rebuilding search infrastructure for new challenges Implementing active/nextgen indexing 以前 DoorDash はBuilding Faster Indexing with Apache Kafka and Elasticsearch - DoorDash Engineering Blog の記事で紹介されたように、Apache Kafka を使って Elasticsaerch へのインデキシング速度を\n 店舗のカタログ全体を backfill する時間を 1 週間から 6.5 時間に短縮 商品のカタログ全体を backfill する時間を 2 週間から 6.5 時間に短縮 再インデックス(re-index)の時間を 1 週間から 2 時間に短縮  と劇的に改善したが、そこから更にインデキシング速度を向上させた。\n具体的なアプローチとして再インデックスをやめて逐次インデキシングを採用することで、優先度の高いデータをリアルタイムに検索エンジンに反映することができるようになった。\nBuilding a federated search 料理、雑貨、食品など複数領域の検索結果を混ぜる federated saerch を導入。 NOTE: イメージとしては、各領域ごとに検索システムのマイクロサービスを作成して、それらの検索結果を混ぜるマイクロサービスも開発した感じです。\n初期はレストラン(料理)検索のみに対応した検索エンジンだったが、新システムでは水平に各領域の検索を行い混ぜることができるようになったので、対応領域拡大の際に、インデックスなどの既存のコードを書き換え対応する必要がなくなった。 また、検索とランキングが水平に分離されたことで、各領域に特化して柔軟に検索性能を向上させることができる。\nまた、 federated saerch の実現により例えば一つの領域の検索システムがダウンしたとしても検索システム全体がダウンすることは避けることが可能になった。\nNew search storage engine Elasticsearch を採用していたが、様々な課題が見えてきたので新しい検索エンジンの検討を開始した。 Apache Lucene をベースにして検索システムを構築した。 利点として、速度向上の他にも、Lucene 9 から使用可能な 近似近傍探索も魅力的な点だった。\nNOTE: yelp の nrtsaerch 4もそうだが、既存の Elasticsaerch や Solr がボトルネックになると自作検索エンジンを作り始めるのかっこよすぎる。\nImproving query and document understanding  手作業でのラベリングを行う。手作業はスケーラブルではないが、高速に仮説を立証して、数百規模のデータセットを作成する。 プロセスが標準化された後は、オペレーションチームや外部パートナーと連携して、数千規模のラベリングを行う。 収集した数千のデータを基に機械学習モデルを構築して、そのモデルを使ってラベリングをスケールさせる。 上記のデータに対して、定期的な品質確認を行う。ラベリングの品質確認は、バイアスの排除やモデルの精度向上に不可欠  Using human annotations to create labels アノテーションの分散を最小化するために、アノテーションプロセスを文書化したガイドライン作成はとても重要である。 Google 検索が公開している検索品質の素晴らしいガイドラインがあるが、同様に DoorDash もアノテーションガイドラインを作成した。\nだが、もし DoorDash のすべての従業員がフルタイムでマニュアルに則ってアノテーションしたとしても数十万規模のアノテーションタスクを終わらせることはできない。 人間によるアノテーションをスケールさせるためには外部の専門のベンダーに頼らざるを得ない。 Amazon Mechanical Turk や、Google Cloud AI Labeling Service, Scale.AI, Appen など多くのアノテーションビジネスが存在している。\n基本的にアノテーションタスクは、一人のアノテーターの判断を信頼することはできない。 バイアス除去のために、よく使われる手法としては多数決を取り入れた手法がある。 適切な精度のレベルまで引き上げるに 3-4 人、もしくはそれ以上の人数で同一のアノテーションタスクを行う必要がある。 また、良質なガイドラインはアノテーションの品質や速度の向上にも寄与する。\nベンダーに依頼後、アノテーションデータセットが作成された後にも、我々はデータセットに対する監査を行う必要がある。 (機械学習のシステムであろうと)他のシステムと同様に、品質保証は重要です。\nNOTE: 同意しか無い。機械学習だから仕方ないよねだと、その先には行けないので出来得る限り (多種多様な状況があるので、それに応じたベストな行動を指す)の取り組みで品質保証を行う必要がある。\nアノテーションデータセットへ監査を行った際に、面白いテーマが見つかった。\n いくらかのベンダーは特定の地域のアノテーターで構成されており、文化の差異によって誤った判断が発生していた 特定のベンダーは他のベンダーと比べて、アノテーターが訓練されており、アノテーション結果がとても良質だった 一部の種類のラベルはアノテーションガイドラインに曖昧性が多すぎた。 アノテーションタスクの複雑さを過小評価した場合、ベンダーはアノテーションタスクの立ち上げと処理に長時間必要とした。  Using natural language processing to enrich query context クエリに対する品詞のアノテーションを行うことで、クエリの言語的な構造を理解ができる。 例えば、 「red pizza」というクエリに対して、パースを行い[JJ NN]というアノテーションを行う。 JJは形容詞で、NN は名詞を指している。 結果として、このクエリは形容詞が名詞を修飾しているということがわかる。 検索の際に、「red pizza」という単語が完全一致で存在しなかった場合、緩和を行い「pizza」のみの単語で検索を行うことが可能になる。(一般的にクエリ拡張と呼ばれる技術)\nNOTE: この POS のアノテーションでわからないのは、クエリ自体正しい英語ではなく誤植まみれの英語がくるから POS アノテーションが必要問事なのかなと思ったりした? 専門分野ではないので素人的発想だが、形態素解析が必要なく誤植ももしなければ POS アノテーションせずとも品詞はすべて把握できそう? だが、後述の Spacy で\n NLP libraries involve far more than POS tagging\n と書いてあるので、アノテーション自体は必要なタスクなんだと理解。\nPOS タギング自体は Spacy を使っている。 POS タギングのサービングだが、検索時にオンライン(リアルタイム)でのサービングが必要なので速度向上のために以下のような選択肢がある。\n オフラインで計算したクエリの品詞のペアを Redis などのインメモリ DB に格納してルックアップテーブルを構築して推論を行わないようにした。(人気のあるクエリのみに焦点をあて、テイルクエリ(頻度の低いクエリ)はカーディナリティが爆発するので DB には格納しない) Spacy を使わずに JVM で動く NLP ライブラリを使ってサービングする Roblox のようにチューニングを極めることで、トランスフォーマーモデルでもオンライン毎日 10 億規模の推論を実現すること5も可能  NOTE: 選択肢は色々とありますといいつつも何を採用したかは次の記事に期待してねと書いていた。個人的には DB でルックアップテーブル使うのが初手だと一番良さそう\nLearning-to-rank DoorDash の ランキングアルゴリズムの変遷\n Heuristic Ranker (BM25+ 店舗の人気度) LTR:Pointwise LTR + Personalization  初期の LTR モデルをデプロイ時に、オンラインでの検索評価のフレームワークを社内で議論して方向性を固めていった。 ビジネス指標と情報検索指標の２つのカテゴリの指標を持つ\n ビジネス指標: 検索のコンバージョン率、CTR、first click rank position などは North star 指標 情報検索指標: mean-reciprical rank, nDCG  定常的にゴールデンデータを作成する仕組みを作成。アノテーターを配置して、関連性のレーティングを行い、最新のゴールデンデータを常に作成できるようにしている。\nHeuristic Ranker から pointwise LTR に切り替えたことで、検索関係のすべての指標が大きく向上。\n一方で pointwise LTR の導入には 6 ヶ月以上が費やされた。\nその後、LTR + Personalization によって、更に指標が向上。 DoorDash では、２つの明確な検索の使用方法が存在し、\n ブランド検索: レストランの名前を検索する、強い意図を持った検索 非ブランド検索: 料理や食品を目的にした検索、検索意図は個人的な思考に強く依存  LTR + Personalization による改善では、非ブランド検索が大きく改善された。(そして検索ボリュームでもかなりの部分を占める)\n Mercari ML\u0026Search Talk #3 ~MLOps \u0026 Platform~ - YouTube\n Build ML platform using Open-Source (English)  メルカリ JP 内の機械学習基盤について語ってくれています。積極的に外部発信されていなかったと思うので気になる方は御覧ください。   How search system evolves in mercari (Japanese)  メルカリの検索基盤の変遷について | メルカリエンジニアリングを基にした講演になっており、この記事が面白いと思った人はぜひ見ましょう! 著者の @shinpei さんはストーリーを語るのが上手いので、自分は記事を読んでいる最中に 2 回笑わせてもらいました。   Mercari Lens beta - product development with WebAssembly × AI (Japanese)  @tkat0 さんによる、WebAssembly を使った機械学習プロダクト開発の裏側の紹介。毎回感嘆するのは、クライアント周りの開発を自分たちでやっているためお客さまの体験に直面する開発になる。インタビューを重ねつつ改善していくのはすごく難しいと思うけど、その姿勢が良いなぁと思っている。バックエンドだけになりがちな機械学習適用ですが、クライアントの要素も考慮しないといけなくなるので、Edge の醍醐味ですね。    新刊『検索システム ― 実務者のための開発改善ガイドブック』のお知らせ – 技術書出版と販売のラムダノート\n 本書は、探索的検索まで考慮しながら「検索システム」と日々格闘している実務家 6 名による実務家のためのガイドブックです。検索エンジンを支えるデータ構造とアルゴリズム、使い勝手のよい UI、検索システムを定量的に評価しつつ改善する手法、個々のユーザーのニーズに寄り添った検索結果を返すための工夫などなど、「よい検索システムをつくる」ために何をどのように始めたらいいのかを伝える羅針盤となっています。\n mocobeta/building-search-system-book: 「仕事ではじめる検索システム」という本があったなら，という想像の産物です - 「検索システム ― 実務者のための開発改善ガイドブック」になりました 1 年半前の構想から、ついに書籍になったという良いお話。 この話題が Twitter で話題になった際に、リポジトリの存在は知ったのですが、commit history を見てみると、ちょこちょこ @mocobeta さんが更新されていたみたいでこの変遷をみるのが書籍完成までの追体験できて面白い。(web 日記みたいで良いですよね 🙂)\n発売日に即購入させていただきましたが、まだじっくりと読めていないので精読後に感想記事を書かせていただこうかなと思っています。\n10X の検索を 10x したい - 10X Product Blog\nネットスーパーのプラットフォームである Stailer の検索システムを改善したお話。 現状の検索システムを理解、ログからパフォーマンスボトルネックを発見して解消するというお手本のようなストーリーで面白かったです。 実際に速度も 10 倍、CPU 使用率も 68%削減というデカイ成果がでていますね。 また、既存のシステム設計も見直すことで費用も 8 割削減と素晴らしい。\nあと冒頭の\n ところで、検索インフラの改善ができるということは、先人たちが検索機能を作り、PMF してサービスが利用されるようになったおかげです。感謝して改善しましょう。\n の言葉がリスペクトに満ちていて個人的にとても好きなのと、\n最後の\n 検索速度の改善や、インフラ負荷対策は楽しく、改善点は無くならないので永遠にできます。しかし、わたしたちの目的は、よい検索機能をお客さまに提供することであることを忘れてはなりません。\n も検索を通じた先の体験改善を念頭においていて素晴らしくないですか?\n著者の @metalunk さんは、一緒に取り組んでくれるエンジニアを募集中なので、カジュアル面談大歓迎6とのことです。\n感想など Twitter で #searchengineeringnewsletter のハッシュタグでつぶやいていただくか、 Google フォーム での感想投稿をお待ちしております。\n投稿の励みにさせていただきます。\nSearch Engineering Newsletter の購読方法 配信記事が蓄積される RSSを作成しています。\nまた、今までの配信記事一覧もこちらから閲覧できます。\n余談 前回と同じく、記事を書く時間の上限を決めた運用にしてみると、頻度も高まりうまく回っていると思う。 DoorDash の記事が面白すぎて抄訳してたら、他の記事を書く時間が消えてしまった。 だが、骨太な記事を公開してくれる DoorDash に感謝。\nまた、Yuki さんという方から、buymeacoffee で ☕ を 3 杯も買っていただき7、非常にテンションが上がりました。\n  Approximate search - OpenSearch documentation ↩︎\n Machine Learning - DoorDash Engineering Blog ↩︎\n Things Not Strings: Understanding Search Intent with Better Recall ↩︎\n Yelp/nrtsearch: A high performance gRPC server on top of Apache Lucene ↩︎\n https://blog.roblox.com/2020/05/scaled-bert-serve-1-billion-daily-requests-cpus/ 。知らなかったので後から読むリストに突っ込んだ。 ゲーム会社の Roblox がそんなに機械学習に力を入れているとは知らなかった…。面白い ↩︎\n @metalunk さんに Twitter で声をかけるといいらしいです https://twitter.com/metalunk ↩︎\n https://www.buymeacoffee.com/hurutoriya/c/3287909 ↩︎\n   ","wordCount":"675","inLanguage":"ja","image":"https://shunyaueta.com/posts/2022-01-16/images/1.png","datePublished":"2022-05-24T23:46:38+09:00","dateModified":"2022-10-17T12:00:06+09:00","author":{"@type":"Person","name":"Shunya Ueta"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://shunyaueta.com/posts/2022-05-24-2346/"},"publisher":{"@type":"Organization","name":"🦅 hurutoriya","logo":{"@type":"ImageObject","url":"https://shunyaueta.com/favicon.ico"}}}</script></head><body id=top><script>if(localStorage.getItem("pref-theme")==="dark"){document.body.classList.add('dark');}else if(localStorage.getItem("pref-theme")==="light"){document.body.classList.remove('dark')}else if(window.matchMedia('(prefers-color-scheme: dark)').matches){document.body.classList.add('dark');}</script><header class=header><nav class=nav><div class=logo><a href=https://shunyaueta.com/ accesskey=h title="🦅 hurutoriya (Alt + H)">🦅 hurutoriya</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://shunyaueta.com/archives title=Archive><span>Archive</span></a></li><li><a href=https://shunyaueta.com/about title=About><span>About</span></a></li><li><a href=https://shunyaueta.com/tags/newsletter/ title=Newsletter><span>Newsletter</span></a></li><li><a href=https://shunyaueta.com/index.xml title=RSS><span>RSS</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Search Engineering Newsletter vol.06</h1><div class=post-meta><span title="2022-05-24 23:46:38 +0900 +0900">May 24, 2022</span>&nbsp;·&nbsp;Shunya Ueta</div></header><figure class=entry-cover><img loading=lazy src=https://shunyaueta.com/posts/2022-01-16/images/1.png alt></figure><div class=post-content><p>6 回目の配信です。
今回のイチオシは、DoorDash の検索システム刷新の記事です。</p><h2 id=search>Search<a hidden class=anchor aria-hidden=true href=#search>#</a></h2><p><a href=https://solr.apache.org/news.html>Apache Solr Release Notes</a></p><p>Solr 9.0.0 がリリースされました。
Elasticsearch と同じく、 Lucene 9 の ANN をサポートしたことにより、近傍探索機能が追加された。</p><p><a href=https://kandasearch.com/news/ac714a31-4a94-42fa-9f2f-3c3da4adc323>Apache Solr 9.0.0 がリリースされました！ - KandaSearch</a></p><p>リリース文の日本語訳も公開されていました。</p><blockquote><p>Also in 9.0 is a brand new Solr Ref Guide, completely re-organized and built on @antoraproject
which gives us a dozen features we&rsquo;ve wanted like search. Which is probably the one you really wanted too:
<a href=https://solr.apache.org/guide/solr/latest/>https://solr.apache.org/guide/solr/latest/</a> > <a href=https://twitter.com/childerelda/status/1524854759022379017>https://twitter.com/childerelda/status/1524854759022379017</a></p></blockquote><p>Solr 9 のリリースに伴い、Apache Solr Reference Guide も再編成されました。検索機能がサイトに搭載されたと言及されているので便利になったのでは?</p><p><a href=https://blog.tensorflow.org/2022/05/on-device-text-to-image-search-with.html>On-device Text-to-Image Search with TensorFlow Lite Searcher Library — The TensorFlow Blog</a></p><p>TensorFlow Lite を使ってデバイス上での言語クエリから画像検索を行った解説記事。
デバイス上で、検索クエリに対応する画像の埋め込みベクトルを ScaNN(Google が開発した近似近傍探索のアルゴリズム)で近似近傍を行い、Top N 枚の画像のメタデータを検索する。つまり、デバイス上には画像のメタデータのみ保有しており、画像自体は例えばネット経由で表示させることも可能。
記事内では、画像をデバイスに保存しているような記述はなかったので、画像の埋め込み空間のみ保持している模様。
Pixel 6 での実機テストでは、各検索クエリは 6m sec で完結しているらしくすべてデバイス上で完結するだけはある鬼の速さ。</p><p>初めて知ったが、<a href=https://www.tensorflow.org/lite/guide/model_maker>TensorFlow Lite Model Maker</a> というライブラリを使うことで、TensorFlow Lite の学習を簡素化できるらしい。</p><p><a href=https://techblog.yahoo.co.jp/entry/2022051130300827/>ユーザの地域考慮＋機械学習モデルによる CTR 改善 〜 ヤフー検索の入力補助機能での事例 - Yahoo! JAPAN Tech Blog</a></p><p>関連検索ワードの精度を地理情報によりパーソナライズしてみたお話。
地理に依存したクエリにおいて曖昧性回避のために有効だが、地理情報ごとに QAC のインデックスを作成するの大変そう。
大まかに分けても地方ごと(関西・関東とか?)にインデックスを作成するのだろうか&mldr;?</p><p>実験結果で、CTR がスマートフォンと PC だと結果が顕著に分かれており、検索結果の上部と下部で PC だと下部が CTR が下がっていて面白かった。
考察しようとしたけどここまで差異がでるのはなぜか思いつかなかった..
これも Web 検索ならではの取り組みがいがある課題ですね。</p><p><a href=https://opensearch.org/blog/community/2022/05/opensearchcon/>OpenSearchCon 2022 · OpenSearch</a></p><p>2022.09.21 に OpenSearch(Elasticsearch をベースに AWS 主体で開発している検索エンジン)のカンファレンスが開催予定。
OpenSearch は近似近傍探索<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>で、 nmslib や faiss を利用しており本元の Elasticsearch と違う方向性に変化していきそうなので、今後に期待している。</p><p><a href=https://doordash.engineering/2022/05/10/3-changes-to-expand-doordashs-product-search/>3 Changes to Expand DoorDash’s Product Search Beyond Delivery</a></p><p>フードデリバリーユニコーンの DoorDash が検索システムで機能を刷新した 3 つの点を解説した記事。
DoorDash の技術ブログは、機械学習<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>や検索システム<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>など、自分の興味ある分野で良質な記事が目白押しなので毎回更新を楽しみにしています。</p><p>かなり面白かったので深堀りして抄訳しました。</p><hr><h3 id=3-changes-to-expand-doordashs-product-search-beyond-delivery-要点まとめ>3 Changes to Expand DoorDash’s Product Search Beyond Delivery 要点まとめ<a hidden class=anchor aria-hidden=true href=#3-changes-to-expand-doordashs-product-search-beyond-delivery-要点まとめ>#</a></h3><p>当初はフードデリバリーのみだったが DoorDash の検索機能は、料理のメニュー検索のために作成された。
ビジネス拡大に伴い、料理のメニュー以外にも、スーパーの食材や雑貨、アルコールやペットフードなど様々な種類の製品を検索可能にする必要があった。</p><ol><li>まず、データレイヤーの視点では、商品のメニュー以外に検索機能を拡大する際に、スーパーの食材などは SKU の単位として非常に粒度が細かく、領域が拡大するたびにその領域に合わせたデータをインデックスする必要がある。</li><li>また、新しい領域にビジネスを拡大する際には、膨大な数の SKU にラベル付をする必要があるが、スケールさせるために機械学習ベースの手法でラベリングをスケールさせた。</li></ol><p>それら２つの課題を解決するために新しく検索システムのインフラを刷新し、 Query undestanding, Document Understanding によって検索結果のランキングを改善する。</p><p>具体的に何をやったのか?</p><ul><li>Rebuilding search infrastructure for new challenges<ul><li><code>active/nextgen indexing</code>: まず DoorDash の事業形態として、高速にインデックスを更新する必要がある。(<code>NOTE:</code>オンライン何かをオーダーする際に、検索インデックスが更新されていなかったので、検索結果には表示されていたけど売り切れてるような体験は避けたいですよね)</li><li><code>federated search</code>: 食料品、料理、アルコールなど複数領域の検索結果を混ぜる</li><li><code>new search storage</code>: 上記を可能にする検索インフラ</li></ul></li><li>Improving query and document understanding<ul><li><code>new taxonomies</code>: Query & Document understanding のために、機械学習を用いた製品のラベリングシステムを開発</li></ul></li><li>Learning-to-rank<ul><li><code>learning-to-rank & evaluation system</code>: Rerank の仕組みと、検索結果の評価を可能にするフレームワークを開発。(モデルの詳細は後日データサイエンスチームがブログ記事を書いてくれるとのこと)</li></ul></li></ul><h4 id=rebuilding-search-infrastructure-for-new-challenges>Rebuilding search infrastructure for new challenges<a hidden class=anchor aria-hidden=true href=#rebuilding-search-infrastructure-for-new-challenges>#</a></h4><h5 id=implementing-activenextgen-indexing>Implementing active/nextgen indexing<a hidden class=anchor aria-hidden=true href=#implementing-activenextgen-indexing>#</a></h5><p>以前 DoorDash は<a href=https://doordash.engineering/2021/07/14/open-source-search-indexing/>Building Faster Indexing with Apache Kafka and Elasticsearch - DoorDash Engineering Blog</a> の記事で紹介されたように、Apache Kafka を使って Elasticsaerch へのインデキシング速度を</p><ul><li>店舗のカタログ全体を backfill する時間を 1 週間から 6.5 時間に短縮</li><li>商品のカタログ全体を backfill する時間を 2 週間から 6.5 時間に短縮</li><li>再インデックス(re-index)の時間を 1 週間から 2 時間に短縮</li></ul><p>と劇的に改善したが、そこから更にインデキシング速度を向上させた。</p><p>具体的なアプローチとして再インデックスをやめて逐次インデキシングを採用することで、優先度の高いデータをリアルタイムに検索エンジンに反映することができるようになった。</p><h5 id=building-a-federated-search>Building a federated search<a hidden class=anchor aria-hidden=true href=#building-a-federated-search>#</a></h5><p>料理、雑貨、食品など複数領域の検索結果を混ぜる federated saerch を導入。
<code>NOTE</code>: イメージとしては、各領域ごとに検索システムのマイクロサービスを作成して、それらの検索結果を混ぜるマイクロサービスも開発した感じです。</p><p>初期はレストラン(料理)検索のみに対応した検索エンジンだったが、新システムでは水平に各領域の検索を行い混ぜることができるようになったので、対応領域拡大の際に、インデックスなどの既存のコードを書き換え対応する必要がなくなった。
また、検索とランキングが水平に分離されたことで、各領域に特化して柔軟に検索性能を向上させることができる。</p><p>また、 federated saerch の実現により例えば一つの領域の検索システムがダウンしたとしても検索システム全体がダウンすることは避けることが可能になった。</p><h5 id=new-search-storage-engine>New search storage engine<a hidden class=anchor aria-hidden=true href=#new-search-storage-engine>#</a></h5><p>Elasticsearch を採用していたが、様々な課題が見えてきたので新しい検索エンジンの検討を開始した。
Apache Lucene をベースにして検索システムを構築した。
利点として、速度向上の他にも、Lucene 9 から使用可能な 近似近傍探索も魅力的な点だった。</p><p><code>NOTE</code>: yelp の nrtsaerch <sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup>もそうだが、既存の Elasticsaerch や Solr がボトルネックになると自作検索エンジンを作り始めるのかっこよすぎる。</p><h4 id=improving-query-and-document-understanding>Improving query and document understanding<a hidden class=anchor aria-hidden=true href=#improving-query-and-document-understanding>#</a></h4><ul><li>手作業でのラベリングを行う。手作業はスケーラブルではないが、高速に仮説を立証して、数百規模のデータセットを作成する。</li><li>プロセスが標準化された後は、オペレーションチームや外部パートナーと連携して、数千規模のラベリングを行う。</li><li>収集した数千のデータを基に機械学習モデルを構築して、そのモデルを使ってラベリングをスケールさせる。</li><li>上記のデータに対して、定期的な品質確認を行う。ラベリングの品質確認は、バイアスの排除やモデルの精度向上に不可欠</li></ul><h5 id=using-human-annotations-to-create-labels>Using human annotations to create labels<a hidden class=anchor aria-hidden=true href=#using-human-annotations-to-create-labels>#</a></h5><p>アノテーションの分散を最小化するために、アノテーションプロセスを文書化したガイドライン作成はとても重要である。
Google 検索が公開している検索品質の<a href=https://static.googleusercontent.com/media/guidelines.raterhub.com/en//searchqualityevaluatorguidelines.pdf>素晴らしいガイドライン</a>があるが、同様に DoorDash もアノテーションガイドラインを作成した。</p><p>だが、もし DoorDash のすべての従業員がフルタイムでマニュアルに則ってアノテーションしたとしても数十万規模のアノテーションタスクを終わらせることはできない。
人間によるアノテーションをスケールさせるためには外部の専門のベンダーに頼らざるを得ない。
Amazon Mechanical Turk や、Google Cloud AI Labeling Service, Scale.AI, Appen など多くのアノテーションビジネスが存在している。</p><p>基本的にアノテーションタスクは、一人のアノテーターの判断を信頼することはできない。
バイアス除去のために、よく使われる手法としては多数決を取り入れた手法がある。
適切な精度のレベルまで引き上げるに 3-4 人、もしくはそれ以上の人数で同一のアノテーションタスクを行う必要がある。
また、良質なガイドラインはアノテーションの品質や速度の向上にも寄与する。</p><p>ベンダーに依頼後、アノテーションデータセットが作成された後にも、我々はデータセットに対する監査を行う必要がある。
(機械学習のシステムであろうと)他のシステムと同様に、品質保証は重要です。</p><p><code>NOTE</code>: 同意しか無い。機械学習だから仕方ないよねだと、その先には行けないので<code>出来得る限り</code> (多種多様な状況があるので、それに応じたベストな行動を指す)の取り組みで品質保証を行う必要がある。</p><p>アノテーションデータセットへ監査を行った際に、面白いテーマが見つかった。</p><ul><li>いくらかのベンダーは特定の地域のアノテーターで構成されており、文化の差異によって誤った判断が発生していた</li><li>特定のベンダーは他のベンダーと比べて、アノテーターが訓練されており、アノテーション結果がとても良質だった</li><li>一部の種類のラベルはアノテーションガイドラインに曖昧性が多すぎた。</li><li>アノテーションタスクの複雑さを過小評価した場合、ベンダーはアノテーションタスクの立ち上げと処理に長時間必要とした。</li></ul><h5 id=using-natural-language-processing-to-enrich-query-context>Using natural language processing to enrich query context<a hidden class=anchor aria-hidden=true href=#using-natural-language-processing-to-enrich-query-context>#</a></h5><p>クエリに対する品詞のアノテーションを行うことで、クエリの言語的な構造を理解ができる。
例えば、 「red pizza」というクエリに対して、パースを行い[JJ NN]というアノテーションを行う。
<code>JJ</code>は形容詞で、<code>NN</code> は名詞を指している。
結果として、このクエリは形容詞が名詞を修飾しているということがわかる。
検索の際に、「red pizza」という単語が完全一致で存在しなかった場合、緩和を行い「pizza」のみの単語で検索を行うことが可能になる。(一般的にクエリ拡張と呼ばれる技術)</p><p><code>NOTE</code>: この POS のアノテーションでわからないのは、クエリ自体正しい英語ではなく誤植まみれの英語がくるから POS アノテーションが必要問事なのかなと思ったりした? 専門分野ではないので素人的発想だが、形態素解析が必要なく誤植ももしなければ POS アノテーションせずとも品詞はすべて把握できそう?
だが、後述の Spacy で</p><blockquote><p>NLP libraries involve far more than POS tagging</p></blockquote><p>と書いてあるので、アノテーション自体は必要なタスクなんだと理解。</p><p>POS タギング自体は <a href=https://spacy.io/>Spacy</a> を使っている。
POS タギングのサービングだが、検索時にオンライン(リアルタイム)でのサービングが必要なので速度向上のために以下のような選択肢がある。</p><ul><li>オフラインで計算したクエリの品詞のペアを Redis などのインメモリ DB に格納してルックアップテーブルを構築して推論を行わないようにした。(人気のあるクエリのみに焦点をあて、テイルクエリ(頻度の低いクエリ)はカーディナリティが爆発するので DB には格納しない)</li><li>Spacy を使わずに JVM で動く NLP ライブラリを使ってサービングする</li><li>Roblox のようにチューニングを極めることで、トランスフォーマーモデルでもオンライン毎日 10 億規模の推論を実現すること<sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup>も可能</li></ul><p><code>NOTE</code>: 選択肢は色々とありますといいつつも何を採用したかは次の記事に期待してねと書いていた。個人的には DB でルックアップテーブル使うのが初手だと一番良さそう</p><h4 id=learning-to-rank>Learning-to-rank<a hidden class=anchor aria-hidden=true href=#learning-to-rank>#</a></h4><p>DoorDash の ランキングアルゴリズムの変遷</p><ol><li>Heuristic Ranker (BM25+ 店舗の人気度)</li><li>LTR:Pointwise</li><li>LTR + Personalization</li></ol><p>初期の LTR モデルをデプロイ時に、オンラインでの検索評価のフレームワークを社内で議論して方向性を固めていった。
ビジネス指標と情報検索指標の２つのカテゴリの指標を持つ</p><ul><li>ビジネス指標: 検索のコンバージョン率、CTR、first click rank position などは North star 指標</li><li>情報検索指標: mean-reciprical rank, nDCG</li></ul><p>定常的にゴールデンデータを作成する仕組みを作成。アノテーターを配置して、関連性のレーティングを行い、最新のゴールデンデータを常に作成できるようにしている。</p><p>Heuristic Ranker から pointwise LTR に切り替えたことで、検索関係のすべての指標が大きく向上。</p><p>一方で pointwise LTR の導入には 6 ヶ月以上が費やされた。</p><p>その後、LTR + Personalization によって、更に指標が向上。
DoorDash では、２つの明確な検索の使用方法が存在し、</p><ul><li>ブランド検索: レストランの名前を検索する、強い意図を持った検索</li><li>非ブランド検索: 料理や食品を目的にした検索、検索意図は個人的な思考に強く依存</li></ul><p>LTR + Personalization による改善では、非ブランド検索が大きく改善された。(そして検索ボリュームでもかなりの部分を占める)</p><hr><p><a href="https://www.youtube.com/watch?v=3fo5YyRqRII">Mercari ML&Search Talk #3 ~MLOps & Platform~ - YouTube</a></p><ul><li><a href="https://www.youtube.com/watch?v=3fo5YyRqRII&t=555s">Build ML platform using Open-Source (English)</a><ul><li>メルカリ JP 内の機械学習基盤について語ってくれています。積極的に外部発信されていなかったと思うので気になる方は御覧ください。</li></ul></li><li><a href="https://youtu.be/3fo5YyRqRII?t=2308">How search system evolves in mercari (Japanese)</a><ul><li><a href=https://engineering.mercari.com/blog/entry/20220207-776318b784/>メルカリの検索基盤の変遷について | メルカリエンジニアリング</a>を基にした講演になっており、この記事が面白いと思った人はぜひ見ましょう!
著者の @shinpei さんはストーリーを語るのが上手いので、自分は記事を読んでいる最中に 2 回笑わせてもらいました。</li></ul></li><li><a href=https://youtu.be/3fo5YyRqRII>Mercari Lens beta - product development with WebAssembly × AI (Japanese)</a><ul><li>@tkat0 さんによる、WebAssembly を使った機械学習プロダクト開発の裏側の紹介。毎回感嘆するのは、クライアント周りの開発を自分たちでやっているためお客さまの体験に直面する開発になる。インタビューを重ねつつ改善していくのはすごく難しいと思うけど、その姿勢が良いなぁと思っている。バックエンドだけになりがちな機械学習適用ですが、クライアントの要素も考慮しないといけなくなるので、Edge の醍醐味ですね。</li></ul></li></ul><p><a href=https://www.lambdanote.com/blogs/news/ir-system>新刊『検索システム ― 実務者のための開発改善ガイドブック』のお知らせ – 技術書出版と販売のラムダノート</a></p><blockquote><p>本書は、探索的検索まで考慮しながら「検索システム」と日々格闘している実務家 6 名による実務家のためのガイドブックです。検索エンジンを支えるデータ構造とアルゴリズム、使い勝手のよい UI、検索システムを定量的に評価しつつ改善する手法、個々のユーザーのニーズに寄り添った検索結果を返すための工夫などなど、「よい検索システムをつくる」ために何をどのように始めたらいいのかを伝える羅針盤となっています。</p></blockquote><p><a href=https://github.com/mocobeta/building-search-system-book>mocobeta/building-search-system-book: 「仕事ではじめる検索システム」という本があったなら，という想像の産物です -> 「検索システム ― 実務者のための開発改善ガイドブック」になりました</a> 1 年半前の構想から、ついに書籍になったという良いお話。
この話題が Twitter で話題になった際に、リポジトリの存在は知ったのですが、<a href=https://github.com/mocobeta/building-search-system-book/commits/master>commit history</a> を見てみると、ちょこちょこ @mocobeta さんが更新されていたみたいでこの変遷をみるのが書籍完成までの追体験できて面白い。(web 日記みたいで良いですよね 🙂)</p><p>発売日に即購入させていただきましたが、まだじっくりと読めていないので精読後に感想記事を書かせていただこうかなと思っています。</p><p><a href=https://product.10x.co.jp/entry/serch-10x>10X の検索を 10x したい - 10X Product Blog</a></p><p>ネットスーパーのプラットフォームである Stailer の検索システムを改善したお話。
現状の検索システムを理解、ログからパフォーマンスボトルネックを発見して解消するというお手本のようなストーリーで面白かったです。
実際に速度も 10 倍、CPU 使用率も 68%削減というデカイ成果がでていますね。
また、既存のシステム設計も見直すことで費用も 8 割削減と素晴らしい。</p><p>あと冒頭の</p><blockquote><p>ところで、検索インフラの改善ができるということは、先人たちが検索機能を作り、PMF してサービスが利用されるようになったおかげです。感謝して改善しましょう。</p></blockquote><p>の言葉がリスペクトに満ちていて個人的にとても好きなのと、</p><p>最後の</p><blockquote><p>検索速度の改善や、インフラ負荷対策は楽しく、改善点は無くならないので永遠にできます。しかし、わたしたちの目的は、よい検索機能をお客さまに提供することであることを忘れてはなりません。</p></blockquote><p>も検索を通じた先の体験改善を念頭においていて素晴らしくないですか?</p><p>著者の @metalunk さんは、一緒に取り組んでくれるエンジニアを募集中なので、カジュアル面談大歓迎<sup id=fnref:6><a href=#fn:6 class=footnote-ref role=doc-noteref>6</a></sup>とのことです。</p><h2 id=感想など>感想など<a hidden class=anchor aria-hidden=true href=#感想など>#</a></h2><p>Twitter で <a href="https://twitter.com/hashtag/searchengineeringnewsletter?f=live">#searchengineeringnewsletter</a> のハッシュタグでつぶやいていただくか、
<a href=https://forms.gle/xFgMwRJbeqJxNtfe9>Google フォーム</a> での感想投稿をお待ちしております。</p><p>投稿の励みにさせていただきます。</p><h2 id=search-engineering-newsletter-の購読方法>Search Engineering Newsletter の購読方法<a hidden class=anchor aria-hidden=true href=#search-engineering-newsletter-の購読方法>#</a></h2><p>配信記事が蓄積される <a href=https://shunyaueta.com/tags/newsletter/index.xml>RSS</a>を作成しています。</p><p>また、今までの配信記事一覧も<a href=https://shunyaueta.com/tags/newsletter/>こちら</a>から閲覧できます。</p><h2 id=余談>余談<a hidden class=anchor aria-hidden=true href=#余談>#</a></h2><p>前回と同じく、記事を書く時間の上限を決めた運用にしてみると、頻度も高まりうまく回っていると思う。
DoorDash の記事が面白すぎて抄訳してたら、他の記事を書く時間が消えてしまった。
だが、骨太な記事を公開してくれる DoorDash に感謝。</p><p>また、Yuki さんという方から、<a href=https://www.buymeacoffee.com/hurutoriya>buymeacoffee</a> で ☕ を 3 杯も買っていただき<sup id=fnref:7><a href=#fn:7 class=footnote-ref role=doc-noteref>7</a></sup>、非常にテンションが上がりました。</p><section class=footnotes role=doc-endnotes><hr><ol><li id=fn:1 role=doc-endnote><p><a href=https://opensearch.org/docs/latest/search-plugins/knn/approximate-knn/>Approximate search - OpenSearch documentation</a> <a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2 role=doc-endnote><p><a href=https://doordash.engineering/category/data-science-and-machine-learning/>Machine Learning - DoorDash Engineering Blog</a> <a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3 role=doc-endnote><p><a href=https://doordash.engineering/2020/12/15/understanding-search-intent-with-better-recall/>Things Not Strings: Understanding Search Intent with Better Recall</a> <a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4 role=doc-endnote><p><a href=https://github.com/Yelp/nrtsearch>Yelp/nrtsearch: A high performance gRPC server on top of Apache Lucene</a> <a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5 role=doc-endnote><p><a href=https://blog.roblox.com/2020/05/scaled-bert-serve-1-billion-daily-requests-cpus/>https://blog.roblox.com/2020/05/scaled-bert-serve-1-billion-daily-requests-cpus/</a> 。知らなかったので後から読むリストに突っ込んだ。 ゲーム会社の Roblox がそんなに機械学習に力を入れているとは知らなかった&mldr;。面白い <a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:6 role=doc-endnote><p>@metalunk さんに Twitter で声をかけるといいらしいです <a href=https://twitter.com/metalunk>https://twitter.com/metalunk</a> <a href=#fnref:6 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:7 role=doc-endnote><p><a href=https://www.buymeacoffee.com/hurutoriya/c/3287909>https://www.buymeacoffee.com/hurutoriya/c/3287909</a> <a href=#fnref:7 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></section><h2>See Also</h2><ul><li><a href=/posts/2022-05-02-2350/>Search Engineering Newsletter vol.05</a></li><li><a href=/posts/2022-04-07/>Search Engineering Newsletter vol.04</a></li><li><a href=/posts/2022-03-28/>Search Engineering Newsletter vol.03</a></li><li><a href=/posts/2022-02-09/>Search Engineering Newsletter vol.02</a></li><li><a href=/posts/2022-01-21/>Search Engineering Newsletter vol.01</a></li></ul><h2>Support</h2>記事をお読みくださりありがとうございます。このウェブサイトの運営を支援していただける方を募集しています。
もしよろしければ、下のボタンからサポート(投げ銭)していただけると、ブログ執筆、情報発信のモチベーションに繋がります✨
<a href=https://www.buymeacoffee.com/hurutoriya><img src="https://img.buymeacoffee.com/button-api/?text=Buy me a coffee&emoji=☕&slug=hurutoriya&button_colour=FFDD00&font_colour=000000&font_family=Inter&outline_colour=000000&coffee_colour=ffffff"></a></div><footer class=post-footer><ul class=post-tags><li><a href=https://shunyaueta.com/tags/newsletter/>newsletter</a></li><li><a href=https://shunyaueta.com/tags/search/>search</a></li></ul><nav class=paginav><a class=prev href=https://shunyaueta.com/posts/2022-06-03-2044/><span class=title>« 前のページ</span><br><span>Label Studio を k8s にデプロイする</span></a>
<a class=next href=https://shunyaueta.com/posts/2022-05-12-2337/><span class=title>次のページ »</span><br><span>Re:プログラム雑談 188回：ゲスト回：MessagePassingの話とか</span></a></nav></footer><script src=https://giscus.app/client.js data-repo=hurutoriya/hurutoriya.github.io data-repo-id="MDEwOlJlcG9zaXRvcnk2MDgyNTY1Nw==" data-category=Comments data-category-id=DIC_kwDOA6AgOc4CAQTX data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=0 data-theme=dark data-lang=ja crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2022 <a href=https://shunyaueta.com/>🦅 hurutoriya</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z" /></svg></a><script>let menu=document.getElementById('menu')
if(menu){menu.scrollLeft=localStorage.getItem("menu-scroll-position");menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft);}}
document.querySelectorAll('a[href^="#"]').forEach(anchor=>{anchor.addEventListener("click",function(e){e.preventDefault();var id=this.getAttribute("href").substr(1);if(!window.matchMedia('(prefers-reduced-motion: reduce)').matches){document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({behavior:"smooth"});}else{document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();}
if(id==="top"){history.replaceState(null,null," ");}else{history.pushState(null,null,`#${id}`);}});});</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){if(document.body.scrollTop>800||document.documentElement.scrollTop>800){mybutton.style.visibility="visible";mybutton.style.opacity="1";}else{mybutton.style.visibility="hidden";mybutton.style.opacity="0";}};</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{if(document.body.className.includes("dark")){document.body.classList.remove('dark');localStorage.setItem("pref-theme",'light');}else{document.body.classList.add('dark');localStorage.setItem("pref-theme",'dark');}})</script><script>document.querySelectorAll('pre > code').forEach((codeblock)=>{const container=codeblock.parentNode.parentNode;const copybutton=document.createElement('button');copybutton.classList.add('copy-code');copybutton.innerHTML='コピー';function copyingDone(){copybutton.innerHTML='コピーされました!';setTimeout(()=>{copybutton.innerHTML='コピー';},2000);}
copybutton.addEventListener('click',(cb)=>{if('clipboard'in navigator){navigator.clipboard.writeText(codeblock.textContent);copyingDone();return;}
const range=document.createRange();range.selectNodeContents(codeblock);const selection=window.getSelection();selection.removeAllRanges();selection.addRange(range);try{document.execCommand('copy');copyingDone();}catch(e){};selection.removeRange(range);});if(container.classList.contains("highlight")){container.appendChild(copybutton);}else if(container.parentNode.firstChild==container){}else if(codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"){codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);}else{codeblock.parentNode.appendChild(copybutton);}});</script></body></html>