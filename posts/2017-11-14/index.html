<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="OpenCV と MobileNet を使って物体検出を行った
Object Detection with OpenCV dnn modules and MobileNetSSD on Jupyter Notebook
Introduction 物体検出を Deep Leaning と OpenCV を用いて行う
OpenCV 3.3 からdnnモジュールが正式にリリースされた
 The main news is that we promoted DNN module from opencv_contrib to the main repository, improved and accelerated it a lot. An external BLAS implementation is not needed anymore. For GPU there is experimental DNN acceleration using Halide (http://halide-lang.org_). The detailed information about the module can be found in our wiki: Deep Learning in OpenCV."><meta name=theme-color content="#d3381c"><meta property="og:title" content="OpenCV 3.3から使えるDNNモジュールを使って物体検出 • Software Engineer as Data Scientist"><meta property="og:description" content="OpenCV と MobileNet を使って物体検出を行った
Object Detection with OpenCV dnn modules and MobileNetSSD on Jupyter Notebook
Introduction 物体検出を Deep Leaning と OpenCV を用いて行う
OpenCV 3.3 からdnnモジュールが正式にリリースされた
 The main news is that we promoted DNN module from opencv_contrib to the main repository, improved and accelerated it a lot. An external BLAS implementation is not needed anymore. For GPU there is experimental DNN acceleration using Halide (http://halide-lang.org_). The detailed information about the module can be found in our wiki: Deep Learning in OpenCV."><meta property="og:url" content="https://shunyaueta.com/posts/2017-11-14/"><meta property="og:site_name" content="Software Engineer as Data Scientist"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:tag" content="Python"><meta property="article:tag" content="OpenCV"><meta property="article:tag" content="Deep Learning"><meta property="article:tag" content="Computer Vision"><meta property="article:published_time" content="2017-11-14T11:36:43Z"><meta property="article:modified_time" content="2019-06-16T18:16:04+09:00"><meta name=twitter:card content="summary"><meta name=twitter:site content="@hurutoriya"><meta name=generator content="Hugo 0.67.1"><title>OpenCV 3.3から使えるDNNモジュールを使って物体検出 • Software Engineer as Data Scientist</title><link rel=canonical href=https://shunyaueta.com/posts/2017-11-14/><link rel=icon href=/favicon.ico><link rel=stylesheet href=/assets/css/main.ab98e12b.css><link rel=stylesheet href=/css/custom.css><style>:root{--color-accent:#d3381c}</style><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-39994406-11','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script data-ad-client=ca-pub-8604812913439531 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body class="page type-posts"><div class=site><a class=screen-reader-text href=#content>Skip to Content</a><div class=main><div class=header-widgets><div class=container><style>.widget-breadcrumbs li:after{content:'\2f '}</style><section class="widget widget-breadcrumbs sep-after"><nav id=breadcrumbs><ol><li><a href=/>Software Engineer as Data Scientist</a></li><li><a href=/posts/>Posts</a></li><li><span>OpenCV 3.3から使えるDNNモジュールを使って物体検出</span></li></ol></nav></section></div></div><header id=header class="header site-header"><div class="container sep-after"><div class=header-info><p class="site-title title">Software Engineer as Data Scientist</p><p class="desc site-desc">Enjoy Software Engineering & Data Science!!</p></div></div></header><main id=content><article lang=ja class=entry><header class="header entry-header"><div class="container sep-after"><div class=header-info><h1 class=title>OpenCV 3.3から使えるDNNモジュールを使って物体検出</h1></div><div class=entry-meta><span class=posted-on><svg class="icon" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"/><line x1="16" y1="2" x2="16" y2="6"/><line x1="8" y1="2" x2="8" y2="6"/><line x1="3" y1="10" x2="21" y2="10"/></svg><span class=screen-reader-text>Posted on</span>
<time class=entry-date datetime=2017-11-14T11:36:43Z>2017.11.14</time></span>
<span class=reading-time><svg class="icon" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><circle cx="12" cy="12" r="10"/><polyline points="12 6 12 12 15 15"/></svg>One min read</span></div></div></header><div class="container entry-content"><p>OpenCV と MobileNet を使って物体検出を行った</p><p><img src=/posts/2017-11-14/images/1.png alt=image></p><p>Object Detection with OpenCV dnn modules and MobileNetSSD on Jupyter Notebook</p><h3 id=introduction>Introduction</h3><p>物体検出を Deep Leaning と OpenCV を用いて行う</p><p>OpenCV 3.3 から<code>dnn</code>モジュールが正式にリリースされた</p><blockquote><p><em>The main news is that we promoted DNN module from opencv_contrib to the main repository, improved and accelerated it a lot. An external BLAS implementation is not needed anymore. For GPU there is experimental DNN acceleration using Halide (</em><a href=http://halide-lang.org><em>http://halide-lang.org</em></a>_). The detailed information about the module can be found in our wiki: Deep Learning in OpenCV.<br>_<a href=https://opencv.org/opencv-3-3.html><em>https://opencv.org/opencv-3-3.html</em></a></p></blockquote><p>今回はその dnn モジュールを使って物体検出を行う</p><ul><li><a href=https://github.com/opencv/opencv/tree/master/modules/dnn>OpenCV dnn modules</a></li><li><a href=https://github.com/opencv/opencv/tree/master/samples/dnn>Official Sample</a></li></ul><p>この記事は主に<a href=https://www.pyimagesearch.com/2017/09/11/object-detection-with-deep-learning-and-opencv/>pyimagesearch の記事</a>を参考に行いました。詳細な解説がありがたいです Deep Leaning を基にした物体検出で有名な手法は以下の 3 つである</p><ul><li>Faster R-CNN : 2015</li><li>YOLO : 2015</li><li>SSDs : 2015</li></ul><p>物体検出を行う際の DNN のアーキテクチャでは主に VGG か ResNet が用いられる。しかし欠点としてこれらのアーキテクチャは非常に大きく 200–500MB のサイズになってしまう</p><p>物体検出において速度、精度、メモリの３つのバランスを考慮する場合、どのアーキテクチャを選ぶべきかを Google が論文としてまとめている</p><p><a href=https://arxiv.org/abs/1611.10012>[1611.10012] Speed/accuracy trade-offs for modern convolutional object detectors</a></p><p>一行でまとめると、基本的に速度と精度はトレードオフであり、最速は SSDs MobileNet, 最高精度は Faster R-CNN w/Inception Resnet at stride 8</p><p>今回は省メモリかつ速度が早い SSDs MobileNet を用いて物体検出を行った</p><p>Demo on JupyterNotebook</p><h3 id=code>Code</h3><p><a href=https://github.com/hurutoriya/yolov2_api>hurutoriya/yolov2_api</a></p><h3 id=study>Study</h3><ul><li>Print デバッグをやめて、logging module に切り替えた。出力が綺麗になっていい感じ</li><li>OpenCV だけで DNN を使えるのは結構便利(学習済モデルとかは必須)</li></ul><h3 id=future-work>Future Work</h3><ul><li>YOLO v2 も C++のサンプルがあるので、Python でも動くようにしたい</li><li>Web App に組み込めるくらい速そうなので、やってみましょう</li></ul></div><footer class=entry-footer><div class="container sep-before"><div class=last-updated><svg class="icon" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M20 14.66V20a2 2 0 01-2 2H4a2 2 0 01-2-2V6a2 2 0 012-2h5.34" /><polygon points="18 2 22 6 12 16 8 16 8 12 18 2" /></svg><span class=screen-reader-text>Last updated:</span>
<time class=entry-date datetime=2019-06-16T18:16:04+09:00>2019.06.16</time></div></div></footer></article><nav class=entry-nav><div class=container><div class="prev-entry sep-before"><a href=/posts/2017-11-13/><span aria-hidden=true><svg class="icon" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><line x1="20" y1="12" x2="4" y2="12"/><polyline points="10 18 4 12 10 6"/></svg>Previous</span>
<span class=screen-reader-text>Previous post: </span>Djangoで顔認識の結果をJSONで返す最小構成のAPIサーバーを作った</a></div><div class="next-entry sep-before"><a href=/posts/2017-11-22/><span class=screen-reader-text>Next post: </span>Jupyter上でSVGのイラストやアニメーションが作成できるプラグイン egel<span aria-hidden=true>Next<svg class="icon" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><line x1="4" y1="12" x2="20" y2="12"/><polyline points="14 6 20 12 14 18"/></svg></span></a></div></div></nav><section id=comments class=comments><div class="container sep-before"><div class=comments-area><script src=https://utteranc.es/client.js repo=hurutoriya/hurutoriya.github.io issue-term=url crossorigin=anonymous async></script></div></div></section></main><footer id=footer class=footer><div class="container sep-before"><section class="widget widget-about sep-after"><header><h2 class="title site-title"><a href=/>Shunya UETA</a></h2><div class=desc>Shunya UETA who is a working on Machine Learning as Software Engineer at <a href=https://about.mercari.com/en/>Mercari, inc</a>. Opinions are my own. → <a href=/about>See more detail!</a></div></header></section><section class="widget widget-social_menu sep-after"><nav aria-label="Social Menu"><ul><li><a href=https://github.com/hurutoriya target=_blank rel=noopener><span class=screen-reader-text>Open Github account in new tab</span><svg class="icon" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77a5.44 5.44.0 00-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></li><li><a href=https://facebook.com/shunyaueta target=_blank rel=noopener><span class=screen-reader-text>Open Facebook account in new tab</span><svg class="icon" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M18 2h-3a5 5 0 00-5 5v3H7v4h3v8h4v-8h3l1-4h-4V7a1 1 0 011-1h3z"/></svg></a></li><li><a href=https://twitter.com/hurutoriya target=_blank rel=noopener><span class=screen-reader-text>Open Twitter account in new tab</span><svg class="icon" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg></a></li><li><a href=https://linkedin.com/in/hurutoriya target=_blank rel=noopener><span class=screen-reader-text>Open Linkedin account in new tab</span><svg class="icon" viewbox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" aria-hidden="true"><path d="M16 8a6 6 0 016 6v7h-4v-7a2 2 0 00-2-2 2 2 0 00-2 2v7h-4v-7a6 6 0 016-6z"/><rect x="2" y="9" width="4" height="12"/><circle cx="4" cy="4" r="2"/></svg></a></li></ul></nav></section><div class=copyright><p>&copy; 2013-2020 Shunya UETA</p></div></div></footer></div></div><script>window.__assets_js_src="/assets/js/"</script><script src=/assets/js/main.c3bcf2df.js></script><script src=/js/custom.js></script></body></html>