<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>search on Shunya Ueta</title><link>https://shunyaueta.com/tags/search/</link><description>Recent content in search on Shunya Ueta</description><generator>Hugo -- gohugo.io</generator><language>ja</language><lastBuildDate>Sat, 10 Jul 2021 23:20:58 +0900</lastBuildDate><atom:link href="https://shunyaueta.com/tags/search/index.xml" rel="self" type="application/rss+xml"/><item><title>eコマースの検索と推薦についてのサーベイ論文である 'Challenges and research opportunities in eCommerce search and recommendations' を社内勉強会で発表した</title><link>https://shunyaueta.com/posts/2021-07-10/</link><pubDate>Sat, 10 Jul 2021 23:20:58 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-07-10/</guid><description>SIGIR eCom を探索していたら発見したサーベイ論文の &amp;ldquo;Challenges and research opportunities in eCommerce search and recommendations&amp;quot;が面白かったので、社内の勉強会で発表してきた。
和訳すると、「eコマースの検索と推薦における挑戦と研究トピック」で、eコマースにおける検索と推薦の課題が明瞭に書かれていて非常に面白い論文でした。 自分もまだ検索エンジニアとして日が浅いので、手持ちのパターンを増やせるように日々勉強していますが、この論文のおかげでかなり解像度が上がった。
Introducing &amp;quot;Challenges and research opportunities in eCommerce search and recommendations&amp;quot; from Shunya Ueta 個人的に面白かったのは、
そもそも、顧客が商品を検索するというタスクの奥深さと面白さが知れる Query Understanding は、非構造なクエリを構造化されたクエリに変換するのが究極的な目標 Learn to Rank(LtR)の実践的な課題点として、LtR適用時に、Native Ranker とのギャップが発生して非連続な検索結果を返してしまうことがある 実際のクエリから、購入される商品はクエリと商品が関連性が高いとは限らないのでモデルを学習させる際には要注意 Amazonでの実例として クエリ「ダイヤモンドリング」に対してLtR を適用すると、実際のクエリとそれに紐づくランキングシグナルから学習すると、「ダイヤモンドリング」というクエリで、「ジルコニウムリング」が大量に購買されていたのでLtRでは、「ダイヤモンドリング」というクエリに対して、「ジルコニウムリング」を表示するようになってしまった これは、学習データを全く見ないで適用するとそうなりそうだけど、広範囲に影響を及ぼすLtRのQAは非常に骨が折れそう Ref: Amazon Search: The Joy of Ranking Products スライド作成元のMarkdownはこちらです。 スライド内のリンクに簡単にアクセスできます。
Matching &amp;amp; Rankingの章までを解説したけど、それでも45m喋りっぱなしで最後のほうがかなり駆け足になってしまった。 また、英語での発表になったけど、やはり熟れたわかりやすい発表レベルに達するには、まだまだだなぁ感じた。精進せねば
余談 今回スライド作成に Marp を使いましたが、VS Code上でスラスラとかけつつ読みやすくテンションの上がるデザインに簡単にできて感動しました。これからも愛用したいなと思います。</description></item><item><title>[抄訳] 検索エンジンの達成度と検索チームの成熟度モデル</title><link>https://shunyaueta.com/posts/2021-05-12/</link><pubDate>Wed, 12 May 2021 22:33:23 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-05-12/</guid><description>@rilmayer_jpさんのツイート をきっかけに、検索チームの成熟度モデルの存在を知りました。ありがとうございます!
Eric Pugh さんが、検索エンジンに関する会議で公演した内容で、検索チームがどのように成熟していくかをモデル化しており、それが面白かったので備忘録として残しておく
更新 2021/05/13 : 原著者のEric Pugh さんから、抄訳のご快諾いただけました。ありがとうございます 翻訳元資料 Search Relevance Organizational Maturity Model slide Haystack LIVE! 2020 Search Relevance Organizational Maturity Model 検索エンジンのレベル 検索エンジンへの要求をどれだけ満たしているかをピラミッド構造でわかりやすく説明している
検索チームの成熟度モデル 7項目の検索チームの評価項目を考え、3段階で評価を行う
ビジネス 顧客の要求の理解 検索技術 実験駆動 UX コンテンツ強化 データ保有 発展 ステークホルダーがリアルタイムKPIを使用している データ解析から質的なデータを得ている カスタムプラグインを作成している A/Bテスト、オフラインテストをサポートしている 革新的な発見性を提供している(chatbot, 等) NLPやデータサイエンティストの専任チームが取り組んでいる 多種多様な、複雑かつ大規模なデータを扱っている 実践 不定期にレポートを行っている いくつかのユーザーテスト、基礎的な分析を行っている 関連性のための複雑な設定、プラグインの使用をしている 実験は適用可能だが、A/Bテストなどはできない 発見しやすくするためのUIを提供している 分類学や概念体型の適用をしている データの複雑度の監視している 基礎 ビジネスインパクトが測定されていない クエリログは存在しない、またはユーザーテストを行っていない 技術スタックを適度に調整している 検索のテストは手作業で行い、デプロイは低頻度 1ページに10個の検索結果がある 僅かな取り組み(シノニムなど) とても単純なデータモデル 感想 ひと目で</description></item></channel></rss>