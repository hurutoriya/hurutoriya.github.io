<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>MLOps on Software Engineer as Data Scientist</title><link>https://shunyaueta.com/tags/mlops/</link><description>Recent content in MLOps on Software Engineer as Data Scientist</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Sun, 17 Jan 2021 00:18:47 +0900</lastBuildDate><atom:link href="https://shunyaueta.com/tags/mlops/index.xml" rel="self" type="application/rss+xml"/><item><title>抄訳 Towards ML Engineering: A Brief History Of TensorFlow Extended (TFX)</title><link>https://shunyaueta.com/posts/2021-01-17/</link><pubDate>Sun, 17 Jan 2021 00:18:47 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-01-17/</guid><description>この記事はMLOps Advent Calendar 2020の25日目の記事です。(盛大に遅れました)
KDD2019の招待講演でGoogleがTFXの歴史について発表されており、TFX信者の自分としては発表内容が以前から気になっていたが、公開はされておらずなんとかして見れないかな~と思っていましたが、TensorFlowのBlogで該当の招待講演が論文化されたことを知ったのでメモがてら抄訳として残しておく。
注意)この翻訳記事は原著論文の著者陣からレビューはされていません Shunya Ueta, are providing a translation and abridgment, which has not been reviewed by the authors. Citation Karmarkar, A., Altay, A., Zaks, A., Polyzotis, N., Ramesh, A., Mathes, B., … &amp;amp; Li, Z. (2020). Towards ML Engineering: A Brief History Of TensorFlow Extended (TFX). arXiv preprint arXiv:2010.02013. ***
Towards ML Engineering with TensorFlow Extended (TFX) at KDD2019 Towards ML Engineering with TensorFlow Extended (TFX) ACM PDFはarxiv でも閲覧可能 https://arxiv.</description></item><item><title>MLOps の国際会議 OpML'20 に論文が採択されたので登壇してきた</title><link>https://shunyaueta.com/posts/2020-09-06/</link><pubDate>Sun, 06 Sep 2020 23:31:03 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-09-06/</guid><description>MLOpsの査読付き国際会議 2020 USENIX Conference on Operational Machine Learning (略称 OpML&amp;rsquo;20)に論文が採択されたので、登壇してきた。
Podcastでも紹介しました
#1 MLOps の国際会議 OpML20 について at just4fun.fm
MLOpsの査読付き国際会議とOpMLの立ち位置 機械学習エンジニアリング・MLOpsの領域の会議でも一番有名なものとして2018年に発足したMLSysがあります。(ちなみに最初はSysMLという名前でした) このカンファレンスの傾向としては、アカデミアの研究者主体の発足経緯からアカデミアからインダストリーへの橋渡し的立ち位置となっています。具体的には、発表者はアカデミアの方が大半でハードウェアから、モデルのOSS公開など幅広く機械学習エンジニアリング・MLOpsの周辺トピックをカバーしています。
OpMLはその一年後に、MLOpsを軸にしたUSENIXが母体の会議として誕生しました。 USENIXはSRECON、OSDIなどを開催している団体です。学会的なスタイルに則り、先端的な計算機システムの成果を論文として公開されています。MLSysと対称的にこちらはインダストリーからアカデミアへの橋渡し的立ち位置となっています。発表内容は企業での発表者が多く、実際の運用で得られた各企業のMLOpsのベストプラクティスなどがメインで話されています。 個人的にはOpMLのほうが、MLOpsのど真ん中を主体に置いているのでMLSysよりも盛り上がってほしいなと思っています。
OpML&amp;rsquo;19がどのような様子だったかは、以下の記事がわかりやすいです。
OpML ‘19参加レポート The first conference of Operational Machine Learning: OpML ‘19 自分自身、機械学習エンジニアリングやMLOps周りのカンファレンス情報などを追いかけていますが、この分野で査読付きかつ論文として残せる形式の国際会議は主に上記の２つの認識です。
KDDやCOLING、NAACLなどの国際会議でもインダストリートラックが常設されるようになって久しいですが、最近ではインダストリートラックだけではなく、積極的に実応用前提のワークショップ(ECNLP at ACL2020, IRS2020 at KDD2020など)が開催されており機械学習の理論と実応用の融合が進んでいます。
OpML&amp;rsquo;20への投稿と採択で得られたもの OpML&amp;rsquo;20では下記２つの発表枠があり、投稿者がどちらかを選んで発表を行います。
査読付きで20mの口頭発表 2ページの査読付き論文+20mの口頭発表 OpML20で推奨されるトピックでも、自分たちが持っているネタで
New model introduction into production (e.g., staging, A/B test)
においてNoveltyがあると考えて、ここからストーリーを組み立てていきました。
スケジュール感として投稿締切が2020/02/25で、その1ヶ月前の1月末から毎日1時間、Google Calendarで時間を抑えて同僚と集中的に論文の執筆を行いました。 最初にガッと3ページほど書いて、その後洗練させて2ページに圧縮して投稿しました。 あらめて添削や執筆をともに行ってくれた同僚たちに感謝します。
そして投稿の1ヶ月後に通知メールが来て採択を知りました。 添削を何度も繰り返して時間が迫るなかなんとか投稿できたという状態で、とりあえず投稿できて良かったなと感じていた最中だったので、採択通知が来て本当におどきました。</description></item><item><title>The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction</title><link>https://shunyaueta.com/posts/2020-04-25/</link><pubDate>Sat, 25 Apr 2020 01:35:20 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-04-25/</guid><description>[抄訳] What’s your ML test score? A rubric for ML production systemsで紹介した論文の続編があったので読んでみました。
注意)この翻訳記事は原著論文の著者陣からレビューはされていません Shunya Ueta, are providing a translation and abridgment, which has not been reviewed by the authors. Change log 2020/06/24 著者のEric Breck さんに連絡をし、抄訳の公開を快諾していただきました。ありがとうございます。 完全な citation 情報を追記しました。 この翻訳記事が著者のレビューを受けていないことを追記しました。 Citation Eric Breck, Shanqing Cai, Michael Salib, . The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction. In 2017 IEEE International Conference on Big Data (Big Data) (pp.</description></item><item><title>What’s your ML test score? A rubric for ML production systems</title><link>https://shunyaueta.com/posts/2020-04-19/</link><pubDate>Sun, 19 Apr 2020 22:18:10 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-04-19/</guid><description>NIPS206にて開催された Reliable Machine Learning in the Wild - NIPS 2016 Workshop (2016) という、現実世界でどうやって信頼性の高い機械学習に取り組んでいくかについてのワークショップがある
ここで Google から発表された What’s your ML test score? A rubric for ML production systems がとても面白く、身になるものが多かったのでメモがてら抄訳を残しておく
PDF Slide 発表動画もワークショップページにて公開されています。 概略 現実世界のプロダクションシステムで機械学習を使う際に、機械学習の研究実験と異なる、小さなもしくは小さくない問題がある テストとモニタリングはプロダクションレディの機械学習システムにとって必要不可欠 しかし、どれくらいのテストとモニタリングをすれば十分と言えるのだろうか? この論文では、それらの問題を解決する ML Test Score という基準を提案する Introduciton Google 内で積み重ねたベストプラクティスをもとに、実行可能なテスト、そしてその機械学習システムがどのていどプロダクションレディなのかを示すスコアシステムを提案
このスコアは、機械学習を始めたばかるのチームからエキスパートがあつまるチームまで幅広く適用可能
注意: 一般的なSofware Engineering のベストプラクティスは含んでいない
そのかわり、学習とサービングのためのUnit Test Coverage の計算方法など機械学習に必要不可欠な点を抑えている
ML Test Score の計算方法 各テストの加点基準 1pt: 手動で実行し、その結果を文章として共有済 2pt: CIに組み込まれ、自動的に反復実行済 最終的なML Score は以下の基準となる 0pt : プロダクション向けというよりも研究プロジェクト 1-2pt : テストが少しはされているが、プロダクションではもっと深刻な罠がある可能性あり 3-4pt : 最初のプロダクションレディへの第一歩。しかし、さらなる投資が必要 5-6pt : 適切なテストがされているが、もっと自動化してみよう 7-10pt : 自動化されたテストとモニタリングが整備されている。重要なシステムでも適切なレベルに達している 12+pt : 卓越した自動化されたテストとモニタリング 前提条件 システムアーキテクチャの前提として、生データから特徴量を抽出し、学習システムに流し込まれる。そして推論のためにサービングされ、その機能は顧客に影響を与える。また、ソースリポジトリやCIを通したテスト、実験のバージョン管理なども可能 特徴量とデータセット 各特徴量の分布が期待した値になっているか?</description></item><item><title>Google, Facebookが提供する機械学習基盤まとめ</title><link>https://shunyaueta.com/posts/2018-04-09/</link><pubDate>Mon, 09 Apr 2018 13:55:44 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-04-09/</guid><description>Google, Facebook の機械学習基盤情報をまとめました
Podcastでも紹介しました
#2 Facebook とGoogleの機械学習基盤について at just4fun.fm
TFX
社内の勉強会で Google, Facebook が提供する機械学習基盤に関する論文を紹介したので、その資料を公開します#### 経緯
機械学習をサービスとして提供開始すると、継続的な学習やプロダクション環境での機械学習の提供はモデル構築以外にもいろいろと考える問題が多くなります ¹
[1] Hidden technical debt in Machine learning systems NIPS’15
要するに機械学習をサービスとして届けるには、実はめちゃんこ大変なんだよという話なんですが、みんな同じ問題にぶち当たります。
そのためプロダクションレディなレベルで機械学習を提供できるプラットフォームを各社が提案しておりその中でも Google, Facebook の事例を提供します。
TL; DR; FBLearner: MLaaS の事例として最初に読むべき論文、MLaaS をどのような戦略で提供しているかを抽象的にまなべるため、鳥瞰図として読みましょう TFX は逆に機械学習基盤が必要とする技術スタックや要件などを詳細に説明しており、教科書的な立ち位置です。社内で機械学習基盤を内製したい場合に詳しく読み込むこと必須 両社とも MLaaS をスケーラブルに提供する環境ができており、サービスのコアテクノロジーになっている Google : Tensorflow Expand TFX: A tensor flow-based production-scale machine learning platform
Facebook : FBLeaner Applied machine learning at facebook a datacenter infrastructure perspective HPCA18
ONNX を見ていると TensorFlow VS.</description></item></channel></rss>