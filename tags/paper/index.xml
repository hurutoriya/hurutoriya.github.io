<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>paper on 🦅 hurutoriya</title><link>https://shunyaueta.com/tags/paper/</link><description>Recent content in paper on 🦅 hurutoriya</description><image><url>https://shunyaueta.com/ogp.jpg</url><link>https://shunyaueta.com/ogp.jpg</link></image><generator>Hugo -- gohugo.io</generator><language>ja</language><lastBuildDate>Mon, 15 Aug 2022 23:35:35 +0900</lastBuildDate><atom:link href="https://shunyaueta.com/tags/paper/index.xml" rel="self" type="application/rss+xml"/><item><title>KDD2022 で気になった研究</title><link>https://shunyaueta.com/posts/2022-08-15-2335/</link><pubDate>Mon, 15 Aug 2022 23:35:35 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-08-15-2335/</guid><description>2022/08/14 - 2022/08/18 に開催される Knowledge Discovery and Data Mining (KDD) 2022 の情報が出揃ってきたので、気になった情報をメモしておく。
自分が気になるトピックは、変わらず機械学習の実応用とその周辺領域なのでそれに偏ったリストになっている。
ADS invited speaker KDD 2022 ADS Invited Speakers
An overview of AWS AI/ML’s recent contributions to open source ML tools: Accelerating discovery and innovation
招待講演は確か毎回論文化されて ACM で公開されるので論文公開されたらぜひ読みたい。
Tutorias KDD 2022 Tutorials Schedule に Tutorial の情報がまとまっているが、タイトルだけでウェブサイトへのリンクが一切なく、読み手に不親切なので来年は、改善してほしい。去年はそんなことなかったので、なんとか来年はもとに戻って欲しい。
Graph-based Representation Learning for Web-scale Recommender Systems. Authors: Ahmed El-Kishky (Twitter)*; Michael Bronstein (Twitter); Ying Xiao (Twitter); Aria Haghighi (Twitter) Twitter が開催する Tutorial で、すごく面白そうなのだが全く情報が見つからなかった。Twitter Cortex にも情報が更新されていないので、しばらくしたら公開されていることを祈る。 New Frontiers of Scientific Text Mining: Tasks, Data, and Tools.</description></item><item><title>Amazon の製品検索で使われるロバストなキャッシュ手法の論文「ROSE: Robust Caches for Amazon Product Search」</title><link>https://shunyaueta.com/posts/2022-03-03/</link><pubDate>Thu, 03 Mar 2022 09:35:29 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-03-03/</guid><description>Web 検索とデータマイニングのトップカンファレンス WSDM2022 のワークショップで The First International Workshop on INTERACTIVE AND SCALABLE INFORMATION RETRIEVAL METHODS FOR ECOMMERCE (ISIR-ecom) が先日開催された。
テーマは e コマース上での検索において
検索システムのスケーラビリティ どうやって適合性(Relevancy)をシステムで改善したか システムの改善 についてをテーマにした検索エンジニアなら垂涎もののワークショップとなっている。
同様の検索システムや実応用に注目したワークショップでは、以下のようなワークショップがある。
SIGIR Workshop On eCommerce 2017 年から毎年開催。累計 5 回開催 International Workshop on Industrial Recommendation Systems 2020 年から開催。累計二回 歴史としては、 SIGIR ecom が長く、これだけの期間継続開催してくれているのはありがたい限り。
機械学習系の国際会議でも手法ではなく、どう現実世界に適用したかに注目したワークショップが益々誕生しており非常に良い流れ。
ACCEPTED PAPERS は 5 本あり、
Amazon: 2 eBay: 1 The Home depot: 2 と企業関係者による論文が 100%となっている。
https://github.com/ISIR-eCom/ISIR-eCom.github.io/tree/main/papers 最後の PDF 番号が 9 なので、最低でも 9 本の投稿はあった模様。</description></item><item><title>Web 検索とデータマイニングのトップカンファレンス WSDM2022 で気になった研究</title><link>https://shunyaueta.com/posts/2022-03-01/</link><pubDate>Tue, 01 Mar 2022 20:47:53 +0900</pubDate><guid>https://shunyaueta.com/posts/2022-03-01/</guid><description>WSDM は web 検索とデータマイニングのトップカンファレンスの一つです。検索好きなら見てて楽しい論文がたくさん公開されており、毎年採択された研究を楽しみに見ています。
今回 WSDM2022 が 2022/02/21 - 2022/02/25 に開催されたので気になった発表をメモ。
今までこういう気になったトピックなどは Joplin にメモして公開していなかったが、公開しても差し支えはないなと思ったので Blog 記事として公開していってみる。
自分の興味関心トピックは今は基本的に検索関連と機械学習の実践事例なので、それに沿った選出になっています。
Industry Day https://www.wsdm-conference.org/2022/industry-day-schedule/
Challenges in Data Production for AI with Human-in-the-Loop, Dmitry Ustalov (Toloka) Scalable Attribute Extraction at Instacart, Shih-Ting Lin (Instacart) Graph Neural Networks for the Global Economy with Microsoft DeepGraph, Jaewon Yang, Alex Samylkin, Baoxu Shi (LinkedIn, Microsoft) Near real time AI personalization for notifications at LinkedIn, Ajith Muralidharan (LinkedIn) Invited Talk: Rethink e-Commerce Search Workshops https://www.</description></item><item><title>TFXの歴史を振り返りつつ機械学習エンジニアリングを提案する論文「Towards ML Engineering: A Brief History Of TensorFlow Extended (TFX)」</title><link>https://shunyaueta.com/posts/2021-01-17/</link><pubDate>Sun, 17 Jan 2021 00:18:47 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-01-17/</guid><description>この記事はMLOps Advent Calendar 2020の 25 日目の記事です。(盛大に遅れました)
KDD2019 の招待講演で Google が TFX の歴史について発表されており、TFX 信者の自分としては発表内容が以前から気になっていたが、公開はされておらずなんとかして見れないかな~と思っていましたが、TensorFlow の Blogで該当の招待講演が論文化されたことを知ったのでメモがてら抄訳として残しておく。
注意)この翻訳記事は原著論文の著者陣からレビューはされていません Shunya Ueta, are providing a translation and abridgment, which has not been reviewed by the authors. Citation Karmarkar, A., Altay, A., Zaks, A., Polyzotis, N., Ramesh, A., Mathes, B., … &amp;amp; Li, Z. (2020). Towards ML Engineering: A Brief History Of TensorFlow Extended (TFX). arXiv preprint arXiv:2010.02013. ***
Towards ML Engineering with TensorFlow Extended (TFX) at KDD2019 Towards ML Engineering with TensorFlow Extended (TFX) ACM PDF は arxiv でも閲覧可能 https://arxiv.</description></item><item><title>機械学習システムの信頼性を数値化し、技術的負債を解消する論文「 The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction」</title><link>https://shunyaueta.com/posts/2020-04-25/</link><pubDate>Sat, 25 Apr 2020 01:35:20 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-04-25/</guid><description>[抄訳] What’s your ML test score? A rubric for ML production systemsで紹介した論文の続編があったので読んでみました。
注意)この翻訳記事は原著論文の著者陣からレビューはされていません Shunya Ueta, are providing a translation and abridgment, which has not been reviewed by the authors. Change log 2021/02/03 ML Test Score を簡単に計算できるGoogle Spread Sheets を公開 2020/06/24 著者の Eric Breck さんに連絡をし、抄訳の公開を快諾していただきました。ありがとうございます。 完全な citation 情報を追記しました。 この翻訳記事が著者のレビューを受けていないことを追記しました。 Citation Eric Breck, Shanqing Cai, Michael Salib, . The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction.</description></item><item><title>機械学習システムの信頼性を数値化する論文「 What’s your ML test score? A rubric for ML production systems」</title><link>https://shunyaueta.com/posts/2020-04-19/</link><pubDate>Sun, 19 Apr 2020 22:18:10 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-04-19/</guid><description>NIPS206 にて開催された Reliable Machine Learning in the Wild - NIPS 2016 Workshop (2016) という、現実世界でどうやって信頼性の高い機械学習に取り組んでいくかについてのワークショップがある。
ここで Google から発表された What’s your ML test score? A rubric for ML production systems がとても面白く、身になるものが多かったのでメモがてら抄訳を残しておく。
PDF Slide 発表動画もワークショップページにて公開されています。 change logs 2021-04-25 この原著論文の完全版になっている論文の抄訳を新たに公開しています。 [抄訳]: The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction 概略 現実世界のプロダクションシステムで機械学習を使う際に、機械学習の研究実験と異なる、小さなもしくは小さくない問題がある テストとモニタリングはプロダクションレディの機械学習システムにとって必要不可欠 しかし、どれくらいのテストとモニタリングをすれば十分と言えるのだろうか? この論文では、それらの問題を解決する ML Test Score という基準を提案する Introduciton Google 内で積み重ねたベストプラクティスをもとに、実行可能なテスト、そしてその機械学習システムがどのていどプロダクションレディなのかを示すスコアシステムを提案</description></item><item><title>Google, Facebookが提供する機械学習基盤まとめ</title><link>https://shunyaueta.com/posts/2018-04-09/</link><pubDate>Mon, 09 Apr 2018 13:55:44 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-04-09/</guid><description>Google, Facebook の機械学習基盤情報をまとめました
Podcast でも紹介しました
#2 Facebook と Google の機械学習基盤について at just4fun.fm
社内の勉強会で Google, Facebook が提供する機械学習基盤に関する論文を紹介したので、その資料を公開します
機械学習をサービスとして提供開始すると、継続的な学習やプロダクション環境での機械学習の提供はモデル構築以外にもいろいろと考える問題が多くなります ¹
[1] Hidden technical debt in Machine learning systems NIPS’15
要するに機械学習をサービスとして届けるには、実はめちゃんこ大変なんだよという話なんですが、みんな同じ問題にぶち当たります。
そのためプロダクションレディなレベルで機械学習を提供できるプラットフォームを各社が提案しておりその中でも Google, Facebook の事例を提供します。
TL; DR; FBLearner: MLaaS の事例として最初に読むべき論文、MLaaS をどのような戦略で提供しているかを抽象的にまなべるため、鳥瞰図として読みましょう TFX は逆に機械学習基盤が必要とする技術スタックや要件などを詳細に説明しており、教科書的な立ち位置です。社内で機械学習基盤を内製したい場合に詳しく読み込むこと必須 両社とも MLaaS をスケーラブルに提供する環境ができており、サービスのコアテクノロジーになっている Google : Tensorflow Expand TFX: A tensor flow-based production-scale machine learning platform
Facebook : FBLeaner Applied machine learning at facebook a datacenter infrastructure perspective HPCA18</description></item><item><title>Where To Look: Focus Regions for Visual Question Answering (CVPR2016)を読んだ</title><link>https://shunyaueta.com/posts/2018-01-18/</link><pubDate>Thu, 18 Jan 2018 05:41:44 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-18/</guid><description>Kevin J. Shih, Saurabh Singh, Derek Hoiem, “Where To Look: Focus Regions for Visual Question Answering”, in CVPR2016 link
Summry
を読んだので、軽くメモ。
VQA(Visual Question Answer) 画像に対する質問に対して応答するタスクに対し、その質問クエリに対して画像のどの領域に注目すべきかのモデルの学習方法について論じた論文。
Contribution VQA datasetに対して、提案手法を適用。従来手法を全て上回った。 画像に対して CNN を用いて物体領域の検出を行った後にベクトル化、質問クエリはword2vecを用いてベクトル化を行う。 その 2 つのベクトルを用いて内積計算により重み付けを行うことで、どの領域に注目すべきかを計算する。 Comments 引用文献の訳 9 割が 2014–2015(直近 2 年間)で発表された論文で、改めてこの分野の最先端を駆け抜けるのは凄まじい能力が必要になるなと思いました。
そして相変わらず CVPR の論文のネーミングセンスは良いですね。(ジャケ買いならぬジャケ読み)
単純な質問なら、人間でも瞬間的に解答可能な物が多いなと感じた。
fig. 1
セマンティックな疑問(Fig.1 雨は降っていますか?)の場合、人間に注目した場合は傘をさしているから雨と判断しても良いがもっと広い範囲で画像を見てみると空は快晴なので人間に注目するのは筋が悪く VQA はとても難しくチャレンジングな問題だと書かれていた。(それでも充分すごい領域に到達しているなと思うが)</description></item><item><title>Data-driven Crowd Analysis in Videos (ICCV2011)を読んだ</title><link>https://shunyaueta.com/posts/2018-01-17/</link><pubDate>Wed, 17 Jan 2018 05:55:41 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-17/</guid><description>Data-driven Crowd Analysis in Videos (ICCV2011)を読んだ
Mikel Rodriguez, Josef Sivic, Ivan Laptev, Jean-Yves Audibert, “Data-driven Crowd Analysis in Videos”, in ICCV2011.
Project Page
を読んだので、メモです。
Summary
tl;dr 高密度な群集内の個人を追跡を転移学習によって精度を向上させる手法 Contribution 追跡の精度を転移学習によって向上させた 転移学習を行うためのデータセットとそのフレームワークを考案 論文内では、転移学習の例としてマラソンAの群集を対象に追跡する際に、以下の流れで転移学習を行う。
大域的な群衆状況のマッチング : 同じようなシーンを探索(この場合 DB 内にあるマラソン動画) 局所的な群衆状況のマッチング : 1でマッチした動画においてオプティカルフローが類似するパッチを探索して転移学習 また、Rare Events(デモの最中に群集を横断するカメラマンなど、群衆の流れに対して同調しない動きを行う人物)に対しても実験を行い評価。
Comments 転移学習は自分のイメージだと、自然言語処理のイメージ(一般的な文書を学習したモデルを法律文書に対して適用するなど)しかなかったので新鮮な気持ちで読めた。
動画なら転移学習を行ったとしても、直感的に良い特徴を学べそうなので、良い仮説を立てている論文でした。
最後に示されてる個人追跡における平均誤検出の単位がpixelだが、Ground-Truth と提案手法の追跡軌跡の重複度具合を見てると誤検出が更に高そうに見えるけどどうなんでしょうか？
(テストデータのみ学習が 58.82、転移学習を行った提案手法だと 46.88になっていてもっと相対的な差が出てくるはず?)</description></item><item><title>Slicing Convolutional Neural Network for Crowd Video Understanding (CVPR2016)を読んだ</title><link>https://shunyaueta.com/posts/2018-01-16/</link><pubDate>Tue, 16 Jan 2018 06:04:37 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-16/</guid><description>群衆解析の手法に興味があるので、サーベイの結果を放流しておきます。
Jing Shao, Chen Change Loy, Kai Kang, and Xiaogang Wang, “Slicing Convolutional Neural Network for Crowd Video Understanding”, in CVPR, 2016.
Project Page
Summary
一言説明 時系列・空間的特徴から CNN で特徴を学習、群衆の動画に対してstate-of-the-artを達成
3 個の CNN を用いて下記の３つの特徴を表現学習
xy- : 空間的特徴 xt- : x 軸の時系列特徴 yt- : y 軸の時系列特徴 Comments Dataset としてWWW Crowd Dataset
が公開されている。10,000 本の群衆の動画を収集公開しているとのこと。
Demo Movie
紹介動画を見てみたら分かるが、群衆の動画というよりも数が増大した結果一般的な画像認識のデモ動画になっている Jing Shaoさんは CVPR2014 から群衆解析のための descriptor を提案したりしてたんだけど、2016 年から Deep な手法での群衆解析の研究をやっているのは手が早いなと 所属グループは ISLVRC2015 の物体認識タスクで優勝した香港大学のグループ Multimedia Laboratory The Chinese University of Hong Kong データセット、実装コードを必ず公開しているのは尊敬、またそれくらいやらないとトップには通過しないんだろうな CNN のアーキテクチャ毎の比較実験と考察をかなり入念に行っていた。数年後には各データのフォーマットに合わせたベストな DNN のアーキテクチャが決まってくるんじゃないだろうか</description></item><item><title>Analyzing Free-standing Conversational Groups: A Multimodal Approach (ACMMM15) を読んだ</title><link>https://shunyaueta.com/posts/2018-01-14/</link><pubDate>Sun, 14 Jan 2018 10:41:12 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-14/</guid><description>スタンディングディスカッション形式での会話を評価した研究
Summary Slide
X Alameda-Pineda, Y Yan, E Ricci, O Lanz, N Sebe
“Analyzing Free-standing Conversational Groups: A Multimodal Approach”, in 2015 ACM Multimedia Conference
link
を読んだので、軽くメモ。
マルチモーダル系の論文初めて読んだんですが、まとめるとコントリビューションが 5 つあると主張。
Contribution 音声・近接情報、そして監視カメラからの身体と頭の姿勢推定からマルチモーダルに解析 フリースタンディングディスカッションを身体・頭の姿勢推定から解析 カメラと音声・近接センサーからなるマルチモーダルな解析するためのフレームワークを提案 ラベリングされてないデータに対する行列補間問題の考案 SALSA(データ・セット)を公開・評価 SALSA というポスターセッションの動画と音声のデータも公開されている
SALSA: Synergetic sociAL Scene Analysis
動画は Google Drive で公開されていて時代の波を感じる。
データセットを公開 論文も読みやすい 新しい行列補完計画法(アルゴリズム)を提案 実問題に取り組む と盛り沢山な内容で面白かった。
スライド内のリンクは Google Slide で共有しているのでこちらを参照すると便利です。
X Alameda-Pineda, Y Yan, E Ricci, O Lanz, N Sebe &amp;quot;Analyzing Free-standing Conversational Groups: A…</description></item><item><title>Call center stress recognition with person-specific models を読んだ</title><link>https://shunyaueta.com/posts/2018-01-12/</link><pubDate>Fri, 12 Jan 2018 17:19:48 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-12/</guid><description>Affective Computing: 計算機と人間の感情や情緒の関係性を考える領域
MIT Media Lab Affective Computing Group のプロジェクト。
2 年前に MIT Media Lab へ訪問した際に、色々と見せてもらったけどかなり野心的な事に取り組んでいて感動してた。(デバイスも自分たちでプロトタイプを作りまくっていて、Deploy or Dieの意思を感じ取れる)
論文のまとめスライドは以下
One Slide Summary
HCI 系の論文は初めてまともに読んだんですが、
実験デザインが一番難しそう。人と計算機の関係を研究するので、必然的に人間の感性をどう評価する話にもつながってきてる? 手法に重きを置くというよりも、問題に重きを置いている印象 普段自分は、数値線形代数や機械学習、コンピュータビジョンを主にやっていて、精度をどれだけ出せるか、正解率をどれだけ向上や、速度をどれだけ上げれるかを理論的に保証、提案したりしていますが、面白い問題や興味深いデータを集めることも大事だなと思った。
実験計画法¹もかなり重要で、メンターの人から実験計画法の成り立ちを教えてもらってとてもおもしろかった。</description></item><item><title>FUSE: Full Spectral Clustering(KDD2016) を読んだ</title><link>https://shunyaueta.com/posts/2018-01-11/</link><pubDate>Thu, 11 Jan 2018 17:30:28 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-11/</guid><description>べき乗法と独立成分分析を用いたマルチスケールに頑強なクラスタリング手法の提案
べき乗法では近似固有ベクトル(Pseudo-eigenvectors)は複数の真の固有ベクトルの線形結合からなる。有益でない固有ベクトルも含まれるのでいかにそれを除去するか Fig.1 で言ってることがいまいちわからない。ｃ,ｄも変化がないように見える。論文で言及してる stripe が何を指してるかが不明 分かった。赤・青・黒の３つのクラスタで分かれている。最初は黒色がクラスタ境界面に見えた。論文内での multi scale というのは、データの幾何的な分布を指している？ 固有値計算は O(n³）かかるから計算量が~~って毎回言われるが、行列の状態に依存するので毎回最悪の場合を主張されてるも困る ZP self-turining spectral clustering をなぜ対抗馬にして比較してるのかは謎。 ICA¹を行ったあとにその行列に対して回転処理を行い情報量の最小化を狙う クラスタ数が多い場合、PIC では良い結果が出づらい multi scale なデータの場合標準の spectral clustering では失敗することが多々ある fig.2 (a) 見ればわかるがk-means では分離が困難 fig.2(b) ４－５本目の固有ベクトルを基底ベクトルにもつ空間ではクラスタのオーバーラップが少ない つまり１－５本目の固有ベクトル全て含めてクラスタリングすれば結果が良好になるのではないか？（仮説） fig.2 © ４回べき乗法を行った。結果が似てる。（縦軸が何を表してるかは不明）。四回が上から四本求めたのか、一番上の固有ベクトルを４回求めたのか分からない fig. (d) 提案手法を適用。k-means で分離可能 行列Vをp回べき乗法を行って構築 E=MVの最小化を行う ICA を最小化するために Jacobi Rotation を用いる。探索には貪欲法を採用 Contribution マルチスケール（多種多様な）データ分布に対してクラスタリングが可能 計算時間は従来（ncut)と同等 感想 PIC(Power Itetaion Clusterg)をまさか拡張してくるとは思わなかったなので、興味深い論文。(実装して再現実験したけど、Early stopping の段階で高確率でクラスタリングが失敗していて使い物にならなかった印象があるので…) データの分布が多様な場合、上位数本のベクトルではなく、そこから更に下の固有ベクトルに着目したほうが結果が良好になるのは面白い KDD の論文、相変わらず読みやすかった。</description></item><item><title>“Learning Deep Representations for Graph Clustering (AAAI2014)” を読んだ</title><link>https://shunyaueta.com/posts/2017-12-23/</link><pubDate>Sat, 23 Dec 2017 17:38:19 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-12-23/</guid><description>自己符号化器と Spectral Clusteing の関連性を示した論文
Paper link Author Fei Tian : http://home.ustc.edu.cn/~tianfei/ 中国科学技術大学 Ph.D １年生 MSRA と共同研究、2014 年に AAAI2 本,COLING1 本を 1st で通してる。 この資料も面白い。ILSVRC2015 で 152 層の Deep Residual Learning を提案し優勝(Error Rate : 3.57%) MSRA @ ILSVRC2015 資料 Motivation (研究背景・動機) Deep Learning が数多くの応用でめざましい成果をあげている。 音声認識 画像認識 自然言語処理 DL において Clustering に関する適切な調査が行われてない。 論文の目的として、DL における Clustering の調査を行う 概要 Graph Clustering はクラスタリングでも重要な手法の一つ Graph Clustering の応用 Image segmentation Community Detection VLSI Design 嬉しい点 : ベクトル空間におけるクラスタリングの問題 → データの類似度グラフ問題への変換が可能 自己符号化器と Spectral Clustering の類似性 Spectral Clustering : グラフラプラシアンに対して EVD を行い k 本の非零固有ベクトルを用いた空間に対して k-means を行ったもの。 自己符号化器 : 入力データを低次元化、情報が最大限になるようにデータの次元を再構築する 計算量 : 対象とするグラフは n 個のノードを持つ EVD : ナイーブに実装すると O(n3)の計算量、最速の実装は O(n2)の計算量 自己符号化器 : ノードがスパースな際は計算量は O(kn) スパース表現 : データが大きくなるならスパース性を有効活用したい EVD : 固有ベクトルが高い確率で密になるため、スパース性が保証されない 自己符号化器 : スパース性を用いるのは容易 既存研究で未検証な事柄、何を解決・解明したいのか？ Graph Clustering のための Deep Learning の活用方法と調査 自己符号化器と Spectral Clustering の類似性とその比較・検証 Method (提案手法) GraphEncoder(for graph clustering.</description></item><item><title>Edge-Weighted Personalized PageRank: Breaking A Decade-Old Performance Barrier を読んだ</title><link>https://shunyaueta.com/posts/2017-12-04/</link><pubDate>Mon, 04 Dec 2017 13:06:15 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-12-04/</guid><description>応用数理研究者が機械学習界に進出していく研究
youtube clip
応用数理界隈ではクラシックな解き方で PageRank が解かれているので最新の数値計算手法に置き換えることで劇的にパフォーマンスが向上して 10 年前のパフォーマンスの鎖を解き放った論文
KDD2015 Best student paper award Slide(PDF) Poster(PDF) Spectral network analysis wenleix/EdgePPR
Presentation Movie is uploaded in Youtube. Author
W. Xie Ph.D Candidate at Cornell University http://wenleix.github.io/ iterative computation on big graph data D. Bindel http://www.cs.cornell.edu/~bindel/ http://www.cs.cornell.edu/~bindel/talks.html He is frequently research activ like ideal young researcher. Nonlinear eigenvalue problem. Alan J. Demers Prof. Johannes Gehrke http://www.cs.cornell.edu/johannes/ Prof. VLDB,SIGMOD,KDD Motivation ページランクは重要な指標。遷移確率を求めるにはランダムサーファーモデル(ランダムウォーク)が必要。 様々な高速解法が提案されている。 Reseatch Question しかし 10 年以上前、PageRank の黎明期から Personalization based の手法は問題がある。 一般的な PageRank の解法の説明、その後に Model Reduction をベースにした約 5 倍の性能を誇る提案手法を説明。 提案手法の性能によって、パフォーマンス上のボトムネックは消えた。 Proposed Method PageRank 初期:WEBPage のランクに使用 → 現在:推薦、ソーシャルネットワーク Random Suffer Model Transition : α の確率で Random Walk(滞在ノードから無作為に遷移) Teleporting : 1−α Random Junmp(滞在ノードに依存せずに全てのノードを対象に無作為遷移) x(t+1)=αPxt+(1−α)v,where P=AD−1 v is represents telepotation probabilitie xt Walker の確率分布 サーファーが来る確率 = RandomWalk の確率_RandomWalk による遷移確率 + RandomJump の確率_RandomJump の遷移確率 = α× RandomWalk による遷移確率 + (1−α)×RandomJump の遷移確率 = α×+(1−α)×v x: Stationary vector(不動ベクトル、定常ベクトル、不動点定理など) x が定常状態になった際に、x の確率分布が PageRank を表す。 x(t),x(t+1)が同一(残差が無い)だと仮定することで、次式の線形方程式を解くことで Pagerank を求める。 Mx=b,where M=(I−αP),b=(1−α)v.</description></item><item><title>Machine Learning that Matters (ICML2012) を読んだ</title><link>https://shunyaueta.com/posts/2017-12-01/</link><pubDate>Fri, 01 Dec 2017 07:55:12 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-12-01/</guid><description>機械学習の研究してる人は全員読んだ方がいい。そう断言できるぐらい良い内容が書かれています。 ICML2012 で発表された最近の機械学習に関する研究の問題点を論じた論文。
Summaly
「あなたは現実世界で役立つデータに対して機械学習の研究を行っていますか?」
著者は NASA の JPL(ジェット推進研究所)、カリフォルニア工科大学に所属する Kiri L.
Kiri L. Wagstaff
発表動画を探してみたんですが、ICML2012 で発表した際のビデオはサーバのクラッシュにより喪失したとのこと。
The video for my controversial ICML 2012 talk is no longer available (lost in a server crash). However, you can read the original paper: Machine Learning that Matters (pdf, 6 pages, 234K) and see the slides from a subsequent invited AAAI talk: Challenges for Machine Learning Impact on the Real World (1.6M). PowerPoint は下記リンク先に配布されています。http://www.</description></item></channel></rss>