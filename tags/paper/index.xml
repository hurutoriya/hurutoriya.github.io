<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Paper on Shunya UETA</title>
    <link>https://shunyaueta.com/tags/paper/</link>
    <description>Recent content in Paper on Shunya UETA</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Mon, 09 Apr 2018 13:55:44 +0000</lastBuildDate>
    
	<atom:link href="https://shunyaueta.com/tags/paper/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Google, Facebookが提供する機械学習基盤まとめ</title>
      <link>https://shunyaueta.com/posts/2018-04-09_google-facebook%E3%81%8C%E6%8F%90%E4%BE%9B%E3%81%99%E3%82%8B%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E5%9F%BA%E7%9B%A4%E3%81%BE%E3%81%A8%E3%82%81/</link>
      <pubDate>Mon, 09 Apr 2018 13:55:44 +0000</pubDate>
      
      <guid>https://shunyaueta.com/posts/2018-04-09_google-facebook%E3%81%8C%E6%8F%90%E4%BE%9B%E3%81%99%E3%82%8B%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E5%9F%BA%E7%9B%A4%E3%81%BE%E3%81%A8%E3%82%81/</guid>
      <description>Google, Facebookの機械学習基盤情報をまとめました TFX 社内の勉強会でGoogle, Facebookが提供する機械学習基盤に関する論文を紹介した</description>
    </item>
    
    <item>
      <title>Slicing Convolutional Neural Network for Crowd Video Understanding (CVPR2016)を読んだ</title>
      <link>https://shunyaueta.com/posts/2018-01-17_slicing-convolutional-neural-network-for-crowd-video-understanding-cvpr2016%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/</link>
      <pubDate>Wed, 17 Jan 2018 06:04:37 +0000</pubDate>
      
      <guid>https://shunyaueta.com/posts/2018-01-17_slicing-convolutional-neural-network-for-crowd-video-understanding-cvpr2016%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/</guid>
      <description>群衆解析の手法に興味があるので、サーベイの結果を放流しておきます。 Jing Shao, Chen Change Loy, Kai Kang, and Xiaogang Wang, “Slicing Convolutional Neural Network for Crowd Video Understanding</description>
    </item>
    
    <item>
      <title>Data-driven Crowd Analysis in Videos (ICCV2011)を読んだ</title>
      <link>https://shunyaueta.com/posts/2018-01-17_datadriven-crowd-analysis-in-videos-iccv2011%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/</link>
      <pubDate>Wed, 17 Jan 2018 05:55:41 +0000</pubDate>
      
      <guid>https://shunyaueta.com/posts/2018-01-17_datadriven-crowd-analysis-in-videos-iccv2011%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/</guid>
      <description>Data-driven Crowd Analysis in Videos (ICCV2011)を読んだ Mikel Rodriguez, Josef Sivic, Ivan Laptev, Jean-Yves Audibert, “Data-driven Crowd Analysis in Videos”, in ICCV2011. Project Page を読んだので、メモです。 Summary tl;dr 高密</description>
    </item>
    
    <item>
      <title>Where To Look: Focus Regions for Visual Question Answering (CVPR2016)を読んだ</title>
      <link>https://shunyaueta.com/posts/2018-01-17_where-to-look-focus-regions-for-visual-question-answering-cvpr2016%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/</link>
      <pubDate>Wed, 17 Jan 2018 05:41:44 +0000</pubDate>
      
      <guid>https://shunyaueta.com/posts/2018-01-17_where-to-look-focus-regions-for-visual-question-answering-cvpr2016%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/</guid>
      <description>Kevin J. Shih, Saurabh Singh, Derek Hoiem, “Where To Look: Focus Regions for Visual Question Answering”, in CVPR2016 link Summry を読んだので、軽くメモ。 VQA(Visual Question Answer) 画像に対する質問に対して応答するタスクに</description>
    </item>
    
    <item>
      <title>Analyzing Free-standing Conversational Groups: A Multimodal Approach (ACMMM15) を読んだ</title>
      <link>https://shunyaueta.com/posts/2018-01-14_analyzing-freestanding-conversational-groups-a-multimodal-approach-acmmm15-%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/</link>
      <pubDate>Sun, 14 Jan 2018 10:41:12 +0000</pubDate>
      
      <guid>https://shunyaueta.com/posts/2018-01-14_analyzing-freestanding-conversational-groups-a-multimodal-approach-acmmm15-%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/</guid>
      <description>スタンディングディスカッション形式での会話を評価した研究 Summary Slide X Alameda-Pineda, Y Yan, E Ricci, O Lanz, N Sebe “Analyzing Free-standing Conversational Groups: A Multimodal Approach”, in 2015 ACM Multimedia Conference</description>
    </item>
    
    <item>
      <title>FUSE: Full Spectral Clustering(KDD2016) を読んだ</title>
      <link>https://shunyaueta.com/posts/2018-01-13_fuse-full-spectral-clusteringkdd2016-%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/</link>
      <pubDate>Sat, 13 Jan 2018 17:30:28 +0000</pubDate>
      
      <guid>https://shunyaueta.com/posts/2018-01-13_fuse-full-spectral-clusteringkdd2016-%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/</guid>
      <description>べき乗法と独立成分分析を用いたマルチスケールに頑強なクラスタリング手法の提案 べき乗法では近似固有ベクトル(Pseudo-eigenvecto</description>
    </item>
    
    <item>
      <title>Call center stress recognition with person-specific models を読んだ</title>
      <link>https://shunyaueta.com/posts/2018-01-13_call-center-stress-recognition-with-personspecific-models-%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/</link>
      <pubDate>Sat, 13 Jan 2018 17:19:48 +0000</pubDate>
      
      <guid>https://shunyaueta.com/posts/2018-01-13_call-center-stress-recognition-with-personspecific-models-%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/</guid>
      <description>Affective Computing: 計算機と人間の感情や情緒の関係性を考える領域 MIT Media Lab Affective Computing Groupのプロジェクト。 2年前にMIT Media Labへ訪問した際に、色々と見せてもらっ</description>
    </item>
    
    <item>
      <title>Edge-Weighted Personalized PageRank: Breaking A Decade-Old Performance Barrier を読んだ</title>
      <link>https://shunyaueta.com/posts/2017-12-04_edgeweighted-personalized-pagerank-breaking-a-decadeold-performance-barrier-%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/</link>
      <pubDate>Mon, 04 Dec 2017 13:06:15 +0000</pubDate>
      
      <guid>https://shunyaueta.com/posts/2017-12-04_edgeweighted-personalized-pagerank-breaking-a-decadeold-performance-barrier-%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/</guid>
      <description>応用数理研究者が機械学習界に進出していく研究 youtube clip 応用数理界隈ではクラシックな解き方でPageRankが解かれているので最新の数値計算手法に置</description>
    </item>
    
    <item>
      <title>Machine Learning that Matters (ICML2012) を読んだ</title>
      <link>https://shunyaueta.com/posts/2017-12-01_machine-learning-that-matters-icml2012-%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/</link>
      <pubDate>Fri, 01 Dec 2017 07:55:12 +0000</pubDate>
      
      <guid>https://shunyaueta.com/posts/2017-12-01_machine-learning-that-matters-icml2012-%E3%82%92%E8%AA%AD%E3%82%93%E3%81%A0/</guid>
      <description>機械学習の研究してる人は全員読んだ方がいい。そう断言できるぐらい良い内容が書かれています。 ICML2012で発表された最近の機械学習に関する</description>
    </item>
    
    <item>
      <title>Machine Learning Companies Tech Blog</title>
      <link>https://shunyaueta.com/posts/2017-10-25_machine-learning-companies-tech-blog/</link>
      <pubDate>Wed, 25 Oct 2017 11:32:31 +0000</pubDate>
      
      <guid>https://shunyaueta.com/posts/2017-10-25_machine-learning-companies-tech-blog/</guid>
      <description>Machine Leaning Blog
We collect a Machine Learning companies Tech Blog lists based on Sponsor of Google Scholar Top Publications list
 https://scholar.google.com/citations?view_op=top_venues&amp;amp;hl=en&amp;amp;vq=eng_artificialintelligence https://scholar.google.com/citations?view_op=top_venues&amp;amp;hl=en&amp;amp;vq=eng_computervisionpatternrecognition https://scholar.google.com/citations?view_op=top_venues&amp;amp;hl=en&amp;amp;vq=eng_datamininganalysis  Machine Leaning &amp;amp; Computer Vision &amp;amp; Data Mining Top Conference Our Sponsors -
ICML 2017 Sponsors
NIPS 2017 Sponsors
KDD 2017 | Sponsors and Sponsorship Opportunities
AAAI-17: Thirty-First AAAI Conference on Artificial Intelligence
CVPR2017
ICCV 2017
Machine Learning Company’s Tech Blog Alibaba
https://cloudfocus.alibabacloud.com/?spm=a2c1b.detail207110.a2c1b31.22.1d234c96CMbTQt&amp;amp;tag_id=16493</description>
    </item>
    
  </channel>
</rss>