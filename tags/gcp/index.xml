<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>GCP on hurutoriya</title><link>https://shunyaueta.com/tags/gcp/</link><description>Recent content in GCP on hurutoriya</description><generator>Hugo -- gohugo.io</generator><language>ja</language><copyright>© Shunya Ueta</copyright><lastBuildDate>Wed, 03 Mar 2021 00:29:03 +0900</lastBuildDate><atom:link href="https://shunyaueta.com/tags/gcp/index.xml" rel="self" type="application/rss+xml"/><item><title>GKE 上でPythonで logger.info() を行うとCloud logging では stderr に保存され、すべてエラーになるときの対処法</title><link>https://shunyaueta.com/posts/2021-03-03/</link><pubDate>Wed, 03 Mar 2021 00:29:03 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-03-03/</guid><description>Python のアプリケーションで、Cloud logger にログを出力したいときに
標準のPython logging モジュールを利用して、ログを出力する Python Cloud Logging package を使用する 上記の２つの方法があります。
不必要にパッケージを増やしたくはないので、1の標準モジュールでCloud Logger へ出力できないか試してみました。
標準のPython logging モジュールを試す 標準のlogging モジュールでログを出力したいときに
import logging logger = logging.getLogger(__name__) def hoge(): logger.info(&amp;#39;logging Start 2021&amp;#39;) と、logging.info() を仕込んで、Cloud logger にログを出力してみると、logger.info() で出しているはずなのに、Cloud logger 上ではすべてエラーとして扱われてしまっています。
原因を特定するために、logger のログを見てみると logger.info() がすべて stderr標準エラーストリームへ出力されてしまっています。
{ &amp;#34;textPayload&amp;#34;: &amp;#34;2021-02-20 21:26:51,012 - root:predict:36 - INFO: logging Start\n&amp;#34;, ... }, &amp;#34;timestamp&amp;#34;: &amp;#34;2021-02-20T12:26:51.013213826Z&amp;#34;, &amp;#34;severity&amp;#34;: &amp;#34;ERROR&amp;#34;, &amp;#34;labels&amp;#34;: { ... }, &amp;#34;logName&amp;#34;: &amp;#34;projects/.../logs/stderr&amp;#34;, &amp;#34;receiveTimestamp&amp;#34;: &amp;#34;2021-02-20T12:26:55.050911180Z&amp;#34; } そのため、明示的に標準出力へ出力先を変更してみました。</description></item><item><title>pandas.read_gbq を使わずに、Google BigQueryから高速にData ETL</title><link>https://shunyaueta.com/posts/2019-10-03/</link><pubDate>Thu, 03 Oct 2019 23:52:54 +0900</pubDate><guid>https://shunyaueta.com/posts/2019-10-03/</guid><description>pandas.read_gbq 便利ですよね。 クレデンシャルファイルを認証画面からコピペすれば Jupyter 上でさっと動き、Google Big Query が実行されてその結果がそのままデータフレームとして扱えます。 Jupyter と Google BQ を連携させたいときはいつも使っています
問題点 そこそこ大きなデータを持ってこようとすると、めちゃくちゃ遅くてストレスが半端ない 解決方法として、Google Big Query で巨大なデータをダウンロードする方法について書く
実は Google の公式ドキュメントでも推奨されています
https://cloud.google.com/bigquery/docs/pandas-gbq-migration https://cloud.google.com/bigquery/docs/bigquery-storage-python-pandas 方法は以下の２つ。
google-cloud-bigquery をインストールして、マジックコマンドで Google BQ を実行 BQ 実行 →BigQuery table として保存 →GCS へ保存 → gsutil でマシンへコピー 1 番目は、Jupyter 上でマジックコマンドで Google BQ が実行できて、速度も pandas.rad_gbq よりも高速です 2 番目はそもそも実行結果が巨大な場合で、目安としては1GB以上なら 2 番目の方法を使えば楽です。
1, google-cloud-bigquery をインストールして、マジックコマンドで Google BQ を実行 pip install --upgrade google-cloud-bigquery[bqstorage,pandas] magic command を実行</description></item><item><title>How to connect the Google Compute Engine via Visual Studio Code</title><link>https://shunyaueta.com/posts/2019-09-24/</link><pubDate>Tue, 24 Sep 2019 17:35:05 +0900</pubDate><guid>https://shunyaueta.com/posts/2019-09-24/</guid><description>1. Generate SSH config file using gcloud command line gcloud compute config-ssh https://cloud.google.com/sdk/gcloud/reference/compute/config-ssh
You cant get ssh config for your Google Compute Engine project!
Notice: you need choose target GCP project before run below command.
gcloud config set project &amp;lt;your-project-id&amp;gt; 2. Install Remote SSH extention in Visual Studio Code. https://code.visualstudio.com/blogs/2019/07/25/remote-ssh 3. Press ⇧⌘P &amp;amp; Select target connection in Visual Studio Code! Finaly you can connect in Visual Studio Code.</description></item></channel></rss>