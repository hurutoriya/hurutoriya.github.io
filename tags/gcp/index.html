<!doctype html><html lang=ja dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>gcp | hurutoriya</title><meta name=keywords content><meta name=description content="Shunya Ueta's blog"><meta name=author content="Shunya Ueta"><link rel=canonical href=https://shunyaueta.com/tags/gcp/><link crossorigin=anonymous href=/assets/css/stylesheet.6a98292fb8fa8cf0f3ba4042d4b75515c04267550f3ad49ff6271b5af9562443.css integrity="sha256-apgpL7j6jPDzukBC1LdVFcBCZ1UPOtSf9icbWvlWJEM=" rel="preload stylesheet" as=style><link rel=icon href=https://shunyaueta.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://shunyaueta.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://shunyaueta.com/favicon-32x32.png><link rel=apple-touch-icon href=https://shunyaueta.com/apple-touch-icon.png><link rel=mask-icon href=https://shunyaueta.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://shunyaueta.com/tags/gcp/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-JMJRQJT0Q3"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-JMJRQJT0Q3")</script><meta property="og:title" content="gcp"><meta property="og:description" content="Shunya Ueta's blog"><meta property="og:type" content="website"><meta property="og:url" content="https://shunyaueta.com/tags/gcp/"><meta property="og:image" content="https://shunyaueta.com/ogp.jpg"><meta property="og:site_name" content="Shunya Ueta"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://shunyaueta.com/ogp.jpg"><meta name=twitter:title content="gcp"><meta name=twitter:description content="Shunya Ueta's blog"></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://shunyaueta.com/ accesskey=h title="hurutoriya (Alt + H)">hurutoriya</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://shunyaueta.com/archives title=Archive><span>Archive</span></a></li><li><a href=https://shunyaueta.com/about title=About><span>About</span></a></li><li><a href=https://searchengineeringnewsletter.substack.com/ title=Newsletter><span>Newsletter</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://shunyaueta.com/index.xml title=RSS><span>RSS</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>gcp</h1></header><article class="post-entry tag-entry"><header class=entry-header><h2>CloudComposer の Variables (環境変数)を gcloud cli で取得する</h2></header><div class=entry-content><p>Airflow 1 系で設定されている環境変数を JSON ファイルとして GUI を使って書き出す方法の続報です。
前回、Airflow CLI からでも環境変数を JSON ファイルとして出力できる1が、手元から実行しても GCP 上のインスタンスにしか保存されなかったので諦めたと書きました。 ですが、その問題を解決できたので、解決方法を公開しておきます。
Cloud Storage に格納されるデータ | Cloud Composer | Google Cloudによると、Cloud Composer インスタンス内部のディレクトリは GCS にマッピングされているらしい。
マッピング関係は以下( GCP のドキュメントをそのまま引用)
フォルダ Storage パス マッピングされたディレクトリ 説明 DAG gs://bucket-name/dags /home/airflow/gcs/dags 環境の DAG を保存します。このフォルダ内の DAG のみが環境にスケジュールされます。 プラグイン gs://bucket-name/plugins /home/airflow/gcs/plugins カスタム プラグインを保存します。カスタムのインハウス Airflow 演算子、フック、センサー、インターフェースなどです。 データ gs://bucket-name/data /home/airflow/gcs/data タスクが生成して使用するデータを保存します。このフォルダは、すべてのワーカーノードにマウントされます。 ログ gs://bucket-name/logs タスクの Airflow ログを保存します。ログは Airflow ウェブ インターフェースでも利用できます。 それを使えば、/home/airflow/gcs/data にファイルを保存すれば、CloudComposer が保有している GCS の gs://bucket-name/data にアクセスすれば、そのファイルが参照可能になる。...</p></div><footer class=entry-footer><span title='2022-10-17 16:30:58 +0900 +0900'>10月 17, 2022</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to CloudComposer の Variables (環境変数)を gcloud cli で取得する" href=https://shunyaueta.com/posts/2022-10-17-1630/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy src=https://shunyaueta.com/posts/2022-10-04-1549/images/1.png alt="Airflow で環境変数をJSONファイルとしてお手軽に書き出す方法"></figure><header class=entry-header><h2>Airflow 1系で設定されている環境変数を JSON ファイルとしてGUIを使って書き出す方法</h2></header><div class=entry-content><p>CloudComposer(GCP の Airflow のマネージドサービス)で運用している Airflow 1 系上で設定されている環境変数を JSON ファイルとして書き出したかったが、つまずいたのでメモを公開しておく。
Airflow の運用の理想としては、リポジトリをベースに CI 経由で CloudComposer を構築していくのがベスト。 だが、Airflow では GUI でお手軽に環境変数(Airflow では Variables という概念1)が設定でき、便利な半面、デメリットとしてリポジトリをベースにした Single Source of Truth の状態が保てなくなってしまう。
Airflow の環境変数を JSON ファイルとして書き出す方法 上部の Admin メニューから、Variablesをクリックしてページに移動 With selectedボタンをクリックすると Exportボタンがドロップダウンリスト内にでてくるので、これをクリックすれば Airflow に保存されている環境変数を JSON ファイルとして書き出せる Export できるとは初見でわからなかったのでこの UI を考えた人は罪深い。@naoさんに教えていただけて感謝! Airflow CLI からでも環境変数を JSON ファイルとして出力できるらしい2が、手元から
1 gcloud composer environments run COMPOSER_NAME --location asia-northeast1 variables -- --export env.json を実行してもローカルには保存されなかったので、実行結果は CloudComposer 内部のインスタンスに保存されている模様。
Bash と GCS のオペレーターを組み合わせれば JSON ファイルを GCS に保存はできそうだが、それもめんどくさそうではある。 直接 SSH で CloudComposer のインスタンスにつなげたほうがまだ楽そうですよね...</p></div><footer class=entry-footer><span title='2022-10-04 15:49:30 +0900 +0900'>10月 4, 2022</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to Airflow 1系で設定されている環境変数を JSON ファイルとしてGUIを使って書き出す方法" href=https://shunyaueta.com/posts/2022-10-04-1549/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy src=https://shunyaueta.com/posts/2022-01-20/images/1.png alt="bqutil.fn.typeof() の実行結果"></figure><header class=entry-header><h2>OSS の Google BigQuery UDF `bqutil.fn` を使えば UDF の独自実装を置き換えられるかもしれない</h2></header><div class=entry-content><p>TL;DR; UDF を独自実装する前に、bqutil.fnを眺めておくと車輪の再発明が回避できるかも
背景 SQL は、特定の処理を行う際にデータの型が同一でないとエラーが発生しますが、もとのスキーマを紹介するよりももっとお手軽にカラムの型を確認したいときがありませんか?
例えば、出力結果を見ただけでは、12345 が STRING なのか INT64 なのか判別不可能ですよね。(もし判別可能な方法知っている人いたら教えて下さい…)
GCP による OSS UDF の bqutil.fn なのでお手軽に BigQuery の結果の型を確認したい時になにか良い方法がないかなと調べていたら、OSS でbqutil.fnという UDF が GCP から提供されていた。
例えば型の確認の場合、以下の ユーザー定義関数（UDF) はどの GCP プロジェクトから実行しても実行可能
1 bqutil.fn.typeof() このbqutil.fn はbigquery-utils/udfs/community/のディレクトリに格納されている UDF がbqutil という GCP プロジェクトのfn データセットに同期されているので、どの GCP プロジェクトの Google BigQuery から実行しても bqutil.fn.typeof()を実行可能にしているらしい。 頭良い
This directory contains community contributed user-defined functions to extend BigQuery for more specialized usage patterns. Each UDF within this directory will be automatically synchronized to the bqutil project within the fn dataset for reference in queries....</p></div><footer class=entry-footer><span title='2022-01-20 00:03:07 +0900 +0900'>1月 20, 2022</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to OSS の Google BigQuery UDF `bqutil.fn` を使えば UDF の独自実装を置き換えられるかもしれない" href=https://shunyaueta.com/posts/2022-01-20/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>Google Cloud Pub/Sub に公開された結果はDataflow template を使えばめちゃくちゃ簡単に確認できる</h2></header><div class=entry-content><p>PubSub に出力された結果を確認するのって、なかなか手間がかかりませんか?
最近同僚に簡単な確認方法を教えてもらい、感動したのでそれを記事にしました。
確認方法 PubSub のメッセージを出力する Google Cloud Storage bucket を同一 GCP プロジェクトで作成する。 GCP の Pub/Sub ページに移動する 確認したい Pub/Sub topic をクリックする ページ下部にある CREATE SUBSCRIPTION ボタンを押すと選択肢で、Create subscription, Export to BigQuery, Export to Cloud Storageがあり、 Export to Cloud Storageを選択する。 BigQuery、 Google Cloud Storage への吐き出しを行い際に、自動的に subscription が生成される。 Export to Cloud Storage を選択すると、Text 形式か Abro 形式での出力にするかを選択できる。基本的には簡単に確認できる Text 形式を選ぶと良さげ。 選択後、下記のような設定画面が出てくるので情報を埋めていく。基本的には、どこの Google Cloud Storage に出力するかを埋めれば完了。 10m ほどすると Streaming job の Dataflow の起動が完了して、一定期間ごとに Pub/Sub の topic に公開されたデータがテキスト形式で出力され始めます。 出力された GCS の結果を眺めるには、 gsutil コマンドなどを使うのが簡単です。自分はgsutil cat の結果をコピーして VS Code で確認しています。 Cloud Dataflow のテンプレート機能については、端的に説明すると、GUI でパラメータを設定するだけで、Dataflow によるデータ処理が簡単に実行できるようになる機能です。...</p></div><footer class=entry-footer><span title='2021-11-05 23:05:22 +0900 +0900'>11月 5, 2021</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to Google Cloud Pub/Sub に公開された結果はDataflow template を使えばめちゃくちゃ簡単に確認できる" href=https://shunyaueta.com/posts/2021-11-05/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>CloudComposer のDAGをCircleCIで更新する</h2></header><div class=entry-content><p>Cloud Composer(Airflow) の DAG を GitHub リポジトリで管理して、CI によりリポジトリで管理している DAG を Pull Request がマージされると Cloud Composer の DAG へ同期する方法について説明する。
DAG は、ルートディレクトリ直下の dags/ というディレクトリに格納されている状態を前提とする。
以下の２つのコマンドラインツールを利用して実現できる。
Service Account の認証のために gcloud DAG の同期のために gsutil CircleCI によるワークフローの記述例は以下のとおり
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 version: 2.1 jobs: rsync-dags: working_directory: ~/workspace docker: - image: gcr.io/google.com/cloudsdktool/cloud-sdk:alpine environment: GOOGLE_APPLICATION_CREDENTIALS: /gcp-service-key.json steps: - checkout - run: name: Sync DAG folder to GCS's DAG folder command: | echo "${CLOUD_COMPOSER_CREDENTIALS_JSON}" > ${GOOGLE_APPLICATION_CREDENTIALS} gcloud auth activate-service-account --key-file ${GOOGLE_APPLICATION_CREDENTIALS} gsutil -m rsync -d -r dags \ "$(gcloud composer environments describe {COMPOSER_NAME} --project={GCP_PROJECT} --location={REGION} --format="get(config....</p></div><footer class=entry-footer><span title='2021-10-04 22:23:24 +0900 +0900'>10月 4, 2021</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to CloudComposer のDAGをCircleCIで更新する" href=https://shunyaueta.com/posts/2021-10-04/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>GCPのCloud Composer のDAGを素早く・簡単にデバッグする</h2></header><div class=entry-content><p>GCPでAirflow をマネージドサービスで使えるサービスで Cloud Composer が存在する。 BigQueryやBigTable, PubSub などGCPの各サービスをDAGとして定義してジョブを定期実行できるので非常に便利だが、その代わりDAGを実行するまで結果がわからないので、CloudComposer を一度実行するしか無いのでデバッグが困難になる傾向がある。
また、GitHubのリポジトリにDAGを保存して、CIでCloud Composerを更新するようしていると PRを都度作ってマージされないと確認できないという場合もある。
ローカルでDocker で走らせれば良いのじゃないかというツッコミがあると思いますが、結局 Cloud Composer 上での動作を確かめないといけないので、今回の記事を書くことにしました。
NOTE: 自分が使用しているComposerのversionはcomposer-1.8.0-Airflow-1.10.3 です。基本的にやれることは一緒だと思います。また、dev, prodで同一のDAGが走るCloud Composer を運用しているという前提です。
アプローチは２つ
logger.info() を仕込んで、DAGのなかで何が起こっているかを理解する 1 2 3 4 5 import logging logger = logging.getLogger(__name__) logger.info() loggerをDAGを記述した Pythonファイルに仕込んで、内部で何が起こっているかを把握する。
各DAGのlogは、
GCPのCloud ComposerのページにアクセスしてAirflow webserver 列のボタンをクリックしてAirflowのWeb applicaiton にログイン 確認したいDAGをクリック DAG内のtask をクリックして表示されるモーダル内の View Logをクリックすると、loggerの情報が確認できる gstuil rsync コマンドでのGCSへのDAGの同期 gstuil rsyncコマンドを使うことで、リポジトリのDAGファイルをGCSに格納されている開発環境上のCloudComposer のDAGファイルに直接同期してPull Request マージ後のDAGの挙動を確認できる。
Cloud Composer のDAGは、自動作成されたGoogle Cloud Storage(GCS)に格納されており、GCSをCloud Composerが定期的に監視してCloud Composerを更新している。 つまり、GCS上のDAGファイルを直接更新してやるとそれがCloud Composerに反映される。 体感として2-3分に一度は監視されているので、ほぼ待ち状態がない状態で確認できて便利です。
以下のコマンドでリポジトリのDAGファイルをGCSに反映させます。...</p></div><footer class=entry-footer><span title='2021-09-29 22:20:23 +0900 +0900'>9月 29, 2021</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to GCPのCloud Composer のDAGを素早く・簡単にデバッグする" href=https://shunyaueta.com/posts/2021-09-29/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>gcloud commands で PubSub に jsonファイルをメッセージとして公開 (Pusblish) する</h2></header><div class=entry-content><p>gcloud commands で PubSub に json ファイルをメッセージとして公開 (Pusblish) する
jq コマンドが必要になるが、一番簡単に実現できるのは
1 $ gcloud pubsub topics publish {PUBSUB_TOPIC_NAME} --message "$(cat {FILE_NAME} | jq -c)" jq コマンドの -c オプションは compact-output を意味している。デフォルトだと pretty-prints になってしまう。 それを避けるために-cオプションを使用している。
ref Publishing messages to topics Read a txt file JSON data to publish the messages in Cloud Pub Sub</p></div><footer class=entry-footer><span title='2021-09-07 12:22:16 +0900 +0900'>9月 7, 2021</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to gcloud commands で PubSub に jsonファイルをメッセージとして公開 (Pusblish) する" href=https://shunyaueta.com/posts/2021-09-07/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>GKE 上にて Pythonで logger.info() を行うとCloud logging では stderr に保存され、すべてエラーになる問題への対処法</h2></header><div class=entry-content><p>Python のアプリケーションで、Cloud logger にログを出力したいときに
標準の Python logging モジュールを利用して、ログを出力する Python Cloud Logging package を使用する 上記の２つの方法があります。
不必要にパッケージを増やしたくはないので、1 の標準モジュールで Cloud Logger へ出力できないか試してみました。
標準の Python logging モジュールを試す 標準の logging モジュールでログを出力したいときに
1 2 3 4 5 6 import logging logger = logging.getLogger(__name__) def hoge(): logger.info('logging Start 2021') と、logging.info() を仕込んで、Cloud logger にログを出力してみると、logger.info() で出しているはずなのに、Cloud logger 上ではすべてエラーとして扱われてしまっています。
原因を特定するために、logger のログを見てみると logger.info() がすべて stderr標準エラーストリームへ出力されてしまっています。
1 2 3 4 5 6 7 8 9 10 11 12 { "textPayload": "2021-02-20 21:26:51,012 - root:predict:36 - INFO: logging Start\n", ....</p></div><footer class=entry-footer><span title='2021-03-03 00:29:03 +0900 +0900'>3月 3, 2021</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to GKE 上にて Pythonで logger.info() を行うとCloud logging では stderr に保存され、すべてエラーになる問題への対処法" href=https://shunyaueta.com/posts/2021-03-03/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>遅すぎる `pandas.read_gbq` を使わずに、Google BigQueryから高速にデータを読み込む</h2></header><div class=entry-content><p>pandas.read_gbq 便利ですよね。 クレデンシャルファイルを認証画面からコピペすれば Jupyter Notebook 上で簡単に認証され、Google BigQuery が実行されてその結果がそのままデータフレームとして扱えます。 Jupyter Notebook と Google BigQuery を連携させたいときは愛用していました(過去形)。
問題点 そこそこ大きなデータを持ってこようとすると、めちゃくちゃ遅くてストレスが凄い 解決方法として、Google BigQuery で巨大なデータをダウンロードする方法について書きます。
実は Google の公式ドキュメントでも推奨されています。
https://cloud.google.com/bigquery/docs/pandas-gbq-migration https://cloud.google.com/bigquery/docs/bigquery-storage-python-pandas 方法は以下の２つ。
google-cloud-bigquery をインストールして、マジックコマンドで Google BQ を実行 BQ 実行 →BigQuery table として保存 →GCS へ保存 → gsutil でマシンへコピー 1 番目は、Jupyter 上でマジックコマンドで Google BQ が実行できて、速度も pandas.rad_gbq よりも高速です 2 番目はそもそも実行結果が巨大な場合で、目安としては1GB以上なら 2 番目の方法を使えば楽です。
1, google-cloud-bigquery をインストールして、Jupyter Notebook のマジックコマンドで Google BQ を実行 1 pip install --upgrade google-cloud-bigquery[bqstorage,pandas] magic command を実行
1 %load_ext google....</p></div><footer class=entry-footer><span title='2019-10-03 23:52:54 +0900 +0900'>10月 3, 2019</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to 遅すぎる `pandas.read_gbq` を使わずに、Google BigQueryから高速にデータを読み込む" href=https://shunyaueta.com/posts/2019-10-03/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>How to connect the Google Compute Engine via Visual Studio Code</h2></header><div class=entry-content><p>1. Generate SSH config file using gcloud command line 1 gcloud compute config-ssh https://cloud.google.com/sdk/gcloud/reference/compute/config-ssh
You cant get ssh config for your Google Compute Engine project!
Notice: you need choose target GCP project before run below command.
1 gcloud config set project &lt;your-project-id> 2. Install Remote SSH extention in Visual Studio Code. https://code.visualstudio.com/blogs/2019/07/25/remote-ssh
3. Press ⇧⌘P & Select target connection in Visual Studio Code! Finaly you can connect in Visual Studio Code....</p></div><footer class=entry-footer><span title='2019-09-24 17:35:05 +0900 +0900'>9月 24, 2019</span>&nbsp;·&nbsp;Shunya Ueta</footer><a class=entry-link aria-label="post link to How to connect the Google Compute Engine via Visual Studio Code" href=https://shunyaueta.com/posts/2019-09-24/></a></article></main><footer class=footer><span>&copy; 2023 <a href=https://shunyaueta.com/>hurutoriya</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>