<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>lucene on hurutoriya</title><link>https://shunyaueta.com/tags/lucene/</link><description>Recent content in lucene on hurutoriya</description><image><title>hurutoriya</title><url>https://shunyaueta.com/ogp.jpg</url><link>https://shunyaueta.com/ogp.jpg</link></image><generator>Hugo -- gohugo.io</generator><language>ja</language><lastBuildDate>Mon, 17 Apr 2023 22:52:30 +0900</lastBuildDate><atom:link href="https://shunyaueta.com/tags/lucene/index.xml" rel="self" type="application/rss+xml"/><item><title>Twitter の検索システムを学ぶ - 概要編</title><link>https://shunyaueta.com/posts/2023-04-17-2252/</link><pubDate>Mon, 17 Apr 2023 22:52:30 +0900</pubDate><guid>https://shunyaueta.com/posts/2023-04-17-2252/</guid><description>Twitter&amp;rsquo;s Recommendation Algorithm Elon Mask が以前から計画していた、Twitter の検索&amp;amp;推薦関連のシステムが GitHub で公開された。 良い機会なので、いままでの Twitter 検索の記事をまとめつつ、コードも読んでみます。
この記事はシリーズになっており、以下の構成で進めていく。
概要編 論文解説 コードを読んでみた Twitter&amp;rsquo;s New Search Architecture 2010-10-06 公開 この時期に新しいアーキテクチャに移行 MySQL による検索から Lucene による検索へ移行 要件 1000 tweets/sec 12000 queries/sec 1 billion queries / day 新しいアーキテクチャで、一桁大きい規模のトラフィックに耐えられることを期待している Tweet はリアルタイムなので、もちろん検索システムもリアルタイム性が非常に重要 indexing latency も非常に重要 tweet された 10 秒後には検索可能になってほしい indexer 自体のレイテンシは 1 秒以下である必要がある(indexer 自体はデータパイプランの一部でしかないため) Lucene を改造 Lucene は素晴らしいが、リアルタイム検索を行うにはまだ足りない点がある メモリ内のデータ構造を書き直す。 ポスティングリストを特に書き直す。 ガーベージコレクションの改善 lock free のデータ構造とアルゴリズム 逆順に走査可能なポスティングリスト 効率的なアーリークエリリターン 移行後 システム全体の 5%しか利用していないが、50 倍近いツイートをインデックスできている。 移行したことでユーザーに利点は果たしてあるのか? 検索対象が非常に増えた(bigger index と書かれているが恐らく検索できる範囲が増えたのでは?</description></item><item><title>現在 Lucene の KNN ベクトルの最大次元数は1024次元 だが、それを2048次元に変更できないかという議論</title><link>https://shunyaueta.com/posts/2023-03-26-2208/</link><pubDate>Sun, 26 Mar 2023 22:08:18 +0900</pubDate><guid>https://shunyaueta.com/posts/2023-03-26-2208/</guid><description>初心者だけど Apache Lucene に貢献したい場合におすすめのチケットラベルのチケットを眺めていたときに面白いチケットがあった。
取り上げるのは、
Increase the number of dims for KNN vectors to 2048 [LUCENE-10471] · Issue #11507 · apache/lucene
というチケットだが、表題の通りで、現在 KNN ベクトルとして扱える最大次元数は 1024 次元だが、それを 2048 次元に変更できないかの議論がされている。
該当 PR はこちら
https://github.com/apache/lucene/pull/874/files
1 2 - public static final int MAX_DIMENSIONS = 1024; + public static final int MAX_DIMENSIONS = 2048; と一行の変更だが、大きな議論が巻き起こっている。
例えば、
MobileNet v2 は 1280 次元 OpenAPI/ GPT-3 のベクトルは 2048 次元 なので、2048 次元にすればそれらのベクトルを扱うことができるのではという課題提起。 概ねみんな反対ではないが懸念点として
ある程度は既存の値から上げてもいいが、制限は設けるべきで次元削減などで特定の次元数以下にユーザーが処理しておくべき ref Java API が Vector API を提供するようになれば、今の実装はすべて変わるので、難しいね ref CNN ベースのモデルを使っている人は、Lucene の近傍探索が使えないという状況は改善すべき。(もちろんどこまで許容すべきかは議論すべきですが) ref この決断は一方通行(制限を再び少なくしようという流れは永久に来ない)なので、急がずに慎重にベンチマークや正当性の議論などが必要 ref プラグラマブルに自由に設定することはできますか？ それは可能ですが、フォークして自分の Lucene をメンテナンスすることになるので推奨できない ref また、この決定にはデータと評価結果が無いと決定できません。争点は、1048 次元にあわせるために、ユーザー側がなぜ次元削減ができないのかという点もあると思います。 ref 歴史的にユーザーは Luene の制限と常に戦ってきているものなので、今回の制限について文句を言われても正直気にしていません。最も心配なのは、KNN Vector の機能は初期段階であり、制限をゆるくすると柔軟性が低下してしまうことです ref 2023-01-03: この issue が作成されてから、多くの変化が起きました。現在では OpenAI の ChatGPT が世の中を席巻しています。最低でも OpenAI が提供するベクトルの次元数である、1536 次元に変更することはできませんか?</description></item><item><title>初心者だけど Apache Lucene に貢献したい場合におすすめのチケットラベル</title><link>https://shunyaueta.com/posts/2023-03-11-1727/</link><pubDate>Sat, 11 Mar 2023 17:27:09 +0900</pubDate><guid>https://shunyaueta.com/posts/2023-03-11-1727/</guid><description>2023 年の目標で、Apache Lucene へのコントリビューションを掲げましたが、既存の GitHub チケットを探しても初心者向けのチケットタグ good first issue にはチケットが紐付けられていなかったので、メーリングリストに質問したら、Lucene PMC の Michael Sokolov さんがこのタグが初心者にはおすすめだよと返信をいただけたので、ここに残しておきます。
メーリングリストに以下の質問をしたら、
Hello Lucene users.
Last time I checked good first issue in GitHub issues to start a contribution of Lucene. https://github.com/apache/lucene/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22
But currently no issues with this label. I don&amp;rsquo;t know the current operation of this label, but in the future, Is this label will utilized? Because good first issues label issues are a very nice starting point for beginner contributors.</description></item><item><title>Amazonがeコマース検索を Lucene により、どうスケールさせているか at Berlin Buzzwords 2019</title><link>https://shunyaueta.com/posts/2021-11-26/</link><pubDate>Fri, 26 Nov 2021 20:59:21 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-11-26/</guid><description>情報検索・検索技術 Advent Calendar 2021 1 日目の記事です。 早めに書き終えたので、カレンダー登録日の 2021/12/01 よりもはやめですが、記事を公開してしまいます。
Berlin Buzzwords はドイツで毎年開催されている OSS を利用した検索、データ処理、データベースに焦点をあてたカンファレンスです。
検索関係のシステムに携わっている場合、毎年面白い内容が目白押しなのでぜひとも見てほしい。
今回は Berlin Buzzwords 2019 で発表された「Amazon では Lucene をどう活用して e コマース検索をスケールさせているか」の講演動画を社内勉強会で紹介するために視聴したので、そのメモを公開する。
E-Commerce search at scale on Apache Lucene YouTube Web page PDF 自分の所感などを切り分けるため、自分の意見は IMO ではじめた文にして、メモっています。
Overview クエリの p999 latency に対して非常に厳しい制限を行っている IMO このクエリの p999 latency 定義は、Lucene+(おそらく内製で今も開発している、response を返すための Lucene server?)が返す検索のレスポンスを指していると思われる p99.9 latency を SLA として、監視しているのはたしかにとてもシビアな基準だと感じる。 Amazon の query rate はめちゃくちゃピーキー (daily, weekly, yearly) Why Lucene? Lucene は成熟しており、豊富な検索エンジンの機能が揃っている 情熱を持ったコミュニティが存在している Uber, Airbnb, Linkedin 全部 Lucene を使っている maxscore scoring , Weak AND, Lucene 8.</description></item></channel></rss>