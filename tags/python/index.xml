<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Python on hurutoriya</title><link>https://shunyaueta.com/tags/python/</link><description>Recent content in Python on hurutoriya</description><generator>Hugo -- gohugo.io</generator><language>ja</language><copyright>© Shunya Ueta</copyright><lastBuildDate>Sat, 13 Mar 2021 21:43:44 +0900</lastBuildDate><atom:link href="https://shunyaueta.com/tags/python/index.xml" rel="self" type="application/rss+xml"/><item><title>pipenv でローカルパッケージが正常にインストールされないときの対処法</title><link>https://shunyaueta.com/posts/2021-03-13/</link><pubDate>Sat, 13 Mar 2021 21:43:44 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-03-13/</guid><description>TL; DR; pip install pipenv==2018.11.26 をすれば直った!!!!! 実行環境 $pipenv --version pipenv, version 2020.11.15 直面した問題 ./app/ ├── model │ └── setup.py └── serving └── Pipfile のような構成で、modelというローカルパッケージを作成しており、serving 直下のPipfile は、model を読み込んでsetup.p</description></item><item><title>pip 実行時に sys.stderr.write(f"ERROR: {exc} ") とエラーが出てpipを実行できないときの対処方法</title><link>https://shunyaueta.com/posts/2021-02-08/</link><pubDate>Mon, 08 Feb 2021 23:29:12 +0900</pubDate><guid>https://shunyaueta.com/posts/2021-02-08/</guid><description>新しいマシンでpipをセットアップして実行しようとすると &amp;gt;&amp;gt; pip Traceback (most recent call last): File &amp;#34;/usr/local/bin/pip&amp;#34;, line 11, in &amp;lt;module&amp;gt; load_entry_point(&amp;#39;pip==21.0&amp;#39;, &amp;#39;console_scripts&amp;#39;, &amp;#39;pip&amp;#39;)() File &amp;#34;/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/pkg_resources/__init__.py&amp;#34;, line 489, in load_entry_point return get_distribution(dist).load_entry_point(group, name) File &amp;#34;/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/pkg_resources/__init__.py&amp;#34;, line 2843, in load_entry_point return ep.load() File &amp;#34;/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/pkg_resources/__init__.py&amp;#34;, line 2434, in load return self.resolve() File &amp;#34;/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/pkg_resources/__init__.py&amp;#34;, line 2440, in resolve module = __import__(self.module_name, fromlist=[&amp;#39;__name__&amp;#39;], level=0) File &amp;#34;/Library/Python/2.7/site-packages/pip-21.0-py2.7.egg/pip/_internal/cli/main.py&amp;#34;, line 60 sys.stderr.write(f&amp;#34;ERROR: {exc}&amp;#34;) というエラーが出た。 デフォルトのPython の実行ランタイムが2.x</description></item><item><title>Apache beam 入門</title><link>https://shunyaueta.com/posts/2020-12-26/</link><pubDate>Sat, 26 Dec 2020 00:41:30 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-12-26/</guid><description>TensorFlowの勉強をしていたら、Apache beam を前処理に採用していたケースがあり、興味を持ったので深堀りしてみます。 興味が湧いたモチベーションとしては、 データ量が増加しても前処理部分を難なくスケールできそう(前処理部分をスケールさせ</description></item><item><title>pandas を使って特定のディレクトリのCSVファイルをすべて連結して一つのCSVファイルを作成</title><link>https://shunyaueta.com/posts/2020-09-09/</link><pubDate>Wed, 09 Sep 2020 23:49:37 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-09-09/</guid><description>目的 複数の同じフォーマットのCSVファイルが特定のディレクトリに配置されており、そのCSVファイル群を一つのCSVファイルに連結したい 今回は、PythonのPandas とpathlibを使って上記の目的を実現します。 実行環境 In [1]: import pandas as pd In [2]:</description></item><item><title>Python の内包表記とジェネレータ式のメモリ使用量比較</title><link>https://shunyaueta.com/posts/2020-08-23/</link><pubDate>Sun, 23 Aug 2020 21:28:10 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-08-23/</guid><description>リストを構築する際にPythonではリスト内包表記とジェネレータ式の２種類が存在する。 今回、リスト構築時にメモリ使用量にどれだけ差異が発生するのか調査をしてみた。 メモリ使用量の調査には、memory_profilerというパッケージを使用し</description></item><item><title>AOJの「ITP I」40問をpythonで解いた</title><link>https://shunyaueta.com/posts/2020-08-04/</link><pubDate>Tue, 04 Aug 2020 03:38:58 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-08-04/</guid><description>はじめに コーディングの腕をもっと磨きたいなと思ったので、以下の記事を参考に始めてみた https://qiita.com/e869120/items/f1c6f98364d1443148b3 全部で 44 問ありますが、最後の 4 問は競プロとはあまり関係ないので、ITP1_1-A から ITP1_10-D までの 40 問を解くことをお勧めします。 まずは最初におすすめされた、AO</description></item><item><title>How to write the UnitTest with stdin at Pytest</title><link>https://shunyaueta.com/posts/2020-07-25/</link><pubDate>Sat, 25 Jul 2020 03:18:14 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-07-25/</guid><description>If you want to write UnitTest when using stdin in Python. Pytest provide setattr function in monkeypatch
from io import StringIO import sys def divide(): input = sys.stdin.readline return list(input()) def gather(): input = sys.stdin.readline return sum(list(map(int, input().split()))) def test_divide(monkeypatch): monkeypatch.setattr(&amp;#39;sys.stdin&amp;#39;, StringIO(&amp;#39;abc&amp;#39;)) assert divide() == [&amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;c&amp;#39;] def test_gather(monkeypatch): monkeypatch.setattr(&amp;#39;sys.stdin&amp;#39;, StringIO(&amp;#39;1 2 3&amp;#39;)) assert gather() == 6 Reference Monkeypatching/mocking modules and environments I want to use stdin in a pytest test https://gist.github.com/GenevieveBuckley/efd16862de9e2fe7adfd2bf2bef93e02</description></item><item><title>自走プログラマーを読み終えた</title><link>https://shunyaueta.com/posts/2020-05-10/</link><pubDate>Sun, 10 May 2020 17:13:34 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-05-10/</guid><description>自走プログラマーを読み終えた。 読み始めたきっかけとして、自分は機械学習エンジニアとして現在働いているが、できることの幅を広げるために最近はソフトウェアエンジニアとしてのスキルをもっと伸ばしたいと考えている。 自走プログラマーは、Pythonを</description></item><item><title>Pythonの関数のデフォルト引数はmutable(上書きされる)</title><link>https://shunyaueta.com/posts/2020-04-26/</link><pubDate>Sun, 26 Apr 2020 12:04:13 +0900</pubDate><guid>https://shunyaueta.com/posts/2020-04-26/</guid><description>例えば以下のように、デフォルト引数で初期化を行い、文字列を追加する関数があるとする。 def append_to(values=[]): values.append(&amp;#34;Hoge&amp;#34;) return values 期待する振る舞いとしては。 In [14]: def append_to(values=[]): ...: values.append(&amp;#34;Hoge&amp;#34;) ...: return values ...: In [17]: append_to() Out[17]: [&amp;#39;Hoge&amp;#39;] In [18]: append_to() Out[18]: [&amp;#39;Hoge&amp;#39;] と関数呼び出しごとに、values は空のリストに初期化されるので上記のように返っ</description></item><item><title>pandas.read_gbq を使わずに、Google BigQueryから高速にData ETL</title><link>https://shunyaueta.com/posts/2019-10-03/</link><pubDate>Thu, 03 Oct 2019 23:52:54 +0900</pubDate><guid>https://shunyaueta.com/posts/2019-10-03/</guid><description>pandas.read_gbq 便利ですよね。 クレデンシャルファイルを認証画面からコピペすれば Jupyter 上でさっと動き、Google Big Query が実行されてその結果がそのままデータフレームとして扱えます。 Jupyter と Google BQ を連携させたいときはいつも使っています 問題点 そこそこ大きなデータを持ってこ</description></item><item><title>Tensorboard を わずか2行で Jupyter Notebook上で表示</title><link>https://shunyaueta.com/posts/2019-09-25/</link><pubDate>Wed, 25 Sep 2019 23:16:07 +0900</pubDate><guid>https://shunyaueta.com/posts/2019-09-25/</guid><description>Pytorch 1.2 からは公式に Tensorboard がサポートされている Tensorboard とは、学習の状況を可視化できる TensorFlow Family の一種 Jupyte Notebook 上で学習状況を確認したい場合に Tensorboard をそのまま表示して確認できれば楽なので、試してみる sample code: https://pytorch.org/docs/stable/tensorboard.html import torch import torchvision from torch.utils.tensorboard import SummaryWriter from torchvision import datasets, transforms # Writer will output to ./runs/ directory by default writer = SummaryWriter() transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]) trainset = datasets.MNIST(&amp;#39;mnist_train&amp;#39;, train=True,</description></item><item><title>How to concat image using skimage</title><link>https://shunyaueta.com/posts/2019-06-17/</link><pubDate>Mon, 17 Jun 2019 00:07:33 +0900</pubDate><guid>https://shunyaueta.com/posts/2019-06-17/</guid><description>When you need to concat same size image to make figure.
skimage &amp;amp; numpy combination is too powerfull to concat images.
This is sample script.
from skimage import data, io import numpy as np img = skimage.data.astronaut() imgs= [img for i in range(10)] skimage.io.imsave(&amp;#34;sample_h.png&amp;#34;,np.hstack(imgs)) skimage.io.imsave(&amp;#34;sample_v.png&amp;#34;,np.vstack(imgs)) After that you can get below images.
Via Gist: https://gist.github.com/hurutoriya/fedf059ad3db5c67b16d8d5dd6d3df70</description></item><item><title>Jupyter Notebookの差分を明瞭に確認する事ができるpackage : nbdime</title><link>https://shunyaueta.com/posts/2018-01-15/</link><pubDate>Mon, 15 Jan 2018 17:14:54 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-15/</guid><description>Jupyter notebook をご利用の皆さん、朗報です。 例えば、下記の２つの notebook の差分を比較したい際に、 nb_1.ipynb nb_2.ipynb diffコマンドを用いると下記のような結果になってしまいます。 &amp;amp;gt;&amp;amp;gt; diff nb_1.ipynb nb_2.ipynb [master] 14c14 &amp;amp;lt; “image/png”: “iVBORw0KGgoAAAANSUhEUgAAAX8A</description></item><item><title>PythonでGaussian Kernelのアニメーションを作成</title><link>https://shunyaueta.com/posts/2018-01-13/</link><pubDate>Sat, 13 Jan 2018 17:03:43 +0000</pubDate><guid>https://shunyaueta.com/posts/2018-01-13/</guid><description>Python でアニメーションを作成したかったのでメモ Gaussian Kernel GIF Animation 当然ながら、HTML5 の Video は再生されないので GIF に変換した結果が以下。 これで HTML5 で再生される。 **GIF**で表示する方法として %matplotlib nbagg というオプションが存在しているが、Kernel が busy 状態を何度も</description></item><item><title>JupyterNotebookをリモートサーバー上で公開して、どこでも研究開発 &amp; 講義でJupyterhubを利用する</title><link>https://shunyaueta.com/posts/2017-12-22/</link><pubDate>Fri, 22 Dec 2017 17:48:12 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-12-22/</guid><description>JupyterNotebook をリモートサーバー上で公開して、どこでも研究開発 &amp;amp; 講義で Jupyterhub を利用するお話です。 GIF 画像は下記の記事で知ったtqdmというパッケージを使いたくなった衝動の成れの果てです。 私が選ぶ 2015 年の”新しい”Python モジュール トップ 5 IPython データサイエンス</description></item><item><title>Jupyter上でSVGのイラストやアニメーションが作成できるプラグイン egel</title><link>https://shunyaueta.com/posts/2017-11-22/</link><pubDate>Wed, 22 Nov 2017 12:04:30 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-11-22/</guid><description>アイデアは面白い… けど easy drawing ではない Jupyter 使ってると作図も Jupyter 上で完結させたいなぁ~って思うときがあるんですが、スクリプトで作図はけっこう辛いものがあります そのため Jupyter 上でフリースタイルに作図できる機能ないかなと探してたら egal という面白そうな拡張機能が</description></item><item><title>OpenCV 3.3から使えるDNNモジュールを使って物体検出</title><link>https://shunyaueta.com/posts/2017-11-14/</link><pubDate>Tue, 14 Nov 2017 11:36:43 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-11-14/</guid><description>OpenCV と MobileNet を使って物体検出を行った Object Detection with OpenCV dnn modules and MobileNetSSD on Jupyter Notebook Introduction 物体検出を Deep Leaning と OpenCV を用いて行う OpenCV 3.3 からdnnモジュールが正式にリリースされた The main news is that we promoted DNN module from opencv_contrib to the main repository, improved and accelerated it a lot. An external BLAS implementation is not needed anymore. For GPU there is experimental DNN acceleration using Halide (http://halide-lang.org_). The detailed information about the module can be found in our wiki: Deep Learning in OpenCV.</description></item><item><title>Djangoで顔認識の結果をJSONで返す最小構成のAPIサーバーを作った</title><link>https://shunyaueta.com/posts/2017-11-13/</link><pubDate>Mon, 13 Nov 2017 17:22:38 +0000</pubDate><guid>https://shunyaueta.com/posts/2017-11-13/</guid><description>DEMO github でコードを公開してます。 hurutoriya/face_detector_api Django の勉強は、基本的なイントロダクションとしてオフィシャルサイトのドキュメントが充実しているのでオススメです 。 pyimagesearch の Blog 記事で最小限の構成で顔検出を行う API サーバーを作る記事があり、今回はそれを基本に作成した。 以下所感</description></item></channel></rss>